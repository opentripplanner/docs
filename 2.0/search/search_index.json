{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"OpenTripPlanner 2 OpenTripPlanner (OTP) is an open source multi-modal trip planner, focusing on travel by scheduled public transportation in combination with bicycling, walking, and mobility services including bike share and ride hailing. Its server component runs on any platform with a Java virtual machine (including Linux, Mac, and Windows). It exposes REST and GraphQL APIs that can be accessed by various clients including open source Javascript components and native mobile applications. It builds its representation of the transportation network from open data in open standard file formats (primarily GTFS and OpenStreetMap). It applies real-time updates and alerts with immediate visibility to clients, finding itineraries that account for disruptions and service changes. OTP is released under the LGPL license . As of 2020, the codebase has been in active development for over ten years, and is relied upon by transportation authorities and travel planning applications in deployments around the world. You are currently reading the documentation for OpenTripPlanner 2 , the second major version of OTP. Versions of this documentation Several versions of this documentation are built and published automatically for different branches of OTP. Each of these has a different stable URL, and you may switch between these versions using the selector in the lower right of the published documentation. Latest - Latest stable release from master branch v2.0.0 - Most recent release 2.0 v1.5.0 - Stable 1.x release dev-1.x - OTP 1 active development dev-2.x - OTP 2 active development Audience The end users of OTP are the millions of people who rely on it to help plan their daily travel, often without even knowing they are using OTP. As an infrastructure component, installation and configuration of OTP tends to be somewhat technical and essentially invisible to those end users. This documentation is indended for people who wish to perform such deployments of OTP without necessarily diving into the internal details of the software. For members of the OTP community interested in software development, additional documentation detailing algorithms, data structures etc. is available as markdown files within the source code packages. It can be read in your IDE or when browsing the source tree on Github. For example, https://github.com/opentripplanner/OpenTripPlanner/blob/dev-2.x/src/main/java/org/opentripplanner/transit/raptor/README.md . Quick Start We encourage you to read the introductory sections of this documentation to familiarize yourself with OpenTripPlanner use cases and configuration. But if you want to get started right away running your own OTP instance, the best place to start is the Basic Tutorial page. Contact Info Send questions and comments to the user mailing list . Discuss internal development details on the dev mailing list . File bug reports via the Github issue tracker . Note that the issue tracker is not intended for support questions or discussions. Please post them to one of the mailing lists instead. Financial and In-Kind Support OpenTripPlanner is a member project of Software Freedom Conservancy, a 501(c)(3) organization incorporated in New York, and donations made to it are fully tax-deductible to the extent permitted by law. Donations can be made by credit card, wire transfer or paper check. Please contact accounting@sfconservancy.org for instructions. OTP development is primarily carried out by full-time software engineers employed by transportation authorities and consultancies. Even with funding, it can be difficult to engage staff who have the specialized skill set required. Therefore, one of the best ways to support OTP is to allocate software development staff at your organization with transportation domain knowledge to participate in weekly development meetings and contribute to this effort. This also builds connections between organizations favoring open source collaboration.","title":"Home"},{"location":"#opentripplanner-2","text":"OpenTripPlanner (OTP) is an open source multi-modal trip planner, focusing on travel by scheduled public transportation in combination with bicycling, walking, and mobility services including bike share and ride hailing. Its server component runs on any platform with a Java virtual machine (including Linux, Mac, and Windows). It exposes REST and GraphQL APIs that can be accessed by various clients including open source Javascript components and native mobile applications. It builds its representation of the transportation network from open data in open standard file formats (primarily GTFS and OpenStreetMap). It applies real-time updates and alerts with immediate visibility to clients, finding itineraries that account for disruptions and service changes. OTP is released under the LGPL license . As of 2020, the codebase has been in active development for over ten years, and is relied upon by transportation authorities and travel planning applications in deployments around the world. You are currently reading the documentation for OpenTripPlanner 2 , the second major version of OTP.","title":"OpenTripPlanner 2"},{"location":"#versions-of-this-documentation","text":"Several versions of this documentation are built and published automatically for different branches of OTP. Each of these has a different stable URL, and you may switch between these versions using the selector in the lower right of the published documentation. Latest - Latest stable release from master branch v2.0.0 - Most recent release 2.0 v1.5.0 - Stable 1.x release dev-1.x - OTP 1 active development dev-2.x - OTP 2 active development","title":"Versions of this documentation"},{"location":"#audience","text":"The end users of OTP are the millions of people who rely on it to help plan their daily travel, often without even knowing they are using OTP. As an infrastructure component, installation and configuration of OTP tends to be somewhat technical and essentially invisible to those end users. This documentation is indended for people who wish to perform such deployments of OTP without necessarily diving into the internal details of the software. For members of the OTP community interested in software development, additional documentation detailing algorithms, data structures etc. is available as markdown files within the source code packages. It can be read in your IDE or when browsing the source tree on Github. For example, https://github.com/opentripplanner/OpenTripPlanner/blob/dev-2.x/src/main/java/org/opentripplanner/transit/raptor/README.md .","title":"Audience"},{"location":"#quick-start","text":"We encourage you to read the introductory sections of this documentation to familiarize yourself with OpenTripPlanner use cases and configuration. But if you want to get started right away running your own OTP instance, the best place to start is the Basic Tutorial page.","title":"Quick Start"},{"location":"#contact-info","text":"Send questions and comments to the user mailing list . Discuss internal development details on the dev mailing list . File bug reports via the Github issue tracker . Note that the issue tracker is not intended for support questions or discussions. Please post them to one of the mailing lists instead.","title":"Contact Info"},{"location":"#financial-and-in-kind-support","text":"OpenTripPlanner is a member project of Software Freedom Conservancy, a 501(c)(3) organization incorporated in New York, and donations made to it are fully tax-deductible to the extent permitted by law. Donations can be made by credit card, wire transfer or paper check. Please contact accounting@sfconservancy.org for instructions. OTP development is primarily carried out by full-time software engineers employed by transportation authorities and consultancies. Even with funding, it can be difficult to engage staff who have the specialized skill set required. Therefore, one of the best ways to support OTP is to allocate software development staff at your organization with transportation domain knowledge to participate in weekly development meetings and contribute to this effort. This also builds connections between organizations favoring open source collaboration.","title":"Financial and In-Kind Support"},{"location":"Basic-Tutorial/","text":"OpenTripPlanner 2 Basic Tutorial This page should allow you to set up and test your own OTP2 server. If all goes well it should only take a few minutes! Note that this covers the OTP2 release candidate undergoing final testing, not the existing OTP 1.x release versions. If you do not wish to try out the 2.0 release candidate, please use the documentation selector in the lower right to choose the 1.x version. Get Java As a Java program, OTP must be run within a Java virtual machine (JVM), which is provided as part of the Java runtime (JRE) or Java development kit (JDK). OTP2 is compatible with Java 11 or later. We recommend running on Java 11 rather than a later version, as it is a long-term support release. Run java -version to check that you have version 11 or newer of the JVM installed. If you do not, you will need to install a recent OpenJDK or Oracle Java package for your operating system. Get OTP OpenTripPlanner is written in Java and distributed as a single runnable JAR file. This is a \"shaded\" JAR containing all other libraries needed for OTP to work. The OTP2 release candidate is available from the Maven Central repository. You will be able to go to the OTP directory at Maven Central , navigate to the directory for the release candidate , and download the file whose name ends with shaded.jar . You may also want to get your own copy of the OTP source code and build a bleeding edge development JAR from scratch , especially if you plan to do some development yourself. Currently the OTP2 release candidate is in feature freeze, meaning we are not adding any new features, only stabilizing the existing ones for release. So if you want to test and fix existing functionality for the release, check out the branch dev-2.x . Get some data GTFS for Transit Schedules and Stops First you'll need GTFS data to build a transit network. There's an excellent description of the GTFS format here . Transport agencies throughout the world provide GTFS schedules to the public. Transitland has a registry of feeds and TransitFeeds also provides an extensive catalog. The best option is often to simply fetch the data directly from a transit operator or agency. If you know of a feed you want to work with, download it and put it in an empty directory you have created for your OTP instance such as /home/username/otp on Linux, /Users/username/otp on OSX, or C:\\Users\\username\\otp on Windows. The GTFS file's name must end in .zip for OTP to detect it. We often use the convention of ending GTFS file names with .gtfs.zip since technically a GTFS feed is just a ZIP file containing a specific set of files. If you don't have a particular feed in mind, the one for Portland, Oregon's TriMet agency is a good option. It is available at this URL . This is a moderate-sized input of good quality (TriMet initiated OTP development and helped develop the GTFS format). On Linux, this could be done on the command line as follows: $ cd /home/username $ mkdir otp $ cd otp $ wget \"http://developer.trimet.org/schedule/gtfs.zip\" -O trimet.gtfs.zip OSM for Streets You'll also need OpenStreetMap data to build a road network for walking, cycling, and driving. OpenStreetMap is a global collaborative map database that rivals or surpasses the quality of commercial maps in many locations. Several services extract smaller geographic regions from this database. Interline Technologies maintains a collection of extracts updated daily for urban areas around the world . Geofabrik provides extracts for larger areas like countries or states, from which you can prepare your own smaller bounding-box extracts using Osmosis , osmconvert , or (our favorite) Osmium-Tool . OSM data can be delivered as XML or in the more compact binary PBF format. OpenTripPlanner consumes only PBF because it's smaller and more efficient. Download OSM PBF data for the same geographic region as your GTFS feed, and place this PBF file in the same directory you created for the OSM data. If you are using the TriMet GTFS feed, you could download the Geofabrik extract for the US state of Oregon , then further trim that to just the TriMet service area using the bounding box switch of one of the above tools. On Linux or MacOS you could do that as follows: $ cd /home/username $ wget http://download.geofabrik.de/north-america/us/oregon-latest.osm.pbf $ osmconvert oregon-latest.osm.pbf -b=-123.043,45.246,-122.276,45.652 --complete-ways -o=portland.pbf $ mv portland.pbf otp We find this tool useful for determining the geographic coordinates of bounding boxes. The CSV option in that tool produces exactly the format expected by the osmconvert -b switch. The --complete-ways switch is important to handle roads that cross outside your bounding box. If you have extracted a smaller PBF file from a larger region, be sure to put only your extract (not the original larger file) in the directory with your GTFS data. Otherwise OTP will try to load both the original file and the extract in a later step. See the page on preparing OSM data for additional information and example commands for cropping and filtering OSM data. Starting OTP A typical command to start OTP looks like java -Xmx1G -jar otp.shaded.jar <options> . The -Xmx parameter sets the limit on how much memory OTP is allowed to consume. GTFS and OSM data sets are often very large, and OTP is relatively memory-hungry. You will need at least 1GB of memory when working with the Portland TriMet data set, and several gigabytes for larger inputs. If you have sufficient memory in your computer, set this to a couple of gigabytes (e.g. -Xmx2G ). Java uses a garbage collection approach to memory management, which requires some \"breathing room\" to efficiently operate. Without sufficient free memory OTP can grind to a halt. VisualVM is a good way to inspect Java memory usage, especially with the VisualGC plugin . Java 11 has tighter security restrictions than previous versions, so when running OTP under Java 11 you will see warnings like this: WARNING: An illegal reflective access operation has occurred WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil These warnings are expected to remain for a while, until all libraries OTP2 depends on have fully migrated to Java 11 and we have upgraded them all. Building Graphs There are two main phases to preparing and deploying an OTP server. The first is to analyze the GTFS, OSM and any other inputs (such as elevation data) and build a representation of the transportation network. Following mathematical terminology we call this a 'graph' , and refer to this phase as \"graph building\". The second phase is to start a server that provides trip planning and other API services for this graph. It is possible to save the graph to a file on disk after the first phase, then load the graph from the file in the second phase. This allows restarting the server or starting multiple instances of the server without repeating the often time-consuming process of building the graph. It is also possible to split the graph building process into separate OSM and GTFS stages for similar reasons: to allow reusing results from slow processes, such as applying elevation data to streets. These different options are controlled with command line switches, and will be described in more detail below and in other tutorials. Simple One-step Server The simplest way to use OTP is to build a graph in a single step and start a server immediately, without saving it to disk. The command to do so is: $ java -Xmx2G -jar otp-2.0.0-rc1-shaded.jar --build --serve /home/username/otp where /home/username/otp should be the directory where you put your configuration and input files. If you're using the Portland input data, the graph build operation should take about one minute to complete, and then you'll see a Grizzly server running message. At this point you have an OpenTripPlanner server running locally and can open http://localhost:8080/ in a web browser. You should be presented with a Javascript client application that will interact with your local OpenTripPlanner instance. This map-based user interface is in fact sending HTTP GET requests to the OTP server running on your local machine. It can be informative to watch the HTTP requests and responses being generated using the developer tools in your web browser. OTP's built-in web server will run by default on ports 8080 and 8081 for HTTP and HTTPS respectively. If by any chance some other software is already using one or both of those port numbers, you can specify different port numbers with switches like --port 8801 --securePort 8802 . Saving a Graph If you want speed up the process of repeatedly starting up a server with the same graph, you can build a graph from street and transit data then save it to a file using the --build and --save command line parameters together. If for example your current working directory ( . ) contains the input files and the OTP JAR file, you can use this command: $ java -Xmx2G -jar otp-2.0.0-rc1-shaded.jar --build --save . This will produce a file called graph.obj in the same directory as the inputs. The server can then be started later using the --load parameter, and will read this file instead of building the graph from scratch: $ java -Xmx2G -jar otp-2.0.0-rc1-shaded.jar --load . Another reason to perform these two phases separately is that the building process loads the entire GTFS and OSM data sets into memory, so can require significantly more memory than just running a server. Accordingly, you may want to perform the build on one machine (e.g. a throw-away cloud instance with more memory or compute capacity), then copy the resulting graph file to one or more smaller machines to serve the API. Layering GTFS onto OSM Building the street graph (especially with elevation data) can take a long time. It is common for transit data to change more frequently than street data, so it can be convenient to build the street graph once, and then layer transit data on top of the streets to make the final graph. Again assuming the input files and OTP JAR file are in the current working directory, you can build a street graph with OSM and elevation data only (ignoring transit input files) with this command: $ java -Xmx2G -jar otp-2.0.0-rc1-shaded.jar --buildStreet . Then, to build a graph layering transit data on top of the saved street graph (built using the previous command): $ java -Xmx2G -jar otp-2.0.0-rc1-shaded.jar --loadStreet --save . Finally, the server can be started using the --load parameter: $ java -Xmx2G -jar otp-2.0.0-rc1-shaded.jar --load . Command Line Switches The flow diagram below summarizes all the command line switches used in the above examples, and how they control which actions are taken when OTP starts up. You must use at least one of the required parameters: --load , --loadStreet , --build , --buildStreet . A required parameter may imply other parameters when the flow allows for no other choice. For example, --load implies --serve , so --serve is not necessary and has no additional effect when used together with --load . You can run the OTP .jar file with the --help option for a full list of command line parameters.","title":"Basic Tutorial"},{"location":"Basic-Tutorial/#opentripplanner-2-basic-tutorial","text":"This page should allow you to set up and test your own OTP2 server. If all goes well it should only take a few minutes! Note that this covers the OTP2 release candidate undergoing final testing, not the existing OTP 1.x release versions. If you do not wish to try out the 2.0 release candidate, please use the documentation selector in the lower right to choose the 1.x version.","title":"OpenTripPlanner 2 Basic Tutorial"},{"location":"Basic-Tutorial/#get-java","text":"As a Java program, OTP must be run within a Java virtual machine (JVM), which is provided as part of the Java runtime (JRE) or Java development kit (JDK). OTP2 is compatible with Java 11 or later. We recommend running on Java 11 rather than a later version, as it is a long-term support release. Run java -version to check that you have version 11 or newer of the JVM installed. If you do not, you will need to install a recent OpenJDK or Oracle Java package for your operating system.","title":"Get Java"},{"location":"Basic-Tutorial/#get-otp","text":"OpenTripPlanner is written in Java and distributed as a single runnable JAR file. This is a \"shaded\" JAR containing all other libraries needed for OTP to work. The OTP2 release candidate is available from the Maven Central repository. You will be able to go to the OTP directory at Maven Central , navigate to the directory for the release candidate , and download the file whose name ends with shaded.jar . You may also want to get your own copy of the OTP source code and build a bleeding edge development JAR from scratch , especially if you plan to do some development yourself. Currently the OTP2 release candidate is in feature freeze, meaning we are not adding any new features, only stabilizing the existing ones for release. So if you want to test and fix existing functionality for the release, check out the branch dev-2.x .","title":"Get OTP"},{"location":"Basic-Tutorial/#get-some-data","text":"","title":"Get some data"},{"location":"Basic-Tutorial/#gtfs-for-transit-schedules-and-stops","text":"First you'll need GTFS data to build a transit network. There's an excellent description of the GTFS format here . Transport agencies throughout the world provide GTFS schedules to the public. Transitland has a registry of feeds and TransitFeeds also provides an extensive catalog. The best option is often to simply fetch the data directly from a transit operator or agency. If you know of a feed you want to work with, download it and put it in an empty directory you have created for your OTP instance such as /home/username/otp on Linux, /Users/username/otp on OSX, or C:\\Users\\username\\otp on Windows. The GTFS file's name must end in .zip for OTP to detect it. We often use the convention of ending GTFS file names with .gtfs.zip since technically a GTFS feed is just a ZIP file containing a specific set of files. If you don't have a particular feed in mind, the one for Portland, Oregon's TriMet agency is a good option. It is available at this URL . This is a moderate-sized input of good quality (TriMet initiated OTP development and helped develop the GTFS format). On Linux, this could be done on the command line as follows: $ cd /home/username $ mkdir otp $ cd otp $ wget \"http://developer.trimet.org/schedule/gtfs.zip\" -O trimet.gtfs.zip","title":"GTFS for Transit Schedules and Stops"},{"location":"Basic-Tutorial/#osm-for-streets","text":"You'll also need OpenStreetMap data to build a road network for walking, cycling, and driving. OpenStreetMap is a global collaborative map database that rivals or surpasses the quality of commercial maps in many locations. Several services extract smaller geographic regions from this database. Interline Technologies maintains a collection of extracts updated daily for urban areas around the world . Geofabrik provides extracts for larger areas like countries or states, from which you can prepare your own smaller bounding-box extracts using Osmosis , osmconvert , or (our favorite) Osmium-Tool . OSM data can be delivered as XML or in the more compact binary PBF format. OpenTripPlanner consumes only PBF because it's smaller and more efficient. Download OSM PBF data for the same geographic region as your GTFS feed, and place this PBF file in the same directory you created for the OSM data. If you are using the TriMet GTFS feed, you could download the Geofabrik extract for the US state of Oregon , then further trim that to just the TriMet service area using the bounding box switch of one of the above tools. On Linux or MacOS you could do that as follows: $ cd /home/username $ wget http://download.geofabrik.de/north-america/us/oregon-latest.osm.pbf $ osmconvert oregon-latest.osm.pbf -b=-123.043,45.246,-122.276,45.652 --complete-ways -o=portland.pbf $ mv portland.pbf otp We find this tool useful for determining the geographic coordinates of bounding boxes. The CSV option in that tool produces exactly the format expected by the osmconvert -b switch. The --complete-ways switch is important to handle roads that cross outside your bounding box. If you have extracted a smaller PBF file from a larger region, be sure to put only your extract (not the original larger file) in the directory with your GTFS data. Otherwise OTP will try to load both the original file and the extract in a later step. See the page on preparing OSM data for additional information and example commands for cropping and filtering OSM data.","title":"OSM for Streets"},{"location":"Basic-Tutorial/#starting-otp","text":"A typical command to start OTP looks like java -Xmx1G -jar otp.shaded.jar <options> . The -Xmx parameter sets the limit on how much memory OTP is allowed to consume. GTFS and OSM data sets are often very large, and OTP is relatively memory-hungry. You will need at least 1GB of memory when working with the Portland TriMet data set, and several gigabytes for larger inputs. If you have sufficient memory in your computer, set this to a couple of gigabytes (e.g. -Xmx2G ). Java uses a garbage collection approach to memory management, which requires some \"breathing room\" to efficiently operate. Without sufficient free memory OTP can grind to a halt. VisualVM is a good way to inspect Java memory usage, especially with the VisualGC plugin . Java 11 has tighter security restrictions than previous versions, so when running OTP under Java 11 you will see warnings like this: WARNING: An illegal reflective access operation has occurred WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil These warnings are expected to remain for a while, until all libraries OTP2 depends on have fully migrated to Java 11 and we have upgraded them all.","title":"Starting OTP"},{"location":"Basic-Tutorial/#building-graphs","text":"There are two main phases to preparing and deploying an OTP server. The first is to analyze the GTFS, OSM and any other inputs (such as elevation data) and build a representation of the transportation network. Following mathematical terminology we call this a 'graph' , and refer to this phase as \"graph building\". The second phase is to start a server that provides trip planning and other API services for this graph. It is possible to save the graph to a file on disk after the first phase, then load the graph from the file in the second phase. This allows restarting the server or starting multiple instances of the server without repeating the often time-consuming process of building the graph. It is also possible to split the graph building process into separate OSM and GTFS stages for similar reasons: to allow reusing results from slow processes, such as applying elevation data to streets. These different options are controlled with command line switches, and will be described in more detail below and in other tutorials.","title":"Building Graphs"},{"location":"Basic-Tutorial/#simple-one-step-server","text":"The simplest way to use OTP is to build a graph in a single step and start a server immediately, without saving it to disk. The command to do so is: $ java -Xmx2G -jar otp-2.0.0-rc1-shaded.jar --build --serve /home/username/otp where /home/username/otp should be the directory where you put your configuration and input files. If you're using the Portland input data, the graph build operation should take about one minute to complete, and then you'll see a Grizzly server running message. At this point you have an OpenTripPlanner server running locally and can open http://localhost:8080/ in a web browser. You should be presented with a Javascript client application that will interact with your local OpenTripPlanner instance. This map-based user interface is in fact sending HTTP GET requests to the OTP server running on your local machine. It can be informative to watch the HTTP requests and responses being generated using the developer tools in your web browser. OTP's built-in web server will run by default on ports 8080 and 8081 for HTTP and HTTPS respectively. If by any chance some other software is already using one or both of those port numbers, you can specify different port numbers with switches like --port 8801 --securePort 8802 .","title":"Simple One-step Server"},{"location":"Basic-Tutorial/#saving-a-graph","text":"If you want speed up the process of repeatedly starting up a server with the same graph, you can build a graph from street and transit data then save it to a file using the --build and --save command line parameters together. If for example your current working directory ( . ) contains the input files and the OTP JAR file, you can use this command: $ java -Xmx2G -jar otp-2.0.0-rc1-shaded.jar --build --save . This will produce a file called graph.obj in the same directory as the inputs. The server can then be started later using the --load parameter, and will read this file instead of building the graph from scratch: $ java -Xmx2G -jar otp-2.0.0-rc1-shaded.jar --load . Another reason to perform these two phases separately is that the building process loads the entire GTFS and OSM data sets into memory, so can require significantly more memory than just running a server. Accordingly, you may want to perform the build on one machine (e.g. a throw-away cloud instance with more memory or compute capacity), then copy the resulting graph file to one or more smaller machines to serve the API.","title":"Saving a Graph"},{"location":"Basic-Tutorial/#layering-gtfs-onto-osm","text":"Building the street graph (especially with elevation data) can take a long time. It is common for transit data to change more frequently than street data, so it can be convenient to build the street graph once, and then layer transit data on top of the streets to make the final graph. Again assuming the input files and OTP JAR file are in the current working directory, you can build a street graph with OSM and elevation data only (ignoring transit input files) with this command: $ java -Xmx2G -jar otp-2.0.0-rc1-shaded.jar --buildStreet . Then, to build a graph layering transit data on top of the saved street graph (built using the previous command): $ java -Xmx2G -jar otp-2.0.0-rc1-shaded.jar --loadStreet --save . Finally, the server can be started using the --load parameter: $ java -Xmx2G -jar otp-2.0.0-rc1-shaded.jar --load .","title":"Layering GTFS onto OSM"},{"location":"Basic-Tutorial/#command-line-switches","text":"The flow diagram below summarizes all the command line switches used in the above examples, and how they control which actions are taken when OTP starts up. You must use at least one of the required parameters: --load , --loadStreet , --build , --buildStreet . A required parameter may imply other parameters when the flow allows for no other choice. For example, --load implies --serve , so --serve is not necessary and has no additional effect when used together with --load . You can run the OTP .jar file with the --help option for a full list of command line parameters.","title":"Command Line Switches"},{"location":"Bibliography/","text":"Routing Bibliography This is a list of articles, dissertations, and books that have inspired and informed both the existing OTP routing engine and some ongoing experiments. OTP1 uses a single time-dependent (as opposed to time-expanded) graph that contains both street and transit networks. Walk-only and bicycle-only trips are generally planned using the A-star algorithm with a Euclidean heuristic. Walk+Transit or Bike+Transit trips are planned using A-star with the Tung-Chew heuristic (i.e. a graph grown backward from the destination providing a lower bound on aggregate weight) for queue ordering. For speed reasons we are performing single-variable generalized cost optimization, which is not ideal. We should be performing Pareto optimization on at least two variables (generalized cost and time). OTP2 splits the search into three segments: access from the origin to transit stops, egress from transit stops to the destination, and transit service connecting the two. For the transit segment, OTP2 uses the Multi-criteria Range Raptor algorithm. For the access and egress searches it uses the same approach as OTP1. Both splitting the search into three parts and use of a table-scanning algorithm like Raptor improve OTP2's performance significantly while increasing result quality by producing true Pareto-optimal sets of results. Algorithms used in OTP2 but not OTP1 Delling, Pajor, Werneck. Round-Based Public Transit Routing (2012) This is a tabular approach to routing in public transit networks that does not use an (explicit) graph. It is simpler and can outperform classic graph algorithms. http://research.microsoft.com/pubs/156567/raptor_alenex.pdf Delling, Dibbelt, and Pajor. Fast and Exact Public Transit Routing with Restricted Pareto Sets (2019) Describes the heuristic used in OTP2 to eliminate options early when they are known to become non-optimal before they reach the destination. https://epubs.siam.org/doi/pdf/10.1137/1.9781611975499.5 Techniques used in or influencing OTP1 and OTP2 General Background Bast, Hannah. Car or public transport -- two worlds. (2009) Explains how car routing is different from schedule-based public transport routing. http://www.mpi-inf.mpg.de/~bast/papers/car_or_public_transport.pdf Delling, Daniel. Engineering and augmenting route planning algorithms. (2009, dissertation) Overview, including time-dependent and Pareto shortest paths. http://i11www.ira.uka.de/extra/publications/d-earpa-09.pdf Delling, Sanders, Schultes, and Wagner. Engineering Route-Planning Algorithms. (2009) Overview. http://i11www.ira.uka.de/extra/publications/dssw-erpa-09.pdf Path Search Speedup Techniques Delling and Wagner. Time-Dependent Route Planning. (2009) Overview. http://i11www.iti.uni-karlsruhe.de/extra/publications/dw-tdrp-09.pdf Delling and Wagner. Landmark-Based Routing in Dynamic Graphs. (2008) http://i11www.ira.uka.de/extra/publications/dw-lbrdg-07.pdf Bauer, Delling, Sanders, Schultes, and Wagner. Combining Hierarchical and Goal-Directed Speed-Up Techniques for Dijkstra\u2019s Algorithm. (2008) http://algo2.iti.kit.edu/download/bdsssw-chgds-10.pdf Bauer and Delling. SHARC: Fast and Robust Unidirectional Routing. (2009) SH ortcuts + ARC flags. Can be combined with ALT. http://www.siam.org/proceedings/alenex/2008/alx08_02bauerr.pdf Delling, Daniel. Time-Dependent SHARC-Routing. (2008) http://i11www.iti.uni-karlsruhe.de/extra/publications/d-tdsr-09.pdf Goldberg, Kaplan, and Werneck. Reach for A\u2217: Efficient Point-to-Point Shortest Path Algorithms. (2005) http://avglab.com/andrew/pub/msr-tr-2005-132.pdf Multi-objective Pareto Shortest Paths Das and Dennis. Drawbacks of minimizing weighted sums of objectives for Pareto set generation in multicriteria optimization problems. (1997) M\u00fcller-Hannemann and Schnee. Finding All Attractive Train Connections by Multi-criteria Pareto Search. (2007) Deutsche Bahn information system. Does not account for on-street travel. Mandow & P\u00e9rez de la Cruz. A New Approach to Multiobjective A Search. (2005) NAMOA http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.8780&rep=rep1&type=pdf Mandow & P\u00e9rez de la Cruz. Multiobjective A search with consistent heuristics. (2008) NAMOA Machuca, Mandow and P\u00e9rez de la Cruz. Evaluation of Heuristic Functions for Bicriterion Shortest Path Problems. (2009) Evaluates heuristics from Tung & Chew (1992) versus lexicographical ordering of priority queue. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.160.4715&rep=rep1&type=pdf Perny and Spanjaard. Near Admissible Algorithms for Multiobjective Search. (2009) Discusses relaxed Pareto dominance (Epsilon-dominance) and its use in Multi-objective A*. This a scheme for approximating the entire pareto-optimal solution set that allows time and space complexity polynomial in the number of nodes. http://www-desir.lip6.fr/publications/pub_1052_1_ECAI08.pdf Tung and Chew. A multicriteria Pareto-optimal path algorithm. (1992) Delling and Wagner. Pareto Paths with SHARC. (2009) http://i11www.iti.uni-karlsruhe.de/extra/publications/dw-pps-09.pdf Resource-constrained Routing Dumitrescu & Boland. Improved Preprocessing, Labeling and Scaling Algorithms for the Weight-Constrained Shortest Path Problem. (2003) Comparison of scaling and label-setting methods. Ziegelmann, Mark. Constrained Shortest Paths and Related Problems. (2001, dissertation) http://scidok.sulb.uni-saarland.de/volltexte/2004/251/pdf/MarkZiegelmann_ProfDrKurtMehlhorn.pdf Contraction and Transfer Patterns Geisberger, Robert. Contraction Hierarchies: Faster and Simpler Hierarchical Routing in Road Networks. (2008, dissertation) http://algo2.iti.kit.edu/documents/routeplanning/geisberger_dipl.pdf Geisberger, Robert. Contraction of Timetable Networks with Realistic Tranfers (2010) Introduces the \"Station Model Graph\". http://algo2.iti.kit.edu/download/time_table_ch.pdf Bast, Carlsson, Eigenwillig, Geisberger Harrelson, Raychev, and Viger. Fast Routing in Very Large Public Transportation Networks Using Transfer Patterns. (2010) http://ad.informatik.uni-freiburg.de/files/transferpatterns.pdf/at_download/file Timetable-based routing Schulz, Frank. Timetable Information and Shortest Paths. (2005, dissertation) Excellent reference. http://d-nb.info/1001586921/34 ALT and Metric Embeddings Goldberg and Werneck. Computing Point-to-Point Shortest Paths from External Memory. (2005) Introduced the ALT algorithm. http://www.cs.princeton.edu/courses/archive/spring06/cos423/Handouts/GW05.pdf Linial, London, and Rabinovich. The Geometry of Graphs and Some of its Algorithmic Applications. (1995) http://pdf.aminer.org/000/798/423/the_geometry_of_graphs_and_some_of_its_algorithmic_applications.pdf Hjaltason and Samet. Contractive Embedding Methods for Similarity Searching in Metric Spaces. (2000) http://www.cs.umd.edu/~hjs/pubs/metricpruning.pdf Potamias, Bonchi, Castillo, and Gionis. Fast Shortest Path Distance Estimation in Large Networks. (2009) Briefly discusses the connection between landmark routing and more general research on metric embeddings. http://dcommon.bu.edu/xmlui/bitstream/handle/2144/1727/2009-004-shortest-distance-estimation.pdf Calibration and Implementation Details Wardman, Mark. Public Transport Values of Time. (2004) http://eprints.whiterose.ac.uk/2062/1/ITS37_WP564_uploadable.pdf A.M. El-Geneidy, K.J. Krizek, M.J. Iacono. Predicting bicycle travel speeds along different facilities using GPS data: a proof of concept model. (2007) Proceedings of the 86th Annual Meeting of the Transportation Research Board, Compendium of Papers, TRB, Washington, D.C., USA (CD-ROM) Chen, Chowdhury, Roche, Ramachandran, Tong. Priority Queues and Dijkstra\u2019s Algorithm. Summary: Despite better theoretical complexity for Fibonacci heaps, it is often as good or better to use a binary heap as a priority queue when doing path searches. http://www.cs.utexas.edu/users/shaikat/papers/TR-07-54.pdf Post-Dijkstra Public Transit Routing Dibbelt, Pajor, Strasser, Wagner. Intriguingly Simple and Fast Transit Routing (2013). Introduces the Connection Scan Algorithm (CSA). http://www.ecompass-project.eu/sites/default/files/ECOMPASS-TR-021.pdf Delling, Katz, and Pajor. Parallel computation of best connections in public transportation networks (2012). \"In this work, we present a novel algorithm for the one-to-all profile-search problem in public transportation networks. It answers the question for all fastest connections between a given station S and any other station at any time of the day in a single query... two interesting questions arise for time-dependent route planning: compute the best connection for a given departure time and the computation of all best connections during a given time interval (e. g., a whole day). The former is called a time-query, while the latter is called a pro\ufb01le-query.\" http://www.ecompass-project.eu/sites/default/files/ECOMPASS-TR-021.pdf","title":"Bibliography"},{"location":"Bibliography/#routing-bibliography","text":"This is a list of articles, dissertations, and books that have inspired and informed both the existing OTP routing engine and some ongoing experiments. OTP1 uses a single time-dependent (as opposed to time-expanded) graph that contains both street and transit networks. Walk-only and bicycle-only trips are generally planned using the A-star algorithm with a Euclidean heuristic. Walk+Transit or Bike+Transit trips are planned using A-star with the Tung-Chew heuristic (i.e. a graph grown backward from the destination providing a lower bound on aggregate weight) for queue ordering. For speed reasons we are performing single-variable generalized cost optimization, which is not ideal. We should be performing Pareto optimization on at least two variables (generalized cost and time). OTP2 splits the search into three segments: access from the origin to transit stops, egress from transit stops to the destination, and transit service connecting the two. For the transit segment, OTP2 uses the Multi-criteria Range Raptor algorithm. For the access and egress searches it uses the same approach as OTP1. Both splitting the search into three parts and use of a table-scanning algorithm like Raptor improve OTP2's performance significantly while increasing result quality by producing true Pareto-optimal sets of results.","title":"Routing Bibliography"},{"location":"Bibliography/#algorithms-used-in-otp2-but-not-otp1","text":"Delling, Pajor, Werneck. Round-Based Public Transit Routing (2012) This is a tabular approach to routing in public transit networks that does not use an (explicit) graph. It is simpler and can outperform classic graph algorithms. http://research.microsoft.com/pubs/156567/raptor_alenex.pdf Delling, Dibbelt, and Pajor. Fast and Exact Public Transit Routing with Restricted Pareto Sets (2019) Describes the heuristic used in OTP2 to eliminate options early when they are known to become non-optimal before they reach the destination. https://epubs.siam.org/doi/pdf/10.1137/1.9781611975499.5","title":"Algorithms used in OTP2 but not OTP1"},{"location":"Bibliography/#techniques-used-in-or-influencing-otp1-and-otp2","text":"","title":"Techniques used in or influencing OTP1 and OTP2"},{"location":"Bibliography/#general-background","text":"Bast, Hannah. Car or public transport -- two worlds. (2009) Explains how car routing is different from schedule-based public transport routing. http://www.mpi-inf.mpg.de/~bast/papers/car_or_public_transport.pdf Delling, Daniel. Engineering and augmenting route planning algorithms. (2009, dissertation) Overview, including time-dependent and Pareto shortest paths. http://i11www.ira.uka.de/extra/publications/d-earpa-09.pdf Delling, Sanders, Schultes, and Wagner. Engineering Route-Planning Algorithms. (2009) Overview. http://i11www.ira.uka.de/extra/publications/dssw-erpa-09.pdf","title":"General Background"},{"location":"Bibliography/#path-search-speedup-techniques","text":"Delling and Wagner. Time-Dependent Route Planning. (2009) Overview. http://i11www.iti.uni-karlsruhe.de/extra/publications/dw-tdrp-09.pdf Delling and Wagner. Landmark-Based Routing in Dynamic Graphs. (2008) http://i11www.ira.uka.de/extra/publications/dw-lbrdg-07.pdf Bauer, Delling, Sanders, Schultes, and Wagner. Combining Hierarchical and Goal-Directed Speed-Up Techniques for Dijkstra\u2019s Algorithm. (2008) http://algo2.iti.kit.edu/download/bdsssw-chgds-10.pdf Bauer and Delling. SHARC: Fast and Robust Unidirectional Routing. (2009) SH ortcuts + ARC flags. Can be combined with ALT. http://www.siam.org/proceedings/alenex/2008/alx08_02bauerr.pdf Delling, Daniel. Time-Dependent SHARC-Routing. (2008) http://i11www.iti.uni-karlsruhe.de/extra/publications/d-tdsr-09.pdf Goldberg, Kaplan, and Werneck. Reach for A\u2217: Efficient Point-to-Point Shortest Path Algorithms. (2005) http://avglab.com/andrew/pub/msr-tr-2005-132.pdf","title":"Path Search Speedup Techniques"},{"location":"Bibliography/#multi-objective-pareto-shortest-paths","text":"Das and Dennis. Drawbacks of minimizing weighted sums of objectives for Pareto set generation in multicriteria optimization problems. (1997) M\u00fcller-Hannemann and Schnee. Finding All Attractive Train Connections by Multi-criteria Pareto Search. (2007) Deutsche Bahn information system. Does not account for on-street travel. Mandow & P\u00e9rez de la Cruz. A New Approach to Multiobjective A Search. (2005) NAMOA http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.8780&rep=rep1&type=pdf Mandow & P\u00e9rez de la Cruz. Multiobjective A search with consistent heuristics. (2008) NAMOA Machuca, Mandow and P\u00e9rez de la Cruz. Evaluation of Heuristic Functions for Bicriterion Shortest Path Problems. (2009) Evaluates heuristics from Tung & Chew (1992) versus lexicographical ordering of priority queue. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.160.4715&rep=rep1&type=pdf Perny and Spanjaard. Near Admissible Algorithms for Multiobjective Search. (2009) Discusses relaxed Pareto dominance (Epsilon-dominance) and its use in Multi-objective A*. This a scheme for approximating the entire pareto-optimal solution set that allows time and space complexity polynomial in the number of nodes. http://www-desir.lip6.fr/publications/pub_1052_1_ECAI08.pdf Tung and Chew. A multicriteria Pareto-optimal path algorithm. (1992) Delling and Wagner. Pareto Paths with SHARC. (2009) http://i11www.iti.uni-karlsruhe.de/extra/publications/dw-pps-09.pdf","title":"Multi-objective Pareto Shortest Paths"},{"location":"Bibliography/#resource-constrained-routing","text":"Dumitrescu & Boland. Improved Preprocessing, Labeling and Scaling Algorithms for the Weight-Constrained Shortest Path Problem. (2003) Comparison of scaling and label-setting methods. Ziegelmann, Mark. Constrained Shortest Paths and Related Problems. (2001, dissertation) http://scidok.sulb.uni-saarland.de/volltexte/2004/251/pdf/MarkZiegelmann_ProfDrKurtMehlhorn.pdf","title":"Resource-constrained Routing"},{"location":"Bibliography/#contraction-and-transfer-patterns","text":"Geisberger, Robert. Contraction Hierarchies: Faster and Simpler Hierarchical Routing in Road Networks. (2008, dissertation) http://algo2.iti.kit.edu/documents/routeplanning/geisberger_dipl.pdf Geisberger, Robert. Contraction of Timetable Networks with Realistic Tranfers (2010) Introduces the \"Station Model Graph\". http://algo2.iti.kit.edu/download/time_table_ch.pdf Bast, Carlsson, Eigenwillig, Geisberger Harrelson, Raychev, and Viger. Fast Routing in Very Large Public Transportation Networks Using Transfer Patterns. (2010) http://ad.informatik.uni-freiburg.de/files/transferpatterns.pdf/at_download/file","title":"Contraction and Transfer Patterns"},{"location":"Bibliography/#timetable-based-routing","text":"Schulz, Frank. Timetable Information and Shortest Paths. (2005, dissertation) Excellent reference. http://d-nb.info/1001586921/34","title":"Timetable-based routing"},{"location":"Bibliography/#alt-and-metric-embeddings","text":"Goldberg and Werneck. Computing Point-to-Point Shortest Paths from External Memory. (2005) Introduced the ALT algorithm. http://www.cs.princeton.edu/courses/archive/spring06/cos423/Handouts/GW05.pdf Linial, London, and Rabinovich. The Geometry of Graphs and Some of its Algorithmic Applications. (1995) http://pdf.aminer.org/000/798/423/the_geometry_of_graphs_and_some_of_its_algorithmic_applications.pdf Hjaltason and Samet. Contractive Embedding Methods for Similarity Searching in Metric Spaces. (2000) http://www.cs.umd.edu/~hjs/pubs/metricpruning.pdf Potamias, Bonchi, Castillo, and Gionis. Fast Shortest Path Distance Estimation in Large Networks. (2009) Briefly discusses the connection between landmark routing and more general research on metric embeddings. http://dcommon.bu.edu/xmlui/bitstream/handle/2144/1727/2009-004-shortest-distance-estimation.pdf","title":"ALT and Metric Embeddings"},{"location":"Bibliography/#calibration-and-implementation-details","text":"Wardman, Mark. Public Transport Values of Time. (2004) http://eprints.whiterose.ac.uk/2062/1/ITS37_WP564_uploadable.pdf A.M. El-Geneidy, K.J. Krizek, M.J. Iacono. Predicting bicycle travel speeds along different facilities using GPS data: a proof of concept model. (2007) Proceedings of the 86th Annual Meeting of the Transportation Research Board, Compendium of Papers, TRB, Washington, D.C., USA (CD-ROM) Chen, Chowdhury, Roche, Ramachandran, Tong. Priority Queues and Dijkstra\u2019s Algorithm. Summary: Despite better theoretical complexity for Fibonacci heaps, it is often as good or better to use a binary heap as a priority queue when doing path searches. http://www.cs.utexas.edu/users/shaikat/papers/TR-07-54.pdf","title":"Calibration and Implementation Details"},{"location":"Bibliography/#post-dijkstra-public-transit-routing","text":"Dibbelt, Pajor, Strasser, Wagner. Intriguingly Simple and Fast Transit Routing (2013). Introduces the Connection Scan Algorithm (CSA). http://www.ecompass-project.eu/sites/default/files/ECOMPASS-TR-021.pdf Delling, Katz, and Pajor. Parallel computation of best connections in public transportation networks (2012). \"In this work, we present a novel algorithm for the one-to-all profile-search problem in public transportation networks. It answers the question for all fastest connections between a given station S and any other station at any time of the day in a single query... two interesting questions arise for time-dependent route planning: compute the best connection for a given departure time and the computation of all best connections during a given time interval (e. g., a whole day). The former is called a time-query, while the latter is called a pro\ufb01le-query.\" http://www.ecompass-project.eu/sites/default/files/ECOMPASS-TR-021.pdf","title":"Post-Dijkstra Public Transit Routing"},{"location":"Changelog/","text":"Changelog 2.0.0 (2020-11-27) See the OTP2 Migration Guide on changes to the REST API. Sandbox for experimental features #2745 Bugfix for Missing platforms for stops in GTFS import causes a NPE #2804 Remove extra Djikstra implementations Remove redundant LineStrings in order to save memory #2795 NeTEx import support #2769 New Transit search algorithm, Raptor, replaces the AStar for all transit searches. Added NeTEx notices #2824 Make transfers and access/egress use effectiveWalkDistance to take slopes into account #2857 Add MultiModalStation and GroupOfStations to OTP model and added these to the NeTEx import #2813 Combined OSM loaders, removing several rarely used ones #2878 New Java Code Style (part of #2755 ) Cleanup and rename Graph Builder Annotations, now Data Import Issues #2871 Bugfix for graph building crashing on unsupported modes #2899 Add command line parameter for building partial graphs #2583 Refactor GenericLocation/AStar/RoutingContext to allow multiple start vertices #2887 New Transit search algorithm, Raptor, replaces the AStar for all transit searches. Update only the relevant parts of the TransitLayer each time an update is applied #2918 Ability to switch off the fare service #2912 . Limit the transit service period #2925 . Removed unwanted cost added for wait time between access and transit with RangeRaptor #2927 Dynamic search parameters, calculate raptor search-window when needed. #2931 Support for next/previous paging trip search results #2941 Fix mismatch in duration for walk legs, resulting in negative wait times #2955 NeTEx import now supports ServiceLinks #2951 Also check TripPatterns added by realtime when showing stoptimes for stop #2954 Copy geometries from previous TripPattern when realtime updates result in a TripPattern being replaced #2987 Support for the Norwegian language. Update pathways support to official GTFS specification #2923 Support for XML (de-)serialization is REMOVED from the REST API #3031 Refactor how to specify access/egress/direct/transit modes in the internal model and the Transmodel API #3011 Make agency id feed scoped #3035 Refactor kiss and ride to a more general car pickup mode #3063 Map NeTEx publicCode to OTP tripShortName and NeTEx private code to OTP internalPlanningCode #3088 Add MQTT transport for the GTFS-RT trip update updater #3094 Add FinlandWayPropertySetSource #3096 Map NeTEx publicCode to OTP tripShortName and NeTEx private code to OTP internalPlanningCode #3088 Reading and writing files(CONFIG, GRAPH, DEM, OSM, GTFS, NETEX, DATA_IMPORT_ISSUES) is changed. All files, except configuration files, are read from a data source. We support Google Cloud Storage and the local file system data sources for now, but plan to add at least support for AWS S3 #2891 Remove AlertPatcher #3134 Update DebugOutput to match new routing phases of OTP2 #3109 Filter transit itineraries with relative high cost #3157 Fix issue with colliding TripPattern ids after modifications form real-time updaters #3202 Fix: The updater config type is unknown: gtfs-http #3195 Fix: Problem building and loading the GTFS file in San Fransisco Bay Area #3195 Fix: The BusRouteStreetMatcher and TransitToTaggedStopsModule graph builder modules are not run if the graph is build in two steps, and add progress tracker to BusRouteStreetMatcher. #3195 Ported over from 1.4 and 1.5 Add application/x-protobuf to accepted protobuf content-types #2839 Make OTP run on Java 11 #2812 Fixes surefire test failure during build #2816 Disable linking from already linked stops #2372 Add Way Property Set for the UK #2818 Remove Open Traffic prototype code #2698 Docs: improve configuration documentation Update onebusaway-gtfs to latest version from OBA project #2636 Remove the coupling to OneBusAway GTFS within OTP's internal model by creating new classes replacing the external classes #2494 Allow itineraries in response to be sorted by duration #2593 Fix reverse optimization bug #2653, #2411 increase GTFS-realtime feeds size limit from 64MB to 2G #2738 Fix XML response serialization #2685 Refactor InterleavedBidirectionalHeuristic #2671 Add \"Accept\" headers to GTFS-RT HTTP requests #2796 Fix minor test failure against BANO geocoder #2798 Fix frequency bounds checking #2540 Remove dependency on Conveyal jackson2-geojson Changed calculation of slope costs #2579 Replace Java built in serialization with faster Kryo #2681 Support OSM highway=razed tag #2660 Add bicimad bike rental updater #2503 Add Smoove citybikes updater #2515 Allow big GTFS-realtime feeds by increasing protobuf size limit to 2G #2739 Cannot transfer between stops at exactly the same location #2371 Improve documentation for mode routing parameter #2809 Switched to single license file, removing all OTP and OBA file license headers 1.3 (2018-08-03) Fix stop linking to only one edge of platform #2472 Log and allow changing number of HTTP handler threads Update Dutch base fare from 89 to 90 cents #2608 Add Dutch fare service #2571 Revise unit tests to use less memory Run all graph updater setup methods sequentially #2545 Allow vehicle rental systems with cars (stopgap parameter on bike rental) Bump R5 version to get newer gtfs-lib and FST serialization Move stopClusterMode parameter from routing config to build config #2558 Update encrypted Maven artifact signing key (it expired) Clean up logging Remove/update deprecated HTTPClient, add missing SSL ciphers #2451 Make maxTransfer options configurable through scripting API #2507 Fix scripts when entity IDs contain colons #2474 Add HTML report for stops more than 20m from linked road #2460 Update fares in NycFareServiceImpl #2466 Compact legs NPE fix #2449 #2490 Docs: elevation data configuration, USGS DEM files Docs: Update list of deployments Docs: API, list of deployments, usage stats and tutorials Docs: Update leadership committee listing following Boston Summit Docs: Update OTP logo (Thanks Kate Chanba!) 1.2 (2017-09-18) Add support for consuming GBFS bike-rental availability feeds. #2458 Add GBFS configuration example Add flag for including requested start/end time in maxHours in planner API. #2457 Add maxTransferDistance graph builder parameter Add option for filtering non-pickup stops in TransitIndex stop times functions. #2377 Support foot/bicycle=discouraged OSM tag. #2415 Improve linking of transit platforms to connecting access ways. #2422 / #2428 Fix bug when building graph with parent station transfers. #2404 / #2410 Fix bugs in park and ride search. #2424 Support different stop ID formats in field trip module Update URL in BANO geocoding module. #2438 / #2439 Add more debug information related to trips matching using GTFS-RT feed. #2432 Update default PATH_NOT_FOUND message to new wording developed w/ TriMet. #2355 Update Travis build configuration to not attempt GPG operations. #2441 Fix javadoc URL in scripting documentation. #2437 Automatically link to GitHub issues in Changelog. #2426 Expose FeedInfo objects in the Index API #2456 Changes to Puget Sound region fare calculation #2484 Fix coordinatates when clustering by parent station #2447 Allow setting OSM Way Properties from build-config.json #2389 Optionally compact (\"reverse-optimize\") results with complete reverse search #2449 Add updater for urbaninfrastructure city bikes #2448 Miscellaneous documentation updates 1.1 (2017-03-16) Deploy to Sonatype OSSRH and Maven Central Documentation updates including repo links New router-config stopClusterMode: clustering by parent station or geography #2364 Spanish and Portuguese UI Translations In TimeSurface API, serialize travel times to every point when detail=true Make OSM highway=corridor pedestrian routable Fix GraphIndex.stopTimesForStop to search on the request day rather than now Update GraphQL to latest version and improve support for complex arguments #2367 Add support for operationName to the graphql endpoint Fix findClosestStopsByWalking, properly set RoutingContext Fixed major routing problem where dead-end SimpleTransfers blocked walking paths #2414 Created Github issue template Avoid negative elevation figures: Compute ellipsoid-geoid offset and optionally apply to elevation calculations #2301 Fix VCub bike share updater using new API variable names. Fix spurious different-day warning #2399 Shutdown hook to gracefully shut down Grizzly #2384 Added headsign attribute for stoptimes in GraphQL #2224 Allow Cars on highway=*;bicycle=designated #2374 Expose PruneFloatingIslands parameters in build-config.json Lazy initialization of stop clusters where needed Include Agency/Route branding in responses Include turn-by-turn walking directions for transfer legs #1707 Output error when edge lengths are negative, and set them to 1mm Add disableAlertFiltering API flag #2351 Do not show arrival times at terminal stops in stop time viewer #2357 Index API now returns stop information URL, enabling hyperlinks in trip viewer #2352 Remove all unused model classes for index API #1301 Apply an interlining fix from 0.10 branch Allow quoted search phrases in the Lucene search #2279 Re-implement maxHours filter #2332 Properly set wheelchairAccessible on area edges Fixed file URL in test #2339 Add details field to fares, listing which legs each fare applies to #1699 1.0 (2016-09-09) Fix problem with missing embedded router-configs. Check whether trips have been banned when applying in-seat transfers (interlining). Load embedded config for existing graphs on disk. Apply max walk distance to transfers, not just initial and final walk. Remove Conveyal tiles from client (which was getting expensive), add free Carto/MapZen tiles. Fixed headsigns: in itineraries, headsign for a leg used to always be the last stop. Updated default map tile sets in the client because Mapquest is no longer gratis. Fix problem with empty list ??? #1873 Rewrite of intermediate places handling in GraphPathFinder. Original request is cloned for each intermediate path. Routes in GraphQL API Change \"type\" to \"mode\" and add \"type\" as route type to Route for GraphQL Add effective end date to alerts (from HSL). Rutebanken Citybike bike share. Correct TPEG transport modes TPEG 401 and 402 to be \"subway\". Ignore exceptions caused by errors in OSM linear rings. Updated to version 2.18 of Jersey to fix hanging threads in Grizzly. Removed confusing \"Busish\" and \"Trainish\" pseudo-modes. FareService for Seattle: allow specifying fares in GTFS instead of hard-coding them in Java. Senior/youth fare prices are given in an extra column in fare attributes. Per-trip fares are taken into consideration when calculating fares in this region. Update new linker to link to transitStops if no streets are found. Show the name supplied in the request for the origin/destination points in the response. Throw a trivialPath exception if start/end point are on the same edge. Switch to only use the new SimpleStreetLinker, even for search start and end points. Completely removed old linker classes. Changes for proper handling of wheelchairs and bicycles at start and end points. Properly handle null timetableSnapshots when there is no real-time data. 0.20 (2016-06-10) Re-enabled Enunciate, which works properly with OTP now. This means we have auto-generated API docs. Make headsign and block ID visible in the Stop Viewer. NYC fare service: filter out non-NYC agencies. Optionally log all requests to a file. Make max distance for in-seat transfers (interlining) configurable. Previously it was hardcoded at 200m. Polish translation for web client. Introduced bikeShareId in trip plans (separate from stopIds). Support for ShareBike bike rental system in Oslo, Drammen, Trondheim, Milan, Barcelona and Mexico City among others. Changed default waitAtBeginningFactor and timeouts. Show alert in client when itinerary departure date differs from search date. Exposed realtimeState in GraphQL responses. Fixed a routerConfig NullPointerException. Support for San Francisco bike share from leoromanovsky. GraphQL API for most transit data from hannesj. Disallow shortcuts through multiple StationStopEdges. Add support for airplanes (from HSL) Major simplification and correction of the longDistance heuristic, removed obsolete runState.options.heuristicWeight. Return default OSM level for ways that are not found. Profile routing: use earliest arrival objective function on-street, properly handle TrivialPathExceptions. Fixed ID matching when applying AlertPatches. Fixed banning of agencies in multi agency feeds. More coherent handling of feed IDs as scope for GTFS IDs. Added transit service start and end timestamps to BuildInfo. Handle embeded router configuration for POSTed graphs and zips for building. Simplified router-config handling. Properly lazy-initialize profile routing stopClusters. Added stop clusters to the Index API. Completely removed the ill-advised path parser system, which was too clever for its own good. Sort itineraries by total travel time rather than in-transit time. Rental bikes: allow loading generic KML. Removed the experimental TransportNetwork classes, which shared no code with the rest of OTP and were duplicated in the R5 project. There are still some elements that can be cleaned out when only R5 is used by Conveyal's analysis system. The broker code in OTP is now able to start up R5 workers for Analyst. Use the Conveyal fork of the OBA GTFS loader, so that we can add our own extensions to GTFS. Updated docs to offer Conveyal Maven repo as a place to get prebuilt OTP. 0.19.0 (2016-05-25) TODO 0.18.0 (2015-05-29) Ability to load elevation from projected GeoTIFF Clarified axis order for unprojected GeoTIFFs Stop viewer and car distance fixed in client Server-side localization improvements Proper names for intersections JSON config for loading bikeshare and park and ride lots from OSM More ways to fetch isochrones Fixed frequency-based routing in repeated RAPTOR Calculate graph envelope at build time not runtime Fixed slow excessive HashGrid search Readthedocs documentation updates 0.17.0 (2015-05-14) Allow fetching arrivals/departures over a particular time window Completely new spatial analysis implementation: repeated RAPTOR search at every minute in a departure time window More reproducible spatial analysis results across similar graphs, thanks to more consistent splitting of streets etc. Sigmoidal accessibility metric rolloff (rather than hard-edged cutoff) Correction of equirectangular projection used in spatial analysis Improved, simplified, deterministic linking of stops into the street network 0.16.0 (2015-05-07) Several improvements to OSM tag based traversal permissions Scripting documentation Accept TIFF files whose names end in .tiff not .tif Store distances (not times) in Analyst Samples to allow variable walk speed Fixed bug in graph auto-scanning Fixed client-side bug in first and last itinerary buttons OTP startup scripts no longer use wildcards Transit, bike rental, and parking linking done in one module Elevation tiles for the US can be fetched from Amazon S3 Bumped language level to Java 8 (lambda functions, method references, collection streams) 0.15.0 (2015-04-14) Fare module for Seattle JSON fare module and OSM street naming configuration Significant improvements to speed and result quality of Profile Routing Support for added and modified GTFS-RT trips (thanks Jaap Koelewijn of DAT Mobility and Plannerstack) Detailed edge lists in profile routing responses (for Transitive.js) Support for multiple access modes including bike rental in profile routing Fixes to graph reloading via web API Improved comments in code and documentation of PointSets Pulled MapDB GTFS loader out into a separate repo Working artifact version was 0.15.0-SNAPSHOT instead of 1.0.0-SNAPSHOT (anticipating frequent point releases) 0.14.0 (2015-03-28) JSON configuration of graph building and routers Began moving documentation (including this changelog) into the OTP repo and rewriting it page by page. It is built statically from Markdown using mkdocs and published on readthedocs. Street edge lists and bike rental station IDs in profile routing results (allows better rendering) Improved correctness of profile routing Qualified modes including rented bikes work in profile routing Simplification of qualified mode sets Elevation models are loaded from TIFFs in graph directory Tiles for differences between TimeSurfaces Restructured relationship between Routers and Graphs Various changes enabling use of Analyst features in a cluster computing environment. Removed several single-implementation interfaces, factories, services and other superfluous abstractions Various client fixes related to the transit index API Revised nearby stops logic and transfer generation to eliminate useless transfer edges New Index API endpoints for geometries, transfers etc. Isochrone generation fixes Default mode of operation is now \u201clong distance mode\u201d Process for finding alternative routes is now based on banning trips and retrying, while reusing the heuristic Optimization objective functions are swappable, and have been simplified and corrected All client Javascript librariess are now pulled from a CDN Dutch BAG and French BANO geocoders Bus to street matching improvements Complete MapDB based GTFS and OSM loader libraries (will become separate projects, not yet connected to OTP graph builder) API documentation generation working again Disable some time consuming graph building steps by default Finnish and Swedish translations Subway-specific JSON configuration options (street to platform time) Realtime fetch / streaming configurable via JSON Stairs reluctance is much higher when carrying a bike Graph visualizer routing progress animates when a search is triggered via the web API Assume WGS84 (spherical distance calculations) everywhere Removed custom motor vehicle (which was unmaintained and not documented) Ability to poll for bike rental locations only once at startup Stoptimes are fetched for a specific service day in index API Bicycle triangle support in profile routing Proper handling of multiple access modes with different speeds in profile routing Command line option to output OTP's version 0.13.0 (2014-12-05) Detect apparent errors in GTFS interlining Long distance mode: use a pure weight-based state comparison, and use trip-banning retrying logic to get multiple paths. This compromises correctness somewhat but brings search times back within reason for large regional graphs. Also, we create significantly less SimpleTransfers. Progress on GTFS reading and writing library (not yet used by OTP). Bug fixes for tiny street edges, time zones. Deployment of artifacts to maven.conveyal.com via S3. Handle park and ride lots that have roads running through them, but don't share nodes with those roads. 0.12.1 (2014-11-17) Fixed threading problem caused by graph visualization instrumentation #1611 Fixed 'unconnected areas' infinite loop #1605 0.12.0 (2014-11-11) Graph building from zipball of data sent over the wire OTP-specific GTFS loader library with error checking and recovery Bike and car park and ride improvements Stable hash codes for stop patterns and trips Bicycle safety and wheelchair access tile generators Newer versions of Grizzly, Jackson, and Enunciate (documentation generation now works) Redesigned HashGrid spatial index Significant reduction in graph size in memory and on disk Improved internationalization Ability to pause and step search in graph visualizer Additional graph visualizer modes for spotting overbranching Movement toward 1.0 web services API Kiss and Ride Complete removal of Spring Complete removal of Lombok CORS replaces JSONP Pointset classes for dealing with one-to-many calculations and accessibility calculations Experimental \"Profile routing\" which enumerates reasonable route combinations over a time range rather than exact itineraries Single-module Maven build (complete elimination of submodules) Alternate Gradle build script full internationalization of the map-based web client basic Lucene-based built-in geocoder 0.11.0 (2014-03-24) Built-in HTTP server layer, making it possible to distribute OTP as a standalone JAR \"Long-distance\" mode for large graphs, including bidirectional goal direction heuristic. Simplified Maven project structure with less submodules GTFS-RT trip update support, including streaming incremental data, which directly affects route optimization 0.10.0 (2014-03-18) This release was made to consolidate all the development that had occurred with a 0.9.x-SNAPSHOT Maven version. The changes were very significant and it was not appropriate to tag them as a minor bugfix release after the 0.9 tag. Though this release was performed at the same time as 0.11.0, it represents a much earlier stage in the development of OTP. 0.7.0 (2012-04-29) Bike rental support (thanks Laurent Gr\u00e9goire) Realtime bike rental availability feed support Updated to new version of One Bus Away GTFS/CSV, fixing timezone and string interning issues (thanks Brian Ferris) Bugfixes in area routing, OSM loading, nonexistant NED tiles, route short names Dutch and French language updates Catch negative edge weights due to broken GTFS Significant (10-20%) speedup by moving a field into StateData (thanks Laurent Gr\u00e9goire) 0.6.0 (2012-04-25) area routing more lenient parsing of times new directions icon set with SVG sources (thanks Laurent G) 0.5.4 (2012-04-06) catch 0 divisors in NED builder, preventing NaN propagation to edge lengths avoid repeated insertion of edges into edge lists, which are now threadsafe edge sets identity equality for edges bounding box check in UnifiedCoverage (speed up NED loading) Dutch API messages elevation override fix less verbose graph builder (be sure to check graphbuilder annotation summary) replacement streets given names geocoder bug fix (thanks Laurent Gregoire) git commit IDs included in MavenVersion, allowing clearer OTP/Graph version mismatch warnings fix problems with immediate reboarding and unexpected edges in itinerary builder favicon (thanks Joel Haasnoot) Legs in API response have TripId (for realtime information) Polish locale (thanks \u0141ukasz Witkowski) transfers.txt can define station paths, entry costs for stations allow loading a base graph into graphbuilder instead of starting from scratch 0.5.3 (2012-03-23) GTFS loader now loads feeds one-at-a-time, allowing per-feed configuration half-written graph files are now deleted on graph build error DST issue OTP-side fixes, tests adjusted to use timezones updated French translation fixed problem with loop ways in OSM graph coherency checking improved OSM floor number handling handle units in ele tags ferry icons (thanks Joel Haasnoot) mapbox streets tile layer is now the default complete Dutch translation 0.5.2 (2012-03-20) hop speed/distance checks, duplicate shape point filtering, etc. 0.5.1 (2012-03-16) more transit index features default agencyIDs now determined on a per-feed basis fixed fare overflow problem fixed bug in loop road turn conversion additional graphbuilder warnings and annotations fixed a batch of bugs found by fixbugs 0.5.0 (2012-03-09) stop codes, zones, and agency names in planner responses encapsulation of edge list modifications expanded edge and vertex type hierarchy use mapquest OSM server by default Turkish locale (thanks Hasan Tayyar Be\u015fik) German and Italian locales (thanks Gerardo Carrieri) bookmarkable trip URLs (thanks Matt Conway) elevator and OSM level support (thanks Matt Conway) BART/Muni fare service release and javadoc/apidoc publishing automation graph versioning based on Maven artifact version API for browsing graph internals improved stop linking optional island removal graphbuilder step and of course, lots of bugfixes 0.4.4 (2012-02-06) Release in anticipation of upcoming merges.","title":"Changelog"},{"location":"Changelog/#changelog","text":"","title":"Changelog"},{"location":"Changelog/#200-2020-11-27","text":"See the OTP2 Migration Guide on changes to the REST API. Sandbox for experimental features #2745 Bugfix for Missing platforms for stops in GTFS import causes a NPE #2804 Remove extra Djikstra implementations Remove redundant LineStrings in order to save memory #2795 NeTEx import support #2769 New Transit search algorithm, Raptor, replaces the AStar for all transit searches. Added NeTEx notices #2824 Make transfers and access/egress use effectiveWalkDistance to take slopes into account #2857 Add MultiModalStation and GroupOfStations to OTP model and added these to the NeTEx import #2813 Combined OSM loaders, removing several rarely used ones #2878 New Java Code Style (part of #2755 ) Cleanup and rename Graph Builder Annotations, now Data Import Issues #2871 Bugfix for graph building crashing on unsupported modes #2899 Add command line parameter for building partial graphs #2583 Refactor GenericLocation/AStar/RoutingContext to allow multiple start vertices #2887 New Transit search algorithm, Raptor, replaces the AStar for all transit searches. Update only the relevant parts of the TransitLayer each time an update is applied #2918 Ability to switch off the fare service #2912 . Limit the transit service period #2925 . Removed unwanted cost added for wait time between access and transit with RangeRaptor #2927 Dynamic search parameters, calculate raptor search-window when needed. #2931 Support for next/previous paging trip search results #2941 Fix mismatch in duration for walk legs, resulting in negative wait times #2955 NeTEx import now supports ServiceLinks #2951 Also check TripPatterns added by realtime when showing stoptimes for stop #2954 Copy geometries from previous TripPattern when realtime updates result in a TripPattern being replaced #2987 Support for the Norwegian language. Update pathways support to official GTFS specification #2923 Support for XML (de-)serialization is REMOVED from the REST API #3031 Refactor how to specify access/egress/direct/transit modes in the internal model and the Transmodel API #3011 Make agency id feed scoped #3035 Refactor kiss and ride to a more general car pickup mode #3063 Map NeTEx publicCode to OTP tripShortName and NeTEx private code to OTP internalPlanningCode #3088 Add MQTT transport for the GTFS-RT trip update updater #3094 Add FinlandWayPropertySetSource #3096 Map NeTEx publicCode to OTP tripShortName and NeTEx private code to OTP internalPlanningCode #3088 Reading and writing files(CONFIG, GRAPH, DEM, OSM, GTFS, NETEX, DATA_IMPORT_ISSUES) is changed. All files, except configuration files, are read from a data source. We support Google Cloud Storage and the local file system data sources for now, but plan to add at least support for AWS S3 #2891 Remove AlertPatcher #3134 Update DebugOutput to match new routing phases of OTP2 #3109 Filter transit itineraries with relative high cost #3157 Fix issue with colliding TripPattern ids after modifications form real-time updaters #3202 Fix: The updater config type is unknown: gtfs-http #3195 Fix: Problem building and loading the GTFS file in San Fransisco Bay Area #3195 Fix: The BusRouteStreetMatcher and TransitToTaggedStopsModule graph builder modules are not run if the graph is build in two steps, and add progress tracker to BusRouteStreetMatcher. #3195","title":"2.0.0 (2020-11-27)"},{"location":"Changelog/#ported-over-from-14-and-15","text":"Add application/x-protobuf to accepted protobuf content-types #2839 Make OTP run on Java 11 #2812 Fixes surefire test failure during build #2816 Disable linking from already linked stops #2372 Add Way Property Set for the UK #2818 Remove Open Traffic prototype code #2698 Docs: improve configuration documentation Update onebusaway-gtfs to latest version from OBA project #2636 Remove the coupling to OneBusAway GTFS within OTP's internal model by creating new classes replacing the external classes #2494 Allow itineraries in response to be sorted by duration #2593 Fix reverse optimization bug #2653, #2411 increase GTFS-realtime feeds size limit from 64MB to 2G #2738 Fix XML response serialization #2685 Refactor InterleavedBidirectionalHeuristic #2671 Add \"Accept\" headers to GTFS-RT HTTP requests #2796 Fix minor test failure against BANO geocoder #2798 Fix frequency bounds checking #2540 Remove dependency on Conveyal jackson2-geojson Changed calculation of slope costs #2579 Replace Java built in serialization with faster Kryo #2681 Support OSM highway=razed tag #2660 Add bicimad bike rental updater #2503 Add Smoove citybikes updater #2515 Allow big GTFS-realtime feeds by increasing protobuf size limit to 2G #2739 Cannot transfer between stops at exactly the same location #2371 Improve documentation for mode routing parameter #2809 Switched to single license file, removing all OTP and OBA file license headers","title":"Ported over from 1.4 and 1.5"},{"location":"Changelog/#13-2018-08-03","text":"Fix stop linking to only one edge of platform #2472 Log and allow changing number of HTTP handler threads Update Dutch base fare from 89 to 90 cents #2608 Add Dutch fare service #2571 Revise unit tests to use less memory Run all graph updater setup methods sequentially #2545 Allow vehicle rental systems with cars (stopgap parameter on bike rental) Bump R5 version to get newer gtfs-lib and FST serialization Move stopClusterMode parameter from routing config to build config #2558 Update encrypted Maven artifact signing key (it expired) Clean up logging Remove/update deprecated HTTPClient, add missing SSL ciphers #2451 Make maxTransfer options configurable through scripting API #2507 Fix scripts when entity IDs contain colons #2474 Add HTML report for stops more than 20m from linked road #2460 Update fares in NycFareServiceImpl #2466 Compact legs NPE fix #2449 #2490 Docs: elevation data configuration, USGS DEM files Docs: Update list of deployments Docs: API, list of deployments, usage stats and tutorials Docs: Update leadership committee listing following Boston Summit Docs: Update OTP logo (Thanks Kate Chanba!)","title":"1.3 (2018-08-03)"},{"location":"Changelog/#12-2017-09-18","text":"Add support for consuming GBFS bike-rental availability feeds. #2458 Add GBFS configuration example Add flag for including requested start/end time in maxHours in planner API. #2457 Add maxTransferDistance graph builder parameter Add option for filtering non-pickup stops in TransitIndex stop times functions. #2377 Support foot/bicycle=discouraged OSM tag. #2415 Improve linking of transit platforms to connecting access ways. #2422 / #2428 Fix bug when building graph with parent station transfers. #2404 / #2410 Fix bugs in park and ride search. #2424 Support different stop ID formats in field trip module Update URL in BANO geocoding module. #2438 / #2439 Add more debug information related to trips matching using GTFS-RT feed. #2432 Update default PATH_NOT_FOUND message to new wording developed w/ TriMet. #2355 Update Travis build configuration to not attempt GPG operations. #2441 Fix javadoc URL in scripting documentation. #2437 Automatically link to GitHub issues in Changelog. #2426 Expose FeedInfo objects in the Index API #2456 Changes to Puget Sound region fare calculation #2484 Fix coordinatates when clustering by parent station #2447 Allow setting OSM Way Properties from build-config.json #2389 Optionally compact (\"reverse-optimize\") results with complete reverse search #2449 Add updater for urbaninfrastructure city bikes #2448 Miscellaneous documentation updates","title":"1.2 (2017-09-18)"},{"location":"Changelog/#11-2017-03-16","text":"Deploy to Sonatype OSSRH and Maven Central Documentation updates including repo links New router-config stopClusterMode: clustering by parent station or geography #2364 Spanish and Portuguese UI Translations In TimeSurface API, serialize travel times to every point when detail=true Make OSM highway=corridor pedestrian routable Fix GraphIndex.stopTimesForStop to search on the request day rather than now Update GraphQL to latest version and improve support for complex arguments #2367 Add support for operationName to the graphql endpoint Fix findClosestStopsByWalking, properly set RoutingContext Fixed major routing problem where dead-end SimpleTransfers blocked walking paths #2414 Created Github issue template Avoid negative elevation figures: Compute ellipsoid-geoid offset and optionally apply to elevation calculations #2301 Fix VCub bike share updater using new API variable names. Fix spurious different-day warning #2399 Shutdown hook to gracefully shut down Grizzly #2384 Added headsign attribute for stoptimes in GraphQL #2224 Allow Cars on highway=*;bicycle=designated #2374 Expose PruneFloatingIslands parameters in build-config.json Lazy initialization of stop clusters where needed Include Agency/Route branding in responses Include turn-by-turn walking directions for transfer legs #1707 Output error when edge lengths are negative, and set them to 1mm Add disableAlertFiltering API flag #2351 Do not show arrival times at terminal stops in stop time viewer #2357 Index API now returns stop information URL, enabling hyperlinks in trip viewer #2352 Remove all unused model classes for index API #1301 Apply an interlining fix from 0.10 branch Allow quoted search phrases in the Lucene search #2279 Re-implement maxHours filter #2332 Properly set wheelchairAccessible on area edges Fixed file URL in test #2339 Add details field to fares, listing which legs each fare applies to #1699","title":"1.1 (2017-03-16)"},{"location":"Changelog/#10-2016-09-09","text":"Fix problem with missing embedded router-configs. Check whether trips have been banned when applying in-seat transfers (interlining). Load embedded config for existing graphs on disk. Apply max walk distance to transfers, not just initial and final walk. Remove Conveyal tiles from client (which was getting expensive), add free Carto/MapZen tiles. Fixed headsigns: in itineraries, headsign for a leg used to always be the last stop. Updated default map tile sets in the client because Mapquest is no longer gratis. Fix problem with empty list ??? #1873 Rewrite of intermediate places handling in GraphPathFinder. Original request is cloned for each intermediate path. Routes in GraphQL API Change \"type\" to \"mode\" and add \"type\" as route type to Route for GraphQL Add effective end date to alerts (from HSL). Rutebanken Citybike bike share. Correct TPEG transport modes TPEG 401 and 402 to be \"subway\". Ignore exceptions caused by errors in OSM linear rings. Updated to version 2.18 of Jersey to fix hanging threads in Grizzly. Removed confusing \"Busish\" and \"Trainish\" pseudo-modes. FareService for Seattle: allow specifying fares in GTFS instead of hard-coding them in Java. Senior/youth fare prices are given in an extra column in fare attributes. Per-trip fares are taken into consideration when calculating fares in this region. Update new linker to link to transitStops if no streets are found. Show the name supplied in the request for the origin/destination points in the response. Throw a trivialPath exception if start/end point are on the same edge. Switch to only use the new SimpleStreetLinker, even for search start and end points. Completely removed old linker classes. Changes for proper handling of wheelchairs and bicycles at start and end points. Properly handle null timetableSnapshots when there is no real-time data.","title":"1.0 (2016-09-09)"},{"location":"Changelog/#020-2016-06-10","text":"Re-enabled Enunciate, which works properly with OTP now. This means we have auto-generated API docs. Make headsign and block ID visible in the Stop Viewer. NYC fare service: filter out non-NYC agencies. Optionally log all requests to a file. Make max distance for in-seat transfers (interlining) configurable. Previously it was hardcoded at 200m. Polish translation for web client. Introduced bikeShareId in trip plans (separate from stopIds). Support for ShareBike bike rental system in Oslo, Drammen, Trondheim, Milan, Barcelona and Mexico City among others. Changed default waitAtBeginningFactor and timeouts. Show alert in client when itinerary departure date differs from search date. Exposed realtimeState in GraphQL responses. Fixed a routerConfig NullPointerException. Support for San Francisco bike share from leoromanovsky. GraphQL API for most transit data from hannesj. Disallow shortcuts through multiple StationStopEdges. Add support for airplanes (from HSL) Major simplification and correction of the longDistance heuristic, removed obsolete runState.options.heuristicWeight. Return default OSM level for ways that are not found. Profile routing: use earliest arrival objective function on-street, properly handle TrivialPathExceptions. Fixed ID matching when applying AlertPatches. Fixed banning of agencies in multi agency feeds. More coherent handling of feed IDs as scope for GTFS IDs. Added transit service start and end timestamps to BuildInfo. Handle embeded router configuration for POSTed graphs and zips for building. Simplified router-config handling. Properly lazy-initialize profile routing stopClusters. Added stop clusters to the Index API. Completely removed the ill-advised path parser system, which was too clever for its own good. Sort itineraries by total travel time rather than in-transit time. Rental bikes: allow loading generic KML. Removed the experimental TransportNetwork classes, which shared no code with the rest of OTP and were duplicated in the R5 project. There are still some elements that can be cleaned out when only R5 is used by Conveyal's analysis system. The broker code in OTP is now able to start up R5 workers for Analyst. Use the Conveyal fork of the OBA GTFS loader, so that we can add our own extensions to GTFS. Updated docs to offer Conveyal Maven repo as a place to get prebuilt OTP.","title":"0.20 (2016-06-10)"},{"location":"Changelog/#0190-2016-05-25","text":"TODO","title":"0.19.0 (2016-05-25)"},{"location":"Changelog/#0180-2015-05-29","text":"Ability to load elevation from projected GeoTIFF Clarified axis order for unprojected GeoTIFFs Stop viewer and car distance fixed in client Server-side localization improvements Proper names for intersections JSON config for loading bikeshare and park and ride lots from OSM More ways to fetch isochrones Fixed frequency-based routing in repeated RAPTOR Calculate graph envelope at build time not runtime Fixed slow excessive HashGrid search Readthedocs documentation updates","title":"0.18.0 (2015-05-29)"},{"location":"Changelog/#0170-2015-05-14","text":"Allow fetching arrivals/departures over a particular time window Completely new spatial analysis implementation: repeated RAPTOR search at every minute in a departure time window More reproducible spatial analysis results across similar graphs, thanks to more consistent splitting of streets etc. Sigmoidal accessibility metric rolloff (rather than hard-edged cutoff) Correction of equirectangular projection used in spatial analysis Improved, simplified, deterministic linking of stops into the street network","title":"0.17.0 (2015-05-14)"},{"location":"Changelog/#0160-2015-05-07","text":"Several improvements to OSM tag based traversal permissions Scripting documentation Accept TIFF files whose names end in .tiff not .tif Store distances (not times) in Analyst Samples to allow variable walk speed Fixed bug in graph auto-scanning Fixed client-side bug in first and last itinerary buttons OTP startup scripts no longer use wildcards Transit, bike rental, and parking linking done in one module Elevation tiles for the US can be fetched from Amazon S3 Bumped language level to Java 8 (lambda functions, method references, collection streams)","title":"0.16.0 (2015-05-07)"},{"location":"Changelog/#0150-2015-04-14","text":"Fare module for Seattle JSON fare module and OSM street naming configuration Significant improvements to speed and result quality of Profile Routing Support for added and modified GTFS-RT trips (thanks Jaap Koelewijn of DAT Mobility and Plannerstack) Detailed edge lists in profile routing responses (for Transitive.js) Support for multiple access modes including bike rental in profile routing Fixes to graph reloading via web API Improved comments in code and documentation of PointSets Pulled MapDB GTFS loader out into a separate repo Working artifact version was 0.15.0-SNAPSHOT instead of 1.0.0-SNAPSHOT (anticipating frequent point releases)","title":"0.15.0 (2015-04-14)"},{"location":"Changelog/#0140-2015-03-28","text":"JSON configuration of graph building and routers Began moving documentation (including this changelog) into the OTP repo and rewriting it page by page. It is built statically from Markdown using mkdocs and published on readthedocs. Street edge lists and bike rental station IDs in profile routing results (allows better rendering) Improved correctness of profile routing Qualified modes including rented bikes work in profile routing Simplification of qualified mode sets Elevation models are loaded from TIFFs in graph directory Tiles for differences between TimeSurfaces Restructured relationship between Routers and Graphs Various changes enabling use of Analyst features in a cluster computing environment. Removed several single-implementation interfaces, factories, services and other superfluous abstractions Various client fixes related to the transit index API Revised nearby stops logic and transfer generation to eliminate useless transfer edges New Index API endpoints for geometries, transfers etc. Isochrone generation fixes Default mode of operation is now \u201clong distance mode\u201d Process for finding alternative routes is now based on banning trips and retrying, while reusing the heuristic Optimization objective functions are swappable, and have been simplified and corrected All client Javascript librariess are now pulled from a CDN Dutch BAG and French BANO geocoders Bus to street matching improvements Complete MapDB based GTFS and OSM loader libraries (will become separate projects, not yet connected to OTP graph builder) API documentation generation working again Disable some time consuming graph building steps by default Finnish and Swedish translations Subway-specific JSON configuration options (street to platform time) Realtime fetch / streaming configurable via JSON Stairs reluctance is much higher when carrying a bike Graph visualizer routing progress animates when a search is triggered via the web API Assume WGS84 (spherical distance calculations) everywhere Removed custom motor vehicle (which was unmaintained and not documented) Ability to poll for bike rental locations only once at startup Stoptimes are fetched for a specific service day in index API Bicycle triangle support in profile routing Proper handling of multiple access modes with different speeds in profile routing Command line option to output OTP's version","title":"0.14.0 (2015-03-28)"},{"location":"Changelog/#0130-2014-12-05","text":"Detect apparent errors in GTFS interlining Long distance mode: use a pure weight-based state comparison, and use trip-banning retrying logic to get multiple paths. This compromises correctness somewhat but brings search times back within reason for large regional graphs. Also, we create significantly less SimpleTransfers. Progress on GTFS reading and writing library (not yet used by OTP). Bug fixes for tiny street edges, time zones. Deployment of artifacts to maven.conveyal.com via S3. Handle park and ride lots that have roads running through them, but don't share nodes with those roads.","title":"0.13.0 (2014-12-05)"},{"location":"Changelog/#0121-2014-11-17","text":"Fixed threading problem caused by graph visualization instrumentation #1611 Fixed 'unconnected areas' infinite loop #1605","title":"0.12.1 (2014-11-17)"},{"location":"Changelog/#0120-2014-11-11","text":"Graph building from zipball of data sent over the wire OTP-specific GTFS loader library with error checking and recovery Bike and car park and ride improvements Stable hash codes for stop patterns and trips Bicycle safety and wheelchair access tile generators Newer versions of Grizzly, Jackson, and Enunciate (documentation generation now works) Redesigned HashGrid spatial index Significant reduction in graph size in memory and on disk Improved internationalization Ability to pause and step search in graph visualizer Additional graph visualizer modes for spotting overbranching Movement toward 1.0 web services API Kiss and Ride Complete removal of Spring Complete removal of Lombok CORS replaces JSONP Pointset classes for dealing with one-to-many calculations and accessibility calculations Experimental \"Profile routing\" which enumerates reasonable route combinations over a time range rather than exact itineraries Single-module Maven build (complete elimination of submodules) Alternate Gradle build script full internationalization of the map-based web client basic Lucene-based built-in geocoder","title":"0.12.0 (2014-11-11)"},{"location":"Changelog/#0110-2014-03-24","text":"Built-in HTTP server layer, making it possible to distribute OTP as a standalone JAR \"Long-distance\" mode for large graphs, including bidirectional goal direction heuristic. Simplified Maven project structure with less submodules GTFS-RT trip update support, including streaming incremental data, which directly affects route optimization","title":"0.11.0 (2014-03-24)"},{"location":"Changelog/#0100-2014-03-18","text":"This release was made to consolidate all the development that had occurred with a 0.9.x-SNAPSHOT Maven version. The changes were very significant and it was not appropriate to tag them as a minor bugfix release after the 0.9 tag. Though this release was performed at the same time as 0.11.0, it represents a much earlier stage in the development of OTP.","title":"0.10.0 (2014-03-18)"},{"location":"Changelog/#070-2012-04-29","text":"Bike rental support (thanks Laurent Gr\u00e9goire) Realtime bike rental availability feed support Updated to new version of One Bus Away GTFS/CSV, fixing timezone and string interning issues (thanks Brian Ferris) Bugfixes in area routing, OSM loading, nonexistant NED tiles, route short names Dutch and French language updates Catch negative edge weights due to broken GTFS Significant (10-20%) speedup by moving a field into StateData (thanks Laurent Gr\u00e9goire)","title":"0.7.0 (2012-04-29)"},{"location":"Changelog/#060-2012-04-25","text":"area routing more lenient parsing of times new directions icon set with SVG sources (thanks Laurent G)","title":"0.6.0 (2012-04-25)"},{"location":"Changelog/#054-2012-04-06","text":"catch 0 divisors in NED builder, preventing NaN propagation to edge lengths avoid repeated insertion of edges into edge lists, which are now threadsafe edge sets identity equality for edges bounding box check in UnifiedCoverage (speed up NED loading) Dutch API messages elevation override fix less verbose graph builder (be sure to check graphbuilder annotation summary) replacement streets given names geocoder bug fix (thanks Laurent Gregoire) git commit IDs included in MavenVersion, allowing clearer OTP/Graph version mismatch warnings fix problems with immediate reboarding and unexpected edges in itinerary builder favicon (thanks Joel Haasnoot) Legs in API response have TripId (for realtime information) Polish locale (thanks \u0141ukasz Witkowski) transfers.txt can define station paths, entry costs for stations allow loading a base graph into graphbuilder instead of starting from scratch","title":"0.5.4 (2012-04-06)"},{"location":"Changelog/#053-2012-03-23","text":"GTFS loader now loads feeds one-at-a-time, allowing per-feed configuration half-written graph files are now deleted on graph build error DST issue OTP-side fixes, tests adjusted to use timezones updated French translation fixed problem with loop ways in OSM graph coherency checking improved OSM floor number handling handle units in ele tags ferry icons (thanks Joel Haasnoot) mapbox streets tile layer is now the default complete Dutch translation","title":"0.5.3 (2012-03-23)"},{"location":"Changelog/#052-2012-03-20","text":"hop speed/distance checks, duplicate shape point filtering, etc.","title":"0.5.2 (2012-03-20)"},{"location":"Changelog/#051-2012-03-16","text":"more transit index features default agencyIDs now determined on a per-feed basis fixed fare overflow problem fixed bug in loop road turn conversion additional graphbuilder warnings and annotations fixed a batch of bugs found by fixbugs","title":"0.5.1 (2012-03-16)"},{"location":"Changelog/#050-2012-03-09","text":"stop codes, zones, and agency names in planner responses encapsulation of edge list modifications expanded edge and vertex type hierarchy use mapquest OSM server by default Turkish locale (thanks Hasan Tayyar Be\u015fik) German and Italian locales (thanks Gerardo Carrieri) bookmarkable trip URLs (thanks Matt Conway) elevator and OSM level support (thanks Matt Conway) BART/Muni fare service release and javadoc/apidoc publishing automation graph versioning based on Maven artifact version API for browsing graph internals improved stop linking optional island removal graphbuilder step and of course, lots of bugfixes","title":"0.5.0 (2012-03-09)"},{"location":"Changelog/#044-2012-02-06","text":"Release in anticipation of upcoming merges.","title":"0.4.4 (2012-02-06)"},{"location":"Codestyle/","text":"Codestyle We use the following code conventions for Java and JavaScript . Java The OpenTripPlanner Java code style is revised in OTP2. We use the Google Java style guide, with a few modifications. Here is the original Google style guide: https://google.github.io/styleguide/javaguide.html IntellJ Code Style formatter If you use IntelliJ, import the provided intellij-code-style.xml . Open the Preferences from the menu and select Editor > Code Style . Then import the code-style xml document. Configure Scheme using Import Scheme > IntelliJ IDEA code style XML . Note that the IntelliJ formatter will not always format the code according to the coding standard. It struggle to do the line breaks properly. Hence, use it to format new code and to rearrange members, then manually fix any mistakes. Other IDEs We do not have support for other IDEs at the moment. If you use another editor and make one please feel free to share it. Code Style Our style differs in the following ways from the Google guide. Each point references the section of the original document that is modified. 4.5.1 We apply the same line breaking rules to parentheses as to curly braces. Any time the contents of the parentheses are not all placed on one line, we insert a line break after the opening paren, and place the closing one at the beginning of a new line. // int value = calculateSomeValue ( arg1 , arg2 , arg3 ); // Also Ok int value = calculateSomeValue ( arg1 , arg2 , arg3 ); // Avoid this int value = calculateSomeValue ( arg1 , arg2 , arg3 ); // and this int value = calculateSomeValue ( arg1 , arg2 , arg3 ) 4.6.1 We insert double empty lines before comments that introduce the highest level groupings of methods or fields within a class, for example /* private methods */ , /* symbolic constants */ . public foo() { } /* private methods */ private bar() ... 4.8.3 the final example is not allowed. All opening brackets or parens should be on the same line as the identifier or other construct that they follow. 4.8.5 All annotations on classes, fields, and methods should always have a newline after the last annotation, i.e. they should not appear on the same line as the identifier they annotate, and should only appear on the same line as other annotations. Series of multiple annotations may each appear on a separate line, or may all be grouped together on the same line. 4.8.6.1 On multi-line /* ... */ comments we do not begin the intermediate lines with asterisks * . 5.2.8 We only use single capital letters (single characters) for generic type parameters. 7.2 We do not begin Javadoc with summary fragments. This is because will no longer generate and publish Javadoc pages, the Javadoc will only be used within IDEs. 7.3.1 The item in the original document implies that trivial Javadoc like /** Returns the canonical name. */ should still be included. There is almost always something more to explain to someone who is seeing this method or class for the first time. Notes on breaking lines The eye scan the code much faster if there is less need of horizontal movement, so formatting the code becomes a balance on how long the lies should be and how to break it. Try to brake the code at the outer-most scope aligning expressions with the same scope. Consider to chop down all expressions with the same scope and indent them, do not align code further to the right than the indentation margin. // Conider this code: xxxx xxx = xxx + xxx * xxx - ( x.xxxx().xx().xxx() - xxx ) / xxx; // Break tha line as every operator, pharenphasis and method chanin. // This is a bit extrem, but illustrates the correct way to break the lines. xxxx xxx = xxx + xxx * xxx - ( x.xxxx() .xx() .xxx() - xxx ) / xxx ; // Prefered compromize xxxx xxx = xxx + xxx * xxx - ( x.xxxx().xx().xxx() - xxx ) / xxx // or xxxx xxx = xxx + xxx * xxx - ( x.xxxx().xx().xxx() - xxx ) / xxx // Right alignment not allowed xxxx xxx = xxx + xxx * xxx; // use indentation margin instead xxxx xxx = xxx + xxx * xxx; Sorting class members Some of the classes in OTP have a lot of fields and methods. Keeping members sorted reduce the merge conflicts. Adding fields and methods to the end of the list will cause merge conflicts more often than inserting methods and fields in an ordered list. Fields and methods can be sorted in \"feature\" sections or alphabetically, but stick to it and respect it when adding new methods and fields. The provided formatter will group class members in this order: Getter and Setter methods are kept together Overridden methods are kept together Dependent methods are sorted in a breadth-first order. Members are sorted like this: static final fields static fields static initializer final fields fields class initializer (avoid using it) Constructor static methods static getter and setters methods getter and setters enums interfaces static classes classes Each section of members are sorted by visibility: \u00b4public\u00b4 package private \u00b4protected\u00b4 \u00b4private\u00b4 JavaDoc Guidlines What to put in Javadoc: - On methods: - Side effects on instance state (is it a pure function) - Contract of the method - Input domain for which the logic is designed - Range of outputs produced from valid inputs - Is behavior undefined or will fail when conditions are not met - Are null values allowed as inputs - Will null values occur as outputs (what do they mean) - Invariants that hold if the preconditions are met - Concurrency - Is method thread-safe - Usage constraints for multi-threaded use - On classes: - Initialization and teardown process - Can instance be reused for multiple operations, or should it be discarded - Is it immutable or should anything be treated as immutable - Is it a utility class of static methods that should not be instantiated JavaScript As of #206, we follow Crockford's JavaScript code conventions . Further guidelines include: All .js source files should contain one class only Capitalize the class name, as well as the source file name (a la Java) Include the namespace definition in each and every file: otp.namespace(\"otp.configure\"); Include a class comment. For example, /** * Configure Class * * Purpose is to allow a generic configuration object to be read via AJAX/JSON, and inserted into an * Ext Store * The implementation is TriMet route map specific...but replacing ConfigureStore object (or member * variables) with another implementation, will give this widget flexibility for other uses beyond * the iMap. * * @class */ Note: There is still a lot of code following other style conventions, but please adhere to consistent style when you write new code, and help clean up and reformat code as you refactor.","title":"Codestyle"},{"location":"Codestyle/#codestyle","text":"We use the following code conventions for Java and JavaScript .","title":"Codestyle"},{"location":"Codestyle/#java","text":"The OpenTripPlanner Java code style is revised in OTP2. We use the Google Java style guide, with a few modifications. Here is the original Google style guide: https://google.github.io/styleguide/javaguide.html","title":"Java"},{"location":"Codestyle/#intellj-code-style-formatter","text":"If you use IntelliJ, import the provided intellij-code-style.xml . Open the Preferences from the menu and select Editor > Code Style . Then import the code-style xml document. Configure Scheme using Import Scheme > IntelliJ IDEA code style XML . Note that the IntelliJ formatter will not always format the code according to the coding standard. It struggle to do the line breaks properly. Hence, use it to format new code and to rearrange members, then manually fix any mistakes.","title":"IntellJ Code Style formatter"},{"location":"Codestyle/#other-ides","text":"We do not have support for other IDEs at the moment. If you use another editor and make one please feel free to share it.","title":"Other IDEs"},{"location":"Codestyle/#code-style","text":"Our style differs in the following ways from the Google guide. Each point references the section of the original document that is modified. 4.5.1 We apply the same line breaking rules to parentheses as to curly braces. Any time the contents of the parentheses are not all placed on one line, we insert a line break after the opening paren, and place the closing one at the beginning of a new line. // int value = calculateSomeValue ( arg1 , arg2 , arg3 ); // Also Ok int value = calculateSomeValue ( arg1 , arg2 , arg3 ); // Avoid this int value = calculateSomeValue ( arg1 , arg2 , arg3 ); // and this int value = calculateSomeValue ( arg1 , arg2 , arg3 ) 4.6.1 We insert double empty lines before comments that introduce the highest level groupings of methods or fields within a class, for example /* private methods */ , /* symbolic constants */ . public foo() { } /* private methods */ private bar() ... 4.8.3 the final example is not allowed. All opening brackets or parens should be on the same line as the identifier or other construct that they follow. 4.8.5 All annotations on classes, fields, and methods should always have a newline after the last annotation, i.e. they should not appear on the same line as the identifier they annotate, and should only appear on the same line as other annotations. Series of multiple annotations may each appear on a separate line, or may all be grouped together on the same line. 4.8.6.1 On multi-line /* ... */ comments we do not begin the intermediate lines with asterisks * . 5.2.8 We only use single capital letters (single characters) for generic type parameters. 7.2 We do not begin Javadoc with summary fragments. This is because will no longer generate and publish Javadoc pages, the Javadoc will only be used within IDEs. 7.3.1 The item in the original document implies that trivial Javadoc like /** Returns the canonical name. */ should still be included. There is almost always something more to explain to someone who is seeing this method or class for the first time.","title":"Code Style"},{"location":"Codestyle/#notes-on-breaking-lines","text":"The eye scan the code much faster if there is less need of horizontal movement, so formatting the code becomes a balance on how long the lies should be and how to break it. Try to brake the code at the outer-most scope aligning expressions with the same scope. Consider to chop down all expressions with the same scope and indent them, do not align code further to the right than the indentation margin. // Conider this code: xxxx xxx = xxx + xxx * xxx - ( x.xxxx().xx().xxx() - xxx ) / xxx; // Break tha line as every operator, pharenphasis and method chanin. // This is a bit extrem, but illustrates the correct way to break the lines. xxxx xxx = xxx + xxx * xxx - ( x.xxxx() .xx() .xxx() - xxx ) / xxx ; // Prefered compromize xxxx xxx = xxx + xxx * xxx - ( x.xxxx().xx().xxx() - xxx ) / xxx // or xxxx xxx = xxx + xxx * xxx - ( x.xxxx().xx().xxx() - xxx ) / xxx // Right alignment not allowed xxxx xxx = xxx + xxx * xxx; // use indentation margin instead xxxx xxx = xxx + xxx * xxx;","title":"Notes on breaking lines"},{"location":"Codestyle/#sorting-class-members","text":"Some of the classes in OTP have a lot of fields and methods. Keeping members sorted reduce the merge conflicts. Adding fields and methods to the end of the list will cause merge conflicts more often than inserting methods and fields in an ordered list. Fields and methods can be sorted in \"feature\" sections or alphabetically, but stick to it and respect it when adding new methods and fields. The provided formatter will group class members in this order: Getter and Setter methods are kept together Overridden methods are kept together Dependent methods are sorted in a breadth-first order. Members are sorted like this: static final fields static fields static initializer final fields fields class initializer (avoid using it) Constructor static methods static getter and setters methods getter and setters enums interfaces static classes classes Each section of members are sorted by visibility: \u00b4public\u00b4 package private \u00b4protected\u00b4 \u00b4private\u00b4","title":"Sorting class members"},{"location":"Codestyle/#javadoc-guidlines","text":"What to put in Javadoc: - On methods: - Side effects on instance state (is it a pure function) - Contract of the method - Input domain for which the logic is designed - Range of outputs produced from valid inputs - Is behavior undefined or will fail when conditions are not met - Are null values allowed as inputs - Will null values occur as outputs (what do they mean) - Invariants that hold if the preconditions are met - Concurrency - Is method thread-safe - Usage constraints for multi-threaded use - On classes: - Initialization and teardown process - Can instance be reused for multiple operations, or should it be discarded - Is it immutable or should anything be treated as immutable - Is it a utility class of static methods that should not be instantiated","title":"JavaDoc Guidlines"},{"location":"Codestyle/#javascript","text":"As of #206, we follow Crockford's JavaScript code conventions . Further guidelines include: All .js source files should contain one class only Capitalize the class name, as well as the source file name (a la Java) Include the namespace definition in each and every file: otp.namespace(\"otp.configure\"); Include a class comment. For example, /** * Configure Class * * Purpose is to allow a generic configuration object to be read via AJAX/JSON, and inserted into an * Ext Store * The implementation is TriMet route map specific...but replacing ConfigureStore object (or member * variables) with another implementation, will give this widget flexibility for other uses beyond * the iMap. * * @class */ Note: There is still a lot of code following other style conventions, but please adhere to consistent style when you write new code, and help clean up and reformat code as you refactor.","title":"JavaScript"},{"location":"Configuration/","text":"Configuring OpenTripPlanner Note: if you are familiar with OTP1 configuration and are migrating to OTP2, please read the OTP2 Migration Guide to learn what has changed. Base Directory On the OTP2 command line you must always specify a single directory after all the switches. This tells OTP2 where to look for any configuration files. By default OTP will also scan this directory for input files to build a graph (GTFS, OSM, elevation, and base street graphs) or the graph.obj file to load when starting a server. A typical OTP2 directory for a New York City graph might include the following: otp-config.json build-config.json router-config.json new-york-city-no-buildings.osm.pbf nyc-elevation.tiff long-island-rail-road.gtfs.zip mta-new-york-city-transit.gtfs.zip port-authority-of-new-york-new-jersey.gtfs.zip graph.obj You could have more than one of these directories if you are building separate graphs for separate regions. Each one should contain one or more GTFS feeds, a PBF OpenStreetMap file, some JSON configuration files, and any output files such as graph.obj . For convenience, especially if you work with only one graph at a time, you may want to place your OTP2 JAR file in this same directory. Note that file types are detected through a case-insensitive combination of file extension and words within the file name. GTFS file names must end in .zip and contain the letters gtfs , and OSM files must end in .pbf . It is also possible to provide a list of input files in the configuration, which will override this default behavior of scanning the base directory for input files. Scanning is overridden independently for each file type, and can point to remote cloud storage with arbitrary URIs. See the storage section for further details. Three Scopes of Configuration OTP is configured via three configuration JSON files which are read from the directory specified on its command line. We try to provide sensible defaults for every option, so all three of these files are optional, as are all the options within each file. Each configuration file corresponds to options that are relevant at a particular phase of OTP usage. Options and parameters that are taken into account during the graph building process will be \"baked into\" the graph, and cannot be changed later in a running server. These are specified in build-config.json . Other details of OTP operation can be modified without rebuilding the graph. These run-time configuration options are found in router-config.json . Finally, otp-config.json contains simple switches that enable or disable system-wide features. Configuration types The OTP configuration files use the JSON file format. OTP allows comments and unquoted field names in the JSON configuration files to be more human-friendly. OTP supports all the basic JSON types: nested objects {...} , arrays [] , numbers 789.0 and boolean true or false . In addition to these basic types some configuration parameters are parsed with some restrictions. In the documentation below we will refer to the following types: Type Description Examples boolean This is the Boolean JSON type. true or false number This is the Number JSON type. 1 , 5 , 3.14 string A quoted string. This is the String JSON type. \"This is a string!\" Type [] Array of of given Type. This is the Array JSON type. [ 1, 2, 3 ] double A decimal floating point number . 64 bit. 3.14 integer A decimal integer number . 32 bit. 1 , -7 , 2100200300 long A decimal integer number . 64 bit. -1234567890123456789 enum A fixed set of string literals. BicycleOptimize: \"QUICK\" , \"SAFE\" ... enum-map List of key/value pairs, where the key is a enum and the value can be any given type. { RAIL: 1.2, BUS: 2.3 } enum-set List of enum string values [ \"RAIL\", \"TRAM\" ] locale Language[\\_country[\\_variant]] . A Locale object represents a specific geographical, political, or cultural region. For more information see the Java 11 Locale . en_US , nn_NO date Local date. The format is YYYY-MM-DD (ISO-8601). 2020-09-21 date or period A local date , or a period relative to today. The local date has the format YYYY-MM-DD and the period has the format PnYnMnD or -PnYnMnD where n is a integer number. P1Y is one year from now, -P3M2D means 3 months and 2 days ago, and P1D means tomorrow. regexp pattern A regular expression pattern used to match a sting. \"$^\" matches an empty string. \"gtfs\" matches \"A-*gtfs*-file.zip\" . \"$\\w{3})-.*\\.xml^\" matches a filename with 3 alpha-numeric characters in the beginning of the filename and .xml as file extension. uri An URI path to a resource like a file or a URL. \"gs://bucket/path/a.obj\" \"http://foo.bar/\" `\"file:///Users/x/local/file\" linear function A linear function with one input parameter(x) used to calculate a value. Usually used to calculate a limit. For example to calculate a limit in seconds to be 1 hour plus 2 times the value(x) use: 3600 + 2.0 x , to set an absolute value(3000) use: 3000 + 0x \"600 + 2.0 x\" System-wide Configuration Using the file otp-config.json you can enable or disable different APIs and experimental Sandbox Extensions . By default, all supported APIs are enabled and all sandbox features are disabled. So for most OTP2 use cases it is not necessary to create this file. Features that can be toggled in this file are generally only affect the routing phase of OTP2 usage, but for consistency all such \"feature flags\", even those that would affect graph building, are managed in this one file. See the OTPFeature Java class for an enumeration of all available features and their default settings. Here is an example: // otp-config.json { \"otpFeatures\" : { \"APIBikeRental\" : false , \"SandboxExampleAPIGraphStatistics\" : true } } Graph Build Configuration This table lists all the JSON properties that can be defined in a build-config.json file. These will be stored in the graph itself, and affect any server that subsequently loads that graph. Sections follow that describe particular settings in more depth. config key description value type value default notes areaVisibility Perform visibility calculations. If this is true OTP attempts to calculate a path straight through an OSM area using the shortest way rather than around the edge of it. (These calculations can be time consuming). boolean false banDiscouragedWalking should walking should be allowed on OSM ways tagged with foot=discouraged\" boolean false banDiscouragedBiking should walking should be allowed on OSM ways tagged with bicycle=discouraged\" boolean false dataImportReport Generate nice HTML report of Graph errors/warnings boolean false distanceBetweenElevationSamples TODO OTP2 double 10 elevationBucket If specified, download NED elevation tiles from the given AWS S3 bucket object null provide an object with accessKey , secretKey , and bucketName for AWS S3 elevationUnitMultiplier Specify a multiplier to convert elevation units from source to meters double 1.0 see Elevation unit conversion embedRouterConfig Embed the Router config in the graph, which allows it to be sent to a server fully configured over the wire boolean true extraEdgesStopPlatformLink add extra edges when linking a stop to a platform, to prevent detours along the platform edge boolean false fares A specific fares service to use object null see fares configuration islandWithStopsMaxSize Pruning threshold for islands with stops. Any such island under this size will be pruned int 5 islandWithoutStopsMaxSize Pruning threshold for islands without stops. Any such island under this size will be pruned int 40 matchBusRoutesToStreets Based on GTFS shape data, guess which OSM streets each bus runs on to improve stop linking boolean false maxDataImportIssuesPerFile If number of data import issues is larger then specified maximum number of issues the report will be split in multiple files int 1,000 maxInterlineDistance Maximal distance between stops in meters that will connect consecutive trips that are made with same vehicle int 200 units: meters maxTransferDistance Transfers up to this length in meters will be pre-calculated and included in the Graph double 2,000 units: meters multiThreadElevationCalculations If true, the elevation module will use multi-threading during elevation calculations. boolean false see Elevation Data Calculation Optimizations osmNaming A custom OSM namer to use object null see custom naming osmWayPropertySet Custom OSM way properties string default options: default , finland , norway , uk platformEntriesLinking Link unconnected entries to public transport platforms boolean false readCachedElevations If true, reads in pre-calculated elevation data. boolean true see Elevation Data Calculation Optimizations staticBikeParkAndRide Whether we should create bike P+R stations from OSM data boolean false staticBikeRental Whether bike rental stations should be loaded from OSM, rather than periodically dynamically pulled from APIs boolean false staticParkAndRide Whether we should create car P+R stations from OSM data boolean true streets Include street input files (OSM/PBF) boolean true storage Configure access to data sources like GRAPH/OSM/DEM/GTFS/NETEX/ISSUE-REPORT. object null subwayAccessTime Minutes necessary to reach stops served by trips on routes of route_type=1 (subway) from the street double 2.0 units: minutes transit Include all transit input files (GTFS) from scanned directory boolean true transitServiceStart Limit the import of transit services to the given start date. Inclusive . Use an absolute date or a period relative to the day the graph is build. To specify a week before the build date use a negative period like -P1W . date or period \u2212P1Y 2020\u201101\u201101, \u2212P1M3D, \u2212P3W transitServiceEnd Limit the import of transit services to the given end date. Inclusive . Use an absolute date or a period relative to the day the graph is build. date or period P3Y 2022\u201112\u201131, P1Y6M10D, P12W useTransfersTxt Create direct transfer edges from transfers.txt in GTFS, instead of based on distance boolean false writeCachedElevations If true, writes the calculated elevation data. boolean false see Elevation Data Calculation Optimizations This list of parameters in defined in the BuildConfig.java . Storage The storage section of build-config.json allows you to override the default behavior of scanning for input files in the base directory and writing output files (such as the graph and error reports) to that same directory. In OTP2 it is now possible to read and write data located outside the local filesystem (including cloud storage services) or at various different locations around the local filesystem. If your OTP instance is running on a cloud compute service, you may get significantly faster start-up and graph build times if you use the cloud storage directly instead of copying the files back and forth to cloud server instances. This also simplifies the deployment process. Specifying Data Sources Here is a summary of the configuration keys that can be nested inside the storage property of the build-config JSON to specify input and output data sources: config key description value type value default gsCredentials Use an environment variable to point to the Google Cloud credentials: \"${MY_GOC_SERVICE}\" . string null graph Absolute path where the graph file will be written, overriding the default of graph.obj in the base directory. Note that currently this option will also affect where the server reads the graph from. uri null streetGraph Absolute path to the input street-graph file. uri null osm List of absolute paths of OpenStreetMap input files to read. uri [] null dem List of absolute paths of Elevation DEM input files to read. uri [] null gtfs List of GTFS transit data files to read. uri [] null netex List of NeTEx transit data files to read. uri [] null buildReportDir Path to directory where the build issue report will be written. uri null localFileNamePatterns Patterns used in determining the type of input files from their names. object null For example, this configuration could be used to load GTFS and OSM inputs from Google Cloud Storage: // build-config.json { \"storage\" : { \"osm\" : [ \"gs://bucket-name/streets.pbf\" ], \"gtfs\" : [ \"gs://bucket-name/transit1.zip\" , \"gs://bucket-name/transit2.zip\" ] } } The Google Storage system will inherit the permissions of the server it's running on within Google Cloud. It is also possible to supply credentials in this configuration file (see example below). Note that when files are specified with URIs in this configuration, the file types do not need to be inferred from the file names so these GTFS files can have any names - there is no requirement that they have the letters \"gtfs\" in them. The default behavior of scanning the base directory for inputs is overridden independently for each file type. So in the above configuration, GTFS and OSM will be loaded from Google Cloud Storage, but OTP2 will still scan the base directory for all other types such as DEM files. Supplying an empty array for a particular file type will ensure that no inputs of that type are loaded, including by local directory scanning. See the comments in the source code of class StorageConfig.java for an up-to-date detailed description of each config parameter. Local Filename Patterns When scanning the base directory for inputs, each file's name is checked against patterns to detect what kind of file it is. These patterns can be overridden in the config, by nesting a localFileNamePatterns property inside the storage property (see example below). Here are the keys you can place inside localFileNamePatterns : config key description value type value default osm Pattern used to match Open Street Map files on local disk regexp pattern (?i)(\\.pbf) dem Pattern used to match Elevation DEM files on local disk regexp pattern (?i)\\.tiff?$ gtfs Pattern used to match GTFS files on local disk regexp pattern (?i)gtfs netex Pattern used to match NeTEx files on local disk regexp pattern (?i)netex OTP1 used to peek inside ZIP files and read the CSV tables to guess if a ZIP was indeed GTFS. Now that we support remote input files (cloud storage or arbitrary URLs) not all data sources allow seeking within files to guess what they are. Therefore, like all other file types GTFS is now detected from a filename pattern. It is not sufficient to look for the .zip extension because Netex data is also often supplied in a ZIP file. Storage example // build-config.json { \"storage\" : { // Use the GCS_SERVICE_CREDENTIALS environment variable to locate GCS credentials \"gsCredentials\" : \"${GCS_SERVICE_CREDENTIALS}\" , \"streetGraph\" : \"file:///Users/kelvin/otp/streetGraph.obj\" , \"osm\" : [ \"gs://bucket-name/shared-osm-file.pbf\" ], \"localFileNamePatterns\" : { // All filenames that start with \"g-\" and end with \".zip\" is imported as a GTFS file. \"gtfs\" : \"^g-.*\\\\.zip$\" } } } Limit the transit service period The properties transitServiceStart and transitServiceEnd can be used to limit the service dates. This affects both GTFS service calendars and dates. The service calendar is reduced and dates outside the period are dropped. OTP2 will compute a transit schedule for every day for which it can find at least one trip running. On the other hand, OTP will waste resources if a service end date is unbounded or very large ( 9999-12-31 ). To avoid this, limit the OTP service period. Also, if you provide a service with multiple feeds they may have different service end dates. To avoid inconsistent results, the period can be limited, so all feeds have data for the entire period. The default is to use a period of 1 year before, and 3 years after the day the graph is built. Limiting the period will not improve the search performance, but OTP will build faster and load faster in most cases. The transitServiceStart and transitServiceEnd parameters are set using an absolute date like 2020-12-31 or a period like P1Y6M5D relative to the graph build date. Negative periods is used to specify dates in the past. The period is computed using the system time-zone, not the feed time-zone. Also, remember that the service day might be more than 24 hours. So be sure to include enough slack to account for the this. Setting the limits too wide have very little impact and is in general better than trying to be exact. The period and date format follow the ISO 8601 standard. Reaching a subway platform The ride locations for some modes of transport such as subways and airplanes can be slow to reach from the street. When planning a trip, we need to allow additional time to reach these locations to properly inform the passenger. For example, this helps avoid suggesting short bus rides between two subway rides as a way to improve travel time. You can specify how long it takes to reach a subway platform // build-config.json { \"subwayAccessTime\" : 2.5 } Stops in GTFS do not necessarily serve a single transit mode, but in practice this is usually the case. This additional access time will be added to any stop that is visited by trips on subway routes (GTFS route_type = 1). This setting does not generalize well to airplanes because you often need much longer to check in to a flight (2-3 hours for international flights) than to alight and exit the airport (perhaps 1 hour). Therefore there is currently no per-mode access time, it is subway-specific. Transferring within stations Subway systems tend to exist in their own layer of the city separate from the surface, though there are exceptions where tracks lie right below the street and transfers happen via the surface. In systems where the subway is quite deep and transfers happen via tunnels, the time required for an in-station transfer is often less than that for a surface transfer. A proposal was made to provide detailed station pathways in GTFS but it is not in common use. One way to resolve this problem is by ensuring that the GTFS feed codes each platform as a separate stop, then micro-mapping stations in OSM. When OSM data contains a detailed description of walkways, stairs, and platforms within a station, GTFS stops can be linked to the nearest platform and transfers will happen via the OSM ways, which should yield very realistic transfer time expectations. This works particularly well in above-ground train stations where the layering of non-intersecting ways is less prevalent. Here's an example in the Netherlands: View Larger Map When such micro-mapping data is not available, we need to rely on information from GTFS including how stops are grouped into stations and a table of transfer timings where available. During the graph build, OTP can create preferential connections between each pair of stops in the same station to favor in-station transfers: // build-config.json { \"stationTransfers\" : true } Note that this method is at odds with micro-mapping and might make some transfers artificially short. Elevation data OpenTripPlanner can \"drape\" the OSM street network over a digital elevation model (DEM). This allows OTP to draw an elevation profile for the on-street portion of itineraries, and helps provide better routing for bicyclists. It even helps avoid hills for walking itineraries. DEMs are usually supplied as rasters (regular grids of numbers) stored in image formats such as GeoTIFF. U.S. National Elevation Dataset In the United States, a high resolution National Elevation Dataset is available for the entire territory. It used to be possible for OTP to download NED tiles on the fly from a rather complex USGS SOAP service. This process was somewhat unreliable and would greatly slow down the graph building process. In any case the service has since been replaced. But the USGS would also deliver the whole dataset in bulk if you sent them a hard drive . We did this many years back and uploaded the entire data set to Amazon AWS S3. OpenTripPlanner contains another module that can automatically fetch data in this format from any Amazon S3 copy of the bulk data. You can configure it as follows in build-config.json : // router-config.json { \"elevationBucket\" : { \"accessKey\" : \"your-aws-access-key\" , \"secretKey\" : \"corresponding-aws-secret-key\" , \"bucketName\" : \"ned13\" } } This ned13 bucket is still available on S3 under a \"requester pays\" policy. As long as you specify valid AWS account credentials you should be able to download tiles, and any bandwidth costs will be billed to your AWS account. Once the tiles are downloaded for a particular geographic area, OTP will keep them in local cache for the next graph build operation. You should add the --cache <directory> command line parameter to specify your NED tile cache location. Geoid Difference Some elevation data sets are relative to mean sea level. At a global scale sea level is represented as a surface called the geoid, which is irregular in shape due to local gravitational anomalies. On the other hand, GPS elevations are reported relative to the WGS84 spheroid, a perfectly smooth mathematical surface approximating the geoid. In cases where the two elevation definitions are mixed, it may be necessary to adjust elevation values to avoid confusing users with things like negative elevation values in places clearly above sea level. See issue #2301 for detailed discussion of this. OTP allows you to adjust the elevation values reported in API responses in two ways. The first way is to store ellipsoid (GPS) elevation values internally, but apply a single geoid difference value in the OTP client where appropriate to display elevations above sea level. This ellipsoid to geoid difference is returned in each trip plan response in the ElevationMetadata field. Using a single value can be sufficient for smaller OTP deployments, but might result in incorrect values at the edges of larger OTP deployments. If your OTP instance uses this, it is recommended to set a default request value in the router-config.json file as follows: // router-config.json { \"routingDefaults\" : { \"geoidElevation\" : true } } The second way is to precompute these geoid difference values at a more granular level and store all elevations internally relative to the geoid (sea level). Elevations returned in the API responses will then not need to be adjusted to match end users' intuitive understanding of elevation. In order to speed up calculations, these geoid difference values are calculated and cached using only 2 significant digits of GPS coordinates. This is more than enough detail for most regions of the world and should result in less than one meter of vertical error even in areas that have the largest geoid irregularities. To enable this, include the following in the build-config.json file: // build-config.json { \"includeEllipsoidToGeoidDifference\" : true } If the geoid difference values are precomputed, be careful to not set the routing resource value of geoidElevation to true in order to avoid having the graph-wide geoid added again to all elevation values in the relevant street edges in responses. Other raster elevation data For other parts of the world you will need a GeoTIFF file containing the elevation data. These are often available from national geographic surveys, or you can always fall back on the worldwide Space Shuttle Radar Topography Mission (SRTM) data. This not particularly high resolution (roughly 30 meters horizontally) but it can give acceptable results. Simply place the elevation data file in the directory with the other graph builder inputs, alongside the GTFS and OSM data. Make sure the file has a .tiff or .tif extension, and the graph builder should detect its presence and apply the elevation data to the streets. OTP should automatically handle DEM GeoTIFFs in most common projections. You may want to check for elevation-related error messages during the graph build process to make sure OTP has properly discovered the projection. If you are using a DEM in unprojected coordinates make sure that the axis order is (longitude, latitude) rather than (latitude, longitude). Unfortunately there is no reliable standard for WGS84 axis order, so OTP uses the same axis order as the above-mentioned SRTM data, which is also the default for the popular Proj4 library. DEM files(USGS DEM) is not supported by OTP, but can be converted to GeoTIFF with tools like GDAL . Use gdal_merge.py -o merged.tiff *.dem to merge a set of dem files into one tif file. See Interline PlanetUtils for a set of scripts to download, merge, and resample Mapzen/Amazon Terrain Tiles . Elevation unit conversion By default, OTP expects the elevation data to use metres. However, by setting elevationUnitMultiplier in build-config.json , it is possible to define a multiplier that converts the elevation values from some other unit to metres. // build-config.json { // Correct conversation multiplier when source data uses decimetres instead of metres \"elevationUnitMultiplier\" : 0.1 } Elevation Data Calculation Optimizations Calculating elevations on all StreetEdges can take a dramatically long time. In a very large graph build for multiple Northeast US states, the time it took to download the elevation data and calculate all of the elevations took 5,509 seconds (roughly 1.5 hours). If you are using cloud computing for your OTP instances, it is recommended to create prebuilt images that contain the elevation data you need. This will save time because all of the data won't need to be downloaded. However, the bulk of the time will still be spent calculating elevations for all of the street edges. Therefore, a further optimization can be done to calculate and save the elevation data during a graph build and then save it for future use. Reusing elevation data from previous builds In order to write out the precalculated elevation data, add this to your build-config.json file: // build-config.json { \"writeCachedElevations\" : true } After building the graph, a file called cached_elevations.obj will be written to the cache directory. By default, this file is not written during graph builds. There is also a graph build parameter called readCachedElevations which is set to true by default. In graph builds, the elevation module will attempt to read the cached_elevations.obj file from the cache directory. The cache directory defaults to /var/otp/cache , but this can be overriden via the CLI argument --cache <directory> . For the same graph build for multiple Northeast US states, the time it took with using this predownloaded and precalculated data became 543.7 seconds (roughly 9 minutes). The cached data is a lookup table where the coordinate sequences of respective street edges are used as keys for calculated data. It is assumed that all of the other input data except for the OpenStreetMap data remains the same between graph builds. Therefore, if the underlying elevation data is changed, or different configuration values for elevationUnitMultiplier or includeEllipsoidToGeoidDifference are used, then this data becomes invalid and all elevation data should be recalculated. Over time, various edits to OpenStreetMap will cause this cached data to become stale and not include new OSM ways. Therefore, periodic update of this cached data is recommended. Configuring multi-threading during elevation calculations For unknown reasons that seem to depend on data and machine settings, it might be faster to use a single processor. For this reason, multi-threading of elevation calculations is only done if multiThreadElevationCalculations is set to true. To enable multi-threading in the elevation module, add the following to the build-config.json file: // build-config.json { \"multiThreadElevationCalculations\" : true } Fares configuration By default OTP will compute fares according to the GTFS specification if fare data is provided in your GTFS input. It is possible to turn off this by setting the fare to \"off\". For more complex scenarios or to handle bike rental fares, it is necessary to manually configure fares using the fares section in build-config.json . You can combine different fares (for example transit and bike-rental) by defining a combinationStrategy parameter, and a list of sub-fares to combine (all fields starting with fare are considered to be sub-fares). // build-config.json { // Select the custom fare \"seattle\" \"fares\" : \"seattle\" , // OR this alternative form that could allow additional configuration \"fares\" : { \"type\" : \"seattle\" } } // build-config.json { \"fares\" : { // Combine two fares by simply adding them \"combinationStrategy\" : \"additive\" , // First fare to combine \"fare0\" : \"new-york\" , // Second fare to combine \"fare1\" : { \"type\" : \"bike-rental-time-based\" , \"currency\" : \"USD\" , \"prices\" : { // For trip shorter than 30', $4 fare \"30\" : 4.00 , // For trip shorter than 1h, $6 fare \"1:00\" : 6.00 } } // We could also add fareFoo, fareBar... } } Turning the fare service off , this will ignore any fare data in the provided GTFS data. // build-config.json { \"fares\" : \"off\" } The current list of custom fare type is: bike-rental-time-based - accepting the following parameters: currency - the ISO 4217 currency code to use, such as \"EUR\" or \"USD\" , prices - a list of {time, price}. The resulting cost is the smallest cost where the elapsed time of bike rental is lower than the defined time. san-francisco (no parameters) new-york (no parameters) seattle (no parameters) off (no parameters) The current list of combinationStrategy is: additive - simply adds all sub-fares. OSM / OpenStreetMap configuration It is possible to adjust how OSM data is interpreted by OpenTripPlanner when building the road part of the routing graph. Way property sets OSM tags have different meanings in different countries, and how the roads in a particular country or region are tagged affects routing. As an example are roads tagged with `highway=trunk (mainly) walkable in Norway, but forbidden in some other countries. This might lead to OTP being unable to snap stops to these roads, or by giving you poor routing results for walking and biking. You can adjust which road types that are accessible by foot, car & bicycle as well as speed limits, suitability for biking and walking. There are currently 3 wayPropertySets defined; default which is based on California/US mapping standard norway which is adjusted to rules and speeds in Norway uk which is adjusted to rules and speed in the UK To add your own custom property set have a look at org.opentripplanner.graph_builder.module.osm.NorwayWayPropertySet and org.opentripplanner.graph_builder.module.osm.DefaultWayPropertySet . If you choose to mainly rely on the default rules, make sure you add your own rules first before applying the default ones. The mechanism is that for any two identical tags, OTP will use the first one. // build-config.json { \"osmWayPropertySet\" : \"norway\" } Custom naming You can define a custom naming scheme for elements drawn from OSM by defining an osmNaming field in build-config.json , such as: // build-config.json { \"osmNaming\" : \"portland\" } There is currently only one custom naming module called portland (which has no parameters). Router configuration This section covers all options that can be set for each router using the router-config.json file. These options can be applied by the OTP server without rebuilding the graph. config key description value type value default notes routingDefaults Default routing parameters, which will be applied to every request object see routing defaults streetRoutingTimeout maximum time limit for street route queries double null units: seconds; see timeout requestLogFile Path to a plain-text file where requests will be logged string null see logging incoming requests transit Transit tuning parameters TransitRoutingConfig see Tuning transit routing updaters configure real-time updaters, such as GTFS-realtime feeds object null see configuring real-time updaters transmodelApi configure Entur Transmodel API ( Sandbox ) object null See the code for parameters, no doc provided. Routing defaults There are many trip planning options used in the OTP web API, and more exist internally that are not exposed via the API. You may want to change the default value for some of these parameters, i.e. the value which will be applied unless it is overridden in a web API request. A full list of them can be found in the RoutingRequest . Any public field or setter method in this class can be given a default value using the routingDefaults section of router-config.json as follows: // router-config.json { \"routingDefaults\" : { \"walkSpeed\" : 2.0 , \"stairsReluctance\" : 4.0 , \"carDropoffTime\" : 240 } } Tuning itinerary filtering Nested inside routingDefaults {...} in router-config.json . OTP2 may produce numerous pareto-optimal results when using time , number-of-transfers and generalized-cost as criteria. Use the parameters listed here to reduce/filter the itineraries return by the search engine before returning the results to client. config key description value type value default debugItineraryFilter Enable this to attach a system notice to itineraries instead of removing them. Some filters are not configurable, byt will show up in the system-notice if debugging is enabled. boolean false groupBySimilarityKeepOne Pick ONE itinerary from each group after putting itineraries that is 85% similar together. double 0.85 (85%) groupBySimilarityKeepNumOfItineraries Reduce the number of itineraries to the requested number by reducing each group of itineraries grouped by 68% similarity. double 0.68 (68%) transitGeneralizedCostLimit A relative maximum limit for the generalized cost for transit itineraries. The limit is a linear function of the minimum generalized-cost. The function is used to calculate a max-limit. The max-limit is then used to to filter by generalized-cost. Transit itineraries with a cost higher than the max-limit is dropped from the result set. None transit itineraries is excluded from the filter. To set a filter to be 1 hour plus 2 times the best cost use: 3600 + 2.0 x . To set an absolute value(3000) use: 3000 + 0x linear function null Group-by-filters The group-by-filter is a bit complex, but should be simple to use. Set debugItineraryFilter=true and experiment with searchWindow and the two group-by parameters( debugItineraryFilter and groupBySimilarityKeepNumOfItineraries ). The group-by-filter work by grouping itineraries together and then reducing the number of itineraries in each group, keeping the itinerary/itineraries with the best generalized-cost . The group-by function first pick all transit legs that account for more than N% of the itinerary based on distance traveled. This become the group-key. To keys are the same if all legs in one of the keys also exist in the other. Note, one key may have a lager set of legs than the other, but they can still be the same. When comparing to legs we compare the tripId and make sure the legs overlap in place and time. Two legs are the same if both legs ride at least a common subsection of the same trip. The groupBySimilarityKeepOne filter will keep ONE itinerary in each group. The groupBySimilarityKeepNumOfItineraries is a bit more complex, because it uses the numOfItineraries request parameter to estimate a maxLimit for each group. For example, if the numOfItineraries is 5 elements and there is 3 groups, we set the max-limit for each group to 2, returning between 4 and 6 elements depending on the distribution. The max-limit can never be less than 1. Drive-to-transit routing defaults When using the \"park and ride\" or \"kiss and ride\" modes (drive to transit), the initial driving time to reach a transit stop or park and ride facility is constrained. You can set a drive time limit in seconds by adding a line like maxPreTransitTime = 1200 to the routingDefaults section. If the limit is too high on a very large street graph, routing performance may suffer. Boarding and alighting times Sometimes there is a need to configure a longer ride or alighting times for specific modes, such as airplanes or ferries, where the check-in process needs to be done in good time before ride. The ride time is added to the time when going from the stop (offboard) vertex to the onboard vertex, and the alight time is added vice versa. The times are configured as seconds needed for the ride and alighting processes in router-config.json as follows: // router-config.json { \"boardTimes\" : { \"AIRPLANE\" : 2700 }, \"alightTimes\" : { \"AIRPLANE\" : 1200 } } Timeout In OTP1 path searches sometimes toke a long time to complete. With the new Raptor algorithm this not the case anymore. The street part of the routing may still take a long time if searching very long distances. You can set the street routing timeout to avoid tying up server resources on pointless searches and ensure that your users receive a timely response. You can also limit the max distance to search for WALK, BIKE and CAR. When a search times out, a WARN level log entry is made with information that can help identify problematic searches and improve our routing methods. There are no timeouts for the transit part of the routing search, instead configure a reasonable dynamic search-window. To set the street routing timeout use the following config: // router-config.json { \"streetRoutingTimeout\" : 5.5 } This specifies a timeout in (optionally fractional) seconds. The search abort after this many seconds and any paths found are returned to the client. Logging incoming requests You can log some characteristics of trip planning requests in a file for later analysis. Some transit agencies and operators find this information useful for identifying existing or unmet transportation demand. Logging will be performed only if you specify a log file name in the router config: // router-config.json { \"requestLogFile\" : \"/var/otp/request.log\" } Each line in the resulting log file will look like this: 2016-04-19T18:23:13.486 0:0:0:0:0:0:0:1 ARRIVE 2016-04-07T00:17 WALK,BUS,CABLE_CAR,TRANSIT,BUSISH 45.559737193889966 -122.64999389648438 45.525592487765635 -122.39044189453124 6095 3 5864 3 6215 3 The fields separated by whitespace are (in order): Date and time the request was received IP address of the user Arrive or depart search The arrival or departure time A comma-separated list of all transport modes selected Origin latitude and longitude Destination latitude and longitude Finally, for each itinerary returned to the user, there is a travel duration in seconds and the number of transit vehicles used in that itinerary. Tuning transit routing Nested inside transit {...} in router-config.json . Some of these parameters for tuning transit routing is only available through configuration and cannot be set in the routing request. These parameters work together with the default routing request and the actual routing request. config key description value type value default maxNumberOfTransfers Use this parameter to allocate enough space for Raptor. Set it to the maximum number of transfers for any given itinerary expected to be found within the entire transit network. The memory overhead of setting this higher than the maximum number of transfers is very little so it is better to set it too high then to low. int 12 scheduledTripBinarySearchThreshold The threshold is used to determine when to perform a binary trip schedule search to reduce the number of trips departure time lookups and comparisons. When testing with data from Entur and all of Norway as a Graph, the optimal value was around 50. Changing this may improve the performance with just a few percent. int 50 iterationDepartureStepInSeconds Step for departure times between each RangeRaptor iterations. A transit network usually uses minute resolution for its depature and arrival times. To match that, set this variable to 60 seconds. int 60 searchThreadPoolSize Split a travel search in smaller jobs and run them in parallel to improve performance. Use this parameter to set the total number of executable threads available across all searches. Multiple searches can run in parallel - this parameter have no effect with regard to that. If 0, no extra threads are started and the search is done in one thread. int 0 dynamicSearchWindow The dynamic search window coefficients used to calculate the EDT(earliest-departure-time), LAT(latest-arrival-time) and SW(raptor-search-window) using heuristics. object null stopTransferCost Use this to set a stop transfer cost for the given TransferPriority . The cost is applied to boarding and alighting at all stops. All stops have a transfer cost priority set, the default is ALLOWED . The stopTransferCost parameter is optional, but if listed all values must be set. enum map null Tuning transit routing - Dynamic search window Nested inside transit : { dynamicSearchWindow : { ... } } in router-config.json . config key description value type value default minTripTimeCoefficient The coefficient to multiply with minimum travel time found using a heuristic search. This value is added to the minWinTimeMinutes . A value between 0.0 to 3.0 is expected to give ok results. double 0.75 minWinTimeMinutes The constant minimum number of minutes for a raptor search window. Use a value between 20-180 minutes in a normal deployment. int 40 maxWinTimeMinutes Set an upper limit to the calculation of the dynamic search window to prevent exceptionable cases to cause very long search windows. Long search windows consumes a lot of resources and may take a long time. Use this parameter to tune the desired maximum search time. int 180 (3 hours) stepMinutes The search window is rounded of to the closest multiplication of N minutes. If N=10 minutes, the search-window can be 10, 20, 30 ... minutes. It the computed search-window is 5 minutes and 17 seconds it will be rounded up to 10 minutes. int 10 Tuning transit routing - Stop transfer cost Nested inside transit : { stopTransferCost : { ... } } in router-config.json . This cost is in addition to other costs like boardCost and indirect cost from waiting (board-/alight-/transfer slack). You should account for this when you tune the routing search parameters. If not set the stopTransferCost is ignored. This is only available for NeTEx imported Stops. The cost is a scalar, but is equivalent to the felt cost of riding a transit trip for 1 second. config key description value type DISCOURAGED Use a very high cost like 72 000 to eliminate transfers ath the stop if not the only option. int ALLOWED Allowed, but not recommended. Use something like 150 . int RECOMMENDED Use a small cost penalty like 60 . int PREFERRED The best place to do transfers. Should be set to 0 (zero). int Use values in a range from 0 to 100 000 . All key/value pairs are required if the stopTransferCost is listed. Transit example // router-config.json { \"transit\" : { \"maxNumberOfTransfers\" : 12 , \"scheduledTripBinarySearchThreshold\" : 50 , \"iterationDepartureStepInSeconds\" : 60 , \"searchThreadPoolSize\" : 0 , \"dynamicSearchWindow\" : { \"minTripTimeCoefficient\" : 0.4 , \"minTimeMinutes\" : 30 , \"maxLengthMinutes\" : 360 , \"stepMinutes\" : 10 }, \"stopTransferCost\" : { \"DISCOURAGED\" : 72000 , \"ALLOWED\" : 150 , \"RECOMMENDED\" : 60 , \"PREFERRED\" : 0 } } } Real-time data GTFS feeds contain schedule data that is is published by an agency or operator in advance. The feed does not account for unexpected service changes or traffic disruptions that occur from day to day. Thus, this kind of data is also referred to as 'static' data or 'theoretical' arrival and departure times. GTFS-Realtime The GTFS-RT spec complements GTFS with three additional kinds of feeds. In contrast to the base GTFS schedule feed, they provide real-time updates ( 'dynamic' data) and are are updated from minute to minute. Alerts are text messages attached to GTFS objects, informing riders of disruptions and changes. TripUpdates report on the status of scheduled trips as they happen, providing observed and predicted arrival and departure times for the remainder of the trip. VehiclePositions give the location of some or all vehicles currently in service, in terms of geographic coordinates or position relative to their scheduled stops. Bicycle rental systems Besides GTFS-RT transit data, OTP can also fetch real-time data about bicycle rental networks including the number of bikes and free parking spaces at each station. We support bike rental systems from JCDecaux, BCycle, VCub, Keolis, Bixi, the Dutch OVFiets system, ShareBike, GBFS and a generic KML format. It is straightforward to extend OTP to support any bike rental system that exposes a JSON API or provides KML place markers, though it requires writing a little code. The generic KML needs to be in format like <?xml version=\"1.0\" encoding=\"utf-8\" ?> <kml xmlns= \"http://www.opengis.net/kml/2.2\" > <Document id= \"root_doc\" > <Schema name= \"citybikes\" id= \"citybikes\" > <SimpleField name= \"ID\" type= \"int\" ></SimpleField> </Schema> <Placemark> <name> A Bike Station </name> <ExtendedData><SchemaData schemaUrl= \"#citybikes\" > <SimpleData name= \"ID\" > 0 </SimpleData> </SchemaData></ExtendedData> <Point><coordinates> 24.950682884886643,60.155923430488102 </coordinates></Point> </Placemark> </Document></kml> Configuring real-time updaters Real-time data can be provided using either a pull or push system. In a pull configuration, the GTFS-RT consumer polls the real-time provider over HTTP. That is to say, OTP fetches a file from a web server every few minutes. In the push configuration, the consumer opens a persistent connection to the GTFS-RT provider, which then sends incremental updates immediately as they become available. OTP can use both approaches. The OneBusAway GTFS-realtime exporter project provides this kind of streaming, incremental updates over a websocket rather than a single large file. Real-time data sources are configured in router-config.json . The updaters section is an array of JSON objects, each of which has a type field and other configuration fields specific to that type. Common to all updater entries that connect to a network resource is the url field. // router-config.json { // Routing defaults are any public field or setter in the Java class // org.opentripplanner.routing.api.request.RoutingRequest \"routingDefaults\" : { \"numItineraries\" : 6 , \"walkSpeed\" : 2.0 , \"stairsReluctance\" : 4.0 , \"carDropoffTime\" : 240 }, \"updaters\" : [ // GTFS-RT service alerts (frequent polling) { \"type\" : \"real-time-alerts\" , \"frequencySec\" : 30 , \"url\" : \"http://developer.trimet.org/ws/V1/FeedSpecAlerts/appID/0123456789ABCDEF\" , \"feedId\" : \"TriMet\" }, // Polling bike rental updater. // sourceType can be: jcdecaux, b-cycle, bixi, keolis-rennes, ov-fiets, // city-bikes, citi-bike-nyc, next-bike, vcub, kml { \"type\" : \"bike-rental\" , \"frequencySec\" : 300 , \"sourceType\" : \"city-bikes\" , \"url\" : \"http://host.domain.tld\" }, //<!--- San Francisco Bay Area bike share --> { \"type\" : \"bike-rental\" , \"frequencySec\" : 300 , \"sourceType\" : \"sf-bay-area\" , \"url\" : \"http://www.bayareabikeshare.com/stations/json\" }, //<!--- Tampa Area bike share --> { \"type\" : \"bike-rental\" , \"frequencySec\" : 300 , \"sourceType\" : \"gbfs\" , \"url\" : \"http://coast.socialbicycles.com/opendata/\" }, // Polling bike rental updater for DC bikeshare (a Bixi system) // Negative update frequency means to run once and then stop updating (essentially static data) { \"type\" : \"bike-rental\" , \"sourceType\" : \"bixi\" , \"url\" : \"https://www.capitalbikeshare.com/data/stations/bikeStations.xml\" , \"frequencySec\" : -1 }, // Bike parking availability { \"type\" : \"bike-park\" }, // Polling for GTFS-RT TripUpdates) { \"type\" : \"stop-time-updater\" , \"frequencySec\" : 60 , // this is either http or file... shouldn't it default to http or guess from the presence of a URL? \"sourceType\" : \"gtfs-http\" , \"url\" : \"http://developer.trimet.org/ws/V1/TripUpdate/appID/0123456789ABCDEF\" , \"feedId\" : \"TriMet\" }, // Streaming differential GTFS-RT TripUpdates over websockets { \"type\" : \"websocket-gtfs-rt-updater\" } ] } GBFS Configuration Steps to add a GBFS feed to a router: Add one entry in the updater field of router-config.json in the format // router-config.json { \"type\" : \"bike-rental\" , \"frequencySec\" : 60 , \"sourceType\" : \"gbfs\" , \"url\" : \"http://coast.socialbicycles.com/opendata/\" } Follow these instructions to fill these fields: type: \"bike-rental\" frequencySec: frequency in seconds in which the GBFS service will be polled sourceType: \"gbfs\" url: the URL of the GBFS feed (do not include the gbfs.json at the end) * * For a list of known GBFS feeds see the list of known GBFS feeds Bike Rental Service Directory configuration (sandbox feature) To configure and url for the BikeRentalServiceDirectory . // router-config.json { \"bikeRentalServiceDirectoryUrl\" : \"https://api.dev.entur.io/mobility/v1/bikes\" } Configure using command-line arguments Certain settings can be provided on the command line, when starting OpenTripPlanner. See the CommandLineParameters class for a full list of arguments .","title":"Configuration"},{"location":"Configuration/#configuring-opentripplanner","text":"Note: if you are familiar with OTP1 configuration and are migrating to OTP2, please read the OTP2 Migration Guide to learn what has changed.","title":"Configuring OpenTripPlanner"},{"location":"Configuration/#base-directory","text":"On the OTP2 command line you must always specify a single directory after all the switches. This tells OTP2 where to look for any configuration files. By default OTP will also scan this directory for input files to build a graph (GTFS, OSM, elevation, and base street graphs) or the graph.obj file to load when starting a server. A typical OTP2 directory for a New York City graph might include the following: otp-config.json build-config.json router-config.json new-york-city-no-buildings.osm.pbf nyc-elevation.tiff long-island-rail-road.gtfs.zip mta-new-york-city-transit.gtfs.zip port-authority-of-new-york-new-jersey.gtfs.zip graph.obj You could have more than one of these directories if you are building separate graphs for separate regions. Each one should contain one or more GTFS feeds, a PBF OpenStreetMap file, some JSON configuration files, and any output files such as graph.obj . For convenience, especially if you work with only one graph at a time, you may want to place your OTP2 JAR file in this same directory. Note that file types are detected through a case-insensitive combination of file extension and words within the file name. GTFS file names must end in .zip and contain the letters gtfs , and OSM files must end in .pbf . It is also possible to provide a list of input files in the configuration, which will override this default behavior of scanning the base directory for input files. Scanning is overridden independently for each file type, and can point to remote cloud storage with arbitrary URIs. See the storage section for further details.","title":"Base Directory"},{"location":"Configuration/#three-scopes-of-configuration","text":"OTP is configured via three configuration JSON files which are read from the directory specified on its command line. We try to provide sensible defaults for every option, so all three of these files are optional, as are all the options within each file. Each configuration file corresponds to options that are relevant at a particular phase of OTP usage. Options and parameters that are taken into account during the graph building process will be \"baked into\" the graph, and cannot be changed later in a running server. These are specified in build-config.json . Other details of OTP operation can be modified without rebuilding the graph. These run-time configuration options are found in router-config.json . Finally, otp-config.json contains simple switches that enable or disable system-wide features.","title":"Three Scopes of Configuration"},{"location":"Configuration/#configuration-types","text":"The OTP configuration files use the JSON file format. OTP allows comments and unquoted field names in the JSON configuration files to be more human-friendly. OTP supports all the basic JSON types: nested objects {...} , arrays [] , numbers 789.0 and boolean true or false . In addition to these basic types some configuration parameters are parsed with some restrictions. In the documentation below we will refer to the following types: Type Description Examples boolean This is the Boolean JSON type. true or false number This is the Number JSON type. 1 , 5 , 3.14 string A quoted string. This is the String JSON type. \"This is a string!\" Type [] Array of of given Type. This is the Array JSON type. [ 1, 2, 3 ] double A decimal floating point number . 64 bit. 3.14 integer A decimal integer number . 32 bit. 1 , -7 , 2100200300 long A decimal integer number . 64 bit. -1234567890123456789 enum A fixed set of string literals. BicycleOptimize: \"QUICK\" , \"SAFE\" ... enum-map List of key/value pairs, where the key is a enum and the value can be any given type. { RAIL: 1.2, BUS: 2.3 } enum-set List of enum string values [ \"RAIL\", \"TRAM\" ] locale Language[\\_country[\\_variant]] . A Locale object represents a specific geographical, political, or cultural region. For more information see the Java 11 Locale . en_US , nn_NO date Local date. The format is YYYY-MM-DD (ISO-8601). 2020-09-21 date or period A local date , or a period relative to today. The local date has the format YYYY-MM-DD and the period has the format PnYnMnD or -PnYnMnD where n is a integer number. P1Y is one year from now, -P3M2D means 3 months and 2 days ago, and P1D means tomorrow. regexp pattern A regular expression pattern used to match a sting. \"$^\" matches an empty string. \"gtfs\" matches \"A-*gtfs*-file.zip\" . \"$\\w{3})-.*\\.xml^\" matches a filename with 3 alpha-numeric characters in the beginning of the filename and .xml as file extension. uri An URI path to a resource like a file or a URL. \"gs://bucket/path/a.obj\" \"http://foo.bar/\" `\"file:///Users/x/local/file\" linear function A linear function with one input parameter(x) used to calculate a value. Usually used to calculate a limit. For example to calculate a limit in seconds to be 1 hour plus 2 times the value(x) use: 3600 + 2.0 x , to set an absolute value(3000) use: 3000 + 0x \"600 + 2.0 x\"","title":"Configuration types"},{"location":"Configuration/#system-wide-configuration","text":"Using the file otp-config.json you can enable or disable different APIs and experimental Sandbox Extensions . By default, all supported APIs are enabled and all sandbox features are disabled. So for most OTP2 use cases it is not necessary to create this file. Features that can be toggled in this file are generally only affect the routing phase of OTP2 usage, but for consistency all such \"feature flags\", even those that would affect graph building, are managed in this one file. See the OTPFeature Java class for an enumeration of all available features and their default settings. Here is an example: // otp-config.json { \"otpFeatures\" : { \"APIBikeRental\" : false , \"SandboxExampleAPIGraphStatistics\" : true } }","title":"System-wide Configuration"},{"location":"Configuration/#graph-build-configuration","text":"This table lists all the JSON properties that can be defined in a build-config.json file. These will be stored in the graph itself, and affect any server that subsequently loads that graph. Sections follow that describe particular settings in more depth. config key description value type value default notes areaVisibility Perform visibility calculations. If this is true OTP attempts to calculate a path straight through an OSM area using the shortest way rather than around the edge of it. (These calculations can be time consuming). boolean false banDiscouragedWalking should walking should be allowed on OSM ways tagged with foot=discouraged\" boolean false banDiscouragedBiking should walking should be allowed on OSM ways tagged with bicycle=discouraged\" boolean false dataImportReport Generate nice HTML report of Graph errors/warnings boolean false distanceBetweenElevationSamples TODO OTP2 double 10 elevationBucket If specified, download NED elevation tiles from the given AWS S3 bucket object null provide an object with accessKey , secretKey , and bucketName for AWS S3 elevationUnitMultiplier Specify a multiplier to convert elevation units from source to meters double 1.0 see Elevation unit conversion embedRouterConfig Embed the Router config in the graph, which allows it to be sent to a server fully configured over the wire boolean true extraEdgesStopPlatformLink add extra edges when linking a stop to a platform, to prevent detours along the platform edge boolean false fares A specific fares service to use object null see fares configuration islandWithStopsMaxSize Pruning threshold for islands with stops. Any such island under this size will be pruned int 5 islandWithoutStopsMaxSize Pruning threshold for islands without stops. Any such island under this size will be pruned int 40 matchBusRoutesToStreets Based on GTFS shape data, guess which OSM streets each bus runs on to improve stop linking boolean false maxDataImportIssuesPerFile If number of data import issues is larger then specified maximum number of issues the report will be split in multiple files int 1,000 maxInterlineDistance Maximal distance between stops in meters that will connect consecutive trips that are made with same vehicle int 200 units: meters maxTransferDistance Transfers up to this length in meters will be pre-calculated and included in the Graph double 2,000 units: meters multiThreadElevationCalculations If true, the elevation module will use multi-threading during elevation calculations. boolean false see Elevation Data Calculation Optimizations osmNaming A custom OSM namer to use object null see custom naming osmWayPropertySet Custom OSM way properties string default options: default , finland , norway , uk platformEntriesLinking Link unconnected entries to public transport platforms boolean false readCachedElevations If true, reads in pre-calculated elevation data. boolean true see Elevation Data Calculation Optimizations staticBikeParkAndRide Whether we should create bike P+R stations from OSM data boolean false staticBikeRental Whether bike rental stations should be loaded from OSM, rather than periodically dynamically pulled from APIs boolean false staticParkAndRide Whether we should create car P+R stations from OSM data boolean true streets Include street input files (OSM/PBF) boolean true storage Configure access to data sources like GRAPH/OSM/DEM/GTFS/NETEX/ISSUE-REPORT. object null subwayAccessTime Minutes necessary to reach stops served by trips on routes of route_type=1 (subway) from the street double 2.0 units: minutes transit Include all transit input files (GTFS) from scanned directory boolean true transitServiceStart Limit the import of transit services to the given start date. Inclusive . Use an absolute date or a period relative to the day the graph is build. To specify a week before the build date use a negative period like -P1W . date or period \u2212P1Y 2020\u201101\u201101, \u2212P1M3D, \u2212P3W transitServiceEnd Limit the import of transit services to the given end date. Inclusive . Use an absolute date or a period relative to the day the graph is build. date or period P3Y 2022\u201112\u201131, P1Y6M10D, P12W useTransfersTxt Create direct transfer edges from transfers.txt in GTFS, instead of based on distance boolean false writeCachedElevations If true, writes the calculated elevation data. boolean false see Elevation Data Calculation Optimizations This list of parameters in defined in the BuildConfig.java .","title":"Graph Build Configuration"},{"location":"Configuration/#storage","text":"The storage section of build-config.json allows you to override the default behavior of scanning for input files in the base directory and writing output files (such as the graph and error reports) to that same directory. In OTP2 it is now possible to read and write data located outside the local filesystem (including cloud storage services) or at various different locations around the local filesystem. If your OTP instance is running on a cloud compute service, you may get significantly faster start-up and graph build times if you use the cloud storage directly instead of copying the files back and forth to cloud server instances. This also simplifies the deployment process.","title":"Storage"},{"location":"Configuration/#specifying-data-sources","text":"Here is a summary of the configuration keys that can be nested inside the storage property of the build-config JSON to specify input and output data sources: config key description value type value default gsCredentials Use an environment variable to point to the Google Cloud credentials: \"${MY_GOC_SERVICE}\" . string null graph Absolute path where the graph file will be written, overriding the default of graph.obj in the base directory. Note that currently this option will also affect where the server reads the graph from. uri null streetGraph Absolute path to the input street-graph file. uri null osm List of absolute paths of OpenStreetMap input files to read. uri [] null dem List of absolute paths of Elevation DEM input files to read. uri [] null gtfs List of GTFS transit data files to read. uri [] null netex List of NeTEx transit data files to read. uri [] null buildReportDir Path to directory where the build issue report will be written. uri null localFileNamePatterns Patterns used in determining the type of input files from their names. object null For example, this configuration could be used to load GTFS and OSM inputs from Google Cloud Storage: // build-config.json { \"storage\" : { \"osm\" : [ \"gs://bucket-name/streets.pbf\" ], \"gtfs\" : [ \"gs://bucket-name/transit1.zip\" , \"gs://bucket-name/transit2.zip\" ] } } The Google Storage system will inherit the permissions of the server it's running on within Google Cloud. It is also possible to supply credentials in this configuration file (see example below). Note that when files are specified with URIs in this configuration, the file types do not need to be inferred from the file names so these GTFS files can have any names - there is no requirement that they have the letters \"gtfs\" in them. The default behavior of scanning the base directory for inputs is overridden independently for each file type. So in the above configuration, GTFS and OSM will be loaded from Google Cloud Storage, but OTP2 will still scan the base directory for all other types such as DEM files. Supplying an empty array for a particular file type will ensure that no inputs of that type are loaded, including by local directory scanning. See the comments in the source code of class StorageConfig.java for an up-to-date detailed description of each config parameter.","title":"Specifying Data Sources"},{"location":"Configuration/#local-filename-patterns","text":"When scanning the base directory for inputs, each file's name is checked against patterns to detect what kind of file it is. These patterns can be overridden in the config, by nesting a localFileNamePatterns property inside the storage property (see example below). Here are the keys you can place inside localFileNamePatterns : config key description value type value default osm Pattern used to match Open Street Map files on local disk regexp pattern (?i)(\\.pbf) dem Pattern used to match Elevation DEM files on local disk regexp pattern (?i)\\.tiff?$ gtfs Pattern used to match GTFS files on local disk regexp pattern (?i)gtfs netex Pattern used to match NeTEx files on local disk regexp pattern (?i)netex OTP1 used to peek inside ZIP files and read the CSV tables to guess if a ZIP was indeed GTFS. Now that we support remote input files (cloud storage or arbitrary URLs) not all data sources allow seeking within files to guess what they are. Therefore, like all other file types GTFS is now detected from a filename pattern. It is not sufficient to look for the .zip extension because Netex data is also often supplied in a ZIP file.","title":"Local Filename Patterns"},{"location":"Configuration/#storage-example","text":"// build-config.json { \"storage\" : { // Use the GCS_SERVICE_CREDENTIALS environment variable to locate GCS credentials \"gsCredentials\" : \"${GCS_SERVICE_CREDENTIALS}\" , \"streetGraph\" : \"file:///Users/kelvin/otp/streetGraph.obj\" , \"osm\" : [ \"gs://bucket-name/shared-osm-file.pbf\" ], \"localFileNamePatterns\" : { // All filenames that start with \"g-\" and end with \".zip\" is imported as a GTFS file. \"gtfs\" : \"^g-.*\\\\.zip$\" } } }","title":"Storage example"},{"location":"Configuration/#limit-the-transit-service-period","text":"The properties transitServiceStart and transitServiceEnd can be used to limit the service dates. This affects both GTFS service calendars and dates. The service calendar is reduced and dates outside the period are dropped. OTP2 will compute a transit schedule for every day for which it can find at least one trip running. On the other hand, OTP will waste resources if a service end date is unbounded or very large ( 9999-12-31 ). To avoid this, limit the OTP service period. Also, if you provide a service with multiple feeds they may have different service end dates. To avoid inconsistent results, the period can be limited, so all feeds have data for the entire period. The default is to use a period of 1 year before, and 3 years after the day the graph is built. Limiting the period will not improve the search performance, but OTP will build faster and load faster in most cases. The transitServiceStart and transitServiceEnd parameters are set using an absolute date like 2020-12-31 or a period like P1Y6M5D relative to the graph build date. Negative periods is used to specify dates in the past. The period is computed using the system time-zone, not the feed time-zone. Also, remember that the service day might be more than 24 hours. So be sure to include enough slack to account for the this. Setting the limits too wide have very little impact and is in general better than trying to be exact. The period and date format follow the ISO 8601 standard.","title":"Limit the transit service period"},{"location":"Configuration/#reaching-a-subway-platform","text":"The ride locations for some modes of transport such as subways and airplanes can be slow to reach from the street. When planning a trip, we need to allow additional time to reach these locations to properly inform the passenger. For example, this helps avoid suggesting short bus rides between two subway rides as a way to improve travel time. You can specify how long it takes to reach a subway platform // build-config.json { \"subwayAccessTime\" : 2.5 } Stops in GTFS do not necessarily serve a single transit mode, but in practice this is usually the case. This additional access time will be added to any stop that is visited by trips on subway routes (GTFS route_type = 1). This setting does not generalize well to airplanes because you often need much longer to check in to a flight (2-3 hours for international flights) than to alight and exit the airport (perhaps 1 hour). Therefore there is currently no per-mode access time, it is subway-specific.","title":"Reaching a subway platform"},{"location":"Configuration/#transferring-within-stations","text":"Subway systems tend to exist in their own layer of the city separate from the surface, though there are exceptions where tracks lie right below the street and transfers happen via the surface. In systems where the subway is quite deep and transfers happen via tunnels, the time required for an in-station transfer is often less than that for a surface transfer. A proposal was made to provide detailed station pathways in GTFS but it is not in common use. One way to resolve this problem is by ensuring that the GTFS feed codes each platform as a separate stop, then micro-mapping stations in OSM. When OSM data contains a detailed description of walkways, stairs, and platforms within a station, GTFS stops can be linked to the nearest platform and transfers will happen via the OSM ways, which should yield very realistic transfer time expectations. This works particularly well in above-ground train stations where the layering of non-intersecting ways is less prevalent. Here's an example in the Netherlands: View Larger Map When such micro-mapping data is not available, we need to rely on information from GTFS including how stops are grouped into stations and a table of transfer timings where available. During the graph build, OTP can create preferential connections between each pair of stops in the same station to favor in-station transfers: // build-config.json { \"stationTransfers\" : true } Note that this method is at odds with micro-mapping and might make some transfers artificially short.","title":"Transferring within stations"},{"location":"Configuration/#elevation-data","text":"OpenTripPlanner can \"drape\" the OSM street network over a digital elevation model (DEM). This allows OTP to draw an elevation profile for the on-street portion of itineraries, and helps provide better routing for bicyclists. It even helps avoid hills for walking itineraries. DEMs are usually supplied as rasters (regular grids of numbers) stored in image formats such as GeoTIFF.","title":"Elevation data"},{"location":"Configuration/#us-national-elevation-dataset","text":"In the United States, a high resolution National Elevation Dataset is available for the entire territory. It used to be possible for OTP to download NED tiles on the fly from a rather complex USGS SOAP service. This process was somewhat unreliable and would greatly slow down the graph building process. In any case the service has since been replaced. But the USGS would also deliver the whole dataset in bulk if you sent them a hard drive . We did this many years back and uploaded the entire data set to Amazon AWS S3. OpenTripPlanner contains another module that can automatically fetch data in this format from any Amazon S3 copy of the bulk data. You can configure it as follows in build-config.json : // router-config.json { \"elevationBucket\" : { \"accessKey\" : \"your-aws-access-key\" , \"secretKey\" : \"corresponding-aws-secret-key\" , \"bucketName\" : \"ned13\" } } This ned13 bucket is still available on S3 under a \"requester pays\" policy. As long as you specify valid AWS account credentials you should be able to download tiles, and any bandwidth costs will be billed to your AWS account. Once the tiles are downloaded for a particular geographic area, OTP will keep them in local cache for the next graph build operation. You should add the --cache <directory> command line parameter to specify your NED tile cache location.","title":"U.S. National Elevation Dataset"},{"location":"Configuration/#geoid-difference","text":"Some elevation data sets are relative to mean sea level. At a global scale sea level is represented as a surface called the geoid, which is irregular in shape due to local gravitational anomalies. On the other hand, GPS elevations are reported relative to the WGS84 spheroid, a perfectly smooth mathematical surface approximating the geoid. In cases where the two elevation definitions are mixed, it may be necessary to adjust elevation values to avoid confusing users with things like negative elevation values in places clearly above sea level. See issue #2301 for detailed discussion of this. OTP allows you to adjust the elevation values reported in API responses in two ways. The first way is to store ellipsoid (GPS) elevation values internally, but apply a single geoid difference value in the OTP client where appropriate to display elevations above sea level. This ellipsoid to geoid difference is returned in each trip plan response in the ElevationMetadata field. Using a single value can be sufficient for smaller OTP deployments, but might result in incorrect values at the edges of larger OTP deployments. If your OTP instance uses this, it is recommended to set a default request value in the router-config.json file as follows: // router-config.json { \"routingDefaults\" : { \"geoidElevation\" : true } } The second way is to precompute these geoid difference values at a more granular level and store all elevations internally relative to the geoid (sea level). Elevations returned in the API responses will then not need to be adjusted to match end users' intuitive understanding of elevation. In order to speed up calculations, these geoid difference values are calculated and cached using only 2 significant digits of GPS coordinates. This is more than enough detail for most regions of the world and should result in less than one meter of vertical error even in areas that have the largest geoid irregularities. To enable this, include the following in the build-config.json file: // build-config.json { \"includeEllipsoidToGeoidDifference\" : true } If the geoid difference values are precomputed, be careful to not set the routing resource value of geoidElevation to true in order to avoid having the graph-wide geoid added again to all elevation values in the relevant street edges in responses.","title":"Geoid Difference"},{"location":"Configuration/#other-raster-elevation-data","text":"For other parts of the world you will need a GeoTIFF file containing the elevation data. These are often available from national geographic surveys, or you can always fall back on the worldwide Space Shuttle Radar Topography Mission (SRTM) data. This not particularly high resolution (roughly 30 meters horizontally) but it can give acceptable results. Simply place the elevation data file in the directory with the other graph builder inputs, alongside the GTFS and OSM data. Make sure the file has a .tiff or .tif extension, and the graph builder should detect its presence and apply the elevation data to the streets. OTP should automatically handle DEM GeoTIFFs in most common projections. You may want to check for elevation-related error messages during the graph build process to make sure OTP has properly discovered the projection. If you are using a DEM in unprojected coordinates make sure that the axis order is (longitude, latitude) rather than (latitude, longitude). Unfortunately there is no reliable standard for WGS84 axis order, so OTP uses the same axis order as the above-mentioned SRTM data, which is also the default for the popular Proj4 library. DEM files(USGS DEM) is not supported by OTP, but can be converted to GeoTIFF with tools like GDAL . Use gdal_merge.py -o merged.tiff *.dem to merge a set of dem files into one tif file. See Interline PlanetUtils for a set of scripts to download, merge, and resample Mapzen/Amazon Terrain Tiles .","title":"Other raster elevation data"},{"location":"Configuration/#elevation-unit-conversion","text":"By default, OTP expects the elevation data to use metres. However, by setting elevationUnitMultiplier in build-config.json , it is possible to define a multiplier that converts the elevation values from some other unit to metres. // build-config.json { // Correct conversation multiplier when source data uses decimetres instead of metres \"elevationUnitMultiplier\" : 0.1 }","title":"Elevation unit conversion"},{"location":"Configuration/#elevation-data-calculation-optimizations","text":"Calculating elevations on all StreetEdges can take a dramatically long time. In a very large graph build for multiple Northeast US states, the time it took to download the elevation data and calculate all of the elevations took 5,509 seconds (roughly 1.5 hours). If you are using cloud computing for your OTP instances, it is recommended to create prebuilt images that contain the elevation data you need. This will save time because all of the data won't need to be downloaded. However, the bulk of the time will still be spent calculating elevations for all of the street edges. Therefore, a further optimization can be done to calculate and save the elevation data during a graph build and then save it for future use.","title":"Elevation Data Calculation Optimizations"},{"location":"Configuration/#reusing-elevation-data-from-previous-builds","text":"In order to write out the precalculated elevation data, add this to your build-config.json file: // build-config.json { \"writeCachedElevations\" : true } After building the graph, a file called cached_elevations.obj will be written to the cache directory. By default, this file is not written during graph builds. There is also a graph build parameter called readCachedElevations which is set to true by default. In graph builds, the elevation module will attempt to read the cached_elevations.obj file from the cache directory. The cache directory defaults to /var/otp/cache , but this can be overriden via the CLI argument --cache <directory> . For the same graph build for multiple Northeast US states, the time it took with using this predownloaded and precalculated data became 543.7 seconds (roughly 9 minutes). The cached data is a lookup table where the coordinate sequences of respective street edges are used as keys for calculated data. It is assumed that all of the other input data except for the OpenStreetMap data remains the same between graph builds. Therefore, if the underlying elevation data is changed, or different configuration values for elevationUnitMultiplier or includeEllipsoidToGeoidDifference are used, then this data becomes invalid and all elevation data should be recalculated. Over time, various edits to OpenStreetMap will cause this cached data to become stale and not include new OSM ways. Therefore, periodic update of this cached data is recommended.","title":"Reusing elevation data from previous builds"},{"location":"Configuration/#configuring-multi-threading-during-elevation-calculations","text":"For unknown reasons that seem to depend on data and machine settings, it might be faster to use a single processor. For this reason, multi-threading of elevation calculations is only done if multiThreadElevationCalculations is set to true. To enable multi-threading in the elevation module, add the following to the build-config.json file: // build-config.json { \"multiThreadElevationCalculations\" : true }","title":"Configuring multi-threading during elevation calculations"},{"location":"Configuration/#fares-configuration","text":"By default OTP will compute fares according to the GTFS specification if fare data is provided in your GTFS input. It is possible to turn off this by setting the fare to \"off\". For more complex scenarios or to handle bike rental fares, it is necessary to manually configure fares using the fares section in build-config.json . You can combine different fares (for example transit and bike-rental) by defining a combinationStrategy parameter, and a list of sub-fares to combine (all fields starting with fare are considered to be sub-fares). // build-config.json { // Select the custom fare \"seattle\" \"fares\" : \"seattle\" , // OR this alternative form that could allow additional configuration \"fares\" : { \"type\" : \"seattle\" } } // build-config.json { \"fares\" : { // Combine two fares by simply adding them \"combinationStrategy\" : \"additive\" , // First fare to combine \"fare0\" : \"new-york\" , // Second fare to combine \"fare1\" : { \"type\" : \"bike-rental-time-based\" , \"currency\" : \"USD\" , \"prices\" : { // For trip shorter than 30', $4 fare \"30\" : 4.00 , // For trip shorter than 1h, $6 fare \"1:00\" : 6.00 } } // We could also add fareFoo, fareBar... } } Turning the fare service off , this will ignore any fare data in the provided GTFS data. // build-config.json { \"fares\" : \"off\" } The current list of custom fare type is: bike-rental-time-based - accepting the following parameters: currency - the ISO 4217 currency code to use, such as \"EUR\" or \"USD\" , prices - a list of {time, price}. The resulting cost is the smallest cost where the elapsed time of bike rental is lower than the defined time. san-francisco (no parameters) new-york (no parameters) seattle (no parameters) off (no parameters) The current list of combinationStrategy is: additive - simply adds all sub-fares.","title":"Fares configuration"},{"location":"Configuration/#osm-openstreetmap-configuration","text":"It is possible to adjust how OSM data is interpreted by OpenTripPlanner when building the road part of the routing graph.","title":"OSM / OpenStreetMap configuration"},{"location":"Configuration/#way-property-sets","text":"OSM tags have different meanings in different countries, and how the roads in a particular country or region are tagged affects routing. As an example are roads tagged with `highway=trunk (mainly) walkable in Norway, but forbidden in some other countries. This might lead to OTP being unable to snap stops to these roads, or by giving you poor routing results for walking and biking. You can adjust which road types that are accessible by foot, car & bicycle as well as speed limits, suitability for biking and walking. There are currently 3 wayPropertySets defined; default which is based on California/US mapping standard norway which is adjusted to rules and speeds in Norway uk which is adjusted to rules and speed in the UK To add your own custom property set have a look at org.opentripplanner.graph_builder.module.osm.NorwayWayPropertySet and org.opentripplanner.graph_builder.module.osm.DefaultWayPropertySet . If you choose to mainly rely on the default rules, make sure you add your own rules first before applying the default ones. The mechanism is that for any two identical tags, OTP will use the first one. // build-config.json { \"osmWayPropertySet\" : \"norway\" }","title":"Way property sets"},{"location":"Configuration/#custom-naming","text":"You can define a custom naming scheme for elements drawn from OSM by defining an osmNaming field in build-config.json , such as: // build-config.json { \"osmNaming\" : \"portland\" } There is currently only one custom naming module called portland (which has no parameters).","title":"Custom naming"},{"location":"Configuration/#router-configuration","text":"This section covers all options that can be set for each router using the router-config.json file. These options can be applied by the OTP server without rebuilding the graph. config key description value type value default notes routingDefaults Default routing parameters, which will be applied to every request object see routing defaults streetRoutingTimeout maximum time limit for street route queries double null units: seconds; see timeout requestLogFile Path to a plain-text file where requests will be logged string null see logging incoming requests transit Transit tuning parameters TransitRoutingConfig see Tuning transit routing updaters configure real-time updaters, such as GTFS-realtime feeds object null see configuring real-time updaters transmodelApi configure Entur Transmodel API ( Sandbox ) object null See the code for parameters, no doc provided.","title":"Router configuration"},{"location":"Configuration/#routing-defaults","text":"There are many trip planning options used in the OTP web API, and more exist internally that are not exposed via the API. You may want to change the default value for some of these parameters, i.e. the value which will be applied unless it is overridden in a web API request. A full list of them can be found in the RoutingRequest . Any public field or setter method in this class can be given a default value using the routingDefaults section of router-config.json as follows: // router-config.json { \"routingDefaults\" : { \"walkSpeed\" : 2.0 , \"stairsReluctance\" : 4.0 , \"carDropoffTime\" : 240 } }","title":"Routing defaults"},{"location":"Configuration/#tuning-itinerary-filtering","text":"Nested inside routingDefaults {...} in router-config.json . OTP2 may produce numerous pareto-optimal results when using time , number-of-transfers and generalized-cost as criteria. Use the parameters listed here to reduce/filter the itineraries return by the search engine before returning the results to client. config key description value type value default debugItineraryFilter Enable this to attach a system notice to itineraries instead of removing them. Some filters are not configurable, byt will show up in the system-notice if debugging is enabled. boolean false groupBySimilarityKeepOne Pick ONE itinerary from each group after putting itineraries that is 85% similar together. double 0.85 (85%) groupBySimilarityKeepNumOfItineraries Reduce the number of itineraries to the requested number by reducing each group of itineraries grouped by 68% similarity. double 0.68 (68%) transitGeneralizedCostLimit A relative maximum limit for the generalized cost for transit itineraries. The limit is a linear function of the minimum generalized-cost. The function is used to calculate a max-limit. The max-limit is then used to to filter by generalized-cost. Transit itineraries with a cost higher than the max-limit is dropped from the result set. None transit itineraries is excluded from the filter. To set a filter to be 1 hour plus 2 times the best cost use: 3600 + 2.0 x . To set an absolute value(3000) use: 3000 + 0x linear function null","title":"Tuning itinerary filtering"},{"location":"Configuration/#group-by-filters","text":"The group-by-filter is a bit complex, but should be simple to use. Set debugItineraryFilter=true and experiment with searchWindow and the two group-by parameters( debugItineraryFilter and groupBySimilarityKeepNumOfItineraries ). The group-by-filter work by grouping itineraries together and then reducing the number of itineraries in each group, keeping the itinerary/itineraries with the best generalized-cost . The group-by function first pick all transit legs that account for more than N% of the itinerary based on distance traveled. This become the group-key. To keys are the same if all legs in one of the keys also exist in the other. Note, one key may have a lager set of legs than the other, but they can still be the same. When comparing to legs we compare the tripId and make sure the legs overlap in place and time. Two legs are the same if both legs ride at least a common subsection of the same trip. The groupBySimilarityKeepOne filter will keep ONE itinerary in each group. The groupBySimilarityKeepNumOfItineraries is a bit more complex, because it uses the numOfItineraries request parameter to estimate a maxLimit for each group. For example, if the numOfItineraries is 5 elements and there is 3 groups, we set the max-limit for each group to 2, returning between 4 and 6 elements depending on the distribution. The max-limit can never be less than 1.","title":"Group-by-filters"},{"location":"Configuration/#drive-to-transit-routing-defaults","text":"When using the \"park and ride\" or \"kiss and ride\" modes (drive to transit), the initial driving time to reach a transit stop or park and ride facility is constrained. You can set a drive time limit in seconds by adding a line like maxPreTransitTime = 1200 to the routingDefaults section. If the limit is too high on a very large street graph, routing performance may suffer.","title":"Drive-to-transit routing defaults"},{"location":"Configuration/#boarding-and-alighting-times","text":"Sometimes there is a need to configure a longer ride or alighting times for specific modes, such as airplanes or ferries, where the check-in process needs to be done in good time before ride. The ride time is added to the time when going from the stop (offboard) vertex to the onboard vertex, and the alight time is added vice versa. The times are configured as seconds needed for the ride and alighting processes in router-config.json as follows: // router-config.json { \"boardTimes\" : { \"AIRPLANE\" : 2700 }, \"alightTimes\" : { \"AIRPLANE\" : 1200 } }","title":"Boarding and alighting times"},{"location":"Configuration/#timeout","text":"In OTP1 path searches sometimes toke a long time to complete. With the new Raptor algorithm this not the case anymore. The street part of the routing may still take a long time if searching very long distances. You can set the street routing timeout to avoid tying up server resources on pointless searches and ensure that your users receive a timely response. You can also limit the max distance to search for WALK, BIKE and CAR. When a search times out, a WARN level log entry is made with information that can help identify problematic searches and improve our routing methods. There are no timeouts for the transit part of the routing search, instead configure a reasonable dynamic search-window. To set the street routing timeout use the following config: // router-config.json { \"streetRoutingTimeout\" : 5.5 } This specifies a timeout in (optionally fractional) seconds. The search abort after this many seconds and any paths found are returned to the client.","title":"Timeout"},{"location":"Configuration/#logging-incoming-requests","text":"You can log some characteristics of trip planning requests in a file for later analysis. Some transit agencies and operators find this information useful for identifying existing or unmet transportation demand. Logging will be performed only if you specify a log file name in the router config: // router-config.json { \"requestLogFile\" : \"/var/otp/request.log\" } Each line in the resulting log file will look like this: 2016-04-19T18:23:13.486 0:0:0:0:0:0:0:1 ARRIVE 2016-04-07T00:17 WALK,BUS,CABLE_CAR,TRANSIT,BUSISH 45.559737193889966 -122.64999389648438 45.525592487765635 -122.39044189453124 6095 3 5864 3 6215 3 The fields separated by whitespace are (in order): Date and time the request was received IP address of the user Arrive or depart search The arrival or departure time A comma-separated list of all transport modes selected Origin latitude and longitude Destination latitude and longitude Finally, for each itinerary returned to the user, there is a travel duration in seconds and the number of transit vehicles used in that itinerary.","title":"Logging incoming requests"},{"location":"Configuration/#tuning-transit-routing","text":"Nested inside transit {...} in router-config.json . Some of these parameters for tuning transit routing is only available through configuration and cannot be set in the routing request. These parameters work together with the default routing request and the actual routing request. config key description value type value default maxNumberOfTransfers Use this parameter to allocate enough space for Raptor. Set it to the maximum number of transfers for any given itinerary expected to be found within the entire transit network. The memory overhead of setting this higher than the maximum number of transfers is very little so it is better to set it too high then to low. int 12 scheduledTripBinarySearchThreshold The threshold is used to determine when to perform a binary trip schedule search to reduce the number of trips departure time lookups and comparisons. When testing with data from Entur and all of Norway as a Graph, the optimal value was around 50. Changing this may improve the performance with just a few percent. int 50 iterationDepartureStepInSeconds Step for departure times between each RangeRaptor iterations. A transit network usually uses minute resolution for its depature and arrival times. To match that, set this variable to 60 seconds. int 60 searchThreadPoolSize Split a travel search in smaller jobs and run them in parallel to improve performance. Use this parameter to set the total number of executable threads available across all searches. Multiple searches can run in parallel - this parameter have no effect with regard to that. If 0, no extra threads are started and the search is done in one thread. int 0 dynamicSearchWindow The dynamic search window coefficients used to calculate the EDT(earliest-departure-time), LAT(latest-arrival-time) and SW(raptor-search-window) using heuristics. object null stopTransferCost Use this to set a stop transfer cost for the given TransferPriority . The cost is applied to boarding and alighting at all stops. All stops have a transfer cost priority set, the default is ALLOWED . The stopTransferCost parameter is optional, but if listed all values must be set. enum map null","title":"Tuning transit routing"},{"location":"Configuration/#tuning-transit-routing-dynamic-search-window","text":"Nested inside transit : { dynamicSearchWindow : { ... } } in router-config.json . config key description value type value default minTripTimeCoefficient The coefficient to multiply with minimum travel time found using a heuristic search. This value is added to the minWinTimeMinutes . A value between 0.0 to 3.0 is expected to give ok results. double 0.75 minWinTimeMinutes The constant minimum number of minutes for a raptor search window. Use a value between 20-180 minutes in a normal deployment. int 40 maxWinTimeMinutes Set an upper limit to the calculation of the dynamic search window to prevent exceptionable cases to cause very long search windows. Long search windows consumes a lot of resources and may take a long time. Use this parameter to tune the desired maximum search time. int 180 (3 hours) stepMinutes The search window is rounded of to the closest multiplication of N minutes. If N=10 minutes, the search-window can be 10, 20, 30 ... minutes. It the computed search-window is 5 minutes and 17 seconds it will be rounded up to 10 minutes. int 10","title":"Tuning transit routing - Dynamic search window"},{"location":"Configuration/#tuning-transit-routing-stop-transfer-cost","text":"Nested inside transit : { stopTransferCost : { ... } } in router-config.json . This cost is in addition to other costs like boardCost and indirect cost from waiting (board-/alight-/transfer slack). You should account for this when you tune the routing search parameters. If not set the stopTransferCost is ignored. This is only available for NeTEx imported Stops. The cost is a scalar, but is equivalent to the felt cost of riding a transit trip for 1 second. config key description value type DISCOURAGED Use a very high cost like 72 000 to eliminate transfers ath the stop if not the only option. int ALLOWED Allowed, but not recommended. Use something like 150 . int RECOMMENDED Use a small cost penalty like 60 . int PREFERRED The best place to do transfers. Should be set to 0 (zero). int Use values in a range from 0 to 100 000 . All key/value pairs are required if the stopTransferCost is listed.","title":"Tuning transit routing - Stop transfer cost"},{"location":"Configuration/#transit-example","text":"// router-config.json { \"transit\" : { \"maxNumberOfTransfers\" : 12 , \"scheduledTripBinarySearchThreshold\" : 50 , \"iterationDepartureStepInSeconds\" : 60 , \"searchThreadPoolSize\" : 0 , \"dynamicSearchWindow\" : { \"minTripTimeCoefficient\" : 0.4 , \"minTimeMinutes\" : 30 , \"maxLengthMinutes\" : 360 , \"stepMinutes\" : 10 }, \"stopTransferCost\" : { \"DISCOURAGED\" : 72000 , \"ALLOWED\" : 150 , \"RECOMMENDED\" : 60 , \"PREFERRED\" : 0 } } }","title":"Transit example"},{"location":"Configuration/#real-time-data","text":"GTFS feeds contain schedule data that is is published by an agency or operator in advance. The feed does not account for unexpected service changes or traffic disruptions that occur from day to day. Thus, this kind of data is also referred to as 'static' data or 'theoretical' arrival and departure times.","title":"Real-time data"},{"location":"Configuration/#gtfs-realtime","text":"The GTFS-RT spec complements GTFS with three additional kinds of feeds. In contrast to the base GTFS schedule feed, they provide real-time updates ( 'dynamic' data) and are are updated from minute to minute. Alerts are text messages attached to GTFS objects, informing riders of disruptions and changes. TripUpdates report on the status of scheduled trips as they happen, providing observed and predicted arrival and departure times for the remainder of the trip. VehiclePositions give the location of some or all vehicles currently in service, in terms of geographic coordinates or position relative to their scheduled stops.","title":"GTFS-Realtime"},{"location":"Configuration/#bicycle-rental-systems","text":"Besides GTFS-RT transit data, OTP can also fetch real-time data about bicycle rental networks including the number of bikes and free parking spaces at each station. We support bike rental systems from JCDecaux, BCycle, VCub, Keolis, Bixi, the Dutch OVFiets system, ShareBike, GBFS and a generic KML format. It is straightforward to extend OTP to support any bike rental system that exposes a JSON API or provides KML place markers, though it requires writing a little code. The generic KML needs to be in format like <?xml version=\"1.0\" encoding=\"utf-8\" ?> <kml xmlns= \"http://www.opengis.net/kml/2.2\" > <Document id= \"root_doc\" > <Schema name= \"citybikes\" id= \"citybikes\" > <SimpleField name= \"ID\" type= \"int\" ></SimpleField> </Schema> <Placemark> <name> A Bike Station </name> <ExtendedData><SchemaData schemaUrl= \"#citybikes\" > <SimpleData name= \"ID\" > 0 </SimpleData> </SchemaData></ExtendedData> <Point><coordinates> 24.950682884886643,60.155923430488102 </coordinates></Point> </Placemark> </Document></kml>","title":"Bicycle rental systems"},{"location":"Configuration/#configuring-real-time-updaters","text":"Real-time data can be provided using either a pull or push system. In a pull configuration, the GTFS-RT consumer polls the real-time provider over HTTP. That is to say, OTP fetches a file from a web server every few minutes. In the push configuration, the consumer opens a persistent connection to the GTFS-RT provider, which then sends incremental updates immediately as they become available. OTP can use both approaches. The OneBusAway GTFS-realtime exporter project provides this kind of streaming, incremental updates over a websocket rather than a single large file. Real-time data sources are configured in router-config.json . The updaters section is an array of JSON objects, each of which has a type field and other configuration fields specific to that type. Common to all updater entries that connect to a network resource is the url field. // router-config.json { // Routing defaults are any public field or setter in the Java class // org.opentripplanner.routing.api.request.RoutingRequest \"routingDefaults\" : { \"numItineraries\" : 6 , \"walkSpeed\" : 2.0 , \"stairsReluctance\" : 4.0 , \"carDropoffTime\" : 240 }, \"updaters\" : [ // GTFS-RT service alerts (frequent polling) { \"type\" : \"real-time-alerts\" , \"frequencySec\" : 30 , \"url\" : \"http://developer.trimet.org/ws/V1/FeedSpecAlerts/appID/0123456789ABCDEF\" , \"feedId\" : \"TriMet\" }, // Polling bike rental updater. // sourceType can be: jcdecaux, b-cycle, bixi, keolis-rennes, ov-fiets, // city-bikes, citi-bike-nyc, next-bike, vcub, kml { \"type\" : \"bike-rental\" , \"frequencySec\" : 300 , \"sourceType\" : \"city-bikes\" , \"url\" : \"http://host.domain.tld\" }, //<!--- San Francisco Bay Area bike share --> { \"type\" : \"bike-rental\" , \"frequencySec\" : 300 , \"sourceType\" : \"sf-bay-area\" , \"url\" : \"http://www.bayareabikeshare.com/stations/json\" }, //<!--- Tampa Area bike share --> { \"type\" : \"bike-rental\" , \"frequencySec\" : 300 , \"sourceType\" : \"gbfs\" , \"url\" : \"http://coast.socialbicycles.com/opendata/\" }, // Polling bike rental updater for DC bikeshare (a Bixi system) // Negative update frequency means to run once and then stop updating (essentially static data) { \"type\" : \"bike-rental\" , \"sourceType\" : \"bixi\" , \"url\" : \"https://www.capitalbikeshare.com/data/stations/bikeStations.xml\" , \"frequencySec\" : -1 }, // Bike parking availability { \"type\" : \"bike-park\" }, // Polling for GTFS-RT TripUpdates) { \"type\" : \"stop-time-updater\" , \"frequencySec\" : 60 , // this is either http or file... shouldn't it default to http or guess from the presence of a URL? \"sourceType\" : \"gtfs-http\" , \"url\" : \"http://developer.trimet.org/ws/V1/TripUpdate/appID/0123456789ABCDEF\" , \"feedId\" : \"TriMet\" }, // Streaming differential GTFS-RT TripUpdates over websockets { \"type\" : \"websocket-gtfs-rt-updater\" } ] }","title":"Configuring real-time updaters"},{"location":"Configuration/#gbfs-configuration","text":"Steps to add a GBFS feed to a router: Add one entry in the updater field of router-config.json in the format // router-config.json { \"type\" : \"bike-rental\" , \"frequencySec\" : 60 , \"sourceType\" : \"gbfs\" , \"url\" : \"http://coast.socialbicycles.com/opendata/\" } Follow these instructions to fill these fields: type: \"bike-rental\" frequencySec: frequency in seconds in which the GBFS service will be polled sourceType: \"gbfs\" url: the URL of the GBFS feed (do not include the gbfs.json at the end) * * For a list of known GBFS feeds see the list of known GBFS feeds","title":"GBFS Configuration"},{"location":"Configuration/#bike-rental-service-directory-configuration-sandbox-feature","text":"To configure and url for the BikeRentalServiceDirectory . // router-config.json { \"bikeRentalServiceDirectoryUrl\" : \"https://api.dev.entur.io/mobility/v1/bikes\" }","title":"Bike Rental Service Directory configuration (sandbox feature)"},{"location":"Configuration/#configure-using-command-line-arguments","text":"Certain settings can be provided on the command line, when starting OpenTripPlanner. See the CommandLineParameters class for a full list of arguments .","title":"Configure using command-line arguments"},{"location":"Deployments/","text":"OpenTripPlanner Deployments Worldwide Official Production The following are known deployments of OTP in a government- or agency-sponsored production capacity: Norway (nationwide) Since November 2017, the national integrated ticketing agency Entur has prodvided a national journey planner which consumes schedule data in the EU standard NeTEx format with SIRI realtime updates. Entur has contributed greatly to the OTP2 effort and is already using OTP2 in production for a subset of requests. Oslo, Norway Ruter provides a journey planner for the Oslo region . It has been in production since January 2016 and serves around 200,000 users per day. Finland (nationwide) The Helsinki Regional Transport Authority , the Finnish Transport Agency , and other Finnish cities have collaborated to create Digitransit , providing OTP-based trip planners, APIs, open data, Docker containers and open source code. Each member organisation runs its own instance of a shared codebase and deployment environment. Their source code is available on Github , including a new custom UI . This system also has a strong real-time component. Finland Intercity The Finnish intercity coach service Matkahuolto has developed a trip planner in partnership with Kyyti . Leipzig, Germany As of summer 2020 Leipzig Move has been using OpenTripPlanner. Portland, Oregon TriMet is the agency that originally started the OpenTripPlanner project. Their Regional Trip Planner is based on OTP and provides about 40,000 trip plans on a typical weekday. New York State The State Department of Transportation's transit trip planner provides itineraries for public transit systems throughout the state in a single unified OTP instance. Los Angeles, California The new metro.net trip planner . Atlanta, Georgia The Metropolitan Atlanta Rapid Transit Authority's (MARTA) trip planner and the Atlanta region's transit information hub atltransit.org both use OTP to power their website trip planners. Boston, Massachusetts The Massachusetts Bay Transportation Authority trip planner . Seattle, Washington The Sound Transit Trip Planner is based on OTP. OTP also powers the trip planning feature of the OneBusAway native apps in the Puget Sound region. Technical details are here . Tampa, Florida Hillsoborough Area Regional Transit uses an OpenTripPlanner server to power the trip planning feature of the OneBusAway native apps in their region. Technical details are here . Piemonte Region, Italy and the City of Torino built on OpenTripPlanner by 5T . Valencia, Spain from the Municipal Transport Company of Valencia S.A.U. Grenoble, France from SMTC, Grenoble Alpes m\u00e9tropole, l'\u00c9tat Fran\u00e7ais, the Rh\u00f4ne-alpes region, the Is\u00e8re council and the City of Grenoble. Rennes, France where the STAR network provides an OTP client for iOS , Android , Windows Phone et Web. Alen\u00e7on, France integrated urban and school bus network planner from R\u00e9unir Alen\u00e7on . Pozna\u0144, Poland from Urban Transport Authority of Pozna\u0144 (ZTM Poznan). Trento Province, Italy - ViaggiaTrento and ViaggiaRovereto were implemented as part of the SmartCampus Project , a research project founded by TrentoRise , UNITN , and FBK . University of South Florida (Tampa, Florida). The USF Maps App is a responsive web application for that helps university students, staff, and visitors find their way around the campus using multiple modes of transportation, including the USF Bull Runner campus shuttle, Share-A-Bull bike share, and pedestrian pathways. Open-sourced on Github . Independent Production The following OTP-based services are presented as production-quality deployments, but are not backed by an official transportation authority or government. OTP is also known to be used on the back end of several popular multi-city mobile trip planning applications. The Netherlands (nationwide) Plannerstack Foundation provides national scale trip planning APIs using OTP and other open source trip planners, based on OpenOV's extremely detailed open data including minutely real-time updates for every vehicle in the country. OTP Android by CUTR-USF and Vreixo Gonz\u00e1lez can find itineraries on many different OTP servers via a service discovery mechanism. ViviBus Bologna Bologna, Italy.","title":"Deployments"},{"location":"Deployments/#opentripplanner-deployments-worldwide","text":"","title":"OpenTripPlanner Deployments Worldwide"},{"location":"Deployments/#official-production","text":"The following are known deployments of OTP in a government- or agency-sponsored production capacity: Norway (nationwide) Since November 2017, the national integrated ticketing agency Entur has prodvided a national journey planner which consumes schedule data in the EU standard NeTEx format with SIRI realtime updates. Entur has contributed greatly to the OTP2 effort and is already using OTP2 in production for a subset of requests. Oslo, Norway Ruter provides a journey planner for the Oslo region . It has been in production since January 2016 and serves around 200,000 users per day. Finland (nationwide) The Helsinki Regional Transport Authority , the Finnish Transport Agency , and other Finnish cities have collaborated to create Digitransit , providing OTP-based trip planners, APIs, open data, Docker containers and open source code. Each member organisation runs its own instance of a shared codebase and deployment environment. Their source code is available on Github , including a new custom UI . This system also has a strong real-time component. Finland Intercity The Finnish intercity coach service Matkahuolto has developed a trip planner in partnership with Kyyti . Leipzig, Germany As of summer 2020 Leipzig Move has been using OpenTripPlanner. Portland, Oregon TriMet is the agency that originally started the OpenTripPlanner project. Their Regional Trip Planner is based on OTP and provides about 40,000 trip plans on a typical weekday. New York State The State Department of Transportation's transit trip planner provides itineraries for public transit systems throughout the state in a single unified OTP instance. Los Angeles, California The new metro.net trip planner . Atlanta, Georgia The Metropolitan Atlanta Rapid Transit Authority's (MARTA) trip planner and the Atlanta region's transit information hub atltransit.org both use OTP to power their website trip planners. Boston, Massachusetts The Massachusetts Bay Transportation Authority trip planner . Seattle, Washington The Sound Transit Trip Planner is based on OTP. OTP also powers the trip planning feature of the OneBusAway native apps in the Puget Sound region. Technical details are here . Tampa, Florida Hillsoborough Area Regional Transit uses an OpenTripPlanner server to power the trip planning feature of the OneBusAway native apps in their region. Technical details are here . Piemonte Region, Italy and the City of Torino built on OpenTripPlanner by 5T . Valencia, Spain from the Municipal Transport Company of Valencia S.A.U. Grenoble, France from SMTC, Grenoble Alpes m\u00e9tropole, l'\u00c9tat Fran\u00e7ais, the Rh\u00f4ne-alpes region, the Is\u00e8re council and the City of Grenoble. Rennes, France where the STAR network provides an OTP client for iOS , Android , Windows Phone et Web. Alen\u00e7on, France integrated urban and school bus network planner from R\u00e9unir Alen\u00e7on . Pozna\u0144, Poland from Urban Transport Authority of Pozna\u0144 (ZTM Poznan). Trento Province, Italy - ViaggiaTrento and ViaggiaRovereto were implemented as part of the SmartCampus Project , a research project founded by TrentoRise , UNITN , and FBK . University of South Florida (Tampa, Florida). The USF Maps App is a responsive web application for that helps university students, staff, and visitors find their way around the campus using multiple modes of transportation, including the USF Bull Runner campus shuttle, Share-A-Bull bike share, and pedestrian pathways. Open-sourced on Github .","title":"Official Production"},{"location":"Deployments/#independent-production","text":"The following OTP-based services are presented as production-quality deployments, but are not backed by an official transportation authority or government. OTP is also known to be used on the back end of several popular multi-city mobile trip planning applications. The Netherlands (nationwide) Plannerstack Foundation provides national scale trip planning APIs using OTP and other open source trip planners, based on OpenOV's extremely detailed open data including minutely real-time updates for every vehicle in the country. OTP Android by CUTR-USF and Vreixo Gonz\u00e1lez can find itineraries on many different OTP servers via a service discovery mechanism. ViviBus Bologna Bologna, Italy.","title":"Independent Production"},{"location":"Developers-Guide/","text":"Developers Guide Quick setup A Quick guide to setting up the OpenTripPlanner project. You need Git, Maven and Java(JDK) and an IDE installed on your computer. You IDE might have JDK and Maven embedded, if so you may skip step 3. Clone OpenTripPlanner from GitHub. Checkout the desired branch git checkout dev-2.x Run maven package - this will download all dependencies, build the project and run tests. Open the project in your IDE. Import the intellij-code-style.xml (IntelliJ IDE). Working on OTP in an IDE Most people writing or modifying OTP code use an Integrated Development Environment (IDE). Some of the most popular IDEs for Java development are IntelliJ IDEA , Eclipse , and NetBeans . All three of these environments are good for working on OTP. IntelliJ is used by most OTP developers, and the only IDE we support with a code style formatter. You may choose another IDE, but Maven and Git integration is a plus since OTP is under Git version control and build with Maven. Many of the Core OTP developers use IntelliJ IDEA. It is an excellent IDE, and in my experience is quicker and more stable than the competition. IntelliJ IDEA is a commercial product, but there is an open source \"community edition\" that is completely sufficient for working on OTP. Rather than using the version control support in my IDE, I usually find it more straightforward to clone the OTP GitHub repository manually (on the command line or using some other Git interface tool), then import the resulting local OTP repository into my IDE as a Maven project. The IDE should then take care of fetching all the libraries OTP depends on, based on the Maven project description (POM file) in the base of the OTP repository. This step can take a long time because it involves downloading a lot of JAR files. When running your local copy of the OTP source within an IDE, all command line switches and configuration options will be identical to the ones used when running the OTP JAR from the command line (as described in the OpenTripPlanner Basic Tutorial and configuration reference ). The only difference is that you need to manually specify the main class. When you run a JAR from the command line, the JVM automatically knows which class contains the entry point into the program (the main function), but in IDEs you must create a \"run configuration\". Both IntelliJ and Eclipse have \"run\" menus, from which you can select an option to edit the run configurations. You want to create a configuration for a Java Application, specifying the main class org.opentripplanner.standalone.OTPMain . Unlike on the command line, the arguments to the JVM and to the main class you are running are specified separately. In the field for the VM options you'll want to put your maximum memory parameter ( -Xmx2G , or whatever limit you want to place on JVM memory usage). The rest of the parameters to OTP itself will go in a different field with a name like \"program arguments\". Contributing to the project OpenTripPlanner is a community based open source project, and we welcome all who wish to contribute. There are several ways to get involved: Join the developer mailing list Fix typos and improve the documentation within the /docs directory of the project (details below). File a bug or new feature request . Submit patches. If you're not yet a committer, please provide patches as pull requests citing the relevant issue. Even when you do have push access to the repository, pull requests are a good way to get feedback on changes. Branches and Branch Protection As of January 2019, we have begun work on OTP 2.x and are using a Git branching model derived from Gitflow . All development will occur on the dev-1.x and dev-2.x branches. Only release commits setting the Maven artifact version to a non-snapshot number should be pushed to the master branch of OTP. All other changes to master should result from fast-forward merges of a Github pull request from the dev-1.x branch. In turn, all changes to dev-1.x should result from a fast-forward merge of a Github pull request for a single feature, fix, or other change. These pull requests are subject to code review. We require two pull request approvals from OTP leadership committee members or designated code reviewers from two different organizations. We also have validation rules ensuring that the code compiles and all tests pass before pull requests can be merged. The dev-2.x branch is managed similarly to dev-1.x but because it's rapidly changing experimental code worked on by relatively few people, we require only one pull request approval from a different organization than the author. Merges will not occur into master from dev-2.x until that branch is sufficiently advanced and receives approval from the OTP project leadership committee. Issues and commits All commits should reference a specific issue number (this was formally decided in issue #175). For example, Simplify module X configuration #9999 . If no ticket exists for the feature or bug your code implements or fixes, you should create a new ticket prior to checking in, or ideally even prior to your development work since this provides a place to carry out implementation discussions (in the comments). GitHub will automatically update issues when commits are merged in: if your commit message includes the text fixes #123 , it will automatically append your message as a comment on the isse and close it. If you simply mention #123 in your message, your message will be appended to the issue but it will remain open. Many other expressions exist to close issues via commit messages. See the GitHub help page on this topic . Code Comments As a matter of policy , all new methods, classes, and fields should include comments explaining what they are for and any other pertinent information. For Java code, the comments should use the JavaDoc conventions . It is best to provide comments that not only explain what you did but also why you did it while providing some context. Please avoid including trivial Javadoc or the empty Javadoc stubs added by IDEs, such as @param annotations with no description. Documentation OTP documentation is included directly in the OpenTripPlanner repository. This allows version control to be applied to documentation as well as program source code. All pull requests that change how OTP is used or configured should include changes to the documentation alongside code modifications. The documentation files are in Markdown format and are in the /docs directory under the root of the project. On every push to the master branch the documentation will be rebuilt and deployed as static pages to our subdomain of ReadTheDocs . MkDocs is a Python program and should run on any major platform. See http://www.mkdocs.org/ for information on how to install it and how to generate a live local preview of the documentation while you're working on writing it. In short: $ pip install mkdocs $ mkdocs serve Debug layers Adding new renderer is very easy. You just need to create new class (preferably in org.opentripplanner.inspector package) which implements EdgeVertexRenderer. It is best if class name ends with Rendered. To implement this interface you need to write three functions renderEdge , renderVertex and getName . Both render functions accepts EdgeVisualAttributes object in which label of edge/vertex and color can be set. And both return true if edge/vertex should be rendered and false otherwise. getName function should return short descriptive name of the class and will be shown in layer chooser. For examples how to write renderers you can look into example renderers which are all in org.opentripplanner.inspector package. After your class is written you only need to add it to TileRenderManager: //This is how Wheelchair renderer is added renderers . put ( \"wheelchair\" , new EdgeVertexTileRenderer ( new WheelchairEdgeRenderer ())); wheelchair is internal layer key and should consist of a-zA-Z and -. By default all the tiles have cache headers to cache them for one hour. This can become problematic if you are changing renderers a lot. To disable this change GraphInspectorTileResource : //This lines CacheControl cc = new CacheControl (); cc . setMaxAge ( 3600 ); cc . setNoCache ( false ); //to this: CacheControl cc = new CacheControl (); cc . setNoCache ( true ); Date format Please use only ISO 8601 date format (YYYY-MM-DD) in documentation, comments, and throughout the project. This avoids the ambiguity that can result from differing local interpretations of date formats like 02/01/12. Code style The OTP code style is described on a separate style guide page . Continuous Integration The OpenTripPlanner project uses the Travis CI continuous integration system . Any time a change is pushed to the main OpenTripPlanner repository on GitHub, this server will compile and test the new code, providing feedback on the stability of the build. Release Process This section serves as a checklist for the person performing releases. Note that much of this mimics the actions taken by the Maven release plugin. Based on past experience, the Maven release plugin can fail at various points in the process leaving the repo in a confusing state. Taking each action manually is more tedious, but keeps eyes on each step and is less prone to failure. Releases are performed off the master branch, and are tagged with git annotated tags. Check that your local copy of the dev branch is up to date with no uncommitted changes git status git checkout dev-1.x git clean -df git pull Verify that all dependencies in the POM are non-SNAPSHOT versions Currently we do have one SNAPSHOT dependency on crosby.binary.osmpbf which we are working to eliminate Update docs/Changelog.md Lines should have been added or updated as each pull request was merged If you suspect any changes are not reflected in the Changelog, review the commit log and add any missing items Update the header at the top of the list from x.y.z-SNAPSHOT to just x.y.z (current date) Check in any changes, and push to Github Check on Travis that the build is currently passing Link to OTP builds on Travis CI Switch to the HEAD of master branch, and ensure it's up to date with no uncommitted changes git checkout master git status git clean -df git pull Merge the dev branch into master git merge dev-1.x Bump the SNAPSHOT version in the POM to the release version Edit version in POM, removing SNAPSHOT and increasing version numbers as needed (following semantic versioning) git add pom.xml git commit -m \"prepare release x.y.z\" Run a test build of the release locally, without deploying it mvn clean install site The install goal will sign the Maven artifacts so you need the GPG signing certificate set up You can also use the package goal instead of the install goal to avoid signing if you don't have the GPG certificate installed. All tests should pass This build will also create Enunciate API docs and Javadoc with the correct non-snapshot version number Deploy the documentation to AWS S3 You have to do this right after the test release build to ensure the right version number in the docs You will need AWSCLI tools ( sudo pip install -U awscli ) You will need AWS credentials with write access to the bucket s3://dev.opentripplanner.org aws s3 cp --recursive target/site/apidocs s3://dev.opentripplanner.org/javadoc/x.y.z --acl public-read aws s3 cp --recursive target/site/enunciate/apidocs s3://dev.opentripplanner.org/apidoc/x.y.z --acl public-read Check that docs are readable and show the correct version via the development documentation landing page . Finally, if everything looks good, tag and push this release to make it official and trigger deployment git tag -a vX.Y.Z -m \"release X.Y.Z\" git push origin vX.Y.Z Pushing the tag will trigger a Travis CI build and deployment of release Maven artifacts Note that only one commit may have a particular non-snapshot version in the POM (this is the commit that should be tagged as the release) Set up next development iteration Add a new section header to docs/Changelog.md like x.y+1.0-SNAPSHOT (in progress) Edit minor version in pom.xml to x.y+1.0-SNAPSHOT git add pom.xml docs/Changelog.md git commit -m \"Prepare next development iteration x.y+1.0-SNAPSHOT\" git push Check that Travis CI build of the release tag succeeded Link to OTP builds on Travis CI Check the end of the build log to make sure the Maven artifacts were staged for release Check that Maven artifact appears on Maven Central (deployment succeeded) Directory listing of OTP releases on Maven Central It may take a while (half an hour) for releases to show up in the central repo after Travis uploads the artifacts Merge master back into dev (to sync up the Maven artifact version from the POM) git checkout dev-1.x git merge master git push Make sure the main documentation is built For some reason it doesn't always build automatically Go to builds of docs.opentripplanner.org Click \"build version: latest\" Email the OTP dev and users mailing lists Mention the new version number. Provide links to the new developer documentation. Provide links to the artifacts directory on Maven Central. Trigger build of latest OTP documentation on Readthedocs. Additional Information on Releases OpenTripPlanner is released as Maven artifacts to Maven Central. These include compiled and source code JARs as well as a \"shaded\" JAR containing all dependencies, allowing stand-alone usage. This release process is handled by the Sonatype Nexus Staging plugin, configured in the OpenTripPlanner POM. Typically this final Maven deployment action is performed automatically when the Travis CI build succeeds in building a non-SNAPSHOT version. Artifact Signing Maven release artifacts must be digitally signed to prove their origin. This is a safeguard against compromised code from a malicious third party being disguised as a trusted library. The OTP artifact signing key was created by Conveyal. We export only that signing subkey, with our company's main key blanked out. Therefore, even if someone managed to acquire the decrypted key file and the associated GPG passphrase, they would not have the main key. We could deactivate the signing key and create a new one, without the main key being compromised. The exported signing key is present in the root of the git repo as the encrypted file maven-artifact-signing-key.asc.enc . When building a tagged release, Travis CI will decrypt this file and import it into GPG on the build machine. The signing key ID and GPG passphrase are also present as encrypted environment variables in the Travis configuration YAML. This only happens on code from non-fork, non-pull-request commits, ensuring that no unreviewed third-party code has access to these files or variables. OpenTripPlanner's POM is set up to sign artifacts in the verify phase, which means signing will happen for the install and deploy targets, but not the package target. When performing a local test build, if you do mvn clean install site it will test the signing process. If you do not have the certificate installed, you can instead to mvn clean package site to bypass signing, but this provides less certainty that everything is set up correctly for the CI-driven final release.","title":"Developers' Guide"},{"location":"Developers-Guide/#developers-guide","text":"","title":"Developers Guide"},{"location":"Developers-Guide/#quick-setup","text":"A Quick guide to setting up the OpenTripPlanner project. You need Git, Maven and Java(JDK) and an IDE installed on your computer. You IDE might have JDK and Maven embedded, if so you may skip step 3. Clone OpenTripPlanner from GitHub. Checkout the desired branch git checkout dev-2.x Run maven package - this will download all dependencies, build the project and run tests. Open the project in your IDE. Import the intellij-code-style.xml (IntelliJ IDE).","title":"Quick setup"},{"location":"Developers-Guide/#working-on-otp-in-an-ide","text":"Most people writing or modifying OTP code use an Integrated Development Environment (IDE). Some of the most popular IDEs for Java development are IntelliJ IDEA , Eclipse , and NetBeans . All three of these environments are good for working on OTP. IntelliJ is used by most OTP developers, and the only IDE we support with a code style formatter. You may choose another IDE, but Maven and Git integration is a plus since OTP is under Git version control and build with Maven. Many of the Core OTP developers use IntelliJ IDEA. It is an excellent IDE, and in my experience is quicker and more stable than the competition. IntelliJ IDEA is a commercial product, but there is an open source \"community edition\" that is completely sufficient for working on OTP. Rather than using the version control support in my IDE, I usually find it more straightforward to clone the OTP GitHub repository manually (on the command line or using some other Git interface tool), then import the resulting local OTP repository into my IDE as a Maven project. The IDE should then take care of fetching all the libraries OTP depends on, based on the Maven project description (POM file) in the base of the OTP repository. This step can take a long time because it involves downloading a lot of JAR files. When running your local copy of the OTP source within an IDE, all command line switches and configuration options will be identical to the ones used when running the OTP JAR from the command line (as described in the OpenTripPlanner Basic Tutorial and configuration reference ). The only difference is that you need to manually specify the main class. When you run a JAR from the command line, the JVM automatically knows which class contains the entry point into the program (the main function), but in IDEs you must create a \"run configuration\". Both IntelliJ and Eclipse have \"run\" menus, from which you can select an option to edit the run configurations. You want to create a configuration for a Java Application, specifying the main class org.opentripplanner.standalone.OTPMain . Unlike on the command line, the arguments to the JVM and to the main class you are running are specified separately. In the field for the VM options you'll want to put your maximum memory parameter ( -Xmx2G , or whatever limit you want to place on JVM memory usage). The rest of the parameters to OTP itself will go in a different field with a name like \"program arguments\".","title":"Working on OTP in an IDE"},{"location":"Developers-Guide/#contributing-to-the-project","text":"OpenTripPlanner is a community based open source project, and we welcome all who wish to contribute. There are several ways to get involved: Join the developer mailing list Fix typos and improve the documentation within the /docs directory of the project (details below). File a bug or new feature request . Submit patches. If you're not yet a committer, please provide patches as pull requests citing the relevant issue. Even when you do have push access to the repository, pull requests are a good way to get feedback on changes.","title":"Contributing to the project"},{"location":"Developers-Guide/#branches-and-branch-protection","text":"As of January 2019, we have begun work on OTP 2.x and are using a Git branching model derived from Gitflow . All development will occur on the dev-1.x and dev-2.x branches. Only release commits setting the Maven artifact version to a non-snapshot number should be pushed to the master branch of OTP. All other changes to master should result from fast-forward merges of a Github pull request from the dev-1.x branch. In turn, all changes to dev-1.x should result from a fast-forward merge of a Github pull request for a single feature, fix, or other change. These pull requests are subject to code review. We require two pull request approvals from OTP leadership committee members or designated code reviewers from two different organizations. We also have validation rules ensuring that the code compiles and all tests pass before pull requests can be merged. The dev-2.x branch is managed similarly to dev-1.x but because it's rapidly changing experimental code worked on by relatively few people, we require only one pull request approval from a different organization than the author. Merges will not occur into master from dev-2.x until that branch is sufficiently advanced and receives approval from the OTP project leadership committee.","title":"Branches and Branch Protection"},{"location":"Developers-Guide/#issues-and-commits","text":"All commits should reference a specific issue number (this was formally decided in issue #175). For example, Simplify module X configuration #9999 . If no ticket exists for the feature or bug your code implements or fixes, you should create a new ticket prior to checking in, or ideally even prior to your development work since this provides a place to carry out implementation discussions (in the comments). GitHub will automatically update issues when commits are merged in: if your commit message includes the text fixes #123 , it will automatically append your message as a comment on the isse and close it. If you simply mention #123 in your message, your message will be appended to the issue but it will remain open. Many other expressions exist to close issues via commit messages. See the GitHub help page on this topic .","title":"Issues and commits"},{"location":"Developers-Guide/#code-comments","text":"As a matter of policy , all new methods, classes, and fields should include comments explaining what they are for and any other pertinent information. For Java code, the comments should use the JavaDoc conventions . It is best to provide comments that not only explain what you did but also why you did it while providing some context. Please avoid including trivial Javadoc or the empty Javadoc stubs added by IDEs, such as @param annotations with no description.","title":"Code Comments"},{"location":"Developers-Guide/#documentation","text":"OTP documentation is included directly in the OpenTripPlanner repository. This allows version control to be applied to documentation as well as program source code. All pull requests that change how OTP is used or configured should include changes to the documentation alongside code modifications. The documentation files are in Markdown format and are in the /docs directory under the root of the project. On every push to the master branch the documentation will be rebuilt and deployed as static pages to our subdomain of ReadTheDocs . MkDocs is a Python program and should run on any major platform. See http://www.mkdocs.org/ for information on how to install it and how to generate a live local preview of the documentation while you're working on writing it. In short: $ pip install mkdocs $ mkdocs serve","title":"Documentation"},{"location":"Developers-Guide/#debug-layers","text":"Adding new renderer is very easy. You just need to create new class (preferably in org.opentripplanner.inspector package) which implements EdgeVertexRenderer. It is best if class name ends with Rendered. To implement this interface you need to write three functions renderEdge , renderVertex and getName . Both render functions accepts EdgeVisualAttributes object in which label of edge/vertex and color can be set. And both return true if edge/vertex should be rendered and false otherwise. getName function should return short descriptive name of the class and will be shown in layer chooser. For examples how to write renderers you can look into example renderers which are all in org.opentripplanner.inspector package. After your class is written you only need to add it to TileRenderManager: //This is how Wheelchair renderer is added renderers . put ( \"wheelchair\" , new EdgeVertexTileRenderer ( new WheelchairEdgeRenderer ())); wheelchair is internal layer key and should consist of a-zA-Z and -. By default all the tiles have cache headers to cache them for one hour. This can become problematic if you are changing renderers a lot. To disable this change GraphInspectorTileResource : //This lines CacheControl cc = new CacheControl (); cc . setMaxAge ( 3600 ); cc . setNoCache ( false ); //to this: CacheControl cc = new CacheControl (); cc . setNoCache ( true );","title":"Debug layers"},{"location":"Developers-Guide/#date-format","text":"Please use only ISO 8601 date format (YYYY-MM-DD) in documentation, comments, and throughout the project. This avoids the ambiguity that can result from differing local interpretations of date formats like 02/01/12.","title":"Date format"},{"location":"Developers-Guide/#code-style","text":"The OTP code style is described on a separate style guide page .","title":"Code style"},{"location":"Developers-Guide/#continuous-integration","text":"The OpenTripPlanner project uses the Travis CI continuous integration system . Any time a change is pushed to the main OpenTripPlanner repository on GitHub, this server will compile and test the new code, providing feedback on the stability of the build.","title":"Continuous Integration"},{"location":"Developers-Guide/#release-process","text":"This section serves as a checklist for the person performing releases. Note that much of this mimics the actions taken by the Maven release plugin. Based on past experience, the Maven release plugin can fail at various points in the process leaving the repo in a confusing state. Taking each action manually is more tedious, but keeps eyes on each step and is less prone to failure. Releases are performed off the master branch, and are tagged with git annotated tags. Check that your local copy of the dev branch is up to date with no uncommitted changes git status git checkout dev-1.x git clean -df git pull Verify that all dependencies in the POM are non-SNAPSHOT versions Currently we do have one SNAPSHOT dependency on crosby.binary.osmpbf which we are working to eliminate Update docs/Changelog.md Lines should have been added or updated as each pull request was merged If you suspect any changes are not reflected in the Changelog, review the commit log and add any missing items Update the header at the top of the list from x.y.z-SNAPSHOT to just x.y.z (current date) Check in any changes, and push to Github Check on Travis that the build is currently passing Link to OTP builds on Travis CI Switch to the HEAD of master branch, and ensure it's up to date with no uncommitted changes git checkout master git status git clean -df git pull Merge the dev branch into master git merge dev-1.x Bump the SNAPSHOT version in the POM to the release version Edit version in POM, removing SNAPSHOT and increasing version numbers as needed (following semantic versioning) git add pom.xml git commit -m \"prepare release x.y.z\" Run a test build of the release locally, without deploying it mvn clean install site The install goal will sign the Maven artifacts so you need the GPG signing certificate set up You can also use the package goal instead of the install goal to avoid signing if you don't have the GPG certificate installed. All tests should pass This build will also create Enunciate API docs and Javadoc with the correct non-snapshot version number Deploy the documentation to AWS S3 You have to do this right after the test release build to ensure the right version number in the docs You will need AWSCLI tools ( sudo pip install -U awscli ) You will need AWS credentials with write access to the bucket s3://dev.opentripplanner.org aws s3 cp --recursive target/site/apidocs s3://dev.opentripplanner.org/javadoc/x.y.z --acl public-read aws s3 cp --recursive target/site/enunciate/apidocs s3://dev.opentripplanner.org/apidoc/x.y.z --acl public-read Check that docs are readable and show the correct version via the development documentation landing page . Finally, if everything looks good, tag and push this release to make it official and trigger deployment git tag -a vX.Y.Z -m \"release X.Y.Z\" git push origin vX.Y.Z Pushing the tag will trigger a Travis CI build and deployment of release Maven artifacts Note that only one commit may have a particular non-snapshot version in the POM (this is the commit that should be tagged as the release) Set up next development iteration Add a new section header to docs/Changelog.md like x.y+1.0-SNAPSHOT (in progress) Edit minor version in pom.xml to x.y+1.0-SNAPSHOT git add pom.xml docs/Changelog.md git commit -m \"Prepare next development iteration x.y+1.0-SNAPSHOT\" git push Check that Travis CI build of the release tag succeeded Link to OTP builds on Travis CI Check the end of the build log to make sure the Maven artifacts were staged for release Check that Maven artifact appears on Maven Central (deployment succeeded) Directory listing of OTP releases on Maven Central It may take a while (half an hour) for releases to show up in the central repo after Travis uploads the artifacts Merge master back into dev (to sync up the Maven artifact version from the POM) git checkout dev-1.x git merge master git push Make sure the main documentation is built For some reason it doesn't always build automatically Go to builds of docs.opentripplanner.org Click \"build version: latest\" Email the OTP dev and users mailing lists Mention the new version number. Provide links to the new developer documentation. Provide links to the artifacts directory on Maven Central. Trigger build of latest OTP documentation on Readthedocs.","title":"Release Process"},{"location":"Developers-Guide/#additional-information-on-releases","text":"OpenTripPlanner is released as Maven artifacts to Maven Central. These include compiled and source code JARs as well as a \"shaded\" JAR containing all dependencies, allowing stand-alone usage. This release process is handled by the Sonatype Nexus Staging plugin, configured in the OpenTripPlanner POM. Typically this final Maven deployment action is performed automatically when the Travis CI build succeeds in building a non-SNAPSHOT version.","title":"Additional Information on Releases"},{"location":"Developers-Guide/#artifact-signing","text":"Maven release artifacts must be digitally signed to prove their origin. This is a safeguard against compromised code from a malicious third party being disguised as a trusted library. The OTP artifact signing key was created by Conveyal. We export only that signing subkey, with our company's main key blanked out. Therefore, even if someone managed to acquire the decrypted key file and the associated GPG passphrase, they would not have the main key. We could deactivate the signing key and create a new one, without the main key being compromised. The exported signing key is present in the root of the git repo as the encrypted file maven-artifact-signing-key.asc.enc . When building a tagged release, Travis CI will decrypt this file and import it into GPG on the build machine. The signing key ID and GPG passphrase are also present as encrypted environment variables in the Travis configuration YAML. This only happens on code from non-fork, non-pull-request commits, ensuring that no unreviewed third-party code has access to these files or variables. OpenTripPlanner's POM is set up to sign artifacts in the verify phase, which means signing will happen for the install and deploy targets, but not the package target. When performing a local test build, if you do mvn clean install site it will test the signing process. If you do not have the certificate installed, you can instead to mvn clean package site to bypass signing, but this provides less certainty that everything is set up correctly for the CI-driven final release.","title":"Artifact Signing"},{"location":"Getting-OTP/","text":"Getting OpenTripPlanner Pre-built JARs OpenTripPlanner is distributed as a single stand-alone runnable JAR file. These JARs are deployed to the Sonatype OSSRH Maven repository, and release versions are synced to the Maven Central repository. Most people will want to go to the OTP directory at Maven Central , navigate to the directory for the highest version number, and download the file whose name ends with .shaded.jar . We use the Travis continuous integration system to build OTP every time a change is made. You can find the JARs resulting from those builds in the OSSRH staging repository . A directory named x.y.z-SNAPSHOT contain JARs for builds leading up to (preceding) the x.y.z release. Files within SNAPSHOT directories are named using the date and time that the build occurred. Building from Source You may also choose to build OTP from its source code. If you will be modifying OTP you will need to know how to rebuild it (though your IDE may take care of this build cycle for you). If you have the right software installed, building OTP locally from its source code is not particularly difficult. You should only need the following software: Git, a version control system Java Development Kit, preferably version 11 Maven, a build and dependency management system You will also need a reliable internet connection so Maven can fetch all of OTP's dependencies (the libraries it uses). Once you have these packages installed, create and/or switch to the directory where you will keep your Git repositories and make a local copy of the OTP source code: mkdir git cd git git clone git@github.com:opentripplanner/OpenTripPlanner.git Then change to the newly cloned OpenTripPlanner repository directory and start a build: cd OpenTripPlanner mvn clean package Maven should then be able to download all the libraries and other dependencies necessary to compile OTP. If all goes well you should see a success message like the following: [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 42.164s [INFO] Finished at: Tue Feb 18 19:35:48 CET 2014 [INFO] Final Memory: 88M/695M [INFO] ------------------------------------------------------------------------ This build process should produce a JAR file called otp-x.y.z-shaded.jar in the target/ directory which contains all the compiled OTP classes and their dependencies (the external libraries they use). The shell script called 'otp' in the root of the cloned repository will start the main class of that JAR file under a Java virtual machine, so after the Maven build completes you should be able to run ./otp --help and see an OTP help message including command line options. Due to the way Maven works, this script is not executable by default, so you will need to do chmod u+x ./otp before you run it to mark it as executable. The words \"clean package\" are the build steps you want to run. You're telling maven to clean up any extraneous junk in the directory, then perform all the build steps, including compilation, up to and including \"package\", which bundles the compiled program into a single JAR file for distribution. If you have just cloned OTP you will be working with the default \"master\" branch, where most active development occurs. This is not the most stable or deployment-ready code available. To avoid newly minted bugs or undocumented behavior, you can use Git to check out a specific release (tag or branch) of OTP to work with. The Maven build also includes many time-consuming integration tests. When working with a stable release of OTP, you may want to turn them off by adding the switch: -DskipTests . For example, you could do the following: cd OpenTripPlanner git checkout v1.4.0 git clean -df mvn clean package -DskipTests Please note that the build process creates two distinct versions of the OTP JAR file. The one ending in -shaded.jar is much bigger because it contains copies of all the external libraries that OTP uses. It serves as a stand-alone runnable distribution of OTP. The one with a version number but without the word shaded contains only OTP itself, without any external dependencies. This JAR is useful when OTP is included as a component in some other project, where we want the dependency management system to gather all the external libraries automatically. Maven Repository OpenTripPlanner is a Maven project. Maven is a combined build and dependency management system: it fetches all the external libraries that OTP uses, runs all the commands to compile the OTP source code into runnable form, performs tests, and can then deploy the final \"artifact\" (the runnable JAR file) to the Maven repository, from which it can be automatically included in other Java projects. This repository is machine-readable (by Maven or other build systems) and also provides human readable directory listings via HTTP. You can fetch an OTP JAR from this repository by constructing the proper URL for the release you want. For example, release 1.1.0 will be found at https://repo1.maven.org/maven2/org/opentripplanner/otp/1.1.0/otp-1.1.0-shaded.jar . To make use of OTP in another Maven project, you must specify it as a dependency in that project's pom.xml : <dependency> <groupId> org.opentripplanner </groupId> <artifactId> otp </artifactId> <version> 1.2.0 </version> </dependency> After each successful build, the Travis continuous integration system deploys the final OTP \"artifact\" (the runnable JAR) to our Maven repository as a \"SNAPSHOT\" build. This means that a Maven project depending on OTP as a library can always fetch the latest work in progress by specifying a snapshot artifact: <repositories> <repository> <id> ossrh_snapshots </id> <name> Sonatype OSSRH Shapshot Repository </name> <url> https://oss.sonatype.org/content/repositories/snapshots/ </url> </repository> </repositories> <dependency> <groupId> org.opentripplanner </groupId> <artifactId> otp </artifactId> <version> 1.2.0-SNAPSHOT </version> </dependency>","title":"Getting OTP"},{"location":"Getting-OTP/#getting-opentripplanner","text":"","title":"Getting OpenTripPlanner"},{"location":"Getting-OTP/#pre-built-jars","text":"OpenTripPlanner is distributed as a single stand-alone runnable JAR file. These JARs are deployed to the Sonatype OSSRH Maven repository, and release versions are synced to the Maven Central repository. Most people will want to go to the OTP directory at Maven Central , navigate to the directory for the highest version number, and download the file whose name ends with .shaded.jar . We use the Travis continuous integration system to build OTP every time a change is made. You can find the JARs resulting from those builds in the OSSRH staging repository . A directory named x.y.z-SNAPSHOT contain JARs for builds leading up to (preceding) the x.y.z release. Files within SNAPSHOT directories are named using the date and time that the build occurred.","title":"Pre-built JARs"},{"location":"Getting-OTP/#building-from-source","text":"You may also choose to build OTP from its source code. If you will be modifying OTP you will need to know how to rebuild it (though your IDE may take care of this build cycle for you). If you have the right software installed, building OTP locally from its source code is not particularly difficult. You should only need the following software: Git, a version control system Java Development Kit, preferably version 11 Maven, a build and dependency management system You will also need a reliable internet connection so Maven can fetch all of OTP's dependencies (the libraries it uses). Once you have these packages installed, create and/or switch to the directory where you will keep your Git repositories and make a local copy of the OTP source code: mkdir git cd git git clone git@github.com:opentripplanner/OpenTripPlanner.git Then change to the newly cloned OpenTripPlanner repository directory and start a build: cd OpenTripPlanner mvn clean package Maven should then be able to download all the libraries and other dependencies necessary to compile OTP. If all goes well you should see a success message like the following: [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 42.164s [INFO] Finished at: Tue Feb 18 19:35:48 CET 2014 [INFO] Final Memory: 88M/695M [INFO] ------------------------------------------------------------------------ This build process should produce a JAR file called otp-x.y.z-shaded.jar in the target/ directory which contains all the compiled OTP classes and their dependencies (the external libraries they use). The shell script called 'otp' in the root of the cloned repository will start the main class of that JAR file under a Java virtual machine, so after the Maven build completes you should be able to run ./otp --help and see an OTP help message including command line options. Due to the way Maven works, this script is not executable by default, so you will need to do chmod u+x ./otp before you run it to mark it as executable. The words \"clean package\" are the build steps you want to run. You're telling maven to clean up any extraneous junk in the directory, then perform all the build steps, including compilation, up to and including \"package\", which bundles the compiled program into a single JAR file for distribution. If you have just cloned OTP you will be working with the default \"master\" branch, where most active development occurs. This is not the most stable or deployment-ready code available. To avoid newly minted bugs or undocumented behavior, you can use Git to check out a specific release (tag or branch) of OTP to work with. The Maven build also includes many time-consuming integration tests. When working with a stable release of OTP, you may want to turn them off by adding the switch: -DskipTests . For example, you could do the following: cd OpenTripPlanner git checkout v1.4.0 git clean -df mvn clean package -DskipTests Please note that the build process creates two distinct versions of the OTP JAR file. The one ending in -shaded.jar is much bigger because it contains copies of all the external libraries that OTP uses. It serves as a stand-alone runnable distribution of OTP. The one with a version number but without the word shaded contains only OTP itself, without any external dependencies. This JAR is useful when OTP is included as a component in some other project, where we want the dependency management system to gather all the external libraries automatically.","title":"Building from Source"},{"location":"Getting-OTP/#maven-repository","text":"OpenTripPlanner is a Maven project. Maven is a combined build and dependency management system: it fetches all the external libraries that OTP uses, runs all the commands to compile the OTP source code into runnable form, performs tests, and can then deploy the final \"artifact\" (the runnable JAR file) to the Maven repository, from which it can be automatically included in other Java projects. This repository is machine-readable (by Maven or other build systems) and also provides human readable directory listings via HTTP. You can fetch an OTP JAR from this repository by constructing the proper URL for the release you want. For example, release 1.1.0 will be found at https://repo1.maven.org/maven2/org/opentripplanner/otp/1.1.0/otp-1.1.0-shaded.jar . To make use of OTP in another Maven project, you must specify it as a dependency in that project's pom.xml : <dependency> <groupId> org.opentripplanner </groupId> <artifactId> otp </artifactId> <version> 1.2.0 </version> </dependency> After each successful build, the Travis continuous integration system deploys the final OTP \"artifact\" (the runnable JAR) to our Maven repository as a \"SNAPSHOT\" build. This means that a Maven project depending on OTP as a library can always fetch the latest work in progress by specifying a snapshot artifact: <repositories> <repository> <id> ossrh_snapshots </id> <name> Sonatype OSSRH Shapshot Repository </name> <url> https://oss.sonatype.org/content/repositories/snapshots/ </url> </repository> </repositories> <dependency> <groupId> org.opentripplanner </groupId> <artifactId> otp </artifactId> <version> 1.2.0-SNAPSHOT </version> </dependency>","title":"Maven Repository"},{"location":"Governance/","text":"Project Governance OpenTripPlanner is a member project of the Software Freedom Conservancy . Development of OpenTripPlanner is managed by a Project Leadership Committee (PLC) which makes decisions by simple majority vote. The current members of this committee are (in alphabetical order): Name Affiliation Sean Barbeau University of South Florida Sheldon Brown Cambridge Systematics Andrew Byrd Conveyal Thomas Craig Trillium Transit Drew Dara-Abrams Interline David Emory MARTA (Atlanta, Georgia USA) Thomas Gran Ruter & Entur (Norway) Tuukka Hastrup Maanteeamet (Estonia) Joel Lappalainan Digitransit (Finland) Frank Purcell TriMet (Portland, Oregon) Evan Siroky IBI Group David Turner ex- OpenPlans The PLC holds a quarterly video conference on the first Tuesday of June, September, December, and March. An agenda is prepared as a collaborative document in advance of each quarterly meeting. These meetings are held at 8AM US Pacific time to accommodate members in the US Pacific, US Eastern, and Central European time zones. We take care to avoid a governance system that is too conceptual or process-heavy. The main goal is to have regular agenda-driven meetings that yield clear decisions and action items assigned to specific people. The committee should ideally be composed of active, professional contributors to the OpenTripPlanner project, including representatives of organizations that host official public deployments of OTP. We enfore a policy on the review and merging of new changes to the OTP system, guided by a roadmap maintained by the committee. All changes must be reviewed and approved by at least two people from two different organizations. The list of approved reviewers is the PLC Github group, visible here https://github.com/orgs/opentripplanner/teams/plc/members","title":"Governance"},{"location":"Governance/#project-governance","text":"OpenTripPlanner is a member project of the Software Freedom Conservancy . Development of OpenTripPlanner is managed by a Project Leadership Committee (PLC) which makes decisions by simple majority vote. The current members of this committee are (in alphabetical order): Name Affiliation Sean Barbeau University of South Florida Sheldon Brown Cambridge Systematics Andrew Byrd Conveyal Thomas Craig Trillium Transit Drew Dara-Abrams Interline David Emory MARTA (Atlanta, Georgia USA) Thomas Gran Ruter & Entur (Norway) Tuukka Hastrup Maanteeamet (Estonia) Joel Lappalainan Digitransit (Finland) Frank Purcell TriMet (Portland, Oregon) Evan Siroky IBI Group David Turner ex- OpenPlans The PLC holds a quarterly video conference on the first Tuesday of June, September, December, and March. An agenda is prepared as a collaborative document in advance of each quarterly meeting. These meetings are held at 8AM US Pacific time to accommodate members in the US Pacific, US Eastern, and Central European time zones. We take care to avoid a governance system that is too conceptual or process-heavy. The main goal is to have regular agenda-driven meetings that yield clear decisions and action items assigned to specific people. The committee should ideally be composed of active, professional contributors to the OpenTripPlanner project, including representatives of organizations that host official public deployments of OTP. We enfore a policy on the review and merging of new changes to the OTP system, guided by a roadmap maintained by the committee. All changes must be reviewed and approved by at least two people from two different organizations. The list of approved reviewers is the PLC Github group, visible here https://github.com/orgs/opentripplanner/teams/plc/members","title":"Project Governance"},{"location":"History/","text":"OpenTripPlanner Project History OpenTripPlanner 1 OpenTripPlanner was seeded by Portland, Oregon's transit agency TriMet with a Regional Travel Options grant and opened with a 3-day Kick-Off Workshop in July of 2009 bringing together transit agencies and the authors of the major open source transit passenger information software of the day: David Emory of FivePoints, Brian Ferris of OneBusAway , and Brandon Martin-Anderson of Graphserver . From 2009 through 2012, development was coordinated by New York nonprofit OpenPlans . In 2011 a second workshop was held to mark the end of the first phase of development. TriMet's 2009-2011 OTP Final Report summarizes progress at that point. The project has since grown to encompass a global community of users and developers. By early 2013, OpenTripPlanner had become the primary trip planning software used by TriMet in the Portland regional trip planner and was backing several popular mobile applications. Public-facing OpenTripPlanner instances were available in at least ten countries throughout the world. At this point the OpenPlans transportation software team became the independent consultancy Conveyal . The original OpenTripPlanner development team from OpenPlans still actively participates in programming, design, and community coordination via the mailing list and their roles on the OTP Project Leadership Committee . In summer of 2013, the OpenTripPlanner project was accepted for membership in the Software Freedom Conservancy (SFC) . SFC handles the legal and financial details common to many open source projects. In 2013-2014 OpenTripPlanner was a focal point in the Dutch Transport Ministry's MMRI (MultiModal Travel Information) project which encouraged investment in trip planning platforms and services. A consortium of five companies worked together to improve OpenTripPlanner performance in large regional transport networks and add support for streaming real-time data, making itineraries reflect service modifications and delays only seconds after vehicles report their positions. Another consortium embarked on a full rewrite of the trip planning core called RRRR (or R4) , a proof of concept validating extremely efficient routing techniques and serving as an early prototype for OTP2. In the fall of 2014, Arlington, Virginia launched a new commute planning site for the Washington, DC metropolitan area, depending on OpenTripPlanner to weigh the costs and benefits of various travel options. In 2015 the New York State department of transportation's 511 transit trip planner began using OTP to provide itineraries for public transit systems throughout the state from a single unified OTP instance. Starting in early 2016, the regional transport authorities of Helsinki, Finland (HSL) and Oslo, Norway (Ruter) began using a completely open source passenger information system based on OpenTripPlanner. National-scale OpenTripPlanner instances were also created in Finland and Norway. After seven years of hard work and almost 10,000 commits from over 100 contributors around the world, OTP version 1.0 was released on 9 September 2016. OpenTripPlanner 2 The OTP community has a long history with round-based routing algorithms. FivePoints, one of the predecessor projects to OTP, used a round-based method several years before the now-familiar Raptor algorithm was published in an influential paper . OpenPlans carried out experiments with routing innovations like Raptor and contraction hierarchies as they emerged in the academic literature. Research and development work on OTP scalability has focused on round-based tabular approaches since the MMRI pre-commercial procurement projects of 2013-2014. Conveyal built its high-performance transportation network analysis system around its R5 router . So in strategy discussions, the expected technical direction was clear. In the second quarter of 2018, Ruter and Entur took the lead on finally integrating a new round-based transit routing engine inspired by R5 into OTP. They also began adding support for importing EU-standard Netex data, making it possible for passenger information services in Europe to achieve regulatory compliance with a fully open source software stack. In June 2018, at the first OTP international summit hosted by Cambridge Systematics in Boston, the project leadership committee officially approved this roadmap toward OTP2. In April of 2019, the second OTP international summit was hosted by Entur in Oslo. Encouraged by the crowd of participants from across the Nordic countries and North America, work on OTP2 continued unabated through 2019 and into 2020 with multiple weekly videoconferences bringing together software developers from Entur, Conveyal, IBI Group, and Kyyti among others. As of September 2020, OTP2 is now in feature freeze, undergoing final testing and cleanup for a 2.0 release in Q4 of 2020. The release candidate of OTP2 is seeing production use for a subset of requests in national-scale trip planners. The release of OTP 2.0 is planned in advance of the next OTP leadership committee meeting in early December 2020. A working group is also being assembled to ensure follow-up maintenance of the final version of OTP1 to be released concurrently with 2.0.","title":"History"},{"location":"History/#opentripplanner-project-history","text":"","title":"OpenTripPlanner Project History"},{"location":"History/#opentripplanner-1","text":"OpenTripPlanner was seeded by Portland, Oregon's transit agency TriMet with a Regional Travel Options grant and opened with a 3-day Kick-Off Workshop in July of 2009 bringing together transit agencies and the authors of the major open source transit passenger information software of the day: David Emory of FivePoints, Brian Ferris of OneBusAway , and Brandon Martin-Anderson of Graphserver . From 2009 through 2012, development was coordinated by New York nonprofit OpenPlans . In 2011 a second workshop was held to mark the end of the first phase of development. TriMet's 2009-2011 OTP Final Report summarizes progress at that point. The project has since grown to encompass a global community of users and developers. By early 2013, OpenTripPlanner had become the primary trip planning software used by TriMet in the Portland regional trip planner and was backing several popular mobile applications. Public-facing OpenTripPlanner instances were available in at least ten countries throughout the world. At this point the OpenPlans transportation software team became the independent consultancy Conveyal . The original OpenTripPlanner development team from OpenPlans still actively participates in programming, design, and community coordination via the mailing list and their roles on the OTP Project Leadership Committee . In summer of 2013, the OpenTripPlanner project was accepted for membership in the Software Freedom Conservancy (SFC) . SFC handles the legal and financial details common to many open source projects. In 2013-2014 OpenTripPlanner was a focal point in the Dutch Transport Ministry's MMRI (MultiModal Travel Information) project which encouraged investment in trip planning platforms and services. A consortium of five companies worked together to improve OpenTripPlanner performance in large regional transport networks and add support for streaming real-time data, making itineraries reflect service modifications and delays only seconds after vehicles report their positions. Another consortium embarked on a full rewrite of the trip planning core called RRRR (or R4) , a proof of concept validating extremely efficient routing techniques and serving as an early prototype for OTP2. In the fall of 2014, Arlington, Virginia launched a new commute planning site for the Washington, DC metropolitan area, depending on OpenTripPlanner to weigh the costs and benefits of various travel options. In 2015 the New York State department of transportation's 511 transit trip planner began using OTP to provide itineraries for public transit systems throughout the state from a single unified OTP instance. Starting in early 2016, the regional transport authorities of Helsinki, Finland (HSL) and Oslo, Norway (Ruter) began using a completely open source passenger information system based on OpenTripPlanner. National-scale OpenTripPlanner instances were also created in Finland and Norway. After seven years of hard work and almost 10,000 commits from over 100 contributors around the world, OTP version 1.0 was released on 9 September 2016.","title":"OpenTripPlanner 1"},{"location":"History/#opentripplanner-2","text":"The OTP community has a long history with round-based routing algorithms. FivePoints, one of the predecessor projects to OTP, used a round-based method several years before the now-familiar Raptor algorithm was published in an influential paper . OpenPlans carried out experiments with routing innovations like Raptor and contraction hierarchies as they emerged in the academic literature. Research and development work on OTP scalability has focused on round-based tabular approaches since the MMRI pre-commercial procurement projects of 2013-2014. Conveyal built its high-performance transportation network analysis system around its R5 router . So in strategy discussions, the expected technical direction was clear. In the second quarter of 2018, Ruter and Entur took the lead on finally integrating a new round-based transit routing engine inspired by R5 into OTP. They also began adding support for importing EU-standard Netex data, making it possible for passenger information services in Europe to achieve regulatory compliance with a fully open source software stack. In June 2018, at the first OTP international summit hosted by Cambridge Systematics in Boston, the project leadership committee officially approved this roadmap toward OTP2. In April of 2019, the second OTP international summit was hosted by Entur in Oslo. Encouraged by the crowd of participants from across the Nordic countries and North America, work on OTP2 continued unabated through 2019 and into 2020 with multiple weekly videoconferences bringing together software developers from Entur, Conveyal, IBI Group, and Kyyti among others. As of September 2020, OTP2 is now in feature freeze, undergoing final testing and cleanup for a 2.0 release in Q4 of 2020. The release candidate of OTP2 is seeing production use for a subset of requests in national-scale trip planners. The release of OTP 2.0 is planned in advance of the next OTP leadership committee meeting in early December 2020. A working group is also being assembled to ensure follow-up maintenance of the final version of OTP1 to be released concurrently with 2.0.","title":"OpenTripPlanner 2"},{"location":"Interfaces-Data-Sources/","text":"OTP Interfaces (APIs) and Data Sources Input Formats At the core of OpenTripPlanner is a library of Java code that finds efficient paths through multi-modal transportation networks built from OpenStreetMap and GTFS data. It can also receive GTFS-RT (realtime) data... In addition to GTFS, OTP2 can also load data in the Nordic Profile of Netex, the EU-standard transit data interchange format. The upcoming EU-wide profile was heavily influenced by the Nordic Profile and uses the same schema, so eventual support for the full the EU profile is a possibility. GTFS and Netex data are converted into OTP's own internal model which is a superset of both. It is therefore possible to mix Netex and GTFS data, and potentially even data from other sources. Interfaces to Services (APIs) Several different services are built upon this routing library, and expose APIs: The OTP Routing API is a RESTful web service that responds to journey planning requests with itineraries in a JSON or XML representation. You can combine this API with OTP's standard Javascript front end to provide users with trip planning functionality in a familiar map interface, or write your own applications that talk directly to the API. The OTP Transit Index API is another RESTful web service that provides information derived from the input GTFS feed(s). Examples include routes serving a particular stop, upcoming vehicles at a particular stop, upcoming stops on a given trip, etc. More complex transit data requests can be formulated using a GraphQL API. Sandbox APIs Additional experimental APIs are provided by sandbox extensions : The Health API provides endpoints for checking the health status of the OTP instance. It can be useful when running OTP in a container. The Transmodel GraphQL API is the Transmodel API (version 3) used at Entur in production(Sep, 2020). The HSL Legacy GraphQL API is the HSL's GraphQL API used by the Digitransit project.","title":"Interfaces and Data Sources"},{"location":"Interfaces-Data-Sources/#otp-interfaces-apis-and-data-sources","text":"","title":"OTP Interfaces (APIs) and Data Sources"},{"location":"Interfaces-Data-Sources/#input-formats","text":"At the core of OpenTripPlanner is a library of Java code that finds efficient paths through multi-modal transportation networks built from OpenStreetMap and GTFS data. It can also receive GTFS-RT (realtime) data... In addition to GTFS, OTP2 can also load data in the Nordic Profile of Netex, the EU-standard transit data interchange format. The upcoming EU-wide profile was heavily influenced by the Nordic Profile and uses the same schema, so eventual support for the full the EU profile is a possibility. GTFS and Netex data are converted into OTP's own internal model which is a superset of both. It is therefore possible to mix Netex and GTFS data, and potentially even data from other sources.","title":"Input Formats"},{"location":"Interfaces-Data-Sources/#interfaces-to-services-apis","text":"Several different services are built upon this routing library, and expose APIs: The OTP Routing API is a RESTful web service that responds to journey planning requests with itineraries in a JSON or XML representation. You can combine this API with OTP's standard Javascript front end to provide users with trip planning functionality in a familiar map interface, or write your own applications that talk directly to the API. The OTP Transit Index API is another RESTful web service that provides information derived from the input GTFS feed(s). Examples include routes serving a particular stop, upcoming vehicles at a particular stop, upcoming stops on a given trip, etc. More complex transit data requests can be formulated using a GraphQL API.","title":"Interfaces to Services (APIs)"},{"location":"Interfaces-Data-Sources/#sandbox-apis","text":"Additional experimental APIs are provided by sandbox extensions : The Health API provides endpoints for checking the health status of the OTP instance. It can be useful when running OTP in a container. The Transmodel GraphQL API is the Transmodel API (version 3) used at Entur in production(Sep, 2020). The HSL Legacy GraphQL API is the HSL's GraphQL API used by the Digitransit project.","title":"Sandbox APIs"},{"location":"Localization/","text":"Localization This page contains instructions for both developers and translators on how to make the OTP interface usable by people who speak different languages. Developers will need to take certain steps to mark translatable strings within the source code. Translators will need to edit specific files within the project to create or revise the translation for their language. In OTP we use gettext for localization, for the following reasons: Plural suport Context support Automatic extraction of translatable strings from source code Translator comments support Source references (we can see where each translated string is used in the source code) In the Javascript UI the i18next library is used. Three types of files are used in the OTP localization process: The .pot file is the message template. It is a starting point for creating new .po files. .po files are created and edited by translators based on the .pot file. .json files are generated from the .po files for each language. .js files are localization configuration files which specify units and time/date formats. Only the .po and .js files are directly edited. The .pot file is created from an automated analysis of annotated source code. The .json files are also automatically generated as an easy way for the Javascript UI to consume the contents of the .po files. All translation files are in the directory /src/client/i18n . For Software Developers: Adding New Strings When you add a string to Javascript source that will be seen by the end user, wherever that string is referenced you should surround it with a call to a special function. The name of the function depends on what kind of string it is: basic string: _tr('string', parameters) basic string with context: ngettext('context', 'string') string with plural: ngettext('singular', 'plural', quantity) string with plural and context: npgettext('context', 'singular', 'plural', quantity) For more detail, see Sprintf parameters . A \"context\" is any string (preferably short and without whitespace) that is used to disambiguate the translation of the main string. It is used when developers get input from translators that some string should be translated in different ways in different parts of the program. Each of those distinct places will be assigned a different context string. When you add strings to the source code, if you think that translators might not understand how the string is used or what parameters it requires, add translator comments like this: //TRANSLATORS: Start: location at [time date] (Used in print itinerary //when do you start your trip) html += '<h3>' + _tr ( 'Start: %s at %s' , this . getStartLocationStr (), this . getStartTimeStr ()) + '</h3>' ; Translator comments must always start with TRANSLATORS: and must be in the line immediately before translated string. Otherwise they won't be extracted together with the string. Examples: Basic translated string //TRANSLATORS: Board Public transit route name (agency name //Stop ID ) start time html += '<li><b>' + _tr ( 'Board' ) + '</b>: ' + leg . from . name + ' (' + leg . from . stopId . agencyId + ' Stop ID #' + //With named sprintf parameters (our preferred option) //TRANSLATORS: Start: location at [time date] (Used in print itinerary //when do you start your trip) html += '<h3>' + _tr ( 'Start: %(location)s at %(time_date)s' , { 'location' : this . getStartLocationStr (), 'time_date' : this . getStartTimeStr ()}) + '</h3>' ; //With positional sprintf parameters (to be avoided because word order changes between languages) html += '<h3>' + _tr ( 'End: %1$s at %2$s' , this . getEndLocationStr (), this . getEndTimeStr ()) + '</h3>' ; Normal string with context if ( leg . headsign ) html += pgettext ( \"bus_direction\" , \" to \" ) + leg . headsign ; //same string could be different translation //TRANSLATORS: [distance] to [name of destination] html += \" \" + otp . util . Itin . distanceString ( leg . distance ) + pgettext ( \"direction\" , \" to \" ) + leg . to . name ; Plural strings //TRANSLATORS: widget title this . setTitle ( ngettext ( \"%d Itinerary Returned\" , \"%d Itineraries Returned\" , this . itineraries . length )); If you add new strings to the source code, it is good practice to also update the translation template and the translations but it is not mandatory (these can be updated later). It is also recommended to include \"i18n string change\" in the commit message. Updating translations Translations are updated with the help of Babel and i18next-conv (xgettext doesn't yet have great Javascript support). Babel is used to extract strings from the Javascript source code into the shared .POT translation template, and also for updating the existing .PO language translations when new strings are introduced in the template. i18next-conv is used to convert the .PO translation files for the individual languages to .json files which are used by the Javascript translation library. Installing Babel You can install it from your operating system's package repository (if available) or you can use virtualenv . Install virtualenv (This depends on your operating system) Create virtualenv with name .venv in directory where src and other files resides (Root OpenTripPlanner directory). virtualenv2 .venv (python 2) or python3 -m venv .venv (python 3) Use virtualenv source .venv/bin/activate Install babel pip install babel If you didn't install babel from virtualenv in root OpenTripPlanner directory you have to add path to babel in Makefile. change PYBABEL variable to path to pybabel. Installing i18next-conv i18next-conv requires nodejs . Once you have NodeJS installed, use npm install i18next-conv to install i18next-conv in the same directory where you created virtualenv. Updating the .pot Template In the root of the OTP repo, run make . The commands in the Makefile will extract the translatable strings from the Javascript files and update the translation template messages.pot , as well as the .po translation files for all the different languages. Once this is done, you can translate the new strings in the .po files. After saving the updated .po file, run make update_js to transform to PO files into .json , which is used at runtime by the Javascript translation library. After you rebuild OTP, all new strings should be visible in the UI. For Translators: Creating New Translations The following can get a bit technical. If you want to do a translation but don't want to / know how to install all this software, post to the opentripplanner-dev mailing list stating what language you want to translate, and someone will make you a corresponding .po file. Creating a New Translation File New .po files are created from the .pot template with the help of msginit , which is run like this: msginit init -l <LAN> -i messages.pot -o <LAN>.po , where <LAN> is a culture code. New .po files can also be created with the help of Poedit . All translation files should be placed in the directory /src/client/i18n . Please use the ISO language code as the culture code (e.g. fr.po for French). We will append country codes in the following limited circumstances: British versus US English ( en_GB.po and en_US.po ) Brazilian Portuguese pt_BR.po , as opposed to pt.po for European Portuguese Chinese: zh_TW.po for traditional characters as used in e.g. Taiwan and Hong Kong, and zh_CN.po for simplified characters as used in mainland China, Singapore, etc. These conventions are based on the Launchpad Translation page. In Linux you can see the culture codes for all the locales you have installed with the command locale -a . A list of culture codes is also availible here . Performing the Translation Configuration Copy the locale configuration script English.js from /src/client/js/otp/locale to YourLanguage.js and customize it to your language. Change the name, units, locale_short and datepicker_locale_short values. Translate infoWidgets and localize the time/date formats. Then take the following steps: Add the culture code to the LANGS variable in the Makefile` Add the new YourLanguage.js to the locales variable in /src/client/js/otp/config.js Add a new datepicker translation to /src/client/js/lib/jquery-ui/i18n Load the new datepicker translation and YourLanguage.js in /src/client/index.html Translating Strings For translating the strings themselves, you can use any program that supports gettext files. You can in theory use any text editor, but programs or plugins purpose-built for translating are recommended. Most of them support checking parameter correctness, translation memory, web translating services etc. to make the task easier. Here are some such programs (all free and open source): Poedit For Linux, Windows, and Mac. Use a version newer then 1.5. This is the recommended choice for getting started with localization. It supports translation memory and file context. Web Poedit Usable from within a web browser, you don't have to install or register Gted A plugin for the Eclipse IDE. Lokalize Runs under KDE on Linux, has some Windows support. Supports translation memory and file context. Virtaal For Linux, Windows, and beta for Mac. Supports Google and Microsoft web translation and other translation memory services. All these programs support setting a string to \"fuzzy\", marking that it needs review etc. in case you translate something but aren't sure of it's correctness. Sometimes those flags are set automatically if the original string was changed and translators must check if the translation is still correct. Caveats Be careful when translating that the translated strings have the same format as the original. If spaces appear at the start or end of the strings, they must also appear in the translation. The order of unnamed (positional) parameters may change depending on the target language. You can also leave parameter out of the translation if it is irrelevant in the target language.","title":"Localization"},{"location":"Localization/#localization","text":"This page contains instructions for both developers and translators on how to make the OTP interface usable by people who speak different languages. Developers will need to take certain steps to mark translatable strings within the source code. Translators will need to edit specific files within the project to create or revise the translation for their language. In OTP we use gettext for localization, for the following reasons: Plural suport Context support Automatic extraction of translatable strings from source code Translator comments support Source references (we can see where each translated string is used in the source code) In the Javascript UI the i18next library is used. Three types of files are used in the OTP localization process: The .pot file is the message template. It is a starting point for creating new .po files. .po files are created and edited by translators based on the .pot file. .json files are generated from the .po files for each language. .js files are localization configuration files which specify units and time/date formats. Only the .po and .js files are directly edited. The .pot file is created from an automated analysis of annotated source code. The .json files are also automatically generated as an easy way for the Javascript UI to consume the contents of the .po files. All translation files are in the directory /src/client/i18n .","title":"Localization"},{"location":"Localization/#for-software-developers-adding-new-strings","text":"When you add a string to Javascript source that will be seen by the end user, wherever that string is referenced you should surround it with a call to a special function. The name of the function depends on what kind of string it is: basic string: _tr('string', parameters) basic string with context: ngettext('context', 'string') string with plural: ngettext('singular', 'plural', quantity) string with plural and context: npgettext('context', 'singular', 'plural', quantity) For more detail, see Sprintf parameters . A \"context\" is any string (preferably short and without whitespace) that is used to disambiguate the translation of the main string. It is used when developers get input from translators that some string should be translated in different ways in different parts of the program. Each of those distinct places will be assigned a different context string. When you add strings to the source code, if you think that translators might not understand how the string is used or what parameters it requires, add translator comments like this: //TRANSLATORS: Start: location at [time date] (Used in print itinerary //when do you start your trip) html += '<h3>' + _tr ( 'Start: %s at %s' , this . getStartLocationStr (), this . getStartTimeStr ()) + '</h3>' ; Translator comments must always start with TRANSLATORS: and must be in the line immediately before translated string. Otherwise they won't be extracted together with the string.","title":"For Software Developers: Adding New Strings"},{"location":"Localization/#examples","text":"","title":"Examples:"},{"location":"Localization/#basic-translated-string","text":"//TRANSLATORS: Board Public transit route name (agency name //Stop ID ) start time html += '<li><b>' + _tr ( 'Board' ) + '</b>: ' + leg . from . name + ' (' + leg . from . stopId . agencyId + ' Stop ID #' + //With named sprintf parameters (our preferred option) //TRANSLATORS: Start: location at [time date] (Used in print itinerary //when do you start your trip) html += '<h3>' + _tr ( 'Start: %(location)s at %(time_date)s' , { 'location' : this . getStartLocationStr (), 'time_date' : this . getStartTimeStr ()}) + '</h3>' ; //With positional sprintf parameters (to be avoided because word order changes between languages) html += '<h3>' + _tr ( 'End: %1$s at %2$s' , this . getEndLocationStr (), this . getEndTimeStr ()) + '</h3>' ;","title":"Basic translated string"},{"location":"Localization/#normal-string-with-context","text":"if ( leg . headsign ) html += pgettext ( \"bus_direction\" , \" to \" ) + leg . headsign ; //same string could be different translation //TRANSLATORS: [distance] to [name of destination] html += \" \" + otp . util . Itin . distanceString ( leg . distance ) + pgettext ( \"direction\" , \" to \" ) + leg . to . name ;","title":"Normal string with context"},{"location":"Localization/#plural-strings","text":"//TRANSLATORS: widget title this . setTitle ( ngettext ( \"%d Itinerary Returned\" , \"%d Itineraries Returned\" , this . itineraries . length )); If you add new strings to the source code, it is good practice to also update the translation template and the translations but it is not mandatory (these can be updated later). It is also recommended to include \"i18n string change\" in the commit message.","title":"Plural strings"},{"location":"Localization/#updating-translations","text":"Translations are updated with the help of Babel and i18next-conv (xgettext doesn't yet have great Javascript support). Babel is used to extract strings from the Javascript source code into the shared .POT translation template, and also for updating the existing .PO language translations when new strings are introduced in the template. i18next-conv is used to convert the .PO translation files for the individual languages to .json files which are used by the Javascript translation library.","title":"Updating translations"},{"location":"Localization/#installing-babel","text":"You can install it from your operating system's package repository (if available) or you can use virtualenv . Install virtualenv (This depends on your operating system) Create virtualenv with name .venv in directory where src and other files resides (Root OpenTripPlanner directory). virtualenv2 .venv (python 2) or python3 -m venv .venv (python 3) Use virtualenv source .venv/bin/activate Install babel pip install babel If you didn't install babel from virtualenv in root OpenTripPlanner directory you have to add path to babel in Makefile. change PYBABEL variable to path to pybabel.","title":"Installing Babel"},{"location":"Localization/#installing-i18next-conv","text":"i18next-conv requires nodejs . Once you have NodeJS installed, use npm install i18next-conv to install i18next-conv in the same directory where you created virtualenv.","title":"Installing i18next-conv"},{"location":"Localization/#updating-the-pot-template","text":"In the root of the OTP repo, run make . The commands in the Makefile will extract the translatable strings from the Javascript files and update the translation template messages.pot , as well as the .po translation files for all the different languages. Once this is done, you can translate the new strings in the .po files. After saving the updated .po file, run make update_js to transform to PO files into .json , which is used at runtime by the Javascript translation library. After you rebuild OTP, all new strings should be visible in the UI.","title":"Updating the .pot Template"},{"location":"Localization/#for-translators-creating-new-translations","text":"The following can get a bit technical. If you want to do a translation but don't want to / know how to install all this software, post to the opentripplanner-dev mailing list stating what language you want to translate, and someone will make you a corresponding .po file.","title":"For Translators: Creating New Translations"},{"location":"Localization/#creating-a-new-translation-file","text":"New .po files are created from the .pot template with the help of msginit , which is run like this: msginit init -l <LAN> -i messages.pot -o <LAN>.po , where <LAN> is a culture code. New .po files can also be created with the help of Poedit . All translation files should be placed in the directory /src/client/i18n . Please use the ISO language code as the culture code (e.g. fr.po for French). We will append country codes in the following limited circumstances: British versus US English ( en_GB.po and en_US.po ) Brazilian Portuguese pt_BR.po , as opposed to pt.po for European Portuguese Chinese: zh_TW.po for traditional characters as used in e.g. Taiwan and Hong Kong, and zh_CN.po for simplified characters as used in mainland China, Singapore, etc. These conventions are based on the Launchpad Translation page. In Linux you can see the culture codes for all the locales you have installed with the command locale -a . A list of culture codes is also availible here .","title":"Creating a New Translation File"},{"location":"Localization/#performing-the-translation","text":"","title":"Performing the Translation"},{"location":"Localization/#configuration","text":"Copy the locale configuration script English.js from /src/client/js/otp/locale to YourLanguage.js and customize it to your language. Change the name, units, locale_short and datepicker_locale_short values. Translate infoWidgets and localize the time/date formats. Then take the following steps: Add the culture code to the LANGS variable in the Makefile` Add the new YourLanguage.js to the locales variable in /src/client/js/otp/config.js Add a new datepicker translation to /src/client/js/lib/jquery-ui/i18n Load the new datepicker translation and YourLanguage.js in /src/client/index.html","title":"Configuration"},{"location":"Localization/#translating-strings","text":"For translating the strings themselves, you can use any program that supports gettext files. You can in theory use any text editor, but programs or plugins purpose-built for translating are recommended. Most of them support checking parameter correctness, translation memory, web translating services etc. to make the task easier. Here are some such programs (all free and open source): Poedit For Linux, Windows, and Mac. Use a version newer then 1.5. This is the recommended choice for getting started with localization. It supports translation memory and file context. Web Poedit Usable from within a web browser, you don't have to install or register Gted A plugin for the Eclipse IDE. Lokalize Runs under KDE on Linux, has some Windows support. Supports translation memory and file context. Virtaal For Linux, Windows, and beta for Mac. Supports Google and Microsoft web translation and other translation memory services. All these programs support setting a string to \"fuzzy\", marking that it needs review etc. in case you translate something but aren't sure of it's correctness. Sometimes those flags are set automatically if the original string was changed and translators must check if the translation is still correct.","title":"Translating Strings"},{"location":"Localization/#caveats","text":"Be careful when translating that the translated strings have the same format as the original. If spaces appear at the start or end of the strings, they must also appear in the translation. The order of unnamed (positional) parameters may change depending on the target language. You can also leave parameter out of the translation if it is irrelevant in the target language.","title":"Caveats"},{"location":"Netex-Norway/","text":"Using European Data Standards Building with Netex Data One important new feature of OTP2 is the ability to load Netex data. Netex is a European specification for transit data exchange , comparable in purpose to GTFS but broader in scope. An EU directive aims to have all EU countries sharing Netex data by the end of 2019. Different countries are currently using different incompatible \"profiles\" of Netex, but an effort is underway to converge on a single European standard profile. This is based in large part on the Norwegian profile, and Norway's national passenger information and ticketing agency Entur has contributed the OTP2 Netex loading code. Therefore if you'd like to try loading Netex data, Norway is a good place to start. The Norwegian Netex data can be downloaded from the Entur developer pages . There is a column of Netex download links partway down the page, and the first row is for all of Norway. Full OSM data for Norway can be downloaded from the Geofabrik Norway downloads page . Get the norway-latest.osm.pbf file, which can then be filtered to remove buildings and other unused data before loading into OTP using a command like the one below. This filtering step can be skipped if you don't have the necessary Osmium tools installed. osmium tags-filter norway-latest.osm.pbf w/highway w/public_transport=platform w/railway=platform w/park_ride=yes r/type=restriction -o norway-filtered.osm.pbf -f pbf,add_metadata=false,pbf_dense_nodes=true Be sure to move the original unfiltered file out of your graph inputs directory (or rename it with a suffix like norway-latest.osm.pbf.ignore ) otherwise OTP2 will try to include both the filtered and unfiltered OSM data in your graph. The build-config.json for a Norwegian graph using Netex data looks like this: { \"areaVisibility\" : true , \"parentStopLinking\" : true , \"platformEntriesLinking\" : true , \"osmWayPropertySet\" : \"norway\" , \"islandWithoutStopsMaxSize\" : 5 , \"islandWithStopsMaxSize\" : 5 , \"dataImportReport\" : true , \"netex\" : { \"moduleFilePattern\" : \".*-netex\\\\.zip\" , \"sharedFilePattern\" : \"_stops.xml\" , \"sharedGroupFilePattern\" : \"_(\\\\w{3})(_flexible)?_shared_data.xml\" , \"groupFilePattern\" : \"(\\\\w{3})_.*\\\\.xml\" , \"netexFeedId\" : \"EN\" } } Note the special section specifying how to find Netex XML files within the single ZIP archive you downloaded. Once you have the graph inputs (the OSM PBF file, the Netex ZIP file, and the build-config.json ) saved together in a directory, you can instruct OTP2 to build a graph from these inputs: java -Xmx10G otp2.jar --build --save /path/to/graph/inputs This should produce a file graph.obj in the same directory as your inputs. Building this Norway graph takes approximately 16 minutes (without elevation data, as configured above), and can be done within 10GB of heap memory (JVM switch -Xmx10G ). Increasing that to 12 or 14GB might speed it up a bit if you have the space. The Graph file it produces is just under 600MB. The server will take about 30 seconds to load this Graph and start up, and will consume about 4GB of heap memory under light use. You can then start up an OTP server with a command like this: java -Xmx6G otp2.jar --load /path/to/graph Once the server is started up, go to http://localhost:8080 in a browser to try out your server using OTP's built in testing web client. Try some long trips like Oslo to Bergen and see if you can get long distance trains and flights as alternatives. You might need to increase the walking limit above its very low default value. Adding SIRI Realtime Data Another important feature in OTP2 is the ability to use SIRI realtime data . Within the EU data standards, SIRI is analogous to GTFS-RT: a way to apply realtime updates on top of schedule data. While technically a distinct specification from Netex, both Netex and SIRI use the Transmodel vocabulary, allowing SIRI messages to reference entities in Netex schedule data. Like GTFS-RT, SIRI is consumed by OTP2 using \"graph updaters\" which are configured in the router-config.json file, which is placed in the same directory as the graph.obj file and loaded at server startup. { \"updaters\" : [ { \"type\" : \"siri-sx-updater\" , \"frequencySec\" : 60 , \"url\" : \"https://api.example.com/siri\" , \"feedId\" : \"siri-sx\" , \"blockReadinessUntilInitialized\" : true }, { \"type\" : \"siri-et-updater\" , \"frequencySec\" : 20 , \"previewIntervalMinutes\" : 180 , \"url\" : \"https://api.example.com/siri\" , \"feedId\" : \"siri-et\" , \"blockReadinessUntilInitialized\" : true }, { \"type\" : \"siri-vm-updater\" , \"frequencySec\" : 60 , \"url\" : \"https://api.example.com/siri\" , \"feedId\" : \"siri-vm\" , \"blockReadinessUntilInitialized\" : true }, { \"type\" : \"raptor-transit-layer\" , \"updateIntervalSeconds\" : 20 } ] } The first three updaters fetch three different kinds of SIRI data: Situation Exchange (SX, text notices analogous to GTFS-RT Alerts) Estimated Timetable (ET, predicted arrival times analogous to GTFS-RT TripUpdates) Vehicle Monitoring (VM, location and status of vehicles analogous to GTFS-RT VehiclePositions) These updaters can handle differential updates, but they use a polling approach rather than the message-oriented streaming approach of the GTFS-RT Websocket updater. The server keeps track of clients, sending only the things that have changed since the last polling operation. Note that between these SIRI updaters and the GTFS-RT Websocket updater, we now have both polling and streaming examples of GTFS-RT \"incrementality\" semantics, so should be able to finalize that part of the specification. The final updater regularly performs a copy of the realtime data into a format suitable for use by OTP2's new Raptor router. Without this updater the realtime data will be received and cataloged, but not visible to the router. TODO explain on blockReadinessUntilInitialized for load balancers.","title":"Netex and SIRI"},{"location":"Netex-Norway/#using-european-data-standards","text":"","title":"Using European Data Standards"},{"location":"Netex-Norway/#building-with-netex-data","text":"One important new feature of OTP2 is the ability to load Netex data. Netex is a European specification for transit data exchange , comparable in purpose to GTFS but broader in scope. An EU directive aims to have all EU countries sharing Netex data by the end of 2019. Different countries are currently using different incompatible \"profiles\" of Netex, but an effort is underway to converge on a single European standard profile. This is based in large part on the Norwegian profile, and Norway's national passenger information and ticketing agency Entur has contributed the OTP2 Netex loading code. Therefore if you'd like to try loading Netex data, Norway is a good place to start. The Norwegian Netex data can be downloaded from the Entur developer pages . There is a column of Netex download links partway down the page, and the first row is for all of Norway. Full OSM data for Norway can be downloaded from the Geofabrik Norway downloads page . Get the norway-latest.osm.pbf file, which can then be filtered to remove buildings and other unused data before loading into OTP using a command like the one below. This filtering step can be skipped if you don't have the necessary Osmium tools installed. osmium tags-filter norway-latest.osm.pbf w/highway w/public_transport=platform w/railway=platform w/park_ride=yes r/type=restriction -o norway-filtered.osm.pbf -f pbf,add_metadata=false,pbf_dense_nodes=true Be sure to move the original unfiltered file out of your graph inputs directory (or rename it with a suffix like norway-latest.osm.pbf.ignore ) otherwise OTP2 will try to include both the filtered and unfiltered OSM data in your graph. The build-config.json for a Norwegian graph using Netex data looks like this: { \"areaVisibility\" : true , \"parentStopLinking\" : true , \"platformEntriesLinking\" : true , \"osmWayPropertySet\" : \"norway\" , \"islandWithoutStopsMaxSize\" : 5 , \"islandWithStopsMaxSize\" : 5 , \"dataImportReport\" : true , \"netex\" : { \"moduleFilePattern\" : \".*-netex\\\\.zip\" , \"sharedFilePattern\" : \"_stops.xml\" , \"sharedGroupFilePattern\" : \"_(\\\\w{3})(_flexible)?_shared_data.xml\" , \"groupFilePattern\" : \"(\\\\w{3})_.*\\\\.xml\" , \"netexFeedId\" : \"EN\" } } Note the special section specifying how to find Netex XML files within the single ZIP archive you downloaded. Once you have the graph inputs (the OSM PBF file, the Netex ZIP file, and the build-config.json ) saved together in a directory, you can instruct OTP2 to build a graph from these inputs: java -Xmx10G otp2.jar --build --save /path/to/graph/inputs This should produce a file graph.obj in the same directory as your inputs. Building this Norway graph takes approximately 16 minutes (without elevation data, as configured above), and can be done within 10GB of heap memory (JVM switch -Xmx10G ). Increasing that to 12 or 14GB might speed it up a bit if you have the space. The Graph file it produces is just under 600MB. The server will take about 30 seconds to load this Graph and start up, and will consume about 4GB of heap memory under light use. You can then start up an OTP server with a command like this: java -Xmx6G otp2.jar --load /path/to/graph Once the server is started up, go to http://localhost:8080 in a browser to try out your server using OTP's built in testing web client. Try some long trips like Oslo to Bergen and see if you can get long distance trains and flights as alternatives. You might need to increase the walking limit above its very low default value.","title":"Building with Netex Data"},{"location":"Netex-Norway/#adding-siri-realtime-data","text":"Another important feature in OTP2 is the ability to use SIRI realtime data . Within the EU data standards, SIRI is analogous to GTFS-RT: a way to apply realtime updates on top of schedule data. While technically a distinct specification from Netex, both Netex and SIRI use the Transmodel vocabulary, allowing SIRI messages to reference entities in Netex schedule data. Like GTFS-RT, SIRI is consumed by OTP2 using \"graph updaters\" which are configured in the router-config.json file, which is placed in the same directory as the graph.obj file and loaded at server startup. { \"updaters\" : [ { \"type\" : \"siri-sx-updater\" , \"frequencySec\" : 60 , \"url\" : \"https://api.example.com/siri\" , \"feedId\" : \"siri-sx\" , \"blockReadinessUntilInitialized\" : true }, { \"type\" : \"siri-et-updater\" , \"frequencySec\" : 20 , \"previewIntervalMinutes\" : 180 , \"url\" : \"https://api.example.com/siri\" , \"feedId\" : \"siri-et\" , \"blockReadinessUntilInitialized\" : true }, { \"type\" : \"siri-vm-updater\" , \"frequencySec\" : 60 , \"url\" : \"https://api.example.com/siri\" , \"feedId\" : \"siri-vm\" , \"blockReadinessUntilInitialized\" : true }, { \"type\" : \"raptor-transit-layer\" , \"updateIntervalSeconds\" : 20 } ] } The first three updaters fetch three different kinds of SIRI data: Situation Exchange (SX, text notices analogous to GTFS-RT Alerts) Estimated Timetable (ET, predicted arrival times analogous to GTFS-RT TripUpdates) Vehicle Monitoring (VM, location and status of vehicles analogous to GTFS-RT VehiclePositions) These updaters can handle differential updates, but they use a polling approach rather than the message-oriented streaming approach of the GTFS-RT Websocket updater. The server keeps track of clients, sending only the things that have changed since the last polling operation. Note that between these SIRI updaters and the GTFS-RT Websocket updater, we now have both polling and streaming examples of GTFS-RT \"incrementality\" semantics, so should be able to finalize that part of the specification. The final updater regularly performs a copy of the realtime data into a format suitable for use by OTP2's new Raptor router. Without this updater the realtime data will be received and cataloged, but not visible to the router. TODO explain on blockReadinessUntilInitialized for load balancers.","title":"Adding SIRI Realtime Data"},{"location":"OTP2-MigrationGuide/","text":"How to migrate from OTP1 to OTP2 Command Line The OTP2 command line parameters are different than in OTP1. Use the --help option to get the current documentation, and look at the Basic Tutorial, Start up OPT for examples. The possibility to build the graph in 2 steps (streets then transit) is new in OTP2. OTP2 does not support multiple routers. File Loading OTP1 accesses all files using the local file system, no other data-source is supported. In OTP2 we support accessing cloud storage. So far Google Cloud Storage is added and we plan to add support for AWS S3 as well. Config files ( otp-config.json, build-config.json, router-config.json ) are read from the local file system, while other files can be read/written from the local file-system or the cloud. OTP2 supports mixing any data sources that are supported. OTP1 loads input data files ( DEM, OSM, GTFS, NeTEx ) based on the suffix (file extension). But for GTFS files OTP1 also opens the zip-file and looks for stops.txt . OTP2 identifies GTFS files by the name only: it will detect any zip-file or directory that contains \"gtfs\" as part of the name. All file types in OTP2 are resolved by matching the name with a regexp pattern. You can configure the patterns in the build-config.json if the defaults do not suit you. OTP2 does not support multiple routers, but you can load as many GTFS and/or NeTEx feeds as you want into a single instance of OTP2. Build Config New parameters: transitServiceStart Limit the import of transit services to the given start date. Default: -P1Y transitServiceEnd Limit the import of transit services to the given end date. Inclusive . Default: P3Y These properties changed names from: htmlAnnotations to dataImportReport maxHtmlAnnotationsPerFile to maxDataImportIssuesPerFile boardTimes to routingDefaults.boardSlackByMode alightTimes to routingDefaults.alightSlackByMode These parameters are no longer supported: stopClusterMode parentStopLinking stationTransfers OTP2 records the \"parentStation\" relationship between stops and stations in its internal transit model, based on the GTFS and/or NeTEx input. This enables OTP to search from all stop in a station without walking/waiting when the request from/to input field is a station id. There is no way to automatically infer this parent station relationship based on geographic proximity in OTP2. Transfers in OTP2 are generated based on the stop location and the OSM data or GTFS Pathways. In future versions of OTP2 we also want to support generating simple transfers based on \"line-of-sight\" if no pathways or OSM data exist. See issue #3204 . Cleaning and patching input data is NOT a core feature of OTP, but anyone is welcome to implement a sandbox plugin to patch data. So, if any of the features above are needed they can be ported from OTP1 into an OTP2 sandbox feature. Router Config See the Router Configuration for a description of the new and existing routing parameters. New parameters: streetRoutingTimeout Maximum time limit for street route queries. Replace the old timeout . transit Transit tuning parameters, configure the raptor router. A set of parameters to tune the Raptor transit router. These parameters are no longer supported: timeout Replaced by streetRoutingTimeout timeouts OTP1 searches the graph many times, while OTP2 do one search finding multiple results in one search. So, there is no need for this parameter. boardTimes is replaced by request parameter boardSlack and boardSlackForMode . alightTimes is replaced by request parameter alightSlack and alightSlackForMode . REST API Trip Planning Support for XML as a request/response format is removed. The only supported format is JSON. Query parameter changes A lot of the query parameters in the REST API are ignored/deprecated, see the RoutingRequest and the RoutingResource class for the documentation on what is now supported in 2.0. A few features did not make it into the 2.0, but is sheduled for the 2.1 release. See GitHub issues 2.1 . The following parameters are missing in OTP2 but will be added: startingTransitTripId The ability to plan a trip from on board a vehicle should be implemented by Q1 2021. intermediatePlaces - ability to specify intermediate destinations along the route. It is not certain when this will be implemented. nonpreferredTransferCost , (un)preferredRoutes , (un)preferredAgencies - these help diversify or customize the trips and operators visible in results. Due to the new transit routing algorithm, Entur plans to completely rewrite these features, accounting for market-neutrality requirements and showing relevant trips and operators in local vs. intercity trips. Some features in OTP1 will not be present upon launch in OTP2, and they are proposed to be removed permanently from OTP2, but may require some development to support valid important cases: maxWalkDistance , maxTransferWalkDistance , & maxWait - these parameters impose hard limits and are no longer the preferred way to reduce the amount of walking or waiting in returned itineraries. In OTP2 the goal is to control this with walkReluctance and waitReluctance . Internally some limits on walking and waiting do still exist, but they are set quite high so trips with long walking or waiting times are still considered. Note that unlike in OTP1, if you do set your own max walk or wait time on an API request, it will apply to both transit searches and non-transit searches. maxHours & useRequestedDateTimeInMaxHours - This is replaced by searchWindow , which limits the arrival or departure window of the trip worstTime - This factor returns the \u201cworst\u201d trip in a depart after/arrive by search, i.e. the latest or earliest trip available. It is not a priority for current OTP2 users but could be added as a filter. waitAtBeginningFactor - No longer necessary to weight the initial wait differently based on the the Range Raptor search algorithm, which no longer prefers a departure at one valid time over another. Filtering could be implemented on top of Raptor to show certain departure times before others. pathComparator - The ability to set a sort order based on departure or arrival should be the domain of the API rather than the search. startingTransitStopId - duplicative with fromPlace onlyTransitTrips - the new feature for specifying access, egress, transit and direct mode replace the need for this parameter. Parameters that have changed: numItineraries The parameter is no longer used to terminate the request when the numItineraries is found, instead the new searchWindow parameter should be used to limit the search. In OTP2 it crops the list of itineraries AFTER the search is complete. This parameter is a post search filter function. The best option is to configure this on the server side and not use it as a client side input parameter. A side effect from reducing the result is that OTP2 cannot guarantee to find all pareto-optimal itineraries when paging. Also, a large search-window and a small numItineraries waste computer CPU calculation time. Consider tuning the searchWindow instead of setting this to a small value. modes The REST API is unchanged, but is mapped into a new structure in the RoutingRequest. This means not all combinations of non-transit modes that was available in OTP1 is available in OTP2. preferredAgencies , unpreferredAgencies , bannedAgencies and whiteListedAgencies use feed-scoped ids. If you are using the ids directly from the Index API, no changes are needed. New parameters in OTP2: searchWindow Limit the departure window or arrival window for the routing search. boardSlackByMode How much time ride a vehicle takes for each given mode. alightSlackByMode How much time alighting a vehicle takes for each given mode. Paging In OTP1 most client provided a way to page the results by looking at the trips returned and passing in something like the last-depature-time + 1 minute to the next request, to get trips to add to the already fetched results. In OTP2 the recommended way to do this is to use the new TripPlan metadata returned by the router call. Response changes metadata is added to TripPlan . The TripSearchMetadata has three fields: searchWindowUsed nextDateTime prevDateTime agencyId in the leg is now feed-scoped and similarly to other ids, is prefixed with <FEED_ID>: debugOutput in TripPlan has changed due to the different algorithms used in OTP version 1.x and 2.x. The totalTime is left as is, directStreetRouterTime , transitRouterTime , filteringTime and renderingTime are new fields. effectiveEndDate is added to the Alert s Changes to the Index API Error handling is improved, this is now consistently applied and uses build in framework support. The HTTP 400 and 404 response now contains a detailed error message in plain text targeted developers to help understanding why the 400 or 404 was returned. Route Deprecated 'routeBikesAllowed' field removed. sortOrder will be empty (missing) when empty, NOT -999 as before. To access or references TripPattern use tripPatternId , not code . In OTP1 the code was used. The code was the same as the id without the feedId prefix. The code is removed from OTP2. Clients may not be affected by this change, unless they toke advantage of the semantics in the old code . The mode field is added to Route , it should probebly replace the type (unchanged). The RouteShort is not chencged - it has the mode field. Pattern (or TripPattern ) The semantics of the id should NOT be used to access other related entities like Route , the routeId is added to TripPatternShort to allow navigation to Route. Trip The deprecated tripBikesAllowed is removed. The routeId replace route . The route is no longer part of the trip. To obtain the Route object call the Index API with the routeId. Stop The new stationId is a feed-scoped-id to the parent station. It should be used instead of the deprecated ~~parentStation~~. StopShort The new stationId is a feed-scoped-id to the parent station. It should be used instead of the deprecated ~~cluster~~. Agency The id is now feed-scoped and similarly to other ids, is prefixed with <FEED_ID>: Alert effectiveEndDate is added to show the end time of the alert validity. AlertPatcher The AlertPatcher, which was under the /patch path, is removed. In order to update alerts, please use a GTFS-RT Service Alert updater instead. An example of a simple service for producing static GTFS-RT Service Alert feed from JSON is manual-gtfsrt . Querying for alerts has been moved under the index API, where /alerts can be appended to stop, route, trip and pattern. Analyst The analyst API endpoints have been removed. Scripting The scripting API endpoint has been removed.","title":"OTP2 migration guide"},{"location":"OTP2-MigrationGuide/#how-to-migrate-from-otp1-to-otp2","text":"","title":"How to migrate from OTP1 to OTP2"},{"location":"OTP2-MigrationGuide/#command-line","text":"The OTP2 command line parameters are different than in OTP1. Use the --help option to get the current documentation, and look at the Basic Tutorial, Start up OPT for examples. The possibility to build the graph in 2 steps (streets then transit) is new in OTP2. OTP2 does not support multiple routers.","title":"Command Line"},{"location":"OTP2-MigrationGuide/#file-loading","text":"OTP1 accesses all files using the local file system, no other data-source is supported. In OTP2 we support accessing cloud storage. So far Google Cloud Storage is added and we plan to add support for AWS S3 as well. Config files ( otp-config.json, build-config.json, router-config.json ) are read from the local file system, while other files can be read/written from the local file-system or the cloud. OTP2 supports mixing any data sources that are supported. OTP1 loads input data files ( DEM, OSM, GTFS, NeTEx ) based on the suffix (file extension). But for GTFS files OTP1 also opens the zip-file and looks for stops.txt . OTP2 identifies GTFS files by the name only: it will detect any zip-file or directory that contains \"gtfs\" as part of the name. All file types in OTP2 are resolved by matching the name with a regexp pattern. You can configure the patterns in the build-config.json if the defaults do not suit you. OTP2 does not support multiple routers, but you can load as many GTFS and/or NeTEx feeds as you want into a single instance of OTP2.","title":"File Loading"},{"location":"OTP2-MigrationGuide/#build-config","text":"New parameters: transitServiceStart Limit the import of transit services to the given start date. Default: -P1Y transitServiceEnd Limit the import of transit services to the given end date. Inclusive . Default: P3Y These properties changed names from: htmlAnnotations to dataImportReport maxHtmlAnnotationsPerFile to maxDataImportIssuesPerFile boardTimes to routingDefaults.boardSlackByMode alightTimes to routingDefaults.alightSlackByMode These parameters are no longer supported: stopClusterMode parentStopLinking stationTransfers OTP2 records the \"parentStation\" relationship between stops and stations in its internal transit model, based on the GTFS and/or NeTEx input. This enables OTP to search from all stop in a station without walking/waiting when the request from/to input field is a station id. There is no way to automatically infer this parent station relationship based on geographic proximity in OTP2. Transfers in OTP2 are generated based on the stop location and the OSM data or GTFS Pathways. In future versions of OTP2 we also want to support generating simple transfers based on \"line-of-sight\" if no pathways or OSM data exist. See issue #3204 . Cleaning and patching input data is NOT a core feature of OTP, but anyone is welcome to implement a sandbox plugin to patch data. So, if any of the features above are needed they can be ported from OTP1 into an OTP2 sandbox feature.","title":"Build Config"},{"location":"OTP2-MigrationGuide/#router-config","text":"See the Router Configuration for a description of the new and existing routing parameters. New parameters: streetRoutingTimeout Maximum time limit for street route queries. Replace the old timeout . transit Transit tuning parameters, configure the raptor router. A set of parameters to tune the Raptor transit router. These parameters are no longer supported: timeout Replaced by streetRoutingTimeout timeouts OTP1 searches the graph many times, while OTP2 do one search finding multiple results in one search. So, there is no need for this parameter. boardTimes is replaced by request parameter boardSlack and boardSlackForMode . alightTimes is replaced by request parameter alightSlack and alightSlackForMode .","title":"Router Config"},{"location":"OTP2-MigrationGuide/#rest-api","text":"","title":"REST API"},{"location":"OTP2-MigrationGuide/#trip-planning","text":"Support for XML as a request/response format is removed. The only supported format is JSON.","title":"Trip Planning"},{"location":"OTP2-MigrationGuide/#query-parameter-changes","text":"A lot of the query parameters in the REST API are ignored/deprecated, see the RoutingRequest and the RoutingResource class for the documentation on what is now supported in 2.0. A few features did not make it into the 2.0, but is sheduled for the 2.1 release. See GitHub issues 2.1 . The following parameters are missing in OTP2 but will be added: startingTransitTripId The ability to plan a trip from on board a vehicle should be implemented by Q1 2021. intermediatePlaces - ability to specify intermediate destinations along the route. It is not certain when this will be implemented. nonpreferredTransferCost , (un)preferredRoutes , (un)preferredAgencies - these help diversify or customize the trips and operators visible in results. Due to the new transit routing algorithm, Entur plans to completely rewrite these features, accounting for market-neutrality requirements and showing relevant trips and operators in local vs. intercity trips. Some features in OTP1 will not be present upon launch in OTP2, and they are proposed to be removed permanently from OTP2, but may require some development to support valid important cases: maxWalkDistance , maxTransferWalkDistance , & maxWait - these parameters impose hard limits and are no longer the preferred way to reduce the amount of walking or waiting in returned itineraries. In OTP2 the goal is to control this with walkReluctance and waitReluctance . Internally some limits on walking and waiting do still exist, but they are set quite high so trips with long walking or waiting times are still considered. Note that unlike in OTP1, if you do set your own max walk or wait time on an API request, it will apply to both transit searches and non-transit searches. maxHours & useRequestedDateTimeInMaxHours - This is replaced by searchWindow , which limits the arrival or departure window of the trip worstTime - This factor returns the \u201cworst\u201d trip in a depart after/arrive by search, i.e. the latest or earliest trip available. It is not a priority for current OTP2 users but could be added as a filter. waitAtBeginningFactor - No longer necessary to weight the initial wait differently based on the the Range Raptor search algorithm, which no longer prefers a departure at one valid time over another. Filtering could be implemented on top of Raptor to show certain departure times before others. pathComparator - The ability to set a sort order based on departure or arrival should be the domain of the API rather than the search. startingTransitStopId - duplicative with fromPlace onlyTransitTrips - the new feature for specifying access, egress, transit and direct mode replace the need for this parameter. Parameters that have changed: numItineraries The parameter is no longer used to terminate the request when the numItineraries is found, instead the new searchWindow parameter should be used to limit the search. In OTP2 it crops the list of itineraries AFTER the search is complete. This parameter is a post search filter function. The best option is to configure this on the server side and not use it as a client side input parameter. A side effect from reducing the result is that OTP2 cannot guarantee to find all pareto-optimal itineraries when paging. Also, a large search-window and a small numItineraries waste computer CPU calculation time. Consider tuning the searchWindow instead of setting this to a small value. modes The REST API is unchanged, but is mapped into a new structure in the RoutingRequest. This means not all combinations of non-transit modes that was available in OTP1 is available in OTP2. preferredAgencies , unpreferredAgencies , bannedAgencies and whiteListedAgencies use feed-scoped ids. If you are using the ids directly from the Index API, no changes are needed. New parameters in OTP2: searchWindow Limit the departure window or arrival window for the routing search. boardSlackByMode How much time ride a vehicle takes for each given mode. alightSlackByMode How much time alighting a vehicle takes for each given mode.","title":"Query parameter changes"},{"location":"OTP2-MigrationGuide/#paging","text":"In OTP1 most client provided a way to page the results by looking at the trips returned and passing in something like the last-depature-time + 1 minute to the next request, to get trips to add to the already fetched results. In OTP2 the recommended way to do this is to use the new TripPlan metadata returned by the router call.","title":"Paging"},{"location":"OTP2-MigrationGuide/#response-changes","text":"metadata is added to TripPlan . The TripSearchMetadata has three fields: searchWindowUsed nextDateTime prevDateTime agencyId in the leg is now feed-scoped and similarly to other ids, is prefixed with <FEED_ID>: debugOutput in TripPlan has changed due to the different algorithms used in OTP version 1.x and 2.x. The totalTime is left as is, directStreetRouterTime , transitRouterTime , filteringTime and renderingTime are new fields. effectiveEndDate is added to the Alert s","title":"Response changes"},{"location":"OTP2-MigrationGuide/#changes-to-the-index-api","text":"Error handling is improved, this is now consistently applied and uses build in framework support. The HTTP 400 and 404 response now contains a detailed error message in plain text targeted developers to help understanding why the 400 or 404 was returned. Route Deprecated 'routeBikesAllowed' field removed. sortOrder will be empty (missing) when empty, NOT -999 as before. To access or references TripPattern use tripPatternId , not code . In OTP1 the code was used. The code was the same as the id without the feedId prefix. The code is removed from OTP2. Clients may not be affected by this change, unless they toke advantage of the semantics in the old code . The mode field is added to Route , it should probebly replace the type (unchanged). The RouteShort is not chencged - it has the mode field. Pattern (or TripPattern ) The semantics of the id should NOT be used to access other related entities like Route , the routeId is added to TripPatternShort to allow navigation to Route. Trip The deprecated tripBikesAllowed is removed. The routeId replace route . The route is no longer part of the trip. To obtain the Route object call the Index API with the routeId. Stop The new stationId is a feed-scoped-id to the parent station. It should be used instead of the deprecated ~~parentStation~~. StopShort The new stationId is a feed-scoped-id to the parent station. It should be used instead of the deprecated ~~cluster~~. Agency The id is now feed-scoped and similarly to other ids, is prefixed with <FEED_ID>: Alert effectiveEndDate is added to show the end time of the alert validity.","title":"Changes to the Index API"},{"location":"OTP2-MigrationGuide/#alertpatcher","text":"The AlertPatcher, which was under the /patch path, is removed. In order to update alerts, please use a GTFS-RT Service Alert updater instead. An example of a simple service for producing static GTFS-RT Service Alert feed from JSON is manual-gtfsrt . Querying for alerts has been moved under the index API, where /alerts can be appended to stop, route, trip and pattern.","title":"AlertPatcher"},{"location":"OTP2-MigrationGuide/#analyst","text":"The analyst API endpoints have been removed.","title":"Analyst"},{"location":"OTP2-MigrationGuide/#scripting","text":"The scripting API endpoint has been removed.","title":"Scripting"},{"location":"Preparing-OSM/","text":"Cropping OSM data Services producing automated extracts of OSM data like Geofabrik or Interline Extracts are limited to predefined areas. You'll often need to download an extract for a country or region larger than your true analysis area, then cut it down to size. Excessively large OSM data can lead to significant increases in computation time and complexity, both while building the graph and handling trip planning requests. You may want to crop the OSM data if they cover an area significantly larger than your transit network. Several command line tools are able to perform these cropping operations: Osmosis is a multi-platform Java tool that works on Windows, Linux, and MacOS but is relatively slow, OSMConvert is a fast tool pre-built for Windows and Linux and available on MacOS and Linux distributions as part of osmctools package. Osmium-Tool is a personal favorite that is extremely fast but only straightforward to install on Linux and MacOS platforms. Below are some example crop commands for these different tools: Osmosis: osmosis --rb input.osm.pbf --bounding-box left=4.34 right=5.84 bottom=43.10 top=43.97 --wb cropped.osm.pbf OsmConvert: osmconvert input.osm.pbf -b=-77.255859375,38.77764022307335,-76.81365966796875,39.02345139405933 --complete-ways -o=cropped.osm.pbf Osmium: osmium extract --strategy complete_ways --bbox 2.25,48.81,2.42,48.91 input.osm.pbf -o cropped.osm.pbf The latter two commands expect bounding boxes to be specified in the format min_lon,min_lat,max_lon,max_lat . We frequently find bounding boxes using the convenient Klokantech bounding box tool . Selecting the \"CSV\" format in the lower left will give exactly the format expected by these tools. Filtering OSM data The OSM database contains a lot of other data besides the roads, paths, and public transportation platform data we need for accessibility analysis. As of this writing, according to TagInfo 59% of the ways in OSM are buildings, and only 23% are roads or paths. Buildings frequently have more complex shapes than roads, and objects like waterways or political boundaries can be very large in size. It has been jokingly said that OSM should be renamed \"OpenBuildingMap\" rather than \"OpenStreetMap\". Removing unneeded data will reduce file sizes, facilitating copying or moving files around and reducing the size of project backups and archives. It may also speed up the processing stage where the OSM data is converted into a routable street network. Several command line tools exist to filter OSM data. Command line tools for this purpose include Osmosis and Osmium-Tool . Osmium-Tool is extremely fast but is only straightforward to install on Linux and MacOS platforms. Osmosis is often slower at filtering but will also work on Windows as it's a multi-platform Java application. OSMFilter cannot work with PBF format files so we rarely use it. Below are some example commands for retaining only OSM data useful for accessibility analysis. Here are some example commands: Osmosis: osmosis --rb input.osm.pbf --tf reject-ways building=* --tf reject-ways waterway=* --tf reject-ways landuse=* --tf reject-ways natural=* --used-node --wb filtered.osm.pbf Osmium-Tool: osmium tags-filter input.osm.pbf w/highway w/public_transport=platform w/railway=platform w/park_ride=yes r/type=restriction -o filtered.osm.pbf -f pbf,add_metadata=false","title":"Preparing OSM Data"},{"location":"Preparing-OSM/#cropping-osm-data","text":"Services producing automated extracts of OSM data like Geofabrik or Interline Extracts are limited to predefined areas. You'll often need to download an extract for a country or region larger than your true analysis area, then cut it down to size. Excessively large OSM data can lead to significant increases in computation time and complexity, both while building the graph and handling trip planning requests. You may want to crop the OSM data if they cover an area significantly larger than your transit network. Several command line tools are able to perform these cropping operations: Osmosis is a multi-platform Java tool that works on Windows, Linux, and MacOS but is relatively slow, OSMConvert is a fast tool pre-built for Windows and Linux and available on MacOS and Linux distributions as part of osmctools package. Osmium-Tool is a personal favorite that is extremely fast but only straightforward to install on Linux and MacOS platforms. Below are some example crop commands for these different tools: Osmosis: osmosis --rb input.osm.pbf --bounding-box left=4.34 right=5.84 bottom=43.10 top=43.97 --wb cropped.osm.pbf OsmConvert: osmconvert input.osm.pbf -b=-77.255859375,38.77764022307335,-76.81365966796875,39.02345139405933 --complete-ways -o=cropped.osm.pbf Osmium: osmium extract --strategy complete_ways --bbox 2.25,48.81,2.42,48.91 input.osm.pbf -o cropped.osm.pbf The latter two commands expect bounding boxes to be specified in the format min_lon,min_lat,max_lon,max_lat . We frequently find bounding boxes using the convenient Klokantech bounding box tool . Selecting the \"CSV\" format in the lower left will give exactly the format expected by these tools.","title":"Cropping OSM data"},{"location":"Preparing-OSM/#filtering-osm-data","text":"The OSM database contains a lot of other data besides the roads, paths, and public transportation platform data we need for accessibility analysis. As of this writing, according to TagInfo 59% of the ways in OSM are buildings, and only 23% are roads or paths. Buildings frequently have more complex shapes than roads, and objects like waterways or political boundaries can be very large in size. It has been jokingly said that OSM should be renamed \"OpenBuildingMap\" rather than \"OpenStreetMap\". Removing unneeded data will reduce file sizes, facilitating copying or moving files around and reducing the size of project backups and archives. It may also speed up the processing stage where the OSM data is converted into a routable street network. Several command line tools exist to filter OSM data. Command line tools for this purpose include Osmosis and Osmium-Tool . Osmium-Tool is extremely fast but is only straightforward to install on Linux and MacOS platforms. Osmosis is often slower at filtering but will also work on Windows as it's a multi-platform Java application. OSMFilter cannot work with PBF format files so we rarely use it. Below are some example commands for retaining only OSM data useful for accessibility analysis. Here are some example commands: Osmosis: osmosis --rb input.osm.pbf --tf reject-ways building=* --tf reject-ways waterway=* --tf reject-ways landuse=* --tf reject-ways natural=* --used-node --wb filtered.osm.pbf Osmium-Tool: osmium tags-filter input.osm.pbf w/highway w/public_transport=platform w/railway=platform w/park_ride=yes r/type=restriction -o filtered.osm.pbf -f pbf,add_metadata=false","title":"Filtering OSM data"},{"location":"RoutingModes/","text":"Routing modes TODO OTP2 - Where in the documentation does this belong? This is currently not part of the menu or - any linked to by any of the other documents. The routing request parameter mode determines which transport modalities should be considered when calculating the list of routes. Some modes (mostly bicycle and car) also have optional qualifiers RENT and PARK to specify if vehicles are to be parked at a station or rented. In theory this can also apply to other modes but makes sense only in select cases which are listed below. Whether a transport mode is available highly depends on the input feeds (GTFS, OSM, bike sharing feeds) and the graph building options supplied to OTP. The complete list of modes are: WALK : Walking some or all of the route. TRANSIT : General catch-all for all public transport modes. BICYCLE : Cycling for the entirety of the route or taking a bicycle onto the public transport and cycling from the arrival station to the destination. BICYCLE_RENT : Taking a rented, shared-mobility bike for part or the entirety of the route. Prerequisite: Vehicle positions need to be added to OTP either as static stations or dynamic data feeds. For dynamic bike positions configure an input feed. See Configuring real-time updaters . For static stations check the graph building documentation for the property staticBikeRental . BICYCLE_PARK : Leaving the bicycle at the departure station and walking from the arrival station to the destination. This mode needs to be combined with at least one transit mode (or TRANSIT ) otherwise it behaves like an ordinary bicycle journey. Prerequisite: Bicycle parking stations present in the OSM file and visible to OTP by enabling the property staticBikeParkAndRide during graph build. CAR : Driving your own car the entirety of the route. If this is combined with TRANSIT it will return routes with a Kiss & Ride component. This means that the car is not parked in a permanent parking area but rather the passenger is dropped off (for example, at an airport) and the driver continues driving the car away from the drop off location. CAR_PARK : Driving a car to the park-and-ride facilities near a station and taking public transport. This mode needs to be combined with at least one transit mode (or TRANSIT ) otherwise it behaves like an ordinary car journey. Prerequisite: Park-and-ride areas near the station need to be present in the OSM input file. The following modes are 1-to-1 mappings from the GTFS route_type : TRAM : Tram, streetcar, or light rail. Used for any light rail or street-level system within a metropolitan area. SUBWAY : Subway or metro. Used for any underground rail system within a metropolitan area. RAIL : Used for intercity or long-distance travel. BUS : Used for short- and long-distance bus routes. FERRY : Ferry. Used for short- and long-distance boat service. CABLE_CAR : Cable car. Used for street-level cable cars where the cable runs beneath the car. GONDOLA : Gondola or suspended cable car. Typically used for aerial cable cars where the car is suspended from the cable. FUNICULAR : Funicular. Used for any rail system that moves on steep inclines with a cable traction system. Lastly, this mode is part of the Extended GTFS route types : AIRPLANE : Taking an airplane. Note that there are conceptual overlaps between TRAM , SUBWAY and RAIL and some transport providers categorize their routes differently to others. In other words, what is considered a SUBWAY in one city might be of type RAIL in another. Study your input GTFS feed carefully to find out the appropriate mapping in your region.","title":"RoutingModes"},{"location":"RoutingModes/#routing-modes","text":"TODO OTP2 - Where in the documentation does this belong? This is currently not part of the menu or - any linked to by any of the other documents. The routing request parameter mode determines which transport modalities should be considered when calculating the list of routes. Some modes (mostly bicycle and car) also have optional qualifiers RENT and PARK to specify if vehicles are to be parked at a station or rented. In theory this can also apply to other modes but makes sense only in select cases which are listed below. Whether a transport mode is available highly depends on the input feeds (GTFS, OSM, bike sharing feeds) and the graph building options supplied to OTP. The complete list of modes are: WALK : Walking some or all of the route. TRANSIT : General catch-all for all public transport modes. BICYCLE : Cycling for the entirety of the route or taking a bicycle onto the public transport and cycling from the arrival station to the destination. BICYCLE_RENT : Taking a rented, shared-mobility bike for part or the entirety of the route. Prerequisite: Vehicle positions need to be added to OTP either as static stations or dynamic data feeds. For dynamic bike positions configure an input feed. See Configuring real-time updaters . For static stations check the graph building documentation for the property staticBikeRental . BICYCLE_PARK : Leaving the bicycle at the departure station and walking from the arrival station to the destination. This mode needs to be combined with at least one transit mode (or TRANSIT ) otherwise it behaves like an ordinary bicycle journey. Prerequisite: Bicycle parking stations present in the OSM file and visible to OTP by enabling the property staticBikeParkAndRide during graph build. CAR : Driving your own car the entirety of the route. If this is combined with TRANSIT it will return routes with a Kiss & Ride component. This means that the car is not parked in a permanent parking area but rather the passenger is dropped off (for example, at an airport) and the driver continues driving the car away from the drop off location. CAR_PARK : Driving a car to the park-and-ride facilities near a station and taking public transport. This mode needs to be combined with at least one transit mode (or TRANSIT ) otherwise it behaves like an ordinary car journey. Prerequisite: Park-and-ride areas near the station need to be present in the OSM input file. The following modes are 1-to-1 mappings from the GTFS route_type : TRAM : Tram, streetcar, or light rail. Used for any light rail or street-level system within a metropolitan area. SUBWAY : Subway or metro. Used for any underground rail system within a metropolitan area. RAIL : Used for intercity or long-distance travel. BUS : Used for short- and long-distance bus routes. FERRY : Ferry. Used for short- and long-distance boat service. CABLE_CAR : Cable car. Used for street-level cable cars where the cable runs beneath the car. GONDOLA : Gondola or suspended cable car. Typically used for aerial cable cars where the car is suspended from the cable. FUNICULAR : Funicular. Used for any rail system that moves on steep inclines with a cable traction system. Lastly, this mode is part of the Extended GTFS route types : AIRPLANE : Taking an airplane. Note that there are conceptual overlaps between TRAM , SUBWAY and RAIL and some transport providers categorize their routes differently to others. In other words, what is considered a SUBWAY in one city might be of type RAIL in another. Study your input GTFS feed carefully to find out the appropriate mapping in your region.","title":"Routing modes"},{"location":"SandboxExtension/","text":"OTP Sandbox Extensions The sandbox is a place to test and implement new \"experimental\" features. This should not be used for bug fixes and smaller changes. Consider forking if the feature is valuable to one deployment only. Available extensions Here is a list of features implemented as OTP Sandbox Extensions. The Sandbox extensions are provided \"as is\". Examples - Sandbox examples on how to implement extensions. Google Cloud Storage - Enable Google Cloud Storage as a OTP Data Source Health API - API used to check the health status of the OTP instance. Transfer analyser - Module used for analyzing the transfers between nearby stops generated by routing via OSM data. HSL Legacy GraphQL API - HSL's GraphQL API used by the Digitransit project. Transmodel API - Enturs GraphQL Transmodel API. SIRI updator - Update OTP with realtime information from a Transmodel SIRI data source. BikeRentalServiceDirectory - GBFS service directory endpoint. Terminology Main/core -- All OTP code and additional files, NOT part of the sandbox. ( docs , src/main , src/test and so on) Extensions -- All features implemented in the OTP Sandbox, provided with no guarantees. ( src/ext , src/ext-test ) Sandbox Goals Reduce work for PR approval Allow experimental code to evolve (in a Sandbox) Encourage refactoring and creation of extension points in the main code. Increase visibility and cooperation of development of new features. Feature toggle Sandbox features should use the OTPFeature to enable the code. Sandbox features are by default off. To toggle features on/off se the configuration documentation . Contract Give your feature a name: <extension name> A new feature is isolated from the rest of the code by putting it in the directory src/ext . Java code should have package prefix org.opentripplanner.ext.<extension name> . Unit tests should be added in the test directory: src/ext-test To integrate the new feature into OTP you may have to create new extension points in the main/core code. Changes to the core OTP are subject to normal a review process. Create a readme file ( docs/sandbox/<Extension Name>.md package including: Extension Name Contact info Change log Documentation of the feature (optional) List your extension in the Available extensions section and in the mydocs config file . Use feature toggling to enable a feature at runtime. The feature must be disabled by default. A feature is toggled on using the config files. Only code modifying the main code( src/main , not src/ext ) is reviewed. The current coding standard apply to the extension code as well - but the code is not necessarily reviewed. There are no grantees - the authors of an extension can change its API any time they want. Anyone can request the feature to be merged into the main code. An approval from the PLC and a new review is then required. The reviewers may request any changes, including API changes. If an extension is taken into the core/main OTP code, any API included may change, no BACKWARD compatibility is guaranteed. I.e. the reviewers may require changes before it is merged. The feature submitters is responsible for maintaining and testing the extension code, but do not need to provide any guarantees or support. If the extension is merged into the main code the author will in fact need to provide support and maintenance. When someone at a later point in time want to change the main code the only thing they are responsible for - with regard to the extension code - is: that it compiles. that the unit tests run. If a test is not easy to fix, it can be tagged with @Ignore. If ignored it would be polite to notify the author. Changes to the main OTP API that cannot be toggled in must be clearly marked/tagged as part of an experimental feature and documented - This code is subject to review. If a feature is old and not maintained it can be removed 1 month after notifying the submitter (using contact info in README file). Introducing new dependencies needs approval. They are NOT approved if they are likely to be a maintenance challenge (many transitive dependencies or potential conflicts with other versions/libraries).","title":"Sandbox development"},{"location":"SandboxExtension/#otp-sandbox-extensions","text":"The sandbox is a place to test and implement new \"experimental\" features. This should not be used for bug fixes and smaller changes. Consider forking if the feature is valuable to one deployment only.","title":"OTP Sandbox Extensions"},{"location":"SandboxExtension/#available-extensions","text":"Here is a list of features implemented as OTP Sandbox Extensions. The Sandbox extensions are provided \"as is\". Examples - Sandbox examples on how to implement extensions. Google Cloud Storage - Enable Google Cloud Storage as a OTP Data Source Health API - API used to check the health status of the OTP instance. Transfer analyser - Module used for analyzing the transfers between nearby stops generated by routing via OSM data. HSL Legacy GraphQL API - HSL's GraphQL API used by the Digitransit project. Transmodel API - Enturs GraphQL Transmodel API. SIRI updator - Update OTP with realtime information from a Transmodel SIRI data source. BikeRentalServiceDirectory - GBFS service directory endpoint.","title":"Available extensions"},{"location":"SandboxExtension/#terminology","text":"Main/core -- All OTP code and additional files, NOT part of the sandbox. ( docs , src/main , src/test and so on) Extensions -- All features implemented in the OTP Sandbox, provided with no guarantees. ( src/ext , src/ext-test )","title":"Terminology"},{"location":"SandboxExtension/#sandbox-goals","text":"Reduce work for PR approval Allow experimental code to evolve (in a Sandbox) Encourage refactoring and creation of extension points in the main code. Increase visibility and cooperation of development of new features. Feature toggle Sandbox features should use the OTPFeature to enable the code. Sandbox features are by default off. To toggle features on/off se the configuration documentation .","title":"Sandbox Goals"},{"location":"SandboxExtension/#contract","text":"Give your feature a name: <extension name> A new feature is isolated from the rest of the code by putting it in the directory src/ext . Java code should have package prefix org.opentripplanner.ext.<extension name> . Unit tests should be added in the test directory: src/ext-test To integrate the new feature into OTP you may have to create new extension points in the main/core code. Changes to the core OTP are subject to normal a review process. Create a readme file ( docs/sandbox/<Extension Name>.md package including: Extension Name Contact info Change log Documentation of the feature (optional) List your extension in the Available extensions section and in the mydocs config file . Use feature toggling to enable a feature at runtime. The feature must be disabled by default. A feature is toggled on using the config files. Only code modifying the main code( src/main , not src/ext ) is reviewed. The current coding standard apply to the extension code as well - but the code is not necessarily reviewed. There are no grantees - the authors of an extension can change its API any time they want. Anyone can request the feature to be merged into the main code. An approval from the PLC and a new review is then required. The reviewers may request any changes, including API changes. If an extension is taken into the core/main OTP code, any API included may change, no BACKWARD compatibility is guaranteed. I.e. the reviewers may require changes before it is merged. The feature submitters is responsible for maintaining and testing the extension code, but do not need to provide any guarantees or support. If the extension is merged into the main code the author will in fact need to provide support and maintenance. When someone at a later point in time want to change the main code the only thing they are responsible for - with regard to the extension code - is: that it compiles. that the unit tests run. If a test is not easy to fix, it can be tagged with @Ignore. If ignored it would be polite to notify the author. Changes to the main OTP API that cannot be toggled in must be clearly marked/tagged as part of an experimental feature and documented - This code is subject to review. If a feature is old and not maintained it can be removed 1 month after notifying the submitter (using contact info in README file). Introducing new dependencies needs approval. They are NOT approved if they are likely to be a maintenance challenge (many transitive dependencies or potential conflicts with other versions/libraries).","title":"Contract"},{"location":"Security/","text":"Security OTP's built-in Grizzly web server is configured to accept HTTPS connections on port 8081 by default, but the HTTPS listener needs an encryption key to establish a connection. The key is placed in a \"keystore\", a format specific to Java server environments. Creating a keystore By default, OTP will look for the keystore at /var/otp/keystore . To generate a self-signed key for testing, use the command: keytool -genkey -keystore /var/otp/keystore -alias OTPServerKey The alias of the key is arbitrary, but it's best to supply one that indicates the purpose of the key to override the default. keytool will ask you a series of questions about you and your organization; again, any values will do when creating this self-signed test key. keytool will also ask you for a password to protect your keystore and key. This password will eventually be configurable, but for now it is hard-coded into the OTP server, so you must set the keystore and key passwords both to opentrip . Of course with a self-signed key, most clients will (rightfully) refuse to connect without special permission from the user. You'll need to add a security exception to most web browsers, or add the --insecure switch when using CURL. You could theoretically buy and install a \"real\" trusted SSL/TLS certificate it in the keystore using keytool -gencert , but since none of the functionality protected by this encryption is public-facing a self-signed key should be sufficient for most use cases. All connections to these API methods should be from trusted parties who can verify the validity of the key with you directly as needed. Testing Once you have created a key, start up the OTP server and test that HTTPS access and authentication are possible. You should also be able to fetch any OTP resources over HTTPS. For example, you could simply open https://localhost:8081/index.html in a browser, or open a raw TLS connection using openssl s_client -connect localhost:8081 , then issue the request GET index.html HTTP/1.1 . Other TODO explain CORS, explain adding TLS with reverse proxy e.g. nginx","title":"Security"},{"location":"Security/#security","text":"OTP's built-in Grizzly web server is configured to accept HTTPS connections on port 8081 by default, but the HTTPS listener needs an encryption key to establish a connection. The key is placed in a \"keystore\", a format specific to Java server environments.","title":"Security"},{"location":"Security/#creating-a-keystore","text":"By default, OTP will look for the keystore at /var/otp/keystore . To generate a self-signed key for testing, use the command: keytool -genkey -keystore /var/otp/keystore -alias OTPServerKey The alias of the key is arbitrary, but it's best to supply one that indicates the purpose of the key to override the default. keytool will ask you a series of questions about you and your organization; again, any values will do when creating this self-signed test key. keytool will also ask you for a password to protect your keystore and key. This password will eventually be configurable, but for now it is hard-coded into the OTP server, so you must set the keystore and key passwords both to opentrip . Of course with a self-signed key, most clients will (rightfully) refuse to connect without special permission from the user. You'll need to add a security exception to most web browsers, or add the --insecure switch when using CURL. You could theoretically buy and install a \"real\" trusted SSL/TLS certificate it in the keystore using keytool -gencert , but since none of the functionality protected by this encryption is public-facing a self-signed key should be sufficient for most use cases. All connections to these API methods should be from trusted parties who can verify the validity of the key with you directly as needed.","title":"Creating a keystore"},{"location":"Security/#testing","text":"Once you have created a key, start up the OTP server and test that HTTPS access and authentication are possible. You should also be able to fetch any OTP resources over HTTPS. For example, you could simply open https://localhost:8081/index.html in a browser, or open a raw TLS connection using openssl s_client -connect localhost:8081 , then issue the request GET index.html HTTP/1.1 .","title":"Testing"},{"location":"Security/#other","text":"TODO explain CORS, explain adding TLS with reverse proxy e.g. nginx","title":"Other"},{"location":"Troubleshooting-Routing/","text":"Troubleshooting Routing Graph Builder Data Import Issues When you build a graph, OTP may encounter clearly incorrect or ambiguous data, or may detect less severe, but potentially problematic situations in the input data. Such problems should result in a \"Data Import Issue\" being generated. These issues are logged the the DATA_IMPORT_ISSUES console logger, depending on your need you might turn this logger on/off. At the end of the graph build process, OTP prints a summary of all the issues, like the following: 11:35:57.515 INFO (Graph.java:970) Summary (number of each type of issues): 11:35:57.518 INFO (Graph.java:976) TurnRestrictionBad - 560 11:35:57.518 INFO (Graph.java:976) TurnRestrictionException - 15 11:35:57.518 INFO (Graph.java:976) StopLinkedTooFar - 22 11:35:57.518 INFO (Graph.java:976) HopSpeedSlow - 22 11:35:57.518 INFO (Graph.java:976) Graphwide - 1 11:35:57.518 INFO (Graph.java:976) GraphConnectivity - 407 11:35:57.519 INFO (Graph.java:976) ParkAndRideUnlinked - 1 11:35:57.519 INFO (Graph.java:976) StopNotLinkedForTransfers - 31 11:35:57.519 INFO (Graph.java:976) NoFutureDates - 1 The full set of issues can be written out to an HTML report for closer inspection. To enable the creation of these (potentially voluminous) HTML reports, add \"dataImportReport\" : true to your graph builder JSON configuration. If the graph is saved to a file, these issues are saved with it and can be examined later. Currently the only tool for doing this is the \"Graph Visualizer\", which is not particularly well maintained and is intended for use by software developers familiar with OTP who can patch up the code as needed. Debug layers OpenTripplanner has option to ease debugging problems with graph. Older option is graph visualizer. Which you can enable with --visualize parameter instead of --server when starting OTP. There you can see whole graph. You can click on edges and vertices and see the metadata. It is useful to see if street has expected options. And if connections are where they are expected. It can be hard to use on large graphs since, whole graph is displayed at once. And it can be hard to search for specific streets since only street graph is shown without the rest of information. Another option is to use debug layers, which shows extra layers on top of normal map. To enable them you need to add ?debug_layers=true to URL. For example http://localhost:8080/?debug_layers=true . This adds debug layers to layer choosing dialog. Currently you can choose between: Wheelchair access (which colors street edges red if they don't allow wheelchair or green otherwise) Bike Safety (colors street edges based on how good are for cycling [smaller is better]) Traversal permissions (colors street edges based on what types of transit modes are allowed to travel on them (Pedestrian, cycling, car are currently supported)) Traversal permissions layer also draws links from transit stops/bike rentals and P+R to graph. And also draws transit stops, bike rentals and P+R vertices with different color. Interpretation Traversal permissions layer A sample traversal permissions layer looks like the following * Yellow lines is the link between a stop and the street graph. * Grey lines are streets one can travel with the mode walk, bike, or car * Green lines are paths one can travel with the mode walk only * Red lines are streets one can travel with the mode car only * Grey dots vertices where edges are connected. If two edges are crossing w/o a vertice at the intersection point, users will not be able to go from one street to the other. But this can be valid in case of over/under pass for example. If it's an error, it's usually caused by improperly connected OSM data (a shared OSM node is required). OpenStreetMap Data Tags Affecting Permissions Access tags (such as bicycle/foot = yes/no/designated) can be used to override default graph-building parameters. As a default, foot and bicycle traffic is ''not'' allowed on highway=trunk , highway=trunk_link , highway=motorway , highway=motorway_link , or highway=construction . Both are allowed on highway=pedestrian , highway=cycleway , and highway=footway . Finally, bicycles are not allowed on highway=footway when any of the following tags appear on a footway: footway=sidewalk , public_transport=platform , or railway=platform . Other access tags (such as access=no and access=private affect routing as well, and can be overridden similarly. While access=no prohibits all traffic, access=private disallows through traffic. See osmWayPropertySet config attribute Railway Platforms OTP users in Helsinki have documented their best practices for coding railway platforms in OpenStreetMap. These guidelines are available in the OSM Wiki. Further information General information Bicycle routing Indoor mapping Elevators","title":"Troubleshooting"},{"location":"Troubleshooting-Routing/#troubleshooting-routing","text":"","title":"Troubleshooting Routing"},{"location":"Troubleshooting-Routing/#graph-builder-data-import-issues","text":"When you build a graph, OTP may encounter clearly incorrect or ambiguous data, or may detect less severe, but potentially problematic situations in the input data. Such problems should result in a \"Data Import Issue\" being generated. These issues are logged the the DATA_IMPORT_ISSUES console logger, depending on your need you might turn this logger on/off. At the end of the graph build process, OTP prints a summary of all the issues, like the following: 11:35:57.515 INFO (Graph.java:970) Summary (number of each type of issues): 11:35:57.518 INFO (Graph.java:976) TurnRestrictionBad - 560 11:35:57.518 INFO (Graph.java:976) TurnRestrictionException - 15 11:35:57.518 INFO (Graph.java:976) StopLinkedTooFar - 22 11:35:57.518 INFO (Graph.java:976) HopSpeedSlow - 22 11:35:57.518 INFO (Graph.java:976) Graphwide - 1 11:35:57.518 INFO (Graph.java:976) GraphConnectivity - 407 11:35:57.519 INFO (Graph.java:976) ParkAndRideUnlinked - 1 11:35:57.519 INFO (Graph.java:976) StopNotLinkedForTransfers - 31 11:35:57.519 INFO (Graph.java:976) NoFutureDates - 1 The full set of issues can be written out to an HTML report for closer inspection. To enable the creation of these (potentially voluminous) HTML reports, add \"dataImportReport\" : true to your graph builder JSON configuration. If the graph is saved to a file, these issues are saved with it and can be examined later. Currently the only tool for doing this is the \"Graph Visualizer\", which is not particularly well maintained and is intended for use by software developers familiar with OTP who can patch up the code as needed.","title":"Graph Builder Data Import Issues"},{"location":"Troubleshooting-Routing/#debug-layers","text":"OpenTripplanner has option to ease debugging problems with graph. Older option is graph visualizer. Which you can enable with --visualize parameter instead of --server when starting OTP. There you can see whole graph. You can click on edges and vertices and see the metadata. It is useful to see if street has expected options. And if connections are where they are expected. It can be hard to use on large graphs since, whole graph is displayed at once. And it can be hard to search for specific streets since only street graph is shown without the rest of information. Another option is to use debug layers, which shows extra layers on top of normal map. To enable them you need to add ?debug_layers=true to URL. For example http://localhost:8080/?debug_layers=true . This adds debug layers to layer choosing dialog. Currently you can choose between: Wheelchair access (which colors street edges red if they don't allow wheelchair or green otherwise) Bike Safety (colors street edges based on how good are for cycling [smaller is better]) Traversal permissions (colors street edges based on what types of transit modes are allowed to travel on them (Pedestrian, cycling, car are currently supported)) Traversal permissions layer also draws links from transit stops/bike rentals and P+R to graph. And also draws transit stops, bike rentals and P+R vertices with different color.","title":"Debug layers"},{"location":"Troubleshooting-Routing/#interpretation-traversal-permissions-layer","text":"A sample traversal permissions layer looks like the following * Yellow lines is the link between a stop and the street graph. * Grey lines are streets one can travel with the mode walk, bike, or car * Green lines are paths one can travel with the mode walk only * Red lines are streets one can travel with the mode car only * Grey dots vertices where edges are connected. If two edges are crossing w/o a vertice at the intersection point, users will not be able to go from one street to the other. But this can be valid in case of over/under pass for example. If it's an error, it's usually caused by improperly connected OSM data (a shared OSM node is required).","title":"Interpretation Traversal permissions layer"},{"location":"Troubleshooting-Routing/#openstreetmap-data","text":"","title":"OpenStreetMap Data"},{"location":"Troubleshooting-Routing/#tags-affecting-permissions","text":"Access tags (such as bicycle/foot = yes/no/designated) can be used to override default graph-building parameters. As a default, foot and bicycle traffic is ''not'' allowed on highway=trunk , highway=trunk_link , highway=motorway , highway=motorway_link , or highway=construction . Both are allowed on highway=pedestrian , highway=cycleway , and highway=footway . Finally, bicycles are not allowed on highway=footway when any of the following tags appear on a footway: footway=sidewalk , public_transport=platform , or railway=platform . Other access tags (such as access=no and access=private affect routing as well, and can be overridden similarly. While access=no prohibits all traffic, access=private disallows through traffic. See osmWayPropertySet config attribute","title":"Tags Affecting Permissions"},{"location":"Troubleshooting-Routing/#railway-platforms","text":"OTP users in Helsinki have documented their best practices for coding railway platforms in OpenStreetMap. These guidelines are available in the OSM Wiki.","title":"Railway Platforms"},{"location":"Troubleshooting-Routing/#further-information","text":"General information Bicycle routing Indoor mapping Elevators","title":"Further information"},{"location":"Version-Comparison/","text":"Comparing OTP2 and OTP1 Summary OpenTripPlanner has been under development since 2009, leading up to a 1.0 release in 2016. Research and development on higher performance routing has been ongoing since 2013-2014, and work on the second major release referred to as OTP2 officially began in 2018. As of Q3 2020, a release candidate of OTP2 is available and in limited production use. This page explains key differences between the two versions (referred to as OTP1 and OTP2) to help you decide which one to use. OTP1 has existed for over a decade and is in widespread use. It aims to do many things for many people: it provides passenger-facing itinerary services over APIs, but also serves as a network analysis toolkit for urban planning and research. Though OTP1 is widely used and gets the job done, its transit routing approach is obsolete. We have long recognized that more resource-efficient approaches were possible. Reasonable response times and scaling to larger data sets have been achieved through a series of complex incremental interventions that became difficult to maintain. OTP1 has also accumulated large amounts of experimental code and specialized tools, which can be useful in a research or consulting setting but complicate long-term maintenance. OTP2 is brand new and still in testing, though based on code and ideas in heavy use for over five years. It offers much better performance in larger transportation networks and geographic areas, and a wider variety of alternative itineraries. OTP2's public transit routing component has been completely rewritten, and is now distinct from bike, walk, and motor vehicle routing. Non-transit routing remains identical to OTP1, benefiting from years of adaptations to nuances of OpenStreetMap data and end-user walking and biking preferences. Unlike OTP1, OTP2 is completely focused on passenger-facing itinerary services. The innovations in OTP2 have already been applied to planning, research, and analysis work for several years through Conveyal's R5 project, which informed and inspired the OTP2 transit routing system. OTP2 will not supersede OTP1 immediately for all use cases. In some situations there are legitimate reasons to continue using OTP1, or even for new OpenTripPlanner users to adopt OTP1 instead of OTP2. As development work continues over 2021 and additional 2.x releases are made, we expect this gap to close and OTP2 (in combination with other projects) may eventually fully replace OTP1, but this process is expected to take a few years. OTP2 Use Cases The benefits of OTP2 will be most evident in large or dense networks spanning multiple cities: entire countries (Netherlands, Switzerland, Norway), US states, metropolitan regions and cross-border conurbations (e.g. NYC metro area). Although the scale of trip planners is sometimes limited by the geographic extent of administrative structures (national rail or bus operators or ticketing agencies), OTP2 should be capable of handling even larger networks, and we do for example regularly test on a unified Nordic trip planner in hopes that such systems will materialize over time as more territories adopt OTP. OTP2 development has been driven by adoption of open source routing software in Northern Europe. Importantly for deployments in Europe, OTP2 introduces support for EU-standard Netex and SIRI data sources in addition to GTFS. The Nordic profile of Netex understood by OTP2 uses the same schema as the EU profile, and generalization to the EU profile should be feasible once it is standardized. Choosing between OTP1 and OTP2 Much development effort has gone into OTP2, and most OTP development effort will continue to focus on OTP2 after its release. OTP2 is much more efficient than OTP1 for certain common use cases, providing faster responses for a larger number of simultaneous users over larger geographic areas and more complex transportation networks. However, this does not mean that all users of OpenTripPlanner should switch to OTP2, or that all new users will want to start with OTP2. As of fall 2020, OTP1 remains much more widely used than OTP2, and most importantly OTP2 has a smaller feature set than OTP1. That is to say, OTP2 can do less things than OTP1, but it does them much more efficiently and tries to cover the most common use cases for large-scale OTP deployments. When in doubt, new users are advised to try out OTP2 and switch to OTP1 if they need features that are not available in OTP2. If some feature you need is missing from OTP2, you can also create a new issue or comment on an existing one on GitHub, letting us know why it is important to you. New features can be added to the OTP2 if there is sufficient demand and development resources to maintain them. High-level feature comparison Feature OTP1 OTP2 OSM street data yes yes GTFS transit data yes yes ( frequency.txt not jet supported ) Netex transit data no yes (Nordic profile) GTFS-Realtime yes (streaming, polling, incremental) yes (streaming, polling, incremental) SIRI Realtime no yes Elevation data TIFF and NED TIFF and NED One-to-many routing, isochrones and scripting yes no Java version 8+ 11+ Multiple regions per server yes no Hot reloading of graphs yes no Street (OSM) routing algorithm Generalized cost A* Generalized cost A* Transit routing algorithm Generalized cost A* Multi-criteria range-RAPTOR Search segmentation Single search through access, transit, egress Access/egress separate from transit search Goal direction Upper bound search backward from destination, over streets and transit, interleaved with forward search Upper bound search backward from destination on transit only, before forward search begins Alternative itineraries \"Trip banning\", N lowest generalized costs True Pareto-optimal results Departure/arrival time Single departure or arrival time only Every minute in a window up to several days long API Paging no yes Timetable View no yes Plugin Sandbox Extensions no yes ( See extensions ) Data storage local, S3 (elevation only) extensible with local, ZIP, and Google Cloud plugins, S3 available Transfer Priority yes (route, trip, stop level) no (planned) / REST API format XML, JSON JSON only Commentary on OTP1 features removed from OTP2 OTP2 brings significant improvements in speed and scalability, but does not retain all features of OTP1. We have chosen to prioritize long-term maintainability, so only those features that are \"owned\" by a team of professional developers will be carried over to OTP2. Features that have been removed to simplify the code base and improve maintainability may be removed permanently. Other missing features are still priorities for the organization leading OTP2 development (Entur) but have not yet been adapted to the new transit routing system, and will be added in upcoming releases. Some features have been removed to reflect separation of concerns: following principles of modular design they should be handled outside OTP, or are already covered by other projects where they are more actively developed. Analysis Many OpenTripPlanner contributors have been primarily interested in transportation and urban planning use cases. We consider these use cases quite important. This has been a major area of application for OpenTripPlanner and has helped popularize cumulative opportunities accessibility metrics. For example, the University of Minnesota Accessibility Observatory used OpenTripPlanner for Access Across America . Nonetheless, the analysis code in OTP1 is essentially an unmaintained and unsupported early prototype for later projects, specifically Conveyal's R5 (and the Conveyal Analysis system built upon it). OTP1 seems to have gained popularity for analysis uses due to the existence of documentation and an active user community, but has significant technical shortcomings. One of these is simply speed: OTP1 can be orders of magnitude slower (and more memory-intensive) than the approaches exemplified in R5. The other is the requirement to search at a single specific time. Travel times and especially wait times on scheduled transit vary greatly depending on when you depart. Accounting for variation over a time window requires repeated independent searches at each possible departure time, which is very inefficient. R5 is highly optimized to capture variations in travel time across time windows and account for uncertainty in waiting times on frequency-based routes. Due to its similarity to the R5 approach, OTP2's transit router would not have these same problems. Nonetheless, we have decided not to port the OTP1 analysis features over to OTP2 since it would broaden the focus away from passenger information and draw finite attention away from existing projects like R5 and Conveyal Analysis. Accordingly, we have made an effort to clean up and augment OTP1 analysis documentation for researchers who will continue to need it. It should remain possible for people to continue using OTP1 if they prefer. If you would instead like to apply the innovations present in OTP2, we recommend looking into R5 or Conveyal Analysis. Routers API and Hot Reloading Via it's Routers API, OTP1 allows loading data and serving APIs for multiple separate geographic areas. This is functionally equivalent to running more than one OTP server with separate data sets. This system also allows reloading transportation network data when it changes, or even pushing new data over a network connection. These were all adaptations to the very different IT environment that existed earlier in OTP history. These days, containerization and on-demand cloud servers have become ubiquitous, and most users solve these problems in totally different ways - by provisioning and starting up entirely new virtual servers, then switching a load balancer over to those new servers. Because the Routers API is complex and exposes potentially damaging functionality over the network, it has been removed from OTP2 to simplify the code base and make it easier to reason about security. Routing request parameters Less parameters are available on the OTP2 REST API than in OTP1. Often there is no practical loss of functionality, just a different way of expressing things due to the new routing algorithms. A summary of parameters that have been removed and their replacements can be found in the migration guide OTP2-MigrationGuide . OTP Trip planning and Transit index APIs OTP1 have two APIs for trip planning, the REST API and an obsolete GraphQL API(early version of the Digitransit GraphQL API). OTP2 still support the REST API and it is very similar in functionality compared with the OTP1 version. In the future we would like to create a new official OTP API using GraphQL replacing the REST API. We will probably support the REST API for a long time to allow everyone to migrate to the new GraphQL API. Today, OTP2 comes with two Sandbox extension APIs: HSL Legacy GraphQL API - HSL's GraphQL API used by the Digitransit project. Transmodel API - Entur\u00b4s Transmodel API The plan is to merge the two APIs above, clean it up and make it the new official API. The HSL API uses GTFS terminology, while the Entur API is Transmodel(NeTEx) based. Both APIs are similar in semantics/structure and provide the same functionality. The plan is to merge these to APIs into one new official OTP2 API. We will then deprecate the REST API, Transmodel API and the HSL API. The new API will be available in a GTFS and a Transmodel \"translated\" version. Additional characteristics added in OTP2 Sandbox Extensions OTP2's Sandbox system allows for plugins, proprietary extensions, and experimental feature development with less overhead. It forces OTP2 to become more extensible, while reducing process overhead when developing non-core features. Cloud support In OTP1 all data access (config, input data, and graph output) is by direct access to the local filesystem. The only exception is elevation data, which can be loaded from AWS S3 as well. In OTP2, all data access is through an abstraction layer. This can be configured to support individual local files, zip files, and Google Cloud Storage. The new data access treats directories and zip files as \u201cequal\u201d, and this functionality is used to read the contents of GTFS and NeTEx archives. Other data sources can be supported by writing plugins. Entur has written a plugin for AWS S3 which has not been merged. If requested they can provide this code for AWS S3. Library upgrades We have adapted OTP2 to run on Java 11+ and moved to newer versions of some dependencies such as GraphQL and One Bus Away. Bugfixes At least bug issues have been resolved in OTP2. Critical fixes have been backported to OTP1. See https://github.com/issues?q=is%3Aclosed+is%3Aissue+label%3AOTP2+label%3Abug Other features removed from OTP2 AlertPatch GTFS-RT Service Alerts will no longer affect routing (e.g. cancel trips). A GTFS-RT Trip Updates feed should be used for this purpose.","title":"Choosing OTP2 or OTP1"},{"location":"Version-Comparison/#comparing-otp2-and-otp1","text":"","title":"Comparing OTP2 and OTP1"},{"location":"Version-Comparison/#summary","text":"OpenTripPlanner has been under development since 2009, leading up to a 1.0 release in 2016. Research and development on higher performance routing has been ongoing since 2013-2014, and work on the second major release referred to as OTP2 officially began in 2018. As of Q3 2020, a release candidate of OTP2 is available and in limited production use. This page explains key differences between the two versions (referred to as OTP1 and OTP2) to help you decide which one to use. OTP1 has existed for over a decade and is in widespread use. It aims to do many things for many people: it provides passenger-facing itinerary services over APIs, but also serves as a network analysis toolkit for urban planning and research. Though OTP1 is widely used and gets the job done, its transit routing approach is obsolete. We have long recognized that more resource-efficient approaches were possible. Reasonable response times and scaling to larger data sets have been achieved through a series of complex incremental interventions that became difficult to maintain. OTP1 has also accumulated large amounts of experimental code and specialized tools, which can be useful in a research or consulting setting but complicate long-term maintenance. OTP2 is brand new and still in testing, though based on code and ideas in heavy use for over five years. It offers much better performance in larger transportation networks and geographic areas, and a wider variety of alternative itineraries. OTP2's public transit routing component has been completely rewritten, and is now distinct from bike, walk, and motor vehicle routing. Non-transit routing remains identical to OTP1, benefiting from years of adaptations to nuances of OpenStreetMap data and end-user walking and biking preferences. Unlike OTP1, OTP2 is completely focused on passenger-facing itinerary services. The innovations in OTP2 have already been applied to planning, research, and analysis work for several years through Conveyal's R5 project, which informed and inspired the OTP2 transit routing system. OTP2 will not supersede OTP1 immediately for all use cases. In some situations there are legitimate reasons to continue using OTP1, or even for new OpenTripPlanner users to adopt OTP1 instead of OTP2. As development work continues over 2021 and additional 2.x releases are made, we expect this gap to close and OTP2 (in combination with other projects) may eventually fully replace OTP1, but this process is expected to take a few years.","title":"Summary"},{"location":"Version-Comparison/#otp2-use-cases","text":"The benefits of OTP2 will be most evident in large or dense networks spanning multiple cities: entire countries (Netherlands, Switzerland, Norway), US states, metropolitan regions and cross-border conurbations (e.g. NYC metro area). Although the scale of trip planners is sometimes limited by the geographic extent of administrative structures (national rail or bus operators or ticketing agencies), OTP2 should be capable of handling even larger networks, and we do for example regularly test on a unified Nordic trip planner in hopes that such systems will materialize over time as more territories adopt OTP. OTP2 development has been driven by adoption of open source routing software in Northern Europe. Importantly for deployments in Europe, OTP2 introduces support for EU-standard Netex and SIRI data sources in addition to GTFS. The Nordic profile of Netex understood by OTP2 uses the same schema as the EU profile, and generalization to the EU profile should be feasible once it is standardized.","title":"OTP2 Use Cases"},{"location":"Version-Comparison/#choosing-between-otp1-and-otp2","text":"Much development effort has gone into OTP2, and most OTP development effort will continue to focus on OTP2 after its release. OTP2 is much more efficient than OTP1 for certain common use cases, providing faster responses for a larger number of simultaneous users over larger geographic areas and more complex transportation networks. However, this does not mean that all users of OpenTripPlanner should switch to OTP2, or that all new users will want to start with OTP2. As of fall 2020, OTP1 remains much more widely used than OTP2, and most importantly OTP2 has a smaller feature set than OTP1. That is to say, OTP2 can do less things than OTP1, but it does them much more efficiently and tries to cover the most common use cases for large-scale OTP deployments. When in doubt, new users are advised to try out OTP2 and switch to OTP1 if they need features that are not available in OTP2. If some feature you need is missing from OTP2, you can also create a new issue or comment on an existing one on GitHub, letting us know why it is important to you. New features can be added to the OTP2 if there is sufficient demand and development resources to maintain them.","title":"Choosing between OTP1 and OTP2"},{"location":"Version-Comparison/#high-level-feature-comparison","text":"Feature OTP1 OTP2 OSM street data yes yes GTFS transit data yes yes ( frequency.txt not jet supported ) Netex transit data no yes (Nordic profile) GTFS-Realtime yes (streaming, polling, incremental) yes (streaming, polling, incremental) SIRI Realtime no yes Elevation data TIFF and NED TIFF and NED One-to-many routing, isochrones and scripting yes no Java version 8+ 11+ Multiple regions per server yes no Hot reloading of graphs yes no Street (OSM) routing algorithm Generalized cost A* Generalized cost A* Transit routing algorithm Generalized cost A* Multi-criteria range-RAPTOR Search segmentation Single search through access, transit, egress Access/egress separate from transit search Goal direction Upper bound search backward from destination, over streets and transit, interleaved with forward search Upper bound search backward from destination on transit only, before forward search begins Alternative itineraries \"Trip banning\", N lowest generalized costs True Pareto-optimal results Departure/arrival time Single departure or arrival time only Every minute in a window up to several days long API Paging no yes Timetable View no yes Plugin Sandbox Extensions no yes ( See extensions ) Data storage local, S3 (elevation only) extensible with local, ZIP, and Google Cloud plugins, S3 available Transfer Priority yes (route, trip, stop level) no (planned) / REST API format XML, JSON JSON only","title":"High-level feature comparison"},{"location":"Version-Comparison/#commentary-on-otp1-features-removed-from-otp2","text":"OTP2 brings significant improvements in speed and scalability, but does not retain all features of OTP1. We have chosen to prioritize long-term maintainability, so only those features that are \"owned\" by a team of professional developers will be carried over to OTP2. Features that have been removed to simplify the code base and improve maintainability may be removed permanently. Other missing features are still priorities for the organization leading OTP2 development (Entur) but have not yet been adapted to the new transit routing system, and will be added in upcoming releases. Some features have been removed to reflect separation of concerns: following principles of modular design they should be handled outside OTP, or are already covered by other projects where they are more actively developed.","title":"Commentary on OTP1 features removed from OTP2"},{"location":"Version-Comparison/#analysis","text":"Many OpenTripPlanner contributors have been primarily interested in transportation and urban planning use cases. We consider these use cases quite important. This has been a major area of application for OpenTripPlanner and has helped popularize cumulative opportunities accessibility metrics. For example, the University of Minnesota Accessibility Observatory used OpenTripPlanner for Access Across America . Nonetheless, the analysis code in OTP1 is essentially an unmaintained and unsupported early prototype for later projects, specifically Conveyal's R5 (and the Conveyal Analysis system built upon it). OTP1 seems to have gained popularity for analysis uses due to the existence of documentation and an active user community, but has significant technical shortcomings. One of these is simply speed: OTP1 can be orders of magnitude slower (and more memory-intensive) than the approaches exemplified in R5. The other is the requirement to search at a single specific time. Travel times and especially wait times on scheduled transit vary greatly depending on when you depart. Accounting for variation over a time window requires repeated independent searches at each possible departure time, which is very inefficient. R5 is highly optimized to capture variations in travel time across time windows and account for uncertainty in waiting times on frequency-based routes. Due to its similarity to the R5 approach, OTP2's transit router would not have these same problems. Nonetheless, we have decided not to port the OTP1 analysis features over to OTP2 since it would broaden the focus away from passenger information and draw finite attention away from existing projects like R5 and Conveyal Analysis. Accordingly, we have made an effort to clean up and augment OTP1 analysis documentation for researchers who will continue to need it. It should remain possible for people to continue using OTP1 if they prefer. If you would instead like to apply the innovations present in OTP2, we recommend looking into R5 or Conveyal Analysis.","title":"Analysis"},{"location":"Version-Comparison/#routers-api-and-hot-reloading","text":"Via it's Routers API, OTP1 allows loading data and serving APIs for multiple separate geographic areas. This is functionally equivalent to running more than one OTP server with separate data sets. This system also allows reloading transportation network data when it changes, or even pushing new data over a network connection. These were all adaptations to the very different IT environment that existed earlier in OTP history. These days, containerization and on-demand cloud servers have become ubiquitous, and most users solve these problems in totally different ways - by provisioning and starting up entirely new virtual servers, then switching a load balancer over to those new servers. Because the Routers API is complex and exposes potentially damaging functionality over the network, it has been removed from OTP2 to simplify the code base and make it easier to reason about security.","title":"Routers API and Hot Reloading"},{"location":"Version-Comparison/#routing-request-parameters","text":"Less parameters are available on the OTP2 REST API than in OTP1. Often there is no practical loss of functionality, just a different way of expressing things due to the new routing algorithms. A summary of parameters that have been removed and their replacements can be found in the migration guide OTP2-MigrationGuide .","title":"Routing request parameters"},{"location":"Version-Comparison/#otp-trip-planning-and-transit-index-apis","text":"OTP1 have two APIs for trip planning, the REST API and an obsolete GraphQL API(early version of the Digitransit GraphQL API). OTP2 still support the REST API and it is very similar in functionality compared with the OTP1 version. In the future we would like to create a new official OTP API using GraphQL replacing the REST API. We will probably support the REST API for a long time to allow everyone to migrate to the new GraphQL API. Today, OTP2 comes with two Sandbox extension APIs: HSL Legacy GraphQL API - HSL's GraphQL API used by the Digitransit project. Transmodel API - Entur\u00b4s Transmodel API The plan is to merge the two APIs above, clean it up and make it the new official API. The HSL API uses GTFS terminology, while the Entur API is Transmodel(NeTEx) based. Both APIs are similar in semantics/structure and provide the same functionality. The plan is to merge these to APIs into one new official OTP2 API. We will then deprecate the REST API, Transmodel API and the HSL API. The new API will be available in a GTFS and a Transmodel \"translated\" version.","title":"OTP Trip planning and Transit index APIs"},{"location":"Version-Comparison/#additional-characteristics-added-in-otp2","text":"Sandbox Extensions OTP2's Sandbox system allows for plugins, proprietary extensions, and experimental feature development with less overhead. It forces OTP2 to become more extensible, while reducing process overhead when developing non-core features. Cloud support In OTP1 all data access (config, input data, and graph output) is by direct access to the local filesystem. The only exception is elevation data, which can be loaded from AWS S3 as well. In OTP2, all data access is through an abstraction layer. This can be configured to support individual local files, zip files, and Google Cloud Storage. The new data access treats directories and zip files as \u201cequal\u201d, and this functionality is used to read the contents of GTFS and NeTEx archives. Other data sources can be supported by writing plugins. Entur has written a plugin for AWS S3 which has not been merged. If requested they can provide this code for AWS S3. Library upgrades We have adapted OTP2 to run on Java 11+ and moved to newer versions of some dependencies such as GraphQL and One Bus Away. Bugfixes At least bug issues have been resolved in OTP2. Critical fixes have been backported to OTP1. See https://github.com/issues?q=is%3Aclosed+is%3Aissue+label%3AOTP2+label%3Abug","title":"Additional characteristics added in OTP2"},{"location":"Version-Comparison/#other-features-removed-from-otp2","text":"AlertPatch GTFS-RT Service Alerts will no longer affect routing (e.g. cancel trips). A GTFS-RT Trip Updates feed should be used for this purpose.","title":"Other features removed from OTP2"},{"location":"Visual-Identity/","text":"OpenTripPlanner Visual Identity This is the OpenTripPlanner logo in scalable vector format, with knockout transparency: Here is a link to this SVG logo as a downloadable file . This is the raw SVG XML source code: <?xml version=\"1.0\" encoding=\"utf-8\"?> <!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"> <svg version=\"1.1\" id=\"Layer_1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" x=\"0px\" y=\"0px\" width=\"512px\" height=\"512px\" viewBox=\"0 0 125.333 125.334\" xml:space=\"preserve\"> <path fill=\"#2179BF\" d=\"M62.668,0C33.83,0,9.559,19.483,2.258,46l72.681-0.003c4.729-0.011,8.555-3.837,8.561-8.568 c-0.006-4.729-3.831-8.555-8.561-8.559c-4.731,0.004-8.557,3.83-8.564,8.559v4.592h-13.7v-4.592 c0-12.294,9.962-22.261,22.265-22.263c12.298,0.002,22.262,9.969,22.266,22.263c-0.003,12.3-9.968,22.264-22.266,22.271H0.074 C0.028,60.684,0,61.671,0,62.666c0,34.611,28.057,62.668,62.668,62.668c34.609,0,62.665-28.057,62.665-62.668 C125.333,28.057,97.277,0,62.668,0 M92.222,85.667v-3.473v-4.86l-47.058,0.003c-4.729,0.011-8.556,3.837-8.561,8.568 c0.005,4.728,3.831,8.555,8.561,8.559c4.731-0.004,8.558-3.831,8.565-8.559v-4.592h13.699v4.592 c0,12.294-9.961,22.261-22.265,22.263c-12.298-0.002-22.26-9.969-22.264-22.263c0.002-12.3,9.966-22.264,22.264-22.271h47.058V56.12 l21.712,14.775L92.222,85.667z\"/> </svg> This concept behind this logo design was \"infinite roads\". Besides the clear references to movement and wayfinding through a transportation network, it (somewhat subliminally) contains the letters O T and P. This design is more geometric and austere than our previous logo, which makes it readily recognizable in a crowd of small app icons, bookmarks, or favicons. It also channels the high modern logos and 1970s supergraphics that were the visual style of public transport for a generation. The color of the logo in the RGB colorspace is #2179BF . The name of the OpenTripPlanner project is written in CamelCase: capital letters at the beginning of each word, with no spaces between the words. For the logotype we do not strictly adhere to a standard typeface. The OTP website just uses the CSS declarations font: 30pt helvetica, sans-serif; font-weight: bold; . The OpenTripPlanner logo was created by Brooklyn-based cartographer and graphic designer Kate Chanba , who has also done extensive work on transit system maps.","title":"Visual Identity"},{"location":"Visual-Identity/#opentripplanner-visual-identity","text":"This is the OpenTripPlanner logo in scalable vector format, with knockout transparency: Here is a link to this SVG logo as a downloadable file . This is the raw SVG XML source code: <?xml version=\"1.0\" encoding=\"utf-8\"?> <!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"> <svg version=\"1.1\" id=\"Layer_1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" x=\"0px\" y=\"0px\" width=\"512px\" height=\"512px\" viewBox=\"0 0 125.333 125.334\" xml:space=\"preserve\"> <path fill=\"#2179BF\" d=\"M62.668,0C33.83,0,9.559,19.483,2.258,46l72.681-0.003c4.729-0.011,8.555-3.837,8.561-8.568 c-0.006-4.729-3.831-8.555-8.561-8.559c-4.731,0.004-8.557,3.83-8.564,8.559v4.592h-13.7v-4.592 c0-12.294,9.962-22.261,22.265-22.263c12.298,0.002,22.262,9.969,22.266,22.263c-0.003,12.3-9.968,22.264-22.266,22.271H0.074 C0.028,60.684,0,61.671,0,62.666c0,34.611,28.057,62.668,62.668,62.668c34.609,0,62.665-28.057,62.665-62.668 C125.333,28.057,97.277,0,62.668,0 M92.222,85.667v-3.473v-4.86l-47.058,0.003c-4.729,0.011-8.556,3.837-8.561,8.568 c0.005,4.728,3.831,8.555,8.561,8.559c4.731-0.004,8.558-3.831,8.565-8.559v-4.592h13.699v4.592 c0,12.294-9.961,22.261-22.265,22.263c-12.298-0.002-22.26-9.969-22.264-22.263c0.002-12.3,9.966-22.264,22.264-22.271h47.058V56.12 l21.712,14.775L92.222,85.667z\"/> </svg> This concept behind this logo design was \"infinite roads\". Besides the clear references to movement and wayfinding through a transportation network, it (somewhat subliminally) contains the letters O T and P. This design is more geometric and austere than our previous logo, which makes it readily recognizable in a crowd of small app icons, bookmarks, or favicons. It also channels the high modern logos and 1970s supergraphics that were the visual style of public transport for a generation. The color of the logo in the RGB colorspace is #2179BF . The name of the OpenTripPlanner project is written in CamelCase: capital letters at the beginning of each word, with no spaces between the words. For the logotype we do not strictly adhere to a standard typeface. The OTP website just uses the CSS declarations font: 30pt helvetica, sans-serif; font-weight: bold; . The OpenTripPlanner logo was created by Brooklyn-based cartographer and graphic designer Kate Chanba , who has also done extensive work on transit system maps.","title":"OpenTripPlanner Visual Identity"},{"location":"examples/Readme/","text":"Example configurations When setting up OTP it is often useful to have some examples to look at. If you have an example to share just add it here. Examples Name Organisation Description entur Entur, Norway Deployment Configuration with NeTEX input data Support The examples are provided \"as is\" - they may get outdated over time or miss information, and it is left to the provider, not the PLC, to include whatever the provider find useful. How to share an example Anyone who want can add their example here as long as it is OTP \"related\". Just create a normal pull-request to add it.","title":"Example configurations"},{"location":"examples/Readme/#example-configurations","text":"When setting up OTP it is often useful to have some examples to look at. If you have an example to share just add it here.","title":"Example configurations"},{"location":"examples/Readme/#examples","text":"Name Organisation Description entur Entur, Norway Deployment Configuration with NeTEX input data","title":"Examples"},{"location":"examples/Readme/#support","text":"The examples are provided \"as is\" - they may get outdated over time or miss information, and it is left to the provider, not the PLC, to include whatever the provider find useful.","title":"Support"},{"location":"examples/Readme/#how-to-share-an-example","text":"Anyone who want can add their example here as long as it is OTP \"related\". Just create a normal pull-request to add it.","title":"How to share an example"},{"location":"examples/entur/Readme/","text":"Entur Deployment Configuration This is a snapshot of Enturs deployment configuration. At Entur we run OTP in the cloud, so some of the provided config will not work outside Enturs cluster, but it is provided \"as is\" for others to replicate if they want. Config files See the config files provided. The updaters section of the router-config.json is provided, but is not working. Remove it if you want to run OTP. It is provided for others as an example on how to configure the SIRI updaters. The same goes for the storage section in the build-config.json , remove it run OTP locally. The <host> , <OperatorNameSpace> and <bucket> are placeholders you need to change. Data input files At Entur we run OTP with the latest NeTEx data we have. You may download it from here: https://developer.entur.org/stops-and-timetable-data We use the Entire Norway file. In the past the file did not contain the stops, so they needed to be downloaded separably (Entire Norway (Current stops) - Latest valid version of all country stops) and inserted into the Netex-file. Unpack the stops zipfile, rename the stops file to _stops.xml . Unpack the netex file and move the _stops.xml into the netex directory. Copy the netex directory and config files into the same directory and start OTP with it as the base directory. We also build with elevation data, witch is not available on the internet without transformation. Send us a request, and we will find a way to share it. We download the OSM data file norway-latest.osm.pbf every night and build a street-graph with OSM and elevation data. We also use some custom OSM files for areas outside Norway, but they in most cases insignificant. If requested, we can provide them.","title":"Entur Deployment Configuration"},{"location":"examples/entur/Readme/#entur-deployment-configuration","text":"This is a snapshot of Enturs deployment configuration. At Entur we run OTP in the cloud, so some of the provided config will not work outside Enturs cluster, but it is provided \"as is\" for others to replicate if they want.","title":"Entur Deployment Configuration"},{"location":"examples/entur/Readme/#config-files","text":"See the config files provided. The updaters section of the router-config.json is provided, but is not working. Remove it if you want to run OTP. It is provided for others as an example on how to configure the SIRI updaters. The same goes for the storage section in the build-config.json , remove it run OTP locally. The <host> , <OperatorNameSpace> and <bucket> are placeholders you need to change.","title":"Config files"},{"location":"examples/entur/Readme/#data-input-files","text":"At Entur we run OTP with the latest NeTEx data we have. You may download it from here: https://developer.entur.org/stops-and-timetable-data We use the Entire Norway file. In the past the file did not contain the stops, so they needed to be downloaded separably (Entire Norway (Current stops) - Latest valid version of all country stops) and inserted into the Netex-file. Unpack the stops zipfile, rename the stops file to _stops.xml . Unpack the netex file and move the _stops.xml into the netex directory. Copy the netex directory and config files into the same directory and start OTP with it as the base directory. We also build with elevation data, witch is not available on the internet without transformation. Send us a request, and we will find a way to share it. We download the OSM data file norway-latest.osm.pbf every night and build a street-graph with OSM and elevation data. We also use some custom OSM files for areas outside Norway, but they in most cases insignificant. If requested, we can provide them.","title":"Data input files"},{"location":"javadoc/","text":"OTP JavaDoc With OTP2, we are not targeting use of OTP as a library, so HTML Javadoc is not as relevant. Use the source artifact, github or an IDE to explore the code instead. Maven Central Repository require javadoc to be present, but it is ok to provide a fake one: If, for some reason (for example, license issue or it's a Scala project), you can not provide -sources.jar or -javadoc.jar , please make fake -sources.jar or -javadoc.jar with simple README inside to pass the checking. We do not want to disable the rules because some people tend to skip it if they have an option and we want to keep the quality of the user experience as high as possible. See: Maven Central Repository - Requirements There is no JavaDoc provided for OTP, use the source artifact, github or an ide to explore the code.","title":"OTP JavaDoc"},{"location":"javadoc/#otp-javadoc","text":"With OTP2, we are not targeting use of OTP as a library, so HTML Javadoc is not as relevant. Use the source artifact, github or an IDE to explore the code instead. Maven Central Repository require javadoc to be present, but it is ok to provide a fake one: If, for some reason (for example, license issue or it's a Scala project), you can not provide -sources.jar or -javadoc.jar , please make fake -sources.jar or -javadoc.jar with simple README inside to pass the checking. We do not want to disable the rules because some people tend to skip it if they have an option and we want to keep the quality of the user experience as high as possible. See: Maven Central Repository - Requirements There is no JavaDoc provided for OTP, use the source artifact, github or an ide to explore the code.","title":"OTP JavaDoc"},{"location":"sandbox/BikeRentalServiceDirectory/","text":"Bike Rental Service Directory API support. Contact Info Gard Mellemstrand, Entur, Norway Changelog Initial implementation of bike share updater API support Documentation This adds support for the GBFS service directory endpoint component located at https://github.com/entur/bikeservice. OTP use the service directory to lookup and connect to all bike share operation registered in the directory. This simplify the management of the bike share enpoints, since multiple services/components like OTP can connect to the directory and get the necessary configuration from it. Configuration To enable this you need to specify a url for the bikeRentalServiceDirectory in the router-config.json","title":"Bike Rental Service Directory API support"},{"location":"sandbox/BikeRentalServiceDirectory/#bike-rental-service-directory-api-support","text":"","title":"Bike Rental Service Directory API support."},{"location":"sandbox/BikeRentalServiceDirectory/#contact-info","text":"Gard Mellemstrand, Entur, Norway","title":"Contact Info"},{"location":"sandbox/BikeRentalServiceDirectory/#changelog","text":"Initial implementation of bike share updater API support","title":"Changelog"},{"location":"sandbox/BikeRentalServiceDirectory/#documentation","text":"This adds support for the GBFS service directory endpoint component located at https://github.com/entur/bikeservice. OTP use the service directory to lookup and connect to all bike share operation registered in the directory. This simplify the management of the bike share enpoints, since multiple services/components like OTP can connect to the directory and get the necessary configuration from it.","title":"Documentation"},{"location":"sandbox/BikeRentalServiceDirectory/#configuration","text":"To enable this you need to specify a url for the bikeRentalServiceDirectory in the router-config.json","title":"Configuration"},{"location":"sandbox/Examples/","text":"Statistics API - OTP Sandbox Extension Example Contact Info Thomas Gran, Entur, Norway Changelog April 2019 (in progress) Initial setup of the first new OTP Sandbox Extension. (April 2019) Added a simple GraphQL API for retrieving Graph statistics. (May 2019) Moved Graph Example Updaters from main code to sandbox examples. (May 2019) Delete the Example Updaters, there are real-life examples in the Sandbox now. (Sep 2020) Documentation Graph Statistics Resource This extension show how to create a web endpoint to get some simple statistics: - Number of stops in the graph","title":"Sandbox Extension Example"},{"location":"sandbox/Examples/#statistics-api-otp-sandbox-extension-example","text":"","title":"Statistics API - OTP Sandbox Extension Example"},{"location":"sandbox/Examples/#contact-info","text":"Thomas Gran, Entur, Norway","title":"Contact Info"},{"location":"sandbox/Examples/#changelog","text":"","title":"Changelog"},{"location":"sandbox/Examples/#april-2019-in-progress","text":"Initial setup of the first new OTP Sandbox Extension. (April 2019) Added a simple GraphQL API for retrieving Graph statistics. (May 2019) Moved Graph Example Updaters from main code to sandbox examples. (May 2019) Delete the Example Updaters, there are real-life examples in the Sandbox now. (Sep 2020)","title":"April 2019 (in progress)"},{"location":"sandbox/Examples/#documentation","text":"","title":"Documentation"},{"location":"sandbox/Examples/#graph-statistics-resource","text":"This extension show how to create a web endpoint to get some simple statistics: - Number of stops in the graph","title":"Graph Statistics Resource"},{"location":"sandbox/GoogleCloudStorage/","text":"Google Cloud Storage - Using GCS Bucket as a OTP Data Source Contact Info Thomas Gran, Entur, Norway Changelog OTP 2.0 Initial implementation to access Google Cloud Storage (read and write). (December 2019) Documentation To enable this turn on the feature GoogleCloudStorage . OTP can load or store artifacts from one or more Google Cloud Storge locations. Each artifact must be configured in the build-config.json : See StorageConfig on how to configure artifacts. Example (build-config.json): { : s t orage : { gcsCrede nt ials : \"/Users/alf/secret/otp-test-1234567890.json\" , osm : [ \"gs://otp-test-bucket/a/b/northpole.pbf\" ], dem : [ \"gs://otp-test-bucket/a/b/northpole.dem.tif\" ], g tfs : [ \"gs://otp-test-bucket/a/b/gtfs.zip\" ], graph : \"gs://otp-test-bucket/a/b/graph.obj\" buildRepor t Dir : \"gs://otp-test-bucket/a/b/np-report\" } }","title":"Google Cloud Storage"},{"location":"sandbox/GoogleCloudStorage/#google-cloud-storage-using-gcs-bucket-as-a-otp-data-source","text":"","title":"Google Cloud Storage - Using GCS Bucket as a OTP Data Source"},{"location":"sandbox/GoogleCloudStorage/#contact-info","text":"Thomas Gran, Entur, Norway","title":"Contact Info"},{"location":"sandbox/GoogleCloudStorage/#changelog","text":"","title":"Changelog"},{"location":"sandbox/GoogleCloudStorage/#otp-20","text":"Initial implementation to access Google Cloud Storage (read and write). (December 2019)","title":"OTP 2.0"},{"location":"sandbox/GoogleCloudStorage/#documentation","text":"To enable this turn on the feature GoogleCloudStorage . OTP can load or store artifacts from one or more Google Cloud Storge locations. Each artifact must be configured in the build-config.json : See StorageConfig on how to configure artifacts. Example (build-config.json): { : s t orage : { gcsCrede nt ials : \"/Users/alf/secret/otp-test-1234567890.json\" , osm : [ \"gs://otp-test-bucket/a/b/northpole.pbf\" ], dem : [ \"gs://otp-test-bucket/a/b/northpole.dem.tif\" ], g tfs : [ \"gs://otp-test-bucket/a/b/gtfs.zip\" ], graph : \"gs://otp-test-bucket/a/b/graph.obj\" buildRepor t Dir : \"gs://otp-test-bucket/a/b/np-report\" } }","title":"Documentation"},{"location":"sandbox/HealthAPI/","text":"Health API Contact Info Entur, Norway Changelog Initial implementation of readiness endpoint (November 2019) Documentation This provides endpoints for checking the health status of the OTP instance. It can be useful when running OTP in a container. The API will be at the endpoint http://localhost:8080/otp/actuators and follows the Spring Boot actuator API standard. Configuration To enable this you need to add the feature ActuatorAPI .","title":"Health API"},{"location":"sandbox/HealthAPI/#health-api","text":"","title":"Health API"},{"location":"sandbox/HealthAPI/#contact-info","text":"Entur, Norway","title":"Contact Info"},{"location":"sandbox/HealthAPI/#changelog","text":"Initial implementation of readiness endpoint (November 2019)","title":"Changelog"},{"location":"sandbox/HealthAPI/#documentation","text":"This provides endpoints for checking the health status of the OTP instance. It can be useful when running OTP in a container. The API will be at the endpoint http://localhost:8080/otp/actuators and follows the Spring Boot actuator API standard.","title":"Documentation"},{"location":"sandbox/HealthAPI/#configuration","text":"To enable this you need to add the feature ActuatorAPI .","title":"Configuration"},{"location":"sandbox/LegacyGraphQLApi/","text":"HSL Legacy GraphQL API - OTP Sandbox Extension Contact Info Digitransit team, HSL, Helsinki, Finland Kyyti, Helsinki, Finland Changelog Initial version of Legacy Graph QL API (September 2020) Documentation This is a copy of HSL's GraphQL API used by the Digitransit project. The API is used to run OTP2 together with the digitransit-ui . OTP2 Official GraphQL API (Not available) We plan to make a new offical OTP2 API, replacing the REST API. The plan is to base the new API on this API and the Legacy GraphQL Api . The new API will most likely have 2 \"translations\": A GTFS version and a Transmodel version, we will try to keep the semantics the same. Configuration To enable this you need to add the feature SandboxAPILegacyGraphQLApi .","title":"HSL Legacy GraphQL API"},{"location":"sandbox/LegacyGraphQLApi/#hsl-legacy-graphql-api-otp-sandbox-extension","text":"","title":"HSL Legacy GraphQL API - OTP Sandbox Extension"},{"location":"sandbox/LegacyGraphQLApi/#contact-info","text":"Digitransit team, HSL, Helsinki, Finland Kyyti, Helsinki, Finland","title":"Contact Info"},{"location":"sandbox/LegacyGraphQLApi/#changelog","text":"Initial version of Legacy Graph QL API (September 2020)","title":"Changelog"},{"location":"sandbox/LegacyGraphQLApi/#documentation","text":"This is a copy of HSL's GraphQL API used by the Digitransit project. The API is used to run OTP2 together with the digitransit-ui .","title":"Documentation"},{"location":"sandbox/LegacyGraphQLApi/#otp2-official-graphql-api-not-available","text":"We plan to make a new offical OTP2 API, replacing the REST API. The plan is to base the new API on this API and the Legacy GraphQL Api . The new API will most likely have 2 \"translations\": A GTFS version and a Transmodel version, we will try to keep the semantics the same.","title":"OTP2 Official GraphQL API (Not available)"},{"location":"sandbox/LegacyGraphQLApi/#configuration","text":"To enable this you need to add the feature SandboxAPILegacyGraphQLApi .","title":"Configuration"},{"location":"sandbox/SiriUpdator/","text":"Siri Updator Support for consuming SIRI ET, SX and ET messages. The updator is developed to support the Norwegian SIRI profile witch is a subset of the SIRI specification. Contact Info Lasse Tyrihjell, Entur, Norway Changelog Initial version of SIRI updator (October 2019) Documentation This updator consumes SIRI Real Time Information. It is developed by entur and support the Nordic Profile for SIRI. It should be possible to develop it further to support a broader set of the SIRI specification. For more documentation goto the Entur Real-Time Data documentation and the Norwegian SIRI profile . Configuration To enable the SIRI updator you need to add it to the updators section of the router-config.json . { \"type\": \"siri-updater\", \"frequencySec\": 60, \"url\": \"https://api.updater.com/example-updater\" }","title":"SIRI Updater"},{"location":"sandbox/SiriUpdator/#siri-updator","text":"Support for consuming SIRI ET, SX and ET messages. The updator is developed to support the Norwegian SIRI profile witch is a subset of the SIRI specification.","title":"Siri Updator"},{"location":"sandbox/SiriUpdator/#contact-info","text":"Lasse Tyrihjell, Entur, Norway","title":"Contact Info"},{"location":"sandbox/SiriUpdator/#changelog","text":"Initial version of SIRI updator (October 2019)","title":"Changelog"},{"location":"sandbox/SiriUpdator/#documentation","text":"This updator consumes SIRI Real Time Information. It is developed by entur and support the Nordic Profile for SIRI. It should be possible to develop it further to support a broader set of the SIRI specification. For more documentation goto the Entur Real-Time Data documentation and the Norwegian SIRI profile .","title":"Documentation"},{"location":"sandbox/SiriUpdator/#configuration","text":"To enable the SIRI updator you need to add it to the updators section of the router-config.json . { \"type\": \"siri-updater\", \"frequencySec\": 60, \"url\": \"https://api.updater.com/example-updater\" }","title":"Configuration"},{"location":"sandbox/TransmodelApi/","text":"Transmodel GraphQL API Contact Info Entur, Norway Changelog Initial version of Transmodel Graph QL API (September 2019) Added support for multimodal StopPlaces (November 2019) Documentation This is the official Entur OTP2 API. The terminology is based on the Transmodel(NeTEx) with some limitations/simplification. It provides both a routing API (trip query) and index API for transit data. Entur provide a GraphQL explorer where you may browse the GraphQL schema and try your own queries. OTP2 Official GraphQL API (Not available) We plan to make a new offical OTP2 API, replacing the REST API. The plan is to base the new API on this API and the Legacy GraphQL Api . The new API will most likely have 2 \"translations\": A GTFS version and a Transmodel version, we will try to keep the semantics the same. Configuration To enable this you need to add the feature SandboxAPITransmodelApi .","title":"Transmodel(NeTEx) GrpahQL API"},{"location":"sandbox/TransmodelApi/#transmodel-graphql-api","text":"","title":"Transmodel GraphQL API"},{"location":"sandbox/TransmodelApi/#contact-info","text":"Entur, Norway","title":"Contact Info"},{"location":"sandbox/TransmodelApi/#changelog","text":"Initial version of Transmodel Graph QL API (September 2019) Added support for multimodal StopPlaces (November 2019)","title":"Changelog"},{"location":"sandbox/TransmodelApi/#documentation","text":"This is the official Entur OTP2 API. The terminology is based on the Transmodel(NeTEx) with some limitations/simplification. It provides both a routing API (trip query) and index API for transit data. Entur provide a GraphQL explorer where you may browse the GraphQL schema and try your own queries.","title":"Documentation"},{"location":"sandbox/TransmodelApi/#otp2-official-graphql-api-not-available","text":"We plan to make a new offical OTP2 API, replacing the REST API. The plan is to base the new API on this API and the Legacy GraphQL Api . The new API will most likely have 2 \"translations\": A GTFS version and a Transmodel version, we will try to keep the semantics the same.","title":"OTP2 Official GraphQL API (Not available)"},{"location":"sandbox/TransmodelApi/#configuration","text":"To enable this you need to add the feature SandboxAPITransmodelApi .","title":"Configuration"},{"location":"sandbox/transferanalyzer/","text":"Direct transfer analyzer module Contact Info Gard Mellemstrand, Entur, Norway Changelog May 20th 2019 Added the direct transfer analyzer module (May 2019) Documentation Module used for analyzing the transfers between nearby stops generated by routing via OSM data. It generates lists of both unusually long and unroutable transfers. These lists can typically be used to improve the quality of OSM data for transfer purposes. See javadoc in DirectTransferAnalyzer class","title":"Direct transfer analyzer"},{"location":"sandbox/transferanalyzer/#direct-transfer-analyzer-module","text":"","title":"Direct transfer analyzer module"},{"location":"sandbox/transferanalyzer/#contact-info","text":"Gard Mellemstrand, Entur, Norway","title":"Contact Info"},{"location":"sandbox/transferanalyzer/#changelog","text":"","title":"Changelog"},{"location":"sandbox/transferanalyzer/#may-20th-2019","text":"Added the direct transfer analyzer module (May 2019)","title":"May 20th 2019"},{"location":"sandbox/transferanalyzer/#documentation","text":"Module used for analyzing the transfers between nearby stops generated by routing via OSM data. It generates lists of both unusually long and unroutable transfers. These lists can typically be used to improve the quality of OSM data for transfer purposes. See javadoc in DirectTransferAnalyzer class","title":"Documentation"}]}