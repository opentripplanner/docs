{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"OpenTripPlanner 2 OpenTripPlanner (OTP) is an open source multi-modal trip planner, focusing on travel by scheduled public transportation in combination with bicycling, walking, and mobility services including bike share and ride hailing. Its server component runs on any platform with a Java virtual machine (including Linux, Mac, and Windows). It exposes REST and GraphQL APIs that can be accessed by various clients including open source Javascript components and native mobile applications. It builds its representation of the transportation network from open data in open standard file formats (primarily GTFS and OpenStreetMap). It applies real-time updates and alerts with immediate visibility to clients, finding itineraries that account for disruptions and service changes. OTP is released under the LGPL license . As of 2020, the codebase has been in active development for over ten years, and is relied upon by transportation authorities and travel planning applications in deployments around the world. You are currently reading the documentation for OpenTripPlanner 2 , the second major version of OTP. Versions of this documentation Several versions of this documentation are built and published automatically for different branches of OTP. Each of these has a different stable URL, and you may switch between these versions using the selector in the lower right of the published documentation. Latest - Version 2.1 (the git master branch) v2.0.0 - Version 2.0 v1.5.0 - Stable 1.x release dev-2.x - OTP 2 active development dev-1.x - OTP 1 active development Audience The end users of OTP are the millions of people who rely on it to help plan their daily travel, often without even knowing they are using OTP. As an infrastructure component, installation and configuration of OTP tends to be somewhat technical and essentially invisible to those end users. This documentation is indended for people who wish to perform such deployments of OTP without necessarily diving into the internal details of the software. For members of the OTP community interested in software development, additional documentation detailing algorithms, data structures etc. is available as markdown files within the source code packages. It can be read in your IDE or when browsing the source tree on Github. See OTP Architecture . Quick Start We encourage you to read the introductory sections of this documentation to familiarize yourself with OpenTripPlanner use cases and configuration. But if you want to get started right away running your own OTP instance, the best place to start is the Basic Tutorial page. Contact Info Send questions and comments to the user mailing list . Discuss internal development details on the dev mailing list . File bug reports via the Github issue tracker . Note that the issue tracker is not intended for support questions or discussions. Please post them to one of the mailing lists instead. Financial and In-Kind Support OpenTripPlanner is a member project of Software Freedom Conservancy, a 501(c)(3) organization incorporated in New York, and donations made to it are fully tax-deductible to the extent permitted by law. Donations can be made by credit card, wire transfer or paper check. Please contact accounting@sfconservancy.org for instructions. OTP development is primarily carried out by full-time software engineers employed by transportation authorities and consultancies. Even with funding, it can be difficult to engage staff who have the specialized skill set required. Therefore, one of the best ways to support OTP is to allocate software development staff at your organization with transportation domain knowledge to participate in weekly development meetings and contribute to this effort. This also builds connections between organizations favoring open source collaboration.","title":"Home"},{"location":"#opentripplanner-2","text":"OpenTripPlanner (OTP) is an open source multi-modal trip planner, focusing on travel by scheduled public transportation in combination with bicycling, walking, and mobility services including bike share and ride hailing. Its server component runs on any platform with a Java virtual machine (including Linux, Mac, and Windows). It exposes REST and GraphQL APIs that can be accessed by various clients including open source Javascript components and native mobile applications. It builds its representation of the transportation network from open data in open standard file formats (primarily GTFS and OpenStreetMap). It applies real-time updates and alerts with immediate visibility to clients, finding itineraries that account for disruptions and service changes. OTP is released under the LGPL license . As of 2020, the codebase has been in active development for over ten years, and is relied upon by transportation authorities and travel planning applications in deployments around the world. You are currently reading the documentation for OpenTripPlanner 2 , the second major version of OTP.","title":"OpenTripPlanner 2"},{"location":"#versions-of-this-documentation","text":"Several versions of this documentation are built and published automatically for different branches of OTP. Each of these has a different stable URL, and you may switch between these versions using the selector in the lower right of the published documentation. Latest - Version 2.1 (the git master branch) v2.0.0 - Version 2.0 v1.5.0 - Stable 1.x release dev-2.x - OTP 2 active development dev-1.x - OTP 1 active development","title":"Versions of this documentation"},{"location":"#audience","text":"The end users of OTP are the millions of people who rely on it to help plan their daily travel, often without even knowing they are using OTP. As an infrastructure component, installation and configuration of OTP tends to be somewhat technical and essentially invisible to those end users. This documentation is indended for people who wish to perform such deployments of OTP without necessarily diving into the internal details of the software. For members of the OTP community interested in software development, additional documentation detailing algorithms, data structures etc. is available as markdown files within the source code packages. It can be read in your IDE or when browsing the source tree on Github. See OTP Architecture .","title":"Audience"},{"location":"#quick-start","text":"We encourage you to read the introductory sections of this documentation to familiarize yourself with OpenTripPlanner use cases and configuration. But if you want to get started right away running your own OTP instance, the best place to start is the Basic Tutorial page.","title":"Quick Start"},{"location":"#contact-info","text":"Send questions and comments to the user mailing list . Discuss internal development details on the dev mailing list . File bug reports via the Github issue tracker . Note that the issue tracker is not intended for support questions or discussions. Please post them to one of the mailing lists instead.","title":"Contact Info"},{"location":"#financial-and-in-kind-support","text":"OpenTripPlanner is a member project of Software Freedom Conservancy, a 501(c)(3) organization incorporated in New York, and donations made to it are fully tax-deductible to the extent permitted by law. Donations can be made by credit card, wire transfer or paper check. Please contact accounting@sfconservancy.org for instructions. OTP development is primarily carried out by full-time software engineers employed by transportation authorities and consultancies. Even with funding, it can be difficult to engage staff who have the specialized skill set required. Therefore, one of the best ways to support OTP is to allocate software development staff at your organization with transportation domain knowledge to participate in weekly development meetings and contribute to this effort. This also builds connections between organizations favoring open source collaboration.","title":"Financial and In-Kind Support"},{"location":"Basic-Tutorial/","text":"OpenTripPlanner Basic Tutorial This page should allow you to set up and test your own OTP2 server. If all goes well it should only take a few minutes! Get Java As a Java program, OTP must be run within a Java virtual machine (JVM), which is provided as part of the Java runtime (JRE) or Java development kit (JDK). OTP2 is compatible with Java 11 or later. We recommend running on Java 11 rather than a later version, as it is a long-term support release. Run java -version to check that you have version 11 or newer of the JVM installed. If you do not, you will need to install a recent OpenJDK or Oracle Java package for your operating system. Get OTP OpenTripPlanner is written in Java and distributed as a single runnable JAR file. This is a \"shaded\" JAR containing all other libraries needed for OTP to work, and is available from the Maven Central repository. You will be able to go to the OTP directory at Maven Central , navigate to the directory for the 2.1 release , and download the file whose name ends with shaded.jar . You may also want to get your own copy of the OTP source code and build a bleeding edge development JAR from scratch , especially if you plan to do some development yourself. In that case, check out the branch dev-2.x . Get some data GTFS for Transit Schedules and Stops First you'll need GTFS data to build a transit network. There's an excellent description of the GTFS format here . Transport agencies throughout the world provide GTFS schedules to the public. Transitland has a registry of feeds and TransitFeeds also provides an extensive catalog. The best option is often to simply fetch the data directly from a transit operator or agency. If you know of a feed you want to work with, download it and put it in an empty directory you have created for your OTP instance such as /home/username/otp on Linux, /Users/username/otp on MacOS, or C:\\Users\\username\\otp on Windows. For OTP2 to detect a GTFS file, its name must end in .zip and must contain the letters 'gtfs' . We often use the convention of saving GTFS files with names ending in .gtfs.zip which meets both these criteria, reflecting the fact that a GTFS feed is just a ZIP file containing a specific set of files. If you don't have a particular feed in mind, the one for Portland, Oregon's TriMet agency is a good option. It is available at this URL . This is a moderate-sized input of good quality (TriMet initiated OTP development and helped develop the GTFS format). On Linux, this could be done on the command line as follows: $ cd /home/username $ mkdir otp $ cd otp $ wget \"http://developer.trimet.org/schedule/gtfs.zip\" -O trimet.gtfs.zip OSM for Streets You'll also need OpenStreetMap data to build a road network for walking, cycling, and driving. OpenStreetMap is a global collaborative map database that rivals or surpasses the quality of commercial maps in many locations. Several services extract smaller geographic regions from this database. Interline Technologies maintains a collection of extracts updated daily for urban areas around the world . Geofabrik provides extracts for larger areas like countries or states, from which you can prepare your own smaller bounding-box extracts using Osmosis , osmconvert , or (our favorite) Osmium-Tool . OSM data can be delivered as XML or in the more compact binary PBF format. OpenTripPlanner consumes only PBF because it's smaller and more efficient. Download OSM PBF data for the same geographic region as your GTFS feed, and place this PBF file in the same directory you created for the OSM data. If you are using the TriMet GTFS feed, you could download the Geofabrik extract for the US state of Oregon , then further trim that to just the TriMet service area using the bounding box switch of one of the above tools. On Linux or MacOS you could do that as follows: $ cd /home/username $ wget http://download.geofabrik.de/north-america/us/oregon-latest.osm.pbf $ osmconvert oregon-latest.osm.pbf -b=-123.043,45.246,-122.276,45.652 --complete-ways -o=portland.pbf $ mv portland.pbf otp We find this tool useful for determining the geographic coordinates of bounding boxes. The CSV option in that tool produces exactly the format expected by the osmconvert -b switch. The --complete-ways switch is important to handle roads that cross outside your bounding box. If you have extracted a smaller PBF file from a larger region, be sure to put only your extract (not the original larger file) in the directory with your GTFS data. Otherwise OTP will try to load both the original file and the extract in a later step. See the page on preparing OSM data for additional information and example commands for cropping and filtering OSM data. Starting OTP A typical command to start OTP looks like java -Xmx2G -jar otp.shaded.jar <options> . The -Xmx parameter sets the limit on how much memory OTP is allowed to consume. GTFS and OSM data sets are often very large, and OTP is relatively memory-hungry. You will need at least 1GB of memory when working with the Portland TriMet data set, and several gigabytes for larger inputs. If you have sufficient memory in your computer, set this to a couple of gigabytes (e.g. -Xmx2G ). Java uses a garbage collection approach to memory management, which requires some \"breathing room\" to efficiently operate. Without sufficient free memory OTP can grind to a halt. VisualVM is a good way to inspect Java memory usage, especially with the VisualGC plugin . Java 11 has tighter security restrictions than previous versions, so when running OTP under Java 11 you will see warnings like this: WARNING: An illegal reflective access operation has occurred WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil These warnings are expected to remain for a while, until all libraries OTP2 depends on have fully migrated to Java 11 and we have upgraded them all. Building Graphs There are two main phases to preparing and deploying an OTP server. The first is to analyze the GTFS, OSM and any other inputs (such as elevation data) and build a representation of the transportation network. Following mathematical terminology we call this a 'graph' , and refer to this phase as \"graph building\". The second phase is to start a server that provides trip planning and other API services for this graph. It is possible to save the graph to a file on disk after the first phase, then load the graph from the file in the second phase. This allows restarting the server or starting multiple instances of the server without repeating the often time-consuming process of building the graph. It is also possible to split the graph building process into separate OSM and GTFS stages for similar reasons: to allow reusing results from slow processes, such as applying elevation data to streets. These different options are controlled with command line switches, and will be described in more detail below and in other tutorials. Simple One-step Server The simplest way to use OTP is to build a graph in a single step and start a server immediately, without saving it to disk. The command to do so is: $ java -Xmx2G -jar otp-2.1.0-shaded.jar --build --serve /home/username/otp where /home/username/otp should be the directory where you put your configuration and input files. If you're using the Portland input data, the graph build operation should take about one minute to complete, and then you'll see a Grizzly server running message. At this point you have an OpenTripPlanner server running locally and can open http://localhost:8080/ in a web browser. You should be presented with a Javascript client application that will interact with your local OpenTripPlanner instance. This map-based user interface is in fact sending HTTP GET requests to the OTP server running on your local machine. It can be informative to watch the HTTP requests and responses being generated using the developer tools in your web browser. OTP's built-in web server will run by default on ports 8080 and 8081 for HTTP and HTTPS respectively. If by any chance some other software is already using one or both of those port numbers, you can specify different port numbers with switches like --port 8801 --securePort 8802 . Saving a Graph If you want speed up the process of repeatedly starting up a server with the same graph, you can build a graph from street and transit data then save it to a file using the --build and --save command line parameters together. If for example your current working directory ( . ) contains the input files and the OTP JAR file, you can use this command: $ java -Xmx2G -jar otp-2.1.0-shaded.jar --build --save . This will produce a file called graph.obj in the same directory as the inputs. The server can then be started later using the --load parameter, and will read this file instead of building the graph from scratch: $ java -Xmx2G -jar otp-2.1.0-shaded.jar --load . Another reason to perform these two phases separately is that the building process loads the entire GTFS and OSM data sets into memory, so can require significantly more memory than just running a server. Accordingly, you may want to perform the build on one machine (e.g. a throw-away cloud instance with more memory or compute capacity), then copy the resulting graph file to one or more smaller machines to serve the API. Layering GTFS onto OSM Building the street graph (especially with elevation data) can take a long time. It is common for transit data to change more frequently than street data, so it can be convenient to build the street graph once, and then layer transit data on top of the streets to make the final graph. Again assuming the input files and OTP JAR file are in the current working directory, you can build a street graph with OSM and elevation data only (ignoring transit input files) with this command: $ java -Xmx2G -jar otp-2.1.0-shaded.jar --buildStreet . Then, to build a graph layering transit data on top of the saved street graph (built using the previous command): $ java -Xmx2G -jar otp-2.1.0-shaded.jar --loadStreet --save . Finally, the server can be started using the --load parameter: $ java -Xmx2G -jar otp-2.1.0-shaded.jar --load . Command Line Switches The flow diagram below summarizes all the command line switches used in the above examples, and how they control which actions are taken when OTP starts up. You must use at least one of the required parameters: --load , --loadStreet , --build , --buildStreet . A required parameter may imply other parameters when the flow allows for no other choice. For example, --load implies --serve , so --serve is not necessary and has no additional effect when used together with --load . You can run the OTP .jar file with the --help option for a full list of command line parameters.","title":"Basic Tutorial"},{"location":"Basic-Tutorial/#opentripplanner-basic-tutorial","text":"This page should allow you to set up and test your own OTP2 server. If all goes well it should only take a few minutes!","title":"OpenTripPlanner Basic Tutorial"},{"location":"Basic-Tutorial/#get-java","text":"As a Java program, OTP must be run within a Java virtual machine (JVM), which is provided as part of the Java runtime (JRE) or Java development kit (JDK). OTP2 is compatible with Java 11 or later. We recommend running on Java 11 rather than a later version, as it is a long-term support release. Run java -version to check that you have version 11 or newer of the JVM installed. If you do not, you will need to install a recent OpenJDK or Oracle Java package for your operating system.","title":"Get Java"},{"location":"Basic-Tutorial/#get-otp","text":"OpenTripPlanner is written in Java and distributed as a single runnable JAR file. This is a \"shaded\" JAR containing all other libraries needed for OTP to work, and is available from the Maven Central repository. You will be able to go to the OTP directory at Maven Central , navigate to the directory for the 2.1 release , and download the file whose name ends with shaded.jar . You may also want to get your own copy of the OTP source code and build a bleeding edge development JAR from scratch , especially if you plan to do some development yourself. In that case, check out the branch dev-2.x .","title":"Get OTP"},{"location":"Basic-Tutorial/#get-some-data","text":"","title":"Get some data"},{"location":"Basic-Tutorial/#gtfs-for-transit-schedules-and-stops","text":"First you'll need GTFS data to build a transit network. There's an excellent description of the GTFS format here . Transport agencies throughout the world provide GTFS schedules to the public. Transitland has a registry of feeds and TransitFeeds also provides an extensive catalog. The best option is often to simply fetch the data directly from a transit operator or agency. If you know of a feed you want to work with, download it and put it in an empty directory you have created for your OTP instance such as /home/username/otp on Linux, /Users/username/otp on MacOS, or C:\\Users\\username\\otp on Windows. For OTP2 to detect a GTFS file, its name must end in .zip and must contain the letters 'gtfs' . We often use the convention of saving GTFS files with names ending in .gtfs.zip which meets both these criteria, reflecting the fact that a GTFS feed is just a ZIP file containing a specific set of files. If you don't have a particular feed in mind, the one for Portland, Oregon's TriMet agency is a good option. It is available at this URL . This is a moderate-sized input of good quality (TriMet initiated OTP development and helped develop the GTFS format). On Linux, this could be done on the command line as follows: $ cd /home/username $ mkdir otp $ cd otp $ wget \"http://developer.trimet.org/schedule/gtfs.zip\" -O trimet.gtfs.zip","title":"GTFS for Transit Schedules and Stops"},{"location":"Basic-Tutorial/#osm-for-streets","text":"You'll also need OpenStreetMap data to build a road network for walking, cycling, and driving. OpenStreetMap is a global collaborative map database that rivals or surpasses the quality of commercial maps in many locations. Several services extract smaller geographic regions from this database. Interline Technologies maintains a collection of extracts updated daily for urban areas around the world . Geofabrik provides extracts for larger areas like countries or states, from which you can prepare your own smaller bounding-box extracts using Osmosis , osmconvert , or (our favorite) Osmium-Tool . OSM data can be delivered as XML or in the more compact binary PBF format. OpenTripPlanner consumes only PBF because it's smaller and more efficient. Download OSM PBF data for the same geographic region as your GTFS feed, and place this PBF file in the same directory you created for the OSM data. If you are using the TriMet GTFS feed, you could download the Geofabrik extract for the US state of Oregon , then further trim that to just the TriMet service area using the bounding box switch of one of the above tools. On Linux or MacOS you could do that as follows: $ cd /home/username $ wget http://download.geofabrik.de/north-america/us/oregon-latest.osm.pbf $ osmconvert oregon-latest.osm.pbf -b=-123.043,45.246,-122.276,45.652 --complete-ways -o=portland.pbf $ mv portland.pbf otp We find this tool useful for determining the geographic coordinates of bounding boxes. The CSV option in that tool produces exactly the format expected by the osmconvert -b switch. The --complete-ways switch is important to handle roads that cross outside your bounding box. If you have extracted a smaller PBF file from a larger region, be sure to put only your extract (not the original larger file) in the directory with your GTFS data. Otherwise OTP will try to load both the original file and the extract in a later step. See the page on preparing OSM data for additional information and example commands for cropping and filtering OSM data.","title":"OSM for Streets"},{"location":"Basic-Tutorial/#starting-otp","text":"A typical command to start OTP looks like java -Xmx2G -jar otp.shaded.jar <options> . The -Xmx parameter sets the limit on how much memory OTP is allowed to consume. GTFS and OSM data sets are often very large, and OTP is relatively memory-hungry. You will need at least 1GB of memory when working with the Portland TriMet data set, and several gigabytes for larger inputs. If you have sufficient memory in your computer, set this to a couple of gigabytes (e.g. -Xmx2G ). Java uses a garbage collection approach to memory management, which requires some \"breathing room\" to efficiently operate. Without sufficient free memory OTP can grind to a halt. VisualVM is a good way to inspect Java memory usage, especially with the VisualGC plugin . Java 11 has tighter security restrictions than previous versions, so when running OTP under Java 11 you will see warnings like this: WARNING: An illegal reflective access operation has occurred WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil These warnings are expected to remain for a while, until all libraries OTP2 depends on have fully migrated to Java 11 and we have upgraded them all.","title":"Starting OTP"},{"location":"Basic-Tutorial/#building-graphs","text":"There are two main phases to preparing and deploying an OTP server. The first is to analyze the GTFS, OSM and any other inputs (such as elevation data) and build a representation of the transportation network. Following mathematical terminology we call this a 'graph' , and refer to this phase as \"graph building\". The second phase is to start a server that provides trip planning and other API services for this graph. It is possible to save the graph to a file on disk after the first phase, then load the graph from the file in the second phase. This allows restarting the server or starting multiple instances of the server without repeating the often time-consuming process of building the graph. It is also possible to split the graph building process into separate OSM and GTFS stages for similar reasons: to allow reusing results from slow processes, such as applying elevation data to streets. These different options are controlled with command line switches, and will be described in more detail below and in other tutorials.","title":"Building Graphs"},{"location":"Basic-Tutorial/#simple-one-step-server","text":"The simplest way to use OTP is to build a graph in a single step and start a server immediately, without saving it to disk. The command to do so is: $ java -Xmx2G -jar otp-2.1.0-shaded.jar --build --serve /home/username/otp where /home/username/otp should be the directory where you put your configuration and input files. If you're using the Portland input data, the graph build operation should take about one minute to complete, and then you'll see a Grizzly server running message. At this point you have an OpenTripPlanner server running locally and can open http://localhost:8080/ in a web browser. You should be presented with a Javascript client application that will interact with your local OpenTripPlanner instance. This map-based user interface is in fact sending HTTP GET requests to the OTP server running on your local machine. It can be informative to watch the HTTP requests and responses being generated using the developer tools in your web browser. OTP's built-in web server will run by default on ports 8080 and 8081 for HTTP and HTTPS respectively. If by any chance some other software is already using one or both of those port numbers, you can specify different port numbers with switches like --port 8801 --securePort 8802 .","title":"Simple One-step Server"},{"location":"Basic-Tutorial/#saving-a-graph","text":"If you want speed up the process of repeatedly starting up a server with the same graph, you can build a graph from street and transit data then save it to a file using the --build and --save command line parameters together. If for example your current working directory ( . ) contains the input files and the OTP JAR file, you can use this command: $ java -Xmx2G -jar otp-2.1.0-shaded.jar --build --save . This will produce a file called graph.obj in the same directory as the inputs. The server can then be started later using the --load parameter, and will read this file instead of building the graph from scratch: $ java -Xmx2G -jar otp-2.1.0-shaded.jar --load . Another reason to perform these two phases separately is that the building process loads the entire GTFS and OSM data sets into memory, so can require significantly more memory than just running a server. Accordingly, you may want to perform the build on one machine (e.g. a throw-away cloud instance with more memory or compute capacity), then copy the resulting graph file to one or more smaller machines to serve the API.","title":"Saving a Graph"},{"location":"Basic-Tutorial/#layering-gtfs-onto-osm","text":"Building the street graph (especially with elevation data) can take a long time. It is common for transit data to change more frequently than street data, so it can be convenient to build the street graph once, and then layer transit data on top of the streets to make the final graph. Again assuming the input files and OTP JAR file are in the current working directory, you can build a street graph with OSM and elevation data only (ignoring transit input files) with this command: $ java -Xmx2G -jar otp-2.1.0-shaded.jar --buildStreet . Then, to build a graph layering transit data on top of the saved street graph (built using the previous command): $ java -Xmx2G -jar otp-2.1.0-shaded.jar --loadStreet --save . Finally, the server can be started using the --load parameter: $ java -Xmx2G -jar otp-2.1.0-shaded.jar --load .","title":"Layering GTFS onto OSM"},{"location":"Basic-Tutorial/#command-line-switches","text":"The flow diagram below summarizes all the command line switches used in the above examples, and how they control which actions are taken when OTP starts up. You must use at least one of the required parameters: --load , --loadStreet , --build , --buildStreet . A required parameter may imply other parameters when the flow allows for no other choice. For example, --load implies --serve , so --serve is not necessary and has no additional effect when used together with --load . You can run the OTP .jar file with the --help option for a full list of command line parameters.","title":"Command Line Switches"},{"location":"Bibliography/","text":"Routing Bibliography This is a list of articles, dissertations, and books that have inspired and informed both the existing OTP routing engine and some ongoing experiments. OTP1 uses a single time-dependent (as opposed to time-expanded) graph that contains both street and transit networks. Walk-only and bicycle-only trips are generally planned using the A-star algorithm with a Euclidean heuristic. Walk+Transit or Bike+Transit trips are planned using A-star with the Tung-Chew heuristic (i.e. a graph grown backward from the destination providing a lower bound on aggregate weight) for queue ordering. For speed reasons we are performing single-variable generalized cost optimization, which is not ideal. We should be performing Pareto optimization on at least two variables (generalized cost and time). OTP2 splits the search into three segments: access from the origin to transit stops, egress from transit stops to the destination, and transit service connecting the two. For the transit segment, OTP2 uses the Multi-criteria Range Raptor algorithm. For the access and egress searches it uses the same approach as OTP1. Both splitting the search into three parts and use of a table-scanning algorithm like Raptor improve OTP2's performance significantly while increasing result quality by producing true Pareto-optimal sets of results. Algorithms used in OTP2 but not OTP1 Delling, Pajor, Werneck. Round-Based Public Transit Routing (2012) This is a tabular approach to routing in public transit networks that does not use an (explicit) graph. It is simpler and can outperform classic graph algorithms. http://research.microsoft.com/pubs/156567/raptor_alenex.pdf Delling, Dibbelt, and Pajor. Fast and Exact Public Transit Routing with Restricted Pareto Sets (2019) Describes the heuristic used in OTP2 to eliminate options early when they are known to become non-optimal before they reach the destination. https://epubs.siam.org/doi/pdf/10.1137/1.9781611975499.5 Techniques used in or influencing OTP1 and OTP2 General Background Bast, Hannah. Car or public transport -- two worlds. (2009) Explains how car routing is different from schedule-based public transport routing. http://www.mpi-inf.mpg.de/~bast/papers/car_or_public_transport.pdf Delling, Daniel. Engineering and augmenting route planning algorithms. (2009, dissertation) Overview, including time-dependent and Pareto shortest paths. http://i11www.ira.uka.de/extra/publications/d-earpa-09.pdf Delling, Sanders, Schultes, and Wagner. Engineering Route-Planning Algorithms. (2009) Overview. http://i11www.ira.uka.de/extra/publications/dssw-erpa-09.pdf Path Search Speedup Techniques Delling and Wagner. Time-Dependent Route Planning. (2009) Overview. http://i11www.iti.uni-karlsruhe.de/extra/publications/dw-tdrp-09.pdf Delling and Wagner. Landmark-Based Routing in Dynamic Graphs. (2008) http://i11www.ira.uka.de/extra/publications/dw-lbrdg-07.pdf Bauer, Delling, Sanders, Schultes, and Wagner. Combining Hierarchical and Goal-Directed Speed-Up Techniques for Dijkstra\u2019s Algorithm. (2008) http://algo2.iti.kit.edu/download/bdsssw-chgds-10.pdf Bauer and Delling. SHARC: Fast and Robust Unidirectional Routing. (2009) SH ortcuts + ARC flags. Can be combined with ALT. http://www.siam.org/proceedings/alenex/2008/alx08_02bauerr.pdf Delling, Daniel. Time-Dependent SHARC-Routing. (2008) http://i11www.iti.uni-karlsruhe.de/extra/publications/d-tdsr-09.pdf Goldberg, Kaplan, and Werneck. Reach for A\u2217: Efficient Point-to-Point Shortest Path Algorithms. (2005) http://avglab.com/andrew/pub/msr-tr-2005-132.pdf Multi-objective Pareto Shortest Paths Das and Dennis. Drawbacks of minimizing weighted sums of objectives for Pareto set generation in multicriteria optimization problems. (1997) M\u00fcller-Hannemann and Schnee. Finding All Attractive Train Connections by Multi-criteria Pareto Search. (2007) Deutsche Bahn information system. Does not account for on-street travel. Mandow & P\u00e9rez de la Cruz. A New Approach to Multiobjective A Search. (2005) NAMOA http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.8780&rep=rep1&type=pdf Mandow & P\u00e9rez de la Cruz. Multiobjective A search with consistent heuristics. (2008) NAMOA Machuca, Mandow and P\u00e9rez de la Cruz. Evaluation of Heuristic Functions for Bicriterion Shortest Path Problems. (2009) Evaluates heuristics from Tung & Chew (1992) versus lexicographical ordering of priority queue. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.160.4715&rep=rep1&type=pdf Perny and Spanjaard. Near Admissible Algorithms for Multiobjective Search. (2009) Discusses relaxed Pareto dominance (Epsilon-dominance) and its use in Multi-objective A*. This a scheme for approximating the entire pareto-optimal solution set that allows time and space complexity polynomial in the number of nodes. http://www-desir.lip6.fr/publications/pub_1052_1_ECAI08.pdf Tung and Chew. A multicriteria Pareto-optimal path algorithm. (1992) Delling and Wagner. Pareto Paths with SHARC. (2009) http://i11www.iti.uni-karlsruhe.de/extra/publications/dw-pps-09.pdf Resource-constrained Routing Dumitrescu & Boland. Improved Preprocessing, Labeling and Scaling Algorithms for the Weight-Constrained Shortest Path Problem. (2003) Comparison of scaling and label-setting methods. Ziegelmann, Mark. Constrained Shortest Paths and Related Problems. (2001, dissertation) http://scidok.sulb.uni-saarland.de/volltexte/2004/251/pdf/MarkZiegelmann_ProfDrKurtMehlhorn.pdf Contraction and Transfer Patterns Geisberger, Robert. Contraction Hierarchies: Faster and Simpler Hierarchical Routing in Road Networks. (2008, dissertation) http://algo2.iti.kit.edu/documents/routeplanning/geisberger_dipl.pdf Geisberger, Robert. Contraction of Timetable Networks with Realistic Tranfers (2010) Introduces the \"Station Model Graph\". http://algo2.iti.kit.edu/download/time_table_ch.pdf Bast, Carlsson, Eigenwillig, Geisberger Harrelson, Raychev, and Viger. Fast Routing in Very Large Public Transportation Networks Using Transfer Patterns. (2010) http://ad.informatik.uni-freiburg.de/files/transferpatterns.pdf/at_download/file Timetable-based routing Schulz, Frank. Timetable Information and Shortest Paths. (2005, dissertation) Excellent reference. http://d-nb.info/1001586921/34 ALT and Metric Embeddings Goldberg and Werneck. Computing Point-to-Point Shortest Paths from External Memory. (2005) Introduced the ALT algorithm. http://www.cs.princeton.edu/courses/archive/spring06/cos423/Handouts/GW05.pdf Linial, London, and Rabinovich. The Geometry of Graphs and Some of its Algorithmic Applications. (1995) http://pdf.aminer.org/000/798/423/the_geometry_of_graphs_and_some_of_its_algorithmic_applications.pdf Hjaltason and Samet. Contractive Embedding Methods for Similarity Searching in Metric Spaces. (2000) http://www.cs.umd.edu/~hjs/pubs/metricpruning.pdf Potamias, Bonchi, Castillo, and Gionis. Fast Shortest Path Distance Estimation in Large Networks. (2009) Briefly discusses the connection between landmark routing and more general research on metric embeddings. http://dcommon.bu.edu/xmlui/bitstream/handle/2144/1727/2009-004-shortest-distance-estimation.pdf Calibration and Implementation Details Wardman, Mark. Public Transport Values of Time. (2004) http://eprints.whiterose.ac.uk/2062/1/ITS37_WP564_uploadable.pdf A.M. El-Geneidy, K.J. Krizek, M.J. Iacono. Predicting bicycle travel speeds along different facilities using GPS data: a proof of concept model. (2007) Proceedings of the 86th Annual Meeting of the Transportation Research Board, Compendium of Papers, TRB, Washington, D.C., USA (CD-ROM) Chen, Chowdhury, Roche, Ramachandran, Tong. Priority Queues and Dijkstra\u2019s Algorithm. Summary: Despite better theoretical complexity for Fibonacci heaps, it is often as good or better to use a binary heap as a priority queue when doing path searches. http://www.cs.utexas.edu/users/shaikat/papers/TR-07-54.pdf Post-Dijkstra Public Transit Routing Dibbelt, Pajor, Strasser, Wagner. Intriguingly Simple and Fast Transit Routing (2013). Introduces the Connection Scan Algorithm (CSA). http://www.ecompass-project.eu/sites/default/files/ECOMPASS-TR-021.pdf Delling, Katz, and Pajor. Parallel computation of best connections in public transportation networks (2012). \"In this work, we present a novel algorithm for the one-to-all profile-search problem in public transportation networks. It answers the question for all fastest connections between a given station S and any other station at any time of the day in a single query... two interesting questions arise for time-dependent route planning: compute the best connection for a given departure time and the computation of all best connections during a given time interval (e. g., a whole day). The former is called a time-query, while the latter is called a pro\ufb01le-query.\" http://www.ecompass-project.eu/sites/default/files/ECOMPASS-TR-021.pdf","title":"Bibliography"},{"location":"Bibliography/#routing-bibliography","text":"This is a list of articles, dissertations, and books that have inspired and informed both the existing OTP routing engine and some ongoing experiments. OTP1 uses a single time-dependent (as opposed to time-expanded) graph that contains both street and transit networks. Walk-only and bicycle-only trips are generally planned using the A-star algorithm with a Euclidean heuristic. Walk+Transit or Bike+Transit trips are planned using A-star with the Tung-Chew heuristic (i.e. a graph grown backward from the destination providing a lower bound on aggregate weight) for queue ordering. For speed reasons we are performing single-variable generalized cost optimization, which is not ideal. We should be performing Pareto optimization on at least two variables (generalized cost and time). OTP2 splits the search into three segments: access from the origin to transit stops, egress from transit stops to the destination, and transit service connecting the two. For the transit segment, OTP2 uses the Multi-criteria Range Raptor algorithm. For the access and egress searches it uses the same approach as OTP1. Both splitting the search into three parts and use of a table-scanning algorithm like Raptor improve OTP2's performance significantly while increasing result quality by producing true Pareto-optimal sets of results.","title":"Routing Bibliography"},{"location":"Bibliography/#algorithms-used-in-otp2-but-not-otp1","text":"Delling, Pajor, Werneck. Round-Based Public Transit Routing (2012) This is a tabular approach to routing in public transit networks that does not use an (explicit) graph. It is simpler and can outperform classic graph algorithms. http://research.microsoft.com/pubs/156567/raptor_alenex.pdf Delling, Dibbelt, and Pajor. Fast and Exact Public Transit Routing with Restricted Pareto Sets (2019) Describes the heuristic used in OTP2 to eliminate options early when they are known to become non-optimal before they reach the destination. https://epubs.siam.org/doi/pdf/10.1137/1.9781611975499.5","title":"Algorithms used in OTP2 but not OTP1"},{"location":"Bibliography/#techniques-used-in-or-influencing-otp1-and-otp2","text":"","title":"Techniques used in or influencing OTP1 and OTP2"},{"location":"Bibliography/#general-background","text":"Bast, Hannah. Car or public transport -- two worlds. (2009) Explains how car routing is different from schedule-based public transport routing. http://www.mpi-inf.mpg.de/~bast/papers/car_or_public_transport.pdf Delling, Daniel. Engineering and augmenting route planning algorithms. (2009, dissertation) Overview, including time-dependent and Pareto shortest paths. http://i11www.ira.uka.de/extra/publications/d-earpa-09.pdf Delling, Sanders, Schultes, and Wagner. Engineering Route-Planning Algorithms. (2009) Overview. http://i11www.ira.uka.de/extra/publications/dssw-erpa-09.pdf","title":"General Background"},{"location":"Bibliography/#path-search-speedup-techniques","text":"Delling and Wagner. Time-Dependent Route Planning. (2009) Overview. http://i11www.iti.uni-karlsruhe.de/extra/publications/dw-tdrp-09.pdf Delling and Wagner. Landmark-Based Routing in Dynamic Graphs. (2008) http://i11www.ira.uka.de/extra/publications/dw-lbrdg-07.pdf Bauer, Delling, Sanders, Schultes, and Wagner. Combining Hierarchical and Goal-Directed Speed-Up Techniques for Dijkstra\u2019s Algorithm. (2008) http://algo2.iti.kit.edu/download/bdsssw-chgds-10.pdf Bauer and Delling. SHARC: Fast and Robust Unidirectional Routing. (2009) SH ortcuts + ARC flags. Can be combined with ALT. http://www.siam.org/proceedings/alenex/2008/alx08_02bauerr.pdf Delling, Daniel. Time-Dependent SHARC-Routing. (2008) http://i11www.iti.uni-karlsruhe.de/extra/publications/d-tdsr-09.pdf Goldberg, Kaplan, and Werneck. Reach for A\u2217: Efficient Point-to-Point Shortest Path Algorithms. (2005) http://avglab.com/andrew/pub/msr-tr-2005-132.pdf","title":"Path Search Speedup Techniques"},{"location":"Bibliography/#multi-objective-pareto-shortest-paths","text":"Das and Dennis. Drawbacks of minimizing weighted sums of objectives for Pareto set generation in multicriteria optimization problems. (1997) M\u00fcller-Hannemann and Schnee. Finding All Attractive Train Connections by Multi-criteria Pareto Search. (2007) Deutsche Bahn information system. Does not account for on-street travel. Mandow & P\u00e9rez de la Cruz. A New Approach to Multiobjective A Search. (2005) NAMOA http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.8780&rep=rep1&type=pdf Mandow & P\u00e9rez de la Cruz. Multiobjective A search with consistent heuristics. (2008) NAMOA Machuca, Mandow and P\u00e9rez de la Cruz. Evaluation of Heuristic Functions for Bicriterion Shortest Path Problems. (2009) Evaluates heuristics from Tung & Chew (1992) versus lexicographical ordering of priority queue. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.160.4715&rep=rep1&type=pdf Perny and Spanjaard. Near Admissible Algorithms for Multiobjective Search. (2009) Discusses relaxed Pareto dominance (Epsilon-dominance) and its use in Multi-objective A*. This a scheme for approximating the entire pareto-optimal solution set that allows time and space complexity polynomial in the number of nodes. http://www-desir.lip6.fr/publications/pub_1052_1_ECAI08.pdf Tung and Chew. A multicriteria Pareto-optimal path algorithm. (1992) Delling and Wagner. Pareto Paths with SHARC. (2009) http://i11www.iti.uni-karlsruhe.de/extra/publications/dw-pps-09.pdf","title":"Multi-objective Pareto Shortest Paths"},{"location":"Bibliography/#resource-constrained-routing","text":"Dumitrescu & Boland. Improved Preprocessing, Labeling and Scaling Algorithms for the Weight-Constrained Shortest Path Problem. (2003) Comparison of scaling and label-setting methods. Ziegelmann, Mark. Constrained Shortest Paths and Related Problems. (2001, dissertation) http://scidok.sulb.uni-saarland.de/volltexte/2004/251/pdf/MarkZiegelmann_ProfDrKurtMehlhorn.pdf","title":"Resource-constrained Routing"},{"location":"Bibliography/#contraction-and-transfer-patterns","text":"Geisberger, Robert. Contraction Hierarchies: Faster and Simpler Hierarchical Routing in Road Networks. (2008, dissertation) http://algo2.iti.kit.edu/documents/routeplanning/geisberger_dipl.pdf Geisberger, Robert. Contraction of Timetable Networks with Realistic Tranfers (2010) Introduces the \"Station Model Graph\". http://algo2.iti.kit.edu/download/time_table_ch.pdf Bast, Carlsson, Eigenwillig, Geisberger Harrelson, Raychev, and Viger. Fast Routing in Very Large Public Transportation Networks Using Transfer Patterns. (2010) http://ad.informatik.uni-freiburg.de/files/transferpatterns.pdf/at_download/file","title":"Contraction and Transfer Patterns"},{"location":"Bibliography/#timetable-based-routing","text":"Schulz, Frank. Timetable Information and Shortest Paths. (2005, dissertation) Excellent reference. http://d-nb.info/1001586921/34","title":"Timetable-based routing"},{"location":"Bibliography/#alt-and-metric-embeddings","text":"Goldberg and Werneck. Computing Point-to-Point Shortest Paths from External Memory. (2005) Introduced the ALT algorithm. http://www.cs.princeton.edu/courses/archive/spring06/cos423/Handouts/GW05.pdf Linial, London, and Rabinovich. The Geometry of Graphs and Some of its Algorithmic Applications. (1995) http://pdf.aminer.org/000/798/423/the_geometry_of_graphs_and_some_of_its_algorithmic_applications.pdf Hjaltason and Samet. Contractive Embedding Methods for Similarity Searching in Metric Spaces. (2000) http://www.cs.umd.edu/~hjs/pubs/metricpruning.pdf Potamias, Bonchi, Castillo, and Gionis. Fast Shortest Path Distance Estimation in Large Networks. (2009) Briefly discusses the connection between landmark routing and more general research on metric embeddings. http://dcommon.bu.edu/xmlui/bitstream/handle/2144/1727/2009-004-shortest-distance-estimation.pdf","title":"ALT and Metric Embeddings"},{"location":"Bibliography/#calibration-and-implementation-details","text":"Wardman, Mark. Public Transport Values of Time. (2004) http://eprints.whiterose.ac.uk/2062/1/ITS37_WP564_uploadable.pdf A.M. El-Geneidy, K.J. Krizek, M.J. Iacono. Predicting bicycle travel speeds along different facilities using GPS data: a proof of concept model. (2007) Proceedings of the 86th Annual Meeting of the Transportation Research Board, Compendium of Papers, TRB, Washington, D.C., USA (CD-ROM) Chen, Chowdhury, Roche, Ramachandran, Tong. Priority Queues and Dijkstra\u2019s Algorithm. Summary: Despite better theoretical complexity for Fibonacci heaps, it is often as good or better to use a binary heap as a priority queue when doing path searches. http://www.cs.utexas.edu/users/shaikat/papers/TR-07-54.pdf","title":"Calibration and Implementation Details"},{"location":"Bibliography/#post-dijkstra-public-transit-routing","text":"Dibbelt, Pajor, Strasser, Wagner. Intriguingly Simple and Fast Transit Routing (2013). Introduces the Connection Scan Algorithm (CSA). http://www.ecompass-project.eu/sites/default/files/ECOMPASS-TR-021.pdf Delling, Katz, and Pajor. Parallel computation of best connections in public transportation networks (2012). \"In this work, we present a novel algorithm for the one-to-all profile-search problem in public transportation networks. It answers the question for all fastest connections between a given station S and any other station at any time of the day in a single query... two interesting questions arise for time-dependent route planning: compute the best connection for a given departure time and the computation of all best connections during a given time interval (e. g., a whole day). The former is called a time-query, while the latter is called a pro\ufb01le-query.\" http://www.ecompass-project.eu/sites/default/files/ECOMPASS-TR-021.pdf","title":"Post-Dijkstra Public Transit Routing"},{"location":"BuildConfiguration/","text":"Graph Build Configuration This table lists all the JSON properties that can be defined in a build-config.json file. These will be stored in the graph itself, and affect any server that subsequently loads that graph. Sections follow that describe particular settings in more depth. config key description value type value default notes areaVisibility Perform visibility calculations. If this is true OTP attempts to calculate a path straight through an OSM area using the shortest way rather than around the edge of it. (These calculations can be time consuming). boolean false banDiscouragedWalking should walking should be allowed on OSM ways tagged with foot=discouraged\" boolean false banDiscouragedBiking should walking should be allowed on OSM ways tagged with bicycle=discouraged\" boolean false dataImportReport Generate nice HTML report of Graph errors/warnings boolean false distanceBetweenElevationSamples TODO OTP2 double 10 elevationBucket If specified, download NED elevation tiles from the given AWS S3 bucket object null provide an object with accessKey , secretKey , and bucketName for AWS S3 elevationUnitMultiplier Specify a multiplier to convert elevation units from source to meters double 1.0 see Elevation unit conversion embedRouterConfig Embed the Router config in the graph, which allows it to be sent to a server fully configured over the wire boolean true extraEdgesStopPlatformLink add extra edges when linking a stop to a platform, to prevent detours along the platform edge boolean false fares A specific fares service to use object null see fares configuration islandWithStopsMaxSize Pruning threshold for islands with stops. Any such island under this size will be pruned int 5 islandWithoutStopsMaxSize Pruning threshold for islands without stops. Any such island under this size will be pruned int 40 matchBusRoutesToStreets Based on GTFS shape data, guess which OSM streets each bus runs on to improve stop linking boolean false maxAreaNodes Visibility calculations for an area will not be done if there are more nodes than this limit integer 500 maxDataImportIssuesPerFile If number of data import issues is larger then specified maximum number of issues the report will be split in multiple files int 1,000 maxInterlineDistance Maximal distance between stops in meters that will connect consecutive trips that are made with same vehicle int 200 units: meters maxStopToShapeSnapDistance This field is used for mapping route's geometry shapes. It determines max distance between shape points and their stop sequence. If the mapper can not find any stops within this radius it will default to simple stop-to-stop geometry instead. double 150 units: meters maxTransferDurationSeconds Transfers up to this duration in seconds will be pre-calculated and included in the Graph double 1800 units: seconds multiThreadElevationCalculations If true, the elevation module will use multi-threading during elevation calculations. boolean false see Elevation Data Calculation Optimizations osmNaming A custom OSM namer to use object null see custom naming osmWayPropertySet Custom OSM way properties string default options: default , finland , norway , uk , germany platformEntriesLinking Link unconnected entries to public transport platforms boolean false readCachedElevations If true, reads in pre-calculated elevation data. boolean true see Elevation Data Calculation Optimizations staticBikeParkAndRide Whether we should create bike P+R stations from OSM data boolean false staticParkAndRide Whether we should create car P+R stations from OSM data boolean true streets Include street input files (OSM/PBF) boolean true storage Configure access to data sources like GRAPH/OSM/DEM/GTFS/NETEX/ISSUE-REPORT. object null subwayAccessTime Minutes necessary to reach stops served by trips on routes of route_type=1 (subway) from the street double 2.0 units: minutes transferRequests Routing requests to use for pre-calculating stop-to-stop transfers. array [ { modes: \"WALK\" } ] transit Include all transit input files (GTFS) from scanned directory boolean true transitServiceStart Limit the import of transit services to the given start date. Inclusive . Use an absolute date or a period relative to the day the graph is build. To specify a week before the build date use a negative period like -P1W . date or period \u2212P1Y 2020\u201101\u201101, \u2212P1M3D, \u2212P3W transitServiceEnd Limit the import of transit services to the given end date. Inclusive . Use an absolute date or a period relative to the day the graph is build. date or period P3Y 2022\u201112\u201131, P1Y6M10D, P12W writeCachedElevations If true, writes the calculated elevation data. boolean false see Elevation Data Calculation Optimizations This list of parameters in defined in the BuildConfig.java . Storage The storage section of build-config.json allows you to override the default behavior of scanning for input files in the base directory and writing output files (such as the graph and error reports) to that same directory. In OTP2 it is now possible to read and write data located outside the local filesystem (including cloud storage services) or at various different locations around the local filesystem. If your OTP instance is running on a cloud compute service, you may get significantly faster start-up and graph build times if you use the cloud storage directly instead of copying the files back and forth to cloud server instances. This also simplifies the deployment process. Specifying Data Sources Here is a summary of the configuration keys that can be nested inside the storage property of the build-config JSON to specify input and output data sources: config key description value type value default gsCredentials Use an environment variable to point to the Google Cloud credentials: \"${MY_GOC_SERVICE}\" . string null graph Absolute path where the graph file will be written, overriding the default of graph.obj in the base directory. Note that currently this option will also affect where the server reads the graph from. uri null streetGraph Absolute path to the input street-graph file. uri null osm List of absolute paths of OpenStreetMap input files to read. uri [] null dem List of absolute paths of Elevation DEM input files to read. uri [] null gtfs List of GTFS transit data files to read. uri [] null netex List of NeTEx transit data files to read. uri [] null buildReportDir Path to directory where the build issue report will be written. uri null localFileNamePatterns Patterns used in determining the type of input files from their names. object null For example, this configuration could be used to load GTFS and OSM inputs from Google Cloud Storage: // build-config.json { \"storage\" : { \"osm\" : [ \"gs://bucket-name/streets.pbf\" ], \"gtfs\" : [ \"gs://bucket-name/transit1.zip\" , \"gs://bucket-name/transit2.zip\" ] } } The Google Storage system will inherit the permissions of the server it's running on within Google Cloud. It is also possible to supply credentials in this configuration file (see example below). Note that when files are specified with URIs in this configuration, the file types do not need to be inferred from the file names, so these GTFS files can have any names - there is no requirement that they have the letters \"gtfs\" in them. The default behavior of scanning the base directory for inputs is overridden independently for each file type. So in the above configuration, GTFS and OSM will be loaded from Google Cloud Storage, but OTP2 will still scan the base directory for all other types such as DEM files. Supplying an empty array for a particular file type will ensure that no inputs of that type are loaded, including by local directory scanning. See the comments in the source code of class StorageConfig.java for an up-to-date detailed description of each config parameter. Local Filename Patterns When scanning the base directory for inputs, each file's name is checked against patterns to detect what kind of file it is. These patterns can be overridden in the config, by nesting a localFileNamePatterns property inside the storage property (see example below). Here are the keys you can place inside localFileNamePatterns : config key description value type value default osm Pattern used to match Open Street Map files on local disk regexp pattern (?i)(\\.pbf) dem Pattern used to match Elevation DEM files on local disk regexp pattern (?i)\\.tiff?$ gtfs Pattern used to match GTFS files on local disk regexp pattern (?i)gtfs netex Pattern used to match NeTEx files on local disk regexp pattern (?i)netex OTP1 used to peek inside ZIP files and read the CSV tables to guess if a ZIP was indeed GTFS. Now that we support remote input files (cloud storage or arbitrary URLs) not all data sources allow seeking within files to guess what they are. Therefore, like all other file types GTFS is now detected from a filename pattern. It is not sufficient to look for the .zip extension because Netex data is also often supplied in a ZIP file. Storage example // build-config.json { \"storage\" : { // Use the GCS_SERVICE_CREDENTIALS environment variable to locate GCS credentials \"gsCredentials\" : \"${GCS_SERVICE_CREDENTIALS}\" , \"streetGraph\" : \"file:///Users/kelvin/otp/streetGraph.obj\" , \"osm\" : [ \"gs://bucket-name/shared-osm-file.pbf\" ], \"localFileNamePatterns\" : { // All filenames that start with \"g-\" and end with \".zip\" is imported as a GTFS file. \"gtfs\" : \"^g-.*\\\\.zip$\" } } } Limit the transit service period The properties transitServiceStart and transitServiceEnd can be used to limit the service dates. This affects both GTFS service calendars and dates. The service calendar is reduced and dates outside the period are dropped. OTP2 will compute a transit schedule for every day for which it can find at least one trip running. On the other hand, OTP will waste resources if a service end date is unbounded or very large ( 9999-12-31 ). To avoid this, limit the OTP service period. Also, if you provide a service with multiple feeds they may have different service end dates. To avoid inconsistent results, the period can be limited, so all feeds have data for the entire period. The default is to use a period of 1 year before, and 3 years after the day the graph is built. Limiting the period will not improve the search performance, but OTP will build faster and load faster in most cases. The transitServiceStart and transitServiceEnd parameters are set using an absolute date like 2020-12-31 or a period like P1Y6M5D relative to the graph build date. Negative periods is used to specify dates in the past. The period is computed using the system time-zone, not the feed time-zone. Also, remember that the service day might be more than 24 hours. So be sure to include enough slack to account for the this. Setting the limits too wide have very little impact and is in general better than trying to be exact. The period and date format follow the ISO 8601 standard. Reaching a subway platform The ride locations for some modes of transport such as subways and airplanes can be slow to reach from the street. When planning a trip, we need to allow additional time to reach these locations to properly inform the passenger. For example, this helps avoid suggesting short bus rides between two subway rides as a way to improve travel time. You can specify how long it takes to reach a subway platform // build-config.json { \"subwayAccessTime\" : 2.5 } Stops in GTFS do not necessarily serve a single transit mode, but in practice this is usually the case. This additional access time will be added to any stop that is visited by trips on subway routes (GTFS route_type = 1). This setting does not generalize well to airplanes because you often need much longer to check in to a flight (2-3 hours for international flights) than to alight and exit the airport (perhaps 1 hour). Therefore there is currently no per-mode access time, it is subway-specific. Transferring within stations Subway systems tend to exist in their own layer of the city separate from the surface, though there are exceptions where tracks lie right below the street and transfers happen via the surface. In systems where the subway is quite deep and transfers happen via tunnels, the time required for an in-station transfer is often less than that for a surface transfer. A proposal was made to provide detailed station pathways in GTFS but it is not in common use. One way to resolve this problem is by ensuring that the GTFS feed codes each platform as a separate stop, then micro-mapping stations in OSM. When OSM data contains a detailed description of walkways, stairs, and platforms within a station, GTFS stops can be linked to the nearest platform and transfers will happen via the OSM ways, which should yield very realistic transfer time expectations. This works particularly well in above-ground train stations where the layering of non-intersecting ways is less prevalent. Here's an example in the Netherlands: View Larger Map When such micro-mapping data is not available, we need to rely on information from GTFS including how stops are grouped into stations and a table of transfer timings where available. During the graph build, OTP can create preferential connections between each pair of stops in the same station to favor in-station transfers: // build-config.json { \"stationTransfers\" : true } Note that this method is at odds with micro-mapping and might make some transfers artificially short. Elevation data OpenTripPlanner can \"drape\" the OSM street network over a digital elevation model (DEM). This allows OTP to draw an elevation profile for the on-street portion of itineraries, and helps provide better routing for bicyclists. It even helps avoid hills for walking itineraries. DEMs are usually supplied as rasters (regular grids of numbers) stored in image formats such as GeoTIFF. U.S. National Elevation Dataset In the United States, a high resolution National Elevation Dataset is available for the entire territory. It used to be possible for OTP to download NED tiles on the fly from a rather complex USGS SOAP service. This process was somewhat unreliable and would greatly slow down the graph building process. In any case the service has since been replaced. But the USGS would also deliver the whole dataset in bulk if you sent them a hard drive . We did this many years back and uploaded the entire data set to Amazon AWS S3. OpenTripPlanner contains another module that can automatically fetch data in this format from any Amazon S3 copy of the bulk data. You can configure it as follows in build-config.json : // router-config.json { \"elevationBucket\" : { \"accessKey\" : \"your-aws-access-key\" , \"secretKey\" : \"corresponding-aws-secret-key\" , \"bucketName\" : \"ned13\" } } This ned13 bucket is still available on S3 under a \"requester pays\" policy. As long as you specify valid AWS account credentials you should be able to download tiles, and any bandwidth costs will be billed to your AWS account. Once the tiles are downloaded for a particular geographic area, OTP will keep them in local cache for the next graph build operation. You should add the --cache <directory> command line parameter to specify your NED tile cache location. Geoid Difference Some elevation data sets are relative to mean sea level. At a global scale sea level is represented as a surface called the geoid, which is irregular in shape due to local gravitational anomalies. On the other hand, GPS elevations are reported relative to the WGS84 spheroid, a perfectly smooth mathematical surface approximating the geoid. In cases where the two elevation definitions are mixed, it may be necessary to adjust elevation values to avoid confusing users with things like negative elevation values in places clearly above sea level. See issue #2301 for detailed discussion of this. OTP allows you to adjust the elevation values reported in API responses in two ways. The first way is to store ellipsoid (GPS) elevation values internally, but apply a single geoid difference value in the OTP client where appropriate to display elevations above sea level. This ellipsoid to geoid difference is returned in each trip plan response in the ElevationMetadata field. Using a single value can be sufficient for smaller OTP deployments, but might result in incorrect values at the edges of larger OTP deployments. If your OTP instance uses this, it is recommended to set a default request value in the router-config.json file as follows: // router-config.json { \"routingDefaults\" : { \"geoidElevation\" : true } } The second way is to precompute these geoid difference values at a more granular level and store all elevations internally relative to the geoid (sea level). Elevations returned in the API responses will then not need to be adjusted to match end users' intuitive understanding of elevation. In order to speed up calculations, these geoid difference values are calculated and cached using only 2 significant digits of GPS coordinates. This is more than enough detail for most regions of the world and should result in less than one meter of vertical error even in areas that have the largest geoid irregularities. To enable this, include the following in the build-config.json file: // build-config.json { \"includeEllipsoidToGeoidDifference\" : true } If the geoid difference values are precomputed, be careful to not set the routing resource value of geoidElevation to true in order to avoid having the graph-wide geoid added again to all elevation values in the relevant street edges in responses. Other raster elevation data For other parts of the world you will need a GeoTIFF file containing the elevation data. These are often available from national geographic surveys, or you can always fall back on the worldwide Space Shuttle Radar Topography Mission (SRTM) data. This not particularly high resolution (roughly 30 meters horizontally) but it can give acceptable results. Simply place the elevation data file in the directory with the other graph builder inputs, alongside the GTFS and OSM data. Make sure the file has a .tiff or .tif extension, and the graph builder should detect its presence and apply the elevation data to the streets. OTP should automatically handle DEM GeoTIFFs in most common projections. You may want to check for elevation-related error messages during the graph build process to make sure OTP has properly discovered the projection. If you are using a DEM in unprojected coordinates make sure that the axis order is (longitude, latitude) rather than (latitude, longitude). Unfortunately there is no reliable standard for WGS84 axis order, so OTP uses the same axis order as the above-mentioned SRTM data, which is also the default for the popular Proj4 library. DEM files(USGS DEM) is not supported by OTP, but can be converted to GeoTIFF with tools like GDAL . Use gdal_merge.py -o merged.tiff *.dem to merge a set of dem files into one tif file. See Interline PlanetUtils for a set of scripts to download, merge, and resample Mapzen/Amazon Terrain Tiles . Elevation unit conversion By default, OTP expects the elevation data to use metres. However, by setting elevationUnitMultiplier in build-config.json , it is possible to define a multiplier that converts the elevation values from some other unit to metres. // build-config.json { // Correct conversation multiplier when source data uses decimetres instead of metres \"elevationUnitMultiplier\" : 0.1 } Elevation Data Calculation Optimizations Calculating elevations on all StreetEdges can take a dramatically long time. In a very large graph build for multiple Northeast US states, the time it took to download the elevation data and calculate all of the elevations took 5,509 seconds (roughly 1.5 hours). If you are using cloud computing for your OTP instances, it is recommended to create prebuilt images that contain the elevation data you need. This will save time because all of the data won't need to be downloaded. However, the bulk of the time will still be spent calculating elevations for all of the street edges. Therefore, a further optimization can be done to calculate and save the elevation data during a graph build and then save it for future use. Reusing elevation data from previous builds In order to write out the precalculated elevation data, add this to your build-config.json file: // build-config.json { \"writeCachedElevations\" : true } After building the graph, a file called cached_elevations.obj will be written to the cache directory. By default, this file is not written during graph builds. There is also a graph build parameter called readCachedElevations which is set to true by default. In graph builds, the elevation module will attempt to read the cached_elevations.obj file from the cache directory. The cache directory defaults to /var/otp/cache , but this can be overriden via the CLI argument --cache <directory> . For the same graph build for multiple Northeast US states, the time it took with using this predownloaded and precalculated data became 543.7 seconds (roughly 9 minutes). The cached data is a lookup table where the coordinate sequences of respective street edges are used as keys for calculated data. It is assumed that all of the other input data except for the OpenStreetMap data remains the same between graph builds. Therefore, if the underlying elevation data is changed, or different configuration values for elevationUnitMultiplier or includeEllipsoidToGeoidDifference are used, then this data becomes invalid and all elevation data should be recalculated. Over time, various edits to OpenStreetMap will cause this cached data to become stale and not include new OSM ways. Therefore, periodic update of this cached data is recommended. Configuring multi-threading during elevation calculations For unknown reasons that seem to depend on data and machine settings, it might be faster to use a single processor. For this reason, multi-threading of elevation calculations is only done if multiThreadElevationCalculations is set to true. To enable multi-threading in the elevation module, add the following to the build-config.json file: // build-config.json { \"multiThreadElevationCalculations\" : true } Fares configuration By default OTP will compute fares according to the GTFS specification if fare data is provided in your GTFS input. It is possible to turn off this by setting the fare to \"off\". For more complex scenarios or to handle vehicle rental fares, it is necessary to manually configure fares using the fares section in build-config.json . You can combine different fares (for example transit and vehicle-rental) by defining a combinationStrategy parameter, and a list of sub-fares to combine (all fields starting with fare are considered to be sub-fares). // build-config.json { // Select the custom fare \"seattle\" \"fares\" : \"seattle\" , // OR this alternative form that could allow additional configuration \"fares\" : { \"type\" : \"seattle\" } } // build-config.json { \"fares\" : { // Combine two fares by simply adding them \"combinationStrategy\" : \"additive\" , // First fare to combine \"fare0\" : \"new-york\" , // Second fare to combine \"fare1\" : { \"type\" : \"vehicle-rental-time-based\" , \"currency\" : \"USD\" , \"prices\" : { // For trip shorter than 30', $4 fare \"30\" : 4.00 , // For trip shorter than 1h, $6 fare \"1:00\" : 6.00 } } // We could also add fareFoo, fareBar... } } Turning the fare service off , this will ignore any fare data in the provided GTFS data. // build-config.json { \"fares\" : \"off\" } The current list of custom fare type is: vehicle-rental-time-based - accepting the following parameters: currency - the ISO 4217 currency code to use, such as \"EUR\" or \"USD\" , prices - a list of {time, price}. The resulting cost is the smallest cost where the elapsed time of vehicle rental is lower than the defined time. san-francisco (no parameters) new-york (no parameters) seattle (no parameters) off (no parameters) The current list of combinationStrategy is: additive - simply adds all sub-fares. OSM / OpenStreetMap configuration It is possible to adjust how OSM data is interpreted by OpenTripPlanner when building the road part of the routing graph. Way property sets OSM tags have different meanings in different countries, and how the roads in a particular country or region are tagged affects routing. As an example are roads tagged with `highway=trunk (mainly) walkable in Norway, but forbidden in some other countries. This might lead to OTP being unable to snap stops to these roads, or by giving you poor routing results for walking and biking. You can adjust which road types that are accessible by foot, car & bicycle as well as speed limits, suitability for biking and walking. There are currently following wayPropertySets defined; default which is based on California/US mapping standard finland which is adjusted to rules and speeds in Finland norway which is adjusted to rules and speeds in Norway uk which is adjusted to rules and speed in the UK To add your own custom property set have a look at org.opentripplanner.graph_builder.module.osm.NorwayWayPropertySet and org.opentripplanner.graph_builder.module.osm.DefaultWayPropertySet . If you choose to mainly rely on the default rules, make sure you add your own rules first before applying the default ones. The mechanism is that for any two identical tags, OTP will use the first one. // build-config.json { \"osmWayPropertySet\" : \"norway\" } Custom naming You can define a custom naming scheme for elements drawn from OSM by defining an osmNaming field in build-config.json , such as: // build-config.json { \"osmNaming\" : \"portland\" } There is currently only one custom naming module called portland (which has no parameters).","title":"Build"},{"location":"BuildConfiguration/#graph-build-configuration","text":"This table lists all the JSON properties that can be defined in a build-config.json file. These will be stored in the graph itself, and affect any server that subsequently loads that graph. Sections follow that describe particular settings in more depth. config key description value type value default notes areaVisibility Perform visibility calculations. If this is true OTP attempts to calculate a path straight through an OSM area using the shortest way rather than around the edge of it. (These calculations can be time consuming). boolean false banDiscouragedWalking should walking should be allowed on OSM ways tagged with foot=discouraged\" boolean false banDiscouragedBiking should walking should be allowed on OSM ways tagged with bicycle=discouraged\" boolean false dataImportReport Generate nice HTML report of Graph errors/warnings boolean false distanceBetweenElevationSamples TODO OTP2 double 10 elevationBucket If specified, download NED elevation tiles from the given AWS S3 bucket object null provide an object with accessKey , secretKey , and bucketName for AWS S3 elevationUnitMultiplier Specify a multiplier to convert elevation units from source to meters double 1.0 see Elevation unit conversion embedRouterConfig Embed the Router config in the graph, which allows it to be sent to a server fully configured over the wire boolean true extraEdgesStopPlatformLink add extra edges when linking a stop to a platform, to prevent detours along the platform edge boolean false fares A specific fares service to use object null see fares configuration islandWithStopsMaxSize Pruning threshold for islands with stops. Any such island under this size will be pruned int 5 islandWithoutStopsMaxSize Pruning threshold for islands without stops. Any such island under this size will be pruned int 40 matchBusRoutesToStreets Based on GTFS shape data, guess which OSM streets each bus runs on to improve stop linking boolean false maxAreaNodes Visibility calculations for an area will not be done if there are more nodes than this limit integer 500 maxDataImportIssuesPerFile If number of data import issues is larger then specified maximum number of issues the report will be split in multiple files int 1,000 maxInterlineDistance Maximal distance between stops in meters that will connect consecutive trips that are made with same vehicle int 200 units: meters maxStopToShapeSnapDistance This field is used for mapping route's geometry shapes. It determines max distance between shape points and their stop sequence. If the mapper can not find any stops within this radius it will default to simple stop-to-stop geometry instead. double 150 units: meters maxTransferDurationSeconds Transfers up to this duration in seconds will be pre-calculated and included in the Graph double 1800 units: seconds multiThreadElevationCalculations If true, the elevation module will use multi-threading during elevation calculations. boolean false see Elevation Data Calculation Optimizations osmNaming A custom OSM namer to use object null see custom naming osmWayPropertySet Custom OSM way properties string default options: default , finland , norway , uk , germany platformEntriesLinking Link unconnected entries to public transport platforms boolean false readCachedElevations If true, reads in pre-calculated elevation data. boolean true see Elevation Data Calculation Optimizations staticBikeParkAndRide Whether we should create bike P+R stations from OSM data boolean false staticParkAndRide Whether we should create car P+R stations from OSM data boolean true streets Include street input files (OSM/PBF) boolean true storage Configure access to data sources like GRAPH/OSM/DEM/GTFS/NETEX/ISSUE-REPORT. object null subwayAccessTime Minutes necessary to reach stops served by trips on routes of route_type=1 (subway) from the street double 2.0 units: minutes transferRequests Routing requests to use for pre-calculating stop-to-stop transfers. array [ { modes: \"WALK\" } ] transit Include all transit input files (GTFS) from scanned directory boolean true transitServiceStart Limit the import of transit services to the given start date. Inclusive . Use an absolute date or a period relative to the day the graph is build. To specify a week before the build date use a negative period like -P1W . date or period \u2212P1Y 2020\u201101\u201101, \u2212P1M3D, \u2212P3W transitServiceEnd Limit the import of transit services to the given end date. Inclusive . Use an absolute date or a period relative to the day the graph is build. date or period P3Y 2022\u201112\u201131, P1Y6M10D, P12W writeCachedElevations If true, writes the calculated elevation data. boolean false see Elevation Data Calculation Optimizations This list of parameters in defined in the BuildConfig.java .","title":"Graph Build Configuration"},{"location":"BuildConfiguration/#storage","text":"The storage section of build-config.json allows you to override the default behavior of scanning for input files in the base directory and writing output files (such as the graph and error reports) to that same directory. In OTP2 it is now possible to read and write data located outside the local filesystem (including cloud storage services) or at various different locations around the local filesystem. If your OTP instance is running on a cloud compute service, you may get significantly faster start-up and graph build times if you use the cloud storage directly instead of copying the files back and forth to cloud server instances. This also simplifies the deployment process.","title":"Storage"},{"location":"BuildConfiguration/#specifying-data-sources","text":"Here is a summary of the configuration keys that can be nested inside the storage property of the build-config JSON to specify input and output data sources: config key description value type value default gsCredentials Use an environment variable to point to the Google Cloud credentials: \"${MY_GOC_SERVICE}\" . string null graph Absolute path where the graph file will be written, overriding the default of graph.obj in the base directory. Note that currently this option will also affect where the server reads the graph from. uri null streetGraph Absolute path to the input street-graph file. uri null osm List of absolute paths of OpenStreetMap input files to read. uri [] null dem List of absolute paths of Elevation DEM input files to read. uri [] null gtfs List of GTFS transit data files to read. uri [] null netex List of NeTEx transit data files to read. uri [] null buildReportDir Path to directory where the build issue report will be written. uri null localFileNamePatterns Patterns used in determining the type of input files from their names. object null For example, this configuration could be used to load GTFS and OSM inputs from Google Cloud Storage: // build-config.json { \"storage\" : { \"osm\" : [ \"gs://bucket-name/streets.pbf\" ], \"gtfs\" : [ \"gs://bucket-name/transit1.zip\" , \"gs://bucket-name/transit2.zip\" ] } } The Google Storage system will inherit the permissions of the server it's running on within Google Cloud. It is also possible to supply credentials in this configuration file (see example below). Note that when files are specified with URIs in this configuration, the file types do not need to be inferred from the file names, so these GTFS files can have any names - there is no requirement that they have the letters \"gtfs\" in them. The default behavior of scanning the base directory for inputs is overridden independently for each file type. So in the above configuration, GTFS and OSM will be loaded from Google Cloud Storage, but OTP2 will still scan the base directory for all other types such as DEM files. Supplying an empty array for a particular file type will ensure that no inputs of that type are loaded, including by local directory scanning. See the comments in the source code of class StorageConfig.java for an up-to-date detailed description of each config parameter.","title":"Specifying Data Sources"},{"location":"BuildConfiguration/#local-filename-patterns","text":"When scanning the base directory for inputs, each file's name is checked against patterns to detect what kind of file it is. These patterns can be overridden in the config, by nesting a localFileNamePatterns property inside the storage property (see example below). Here are the keys you can place inside localFileNamePatterns : config key description value type value default osm Pattern used to match Open Street Map files on local disk regexp pattern (?i)(\\.pbf) dem Pattern used to match Elevation DEM files on local disk regexp pattern (?i)\\.tiff?$ gtfs Pattern used to match GTFS files on local disk regexp pattern (?i)gtfs netex Pattern used to match NeTEx files on local disk regexp pattern (?i)netex OTP1 used to peek inside ZIP files and read the CSV tables to guess if a ZIP was indeed GTFS. Now that we support remote input files (cloud storage or arbitrary URLs) not all data sources allow seeking within files to guess what they are. Therefore, like all other file types GTFS is now detected from a filename pattern. It is not sufficient to look for the .zip extension because Netex data is also often supplied in a ZIP file.","title":"Local Filename Patterns"},{"location":"BuildConfiguration/#storage-example","text":"// build-config.json { \"storage\" : { // Use the GCS_SERVICE_CREDENTIALS environment variable to locate GCS credentials \"gsCredentials\" : \"${GCS_SERVICE_CREDENTIALS}\" , \"streetGraph\" : \"file:///Users/kelvin/otp/streetGraph.obj\" , \"osm\" : [ \"gs://bucket-name/shared-osm-file.pbf\" ], \"localFileNamePatterns\" : { // All filenames that start with \"g-\" and end with \".zip\" is imported as a GTFS file. \"gtfs\" : \"^g-.*\\\\.zip$\" } } }","title":"Storage example"},{"location":"BuildConfiguration/#limit-the-transit-service-period","text":"The properties transitServiceStart and transitServiceEnd can be used to limit the service dates. This affects both GTFS service calendars and dates. The service calendar is reduced and dates outside the period are dropped. OTP2 will compute a transit schedule for every day for which it can find at least one trip running. On the other hand, OTP will waste resources if a service end date is unbounded or very large ( 9999-12-31 ). To avoid this, limit the OTP service period. Also, if you provide a service with multiple feeds they may have different service end dates. To avoid inconsistent results, the period can be limited, so all feeds have data for the entire period. The default is to use a period of 1 year before, and 3 years after the day the graph is built. Limiting the period will not improve the search performance, but OTP will build faster and load faster in most cases. The transitServiceStart and transitServiceEnd parameters are set using an absolute date like 2020-12-31 or a period like P1Y6M5D relative to the graph build date. Negative periods is used to specify dates in the past. The period is computed using the system time-zone, not the feed time-zone. Also, remember that the service day might be more than 24 hours. So be sure to include enough slack to account for the this. Setting the limits too wide have very little impact and is in general better than trying to be exact. The period and date format follow the ISO 8601 standard.","title":"Limit the transit service period"},{"location":"BuildConfiguration/#reaching-a-subway-platform","text":"The ride locations for some modes of transport such as subways and airplanes can be slow to reach from the street. When planning a trip, we need to allow additional time to reach these locations to properly inform the passenger. For example, this helps avoid suggesting short bus rides between two subway rides as a way to improve travel time. You can specify how long it takes to reach a subway platform // build-config.json { \"subwayAccessTime\" : 2.5 } Stops in GTFS do not necessarily serve a single transit mode, but in practice this is usually the case. This additional access time will be added to any stop that is visited by trips on subway routes (GTFS route_type = 1). This setting does not generalize well to airplanes because you often need much longer to check in to a flight (2-3 hours for international flights) than to alight and exit the airport (perhaps 1 hour). Therefore there is currently no per-mode access time, it is subway-specific.","title":"Reaching a subway platform"},{"location":"BuildConfiguration/#transferring-within-stations","text":"Subway systems tend to exist in their own layer of the city separate from the surface, though there are exceptions where tracks lie right below the street and transfers happen via the surface. In systems where the subway is quite deep and transfers happen via tunnels, the time required for an in-station transfer is often less than that for a surface transfer. A proposal was made to provide detailed station pathways in GTFS but it is not in common use. One way to resolve this problem is by ensuring that the GTFS feed codes each platform as a separate stop, then micro-mapping stations in OSM. When OSM data contains a detailed description of walkways, stairs, and platforms within a station, GTFS stops can be linked to the nearest platform and transfers will happen via the OSM ways, which should yield very realistic transfer time expectations. This works particularly well in above-ground train stations where the layering of non-intersecting ways is less prevalent. Here's an example in the Netherlands: View Larger Map When such micro-mapping data is not available, we need to rely on information from GTFS including how stops are grouped into stations and a table of transfer timings where available. During the graph build, OTP can create preferential connections between each pair of stops in the same station to favor in-station transfers: // build-config.json { \"stationTransfers\" : true } Note that this method is at odds with micro-mapping and might make some transfers artificially short.","title":"Transferring within stations"},{"location":"BuildConfiguration/#elevation-data","text":"OpenTripPlanner can \"drape\" the OSM street network over a digital elevation model (DEM). This allows OTP to draw an elevation profile for the on-street portion of itineraries, and helps provide better routing for bicyclists. It even helps avoid hills for walking itineraries. DEMs are usually supplied as rasters (regular grids of numbers) stored in image formats such as GeoTIFF.","title":"Elevation data"},{"location":"BuildConfiguration/#us-national-elevation-dataset","text":"In the United States, a high resolution National Elevation Dataset is available for the entire territory. It used to be possible for OTP to download NED tiles on the fly from a rather complex USGS SOAP service. This process was somewhat unreliable and would greatly slow down the graph building process. In any case the service has since been replaced. But the USGS would also deliver the whole dataset in bulk if you sent them a hard drive . We did this many years back and uploaded the entire data set to Amazon AWS S3. OpenTripPlanner contains another module that can automatically fetch data in this format from any Amazon S3 copy of the bulk data. You can configure it as follows in build-config.json : // router-config.json { \"elevationBucket\" : { \"accessKey\" : \"your-aws-access-key\" , \"secretKey\" : \"corresponding-aws-secret-key\" , \"bucketName\" : \"ned13\" } } This ned13 bucket is still available on S3 under a \"requester pays\" policy. As long as you specify valid AWS account credentials you should be able to download tiles, and any bandwidth costs will be billed to your AWS account. Once the tiles are downloaded for a particular geographic area, OTP will keep them in local cache for the next graph build operation. You should add the --cache <directory> command line parameter to specify your NED tile cache location.","title":"U.S. National Elevation Dataset"},{"location":"BuildConfiguration/#geoid-difference","text":"Some elevation data sets are relative to mean sea level. At a global scale sea level is represented as a surface called the geoid, which is irregular in shape due to local gravitational anomalies. On the other hand, GPS elevations are reported relative to the WGS84 spheroid, a perfectly smooth mathematical surface approximating the geoid. In cases where the two elevation definitions are mixed, it may be necessary to adjust elevation values to avoid confusing users with things like negative elevation values in places clearly above sea level. See issue #2301 for detailed discussion of this. OTP allows you to adjust the elevation values reported in API responses in two ways. The first way is to store ellipsoid (GPS) elevation values internally, but apply a single geoid difference value in the OTP client where appropriate to display elevations above sea level. This ellipsoid to geoid difference is returned in each trip plan response in the ElevationMetadata field. Using a single value can be sufficient for smaller OTP deployments, but might result in incorrect values at the edges of larger OTP deployments. If your OTP instance uses this, it is recommended to set a default request value in the router-config.json file as follows: // router-config.json { \"routingDefaults\" : { \"geoidElevation\" : true } } The second way is to precompute these geoid difference values at a more granular level and store all elevations internally relative to the geoid (sea level). Elevations returned in the API responses will then not need to be adjusted to match end users' intuitive understanding of elevation. In order to speed up calculations, these geoid difference values are calculated and cached using only 2 significant digits of GPS coordinates. This is more than enough detail for most regions of the world and should result in less than one meter of vertical error even in areas that have the largest geoid irregularities. To enable this, include the following in the build-config.json file: // build-config.json { \"includeEllipsoidToGeoidDifference\" : true } If the geoid difference values are precomputed, be careful to not set the routing resource value of geoidElevation to true in order to avoid having the graph-wide geoid added again to all elevation values in the relevant street edges in responses.","title":"Geoid Difference"},{"location":"BuildConfiguration/#other-raster-elevation-data","text":"For other parts of the world you will need a GeoTIFF file containing the elevation data. These are often available from national geographic surveys, or you can always fall back on the worldwide Space Shuttle Radar Topography Mission (SRTM) data. This not particularly high resolution (roughly 30 meters horizontally) but it can give acceptable results. Simply place the elevation data file in the directory with the other graph builder inputs, alongside the GTFS and OSM data. Make sure the file has a .tiff or .tif extension, and the graph builder should detect its presence and apply the elevation data to the streets. OTP should automatically handle DEM GeoTIFFs in most common projections. You may want to check for elevation-related error messages during the graph build process to make sure OTP has properly discovered the projection. If you are using a DEM in unprojected coordinates make sure that the axis order is (longitude, latitude) rather than (latitude, longitude). Unfortunately there is no reliable standard for WGS84 axis order, so OTP uses the same axis order as the above-mentioned SRTM data, which is also the default for the popular Proj4 library. DEM files(USGS DEM) is not supported by OTP, but can be converted to GeoTIFF with tools like GDAL . Use gdal_merge.py -o merged.tiff *.dem to merge a set of dem files into one tif file. See Interline PlanetUtils for a set of scripts to download, merge, and resample Mapzen/Amazon Terrain Tiles .","title":"Other raster elevation data"},{"location":"BuildConfiguration/#elevation-unit-conversion","text":"By default, OTP expects the elevation data to use metres. However, by setting elevationUnitMultiplier in build-config.json , it is possible to define a multiplier that converts the elevation values from some other unit to metres. // build-config.json { // Correct conversation multiplier when source data uses decimetres instead of metres \"elevationUnitMultiplier\" : 0.1 }","title":"Elevation unit conversion"},{"location":"BuildConfiguration/#elevation-data-calculation-optimizations","text":"Calculating elevations on all StreetEdges can take a dramatically long time. In a very large graph build for multiple Northeast US states, the time it took to download the elevation data and calculate all of the elevations took 5,509 seconds (roughly 1.5 hours). If you are using cloud computing for your OTP instances, it is recommended to create prebuilt images that contain the elevation data you need. This will save time because all of the data won't need to be downloaded. However, the bulk of the time will still be spent calculating elevations for all of the street edges. Therefore, a further optimization can be done to calculate and save the elevation data during a graph build and then save it for future use.","title":"Elevation Data Calculation Optimizations"},{"location":"BuildConfiguration/#reusing-elevation-data-from-previous-builds","text":"In order to write out the precalculated elevation data, add this to your build-config.json file: // build-config.json { \"writeCachedElevations\" : true } After building the graph, a file called cached_elevations.obj will be written to the cache directory. By default, this file is not written during graph builds. There is also a graph build parameter called readCachedElevations which is set to true by default. In graph builds, the elevation module will attempt to read the cached_elevations.obj file from the cache directory. The cache directory defaults to /var/otp/cache , but this can be overriden via the CLI argument --cache <directory> . For the same graph build for multiple Northeast US states, the time it took with using this predownloaded and precalculated data became 543.7 seconds (roughly 9 minutes). The cached data is a lookup table where the coordinate sequences of respective street edges are used as keys for calculated data. It is assumed that all of the other input data except for the OpenStreetMap data remains the same between graph builds. Therefore, if the underlying elevation data is changed, or different configuration values for elevationUnitMultiplier or includeEllipsoidToGeoidDifference are used, then this data becomes invalid and all elevation data should be recalculated. Over time, various edits to OpenStreetMap will cause this cached data to become stale and not include new OSM ways. Therefore, periodic update of this cached data is recommended.","title":"Reusing elevation data from previous builds"},{"location":"BuildConfiguration/#configuring-multi-threading-during-elevation-calculations","text":"For unknown reasons that seem to depend on data and machine settings, it might be faster to use a single processor. For this reason, multi-threading of elevation calculations is only done if multiThreadElevationCalculations is set to true. To enable multi-threading in the elevation module, add the following to the build-config.json file: // build-config.json { \"multiThreadElevationCalculations\" : true }","title":"Configuring multi-threading during elevation calculations"},{"location":"BuildConfiguration/#fares-configuration","text":"By default OTP will compute fares according to the GTFS specification if fare data is provided in your GTFS input. It is possible to turn off this by setting the fare to \"off\". For more complex scenarios or to handle vehicle rental fares, it is necessary to manually configure fares using the fares section in build-config.json . You can combine different fares (for example transit and vehicle-rental) by defining a combinationStrategy parameter, and a list of sub-fares to combine (all fields starting with fare are considered to be sub-fares). // build-config.json { // Select the custom fare \"seattle\" \"fares\" : \"seattle\" , // OR this alternative form that could allow additional configuration \"fares\" : { \"type\" : \"seattle\" } } // build-config.json { \"fares\" : { // Combine two fares by simply adding them \"combinationStrategy\" : \"additive\" , // First fare to combine \"fare0\" : \"new-york\" , // Second fare to combine \"fare1\" : { \"type\" : \"vehicle-rental-time-based\" , \"currency\" : \"USD\" , \"prices\" : { // For trip shorter than 30', $4 fare \"30\" : 4.00 , // For trip shorter than 1h, $6 fare \"1:00\" : 6.00 } } // We could also add fareFoo, fareBar... } } Turning the fare service off , this will ignore any fare data in the provided GTFS data. // build-config.json { \"fares\" : \"off\" } The current list of custom fare type is: vehicle-rental-time-based - accepting the following parameters: currency - the ISO 4217 currency code to use, such as \"EUR\" or \"USD\" , prices - a list of {time, price}. The resulting cost is the smallest cost where the elapsed time of vehicle rental is lower than the defined time. san-francisco (no parameters) new-york (no parameters) seattle (no parameters) off (no parameters) The current list of combinationStrategy is: additive - simply adds all sub-fares.","title":"Fares configuration"},{"location":"BuildConfiguration/#osm-openstreetmap-configuration","text":"It is possible to adjust how OSM data is interpreted by OpenTripPlanner when building the road part of the routing graph.","title":"OSM / OpenStreetMap configuration"},{"location":"BuildConfiguration/#way-property-sets","text":"OSM tags have different meanings in different countries, and how the roads in a particular country or region are tagged affects routing. As an example are roads tagged with `highway=trunk (mainly) walkable in Norway, but forbidden in some other countries. This might lead to OTP being unable to snap stops to these roads, or by giving you poor routing results for walking and biking. You can adjust which road types that are accessible by foot, car & bicycle as well as speed limits, suitability for biking and walking. There are currently following wayPropertySets defined; default which is based on California/US mapping standard finland which is adjusted to rules and speeds in Finland norway which is adjusted to rules and speeds in Norway uk which is adjusted to rules and speed in the UK To add your own custom property set have a look at org.opentripplanner.graph_builder.module.osm.NorwayWayPropertySet and org.opentripplanner.graph_builder.module.osm.DefaultWayPropertySet . If you choose to mainly rely on the default rules, make sure you add your own rules first before applying the default ones. The mechanism is that for any two identical tags, OTP will use the first one. // build-config.json { \"osmWayPropertySet\" : \"norway\" }","title":"Way property sets"},{"location":"BuildConfiguration/#custom-naming","text":"You can define a custom naming scheme for elements drawn from OSM by defining an osmNaming field in build-config.json , such as: // build-config.json { \"osmNaming\" : \"portland\" } There is currently only one custom naming module called portland (which has no parameters).","title":"Custom naming"},{"location":"Changelog/","text":"Changelog The changelog list most feature changes between each release. The list is automatically created based on merged pull requests. Search GitHub issues and pull requests for smaller issues. 2.1.0 (2022-03-17) Notable Changes GBFS 2.2 is supported including \"form factors\" (bike, scooter, car) and floating vehicles (with no fixed station) Constrained Transfers (Netex interchanges / GTFS transfers.txt ) Transfers for bicycle and wheelchair users distinct from walking paths Support for GTFS-Flex v2 Support for frequency-based trips (GTFS frequencies.txt , does not exist in Netex) Many 1.5 features not fully implemented in 2.0 have been reintroduced Improved result quality relative to both 1.5 and 2.0: filtering of itineraries and selection of transfer points between routes Car and bicycle parking has been combined into vehicle parking (enhanced with real-time details like remaining parking spaces) New system for paging of routing results via cursor token Response times should be roughly stable since 2.0. Performance much improved over OTP1 for long searches, may be somewhat slower for short searches. Extremely depdendent on data set used, so test on your specific data. System integration tests for ongoing performance measurement Detailed changes by Pull Request Fix NullPointerException when a RealTime update do not match an existing TripPattern #3284 Support for versioning the configuration files #3282 Prioritize \"direct\" routes over transfers in group-filters #3309 Remove poor transit results for short trips, when walking is better #3331 GTFS Trips will by default not allow bikes if no explicit value is set #3359 . Improve the dynamic search window calculation. The configuration parameters minTransitTimeCoefficient and minWaitTimeCoefficient replace the old minTripTimeCoefficient parameter. #3366 Allow loops caused by turn restriction in street routes #3399 Apply turn restrictions when splitting edges. #3414 Add separate no-thru handling for bicycles #3410 Add German way property set #3359 Process OSM bicycle routes correctly #3359 Avoid turns across traffic on bicycles #3359 Remove request parameter driveOnRight and derive information from way property set #3359 Add basic support for routing using floating bikes #3370 Optimize which stops are used for transfers, using generalized-cost, wait-time and transfer priority. Partially implements #2788 Support for stay-seated and guaranteed transfers #3193 Fix reading of cached elevation files #3455 Added BikeRentalWithMostlyWalking filter #3446 Import GTFS-Flex v2 Flexible trips #3453 Add support for arriving at the destination with rented bicycles #3459 Allow IntersectionTraversalCostModel to be specified in the WayPropertySet #3472 Fix for traveling back in time when optimize transfers #3491 Transit reluctance per transit mode #3440 Allow the removal of P+R results consisting only of driving of walking #3515 Allow http headers to be specified for bike rental updaters #3533 Per-mode reluctance parameters are added so that itineraries with multiple modes may have varying reluctances. #3501 Add maxAreaNodes configuration parameter for changing an area visibility calculation limit (https://github.com/opentripplanner/OpenTripPlanner/issues/3534) Add maxAccessEgressDurationSecondsForMode to RoutingRequest #3560 Add bicycle safety report to report API #3563 Optimize Transfers performance issue #3513 Don't allow bicycle loops in A* #3574 Cancel individual stop on StopPattern instead of TripTimes #3575 Do not allow bicycle traversal on ways tagged with mtb:scale #3578 Changes to the StopTimes call #3576 Fix bug in optimize transfer service decorating path #3587 Remove non-GBFS bicycle rental updaters #3562 Remove possibility to import vehicle rental stations from OSM, make vehicle rental stations feed scoped #3601 When importing Netex, allow bicycles on ferries by default #3596 Safely catch some elevation interpolation exceptions #3412 Route not found in some conditions with boarding/alighting restrictions #3621 Load additional data from GBFS and expose it #3610 Allow transfers to use customizable request options #3324 Check boarding and alighting permissions in TransferGenerator #3641 Stoptimes should return tripId on the REST API. #3589 Handle non-symmetric transfers in RAPTOR #3634 . Order RAPTOR input data so that plans are deterministic #3580 Cost on transfer in Raptor #3617 Allow for combined NeTEx and GTFS data sources #3650 Generalized graph connectivity pruning #3426 Stop linking to area/platform edges obeys area boundaries and traverse modes #3201 Add service day mapping to REST API #3659 Generalized cost on transfer in Raptor #3629 Add two new filters for use within grouping filter #3638 Correct usage of boardSlackForMode / alightSlackForMode #3693 Do not parse pass-through information in GBFS mappers #3709 Vehicle rental updates #3632 add trolleybus & monorail support #3658 Do not create zero length StreetEdges #3716 Add pickup and dropoff booking info to REST API #3710 Use the whole duration of the filtered transit data for the raptor heuristic search #3664 Performance improvement for flex access/egress searches #3661 Add new routing errors for cases where all itineraries were filtered by post-processing #3628 Fix combination of flex access and constrained transfer #3726 Merge B+R and P+R functionality into vehicle parking #3480 Add cost to maximize wait-time and avoid back-travel in optimize transfers #3654 Calculate fares from itineraries not Raptor paths, calculate flex fares #3743 Logging first time instance reports it is ready to use #3733 Allow limiting the used vehicle rentals and parkings #3746 Add support for car and scooter rental modes #3706 Extra stop priority cost in optimized transfer service #3731 Remove old visibility graph library from walkable area builder #3753 Update GtfsRealtime and include severity, effect and cause from GTFS RT #3747 Handle miscellaneous service as BUS instead of crashing build #3755 Update all timers to micrometer instances #3744 Bugfix: ClassCastException when planning flex routes #3762 Add mode from parent StopPlace for Quays in Netex mapper #3751 Minor performance improvements #3767 Parallelise computing of trip pattern geometries #3766 Add flex stop to TripTimes, return geometries in GraphQL API #3757 Fix checking allowed boarding/alighting for unscheduled flex trips #3782 Calculating number of days to use in StopTimes-request #3742 Walkable area builder improvements #3765 Remove hardcoded alighting/boarding on first/last stop #3784 Add support for include-file-directive in config files. #3771 Remove build parameter 'useTransfersTxt' #3791 Add cursor-based paging #3759 Data overlay sandbox feature #3760 Add support for sandboxed realtime vehicle parking updaters #3796 Add reading and exposing of Netex submodes #3793 Fix: Account for wait-time in no-wait Raptor strategy #3798 Read in flex window from Netex feeds #3800 Fix NPE when routing on a graph without transit data. #3804 Read leg mode from trip, instead of route #3819 Use API mapping in snapshot tests #3823 Store stop indices in leg and use them to simplify logic in TripTimeShortHelper #3820 Include all trips in stopTimesForStop #3817 Store all alerts and add support for route_type and direction_id selectors #3780 Remove outdated realtime-update from TimetableSnapshot #3770 Contributing Guide #3769 OTP support for NeTEx branding #3829 Not allowed transfers and support for GTFS transfer points #3792 Simple implementation of horizontally moving elevators (Elevator way) #3750 fix: Avoid mixed path separators on Windows in Park API test #3845 Filter out elevator ways that are also implicit areas #3850 Dynamically compute additional search days #3824 Mode & submode filter for NeTEx Service Journeys #3844 Return correct heuristic values, when constrained transfers is turned on #3841 Adjust search window dynamically to fit the number of itineraries #3828 Implement minimum transfer time from GTFS transfers.txt #3830 Fix number format exception for elevator duration parsing OSM data #3871 Include generalizedCost in the optimized transfers wait-time cost #3864 Expose maxStopToShapeSnapDistance as build-config.json parameter #3874 Implement in-seat transfers per GTFS draft #3831 Add stairsTimeFactor to StreetEdge #3832 Make sure we keep the itinerary with the least number of transfers when grouping the itineraries #3833 Don't expect every pattern in a route to have the specified stop with constrained transfers #3868 Add support for creating constrained transfers from real-time generated patterns #3878 Account for stay seated transfers when calculating the number of transfers #3888 Add Hungarian translation #3861 Add support for \"via\" in NeTEx headsigns #3883 NeTEx mapping to StopTime.timepoint #3898 Optimize RAPTOR trip search by pre-calculating arrival/departure time arrays #3919 Make turn restrictions faster and thread-safe by moving them into StreetEdge #3899 Add routing using frequency trips #3916 Remove ET realtime override code #3912 Allow traversal of pathways without traversal time, distance or steps #3910 2.0.0 (2020-11-27) See the OTP2 Migration Guide on changes to the REST API. Sandbox for experimental features #2745 Bugfix for Missing platforms for stops in GTFS import causes a NPE #2804 Remove extra Djikstra implementations Remove redundant LineStrings in order to save memory #2795 NeTEx import support #2769 New Transit search algorithm, Raptor, replaces the AStar for all transit searches. Added NeTEx notices #2824 Make transfers and access/egress use effectiveWalkDistance to take slopes into account #2857 Add MultiModalStation and GroupOfStations to OTP model and added these to the NeTEx import #2813 Combined OSM loaders, removing several rarely used ones #2878 New Java Code Style (part of #2755 ) Cleanup and rename Graph Builder Annotations, now Data Import Issues #2871 Bugfix for graph building crashing on unsupported modes #2899 Add command line parameter for building partial graphs #2583 Refactor GenericLocation/AStar/RoutingContext to allow multiple start vertices #2887 New Transit search algorithm, Raptor, replaces the AStar for all transit searches. Update only the relevant parts of the TransitLayer each time an update is applied #2918 Ability to switch off the fare service #2912 . Limit the transit service period #2925 . Removed unwanted cost added for wait time between access and transit with RangeRaptor #2927 Dynamic search parameters, calculate raptor search-window when needed. #2931 Support for next/previous paging trip search results #2941 Fix mismatch in duration for walk legs, resulting in negative wait times #2955 NeTEx import now supports ServiceLinks #2951 Also check TripPatterns added by realtime when showing stoptimes for stop #2954 Copy geometries from previous TripPattern when realtime updates result in a TripPattern being replaced #2987 Support for the Norwegian language. Update pathways support to official GTFS specification #2923 Support for XML (de-)serialization is REMOVED from the REST API #3031 Refactor how to specify access/egress/direct/transit modes in the internal model and the Transmodel API #3011 Make agency id feed scoped #3035 Refactor kiss and ride to a more general car pickup mode #3063 Map NeTEx publicCode to OTP tripShortName and NeTEx private code to OTP internalPlanningCode #3088 Add MQTT transport for the GTFS-RT trip update updater #3094 Add FinlandWayPropertySetSource #3096 Map NeTEx publicCode to OTP tripShortName and NeTEx private code to OTP internalPlanningCode #3088 Reading and writing files(CONFIG, GRAPH, DEM, OSM, GTFS, NETEX, DATA_IMPORT_ISSUES) is changed. All files, except configuration files, are read from a data source. We support Google Cloud Storage and the local file system data sources for now, but plan to add at least support for AWS S3 #2891 Remove AlertPatcher #3134 Update DebugOutput to match new routing phases of OTP2 #3109 Filter transit itineraries with relative high cost #3157 Fix issue with colliding TripPattern ids after modifications form real-time updaters #3202 Fix: The updater config type is unknown: gtfs-http #3195 Fix: Problem building and loading the GTFS file in San Fransisco Bay Area #3195 Fix: The BusRouteStreetMatcher and TransitToTaggedStopsModule graph builder modules are not run if the graph is build in two steps, and add progress tracker to BusRouteStreetMatcher. #3195 Improvement: Insert project information like Maven version number into configuration files. #3254 Added pathway FeedScopedId as the route text to trip plan responses. #3287 Ported over from 1.4 and 1.5 Add application/x-protobuf to accepted protobuf content-types #2839 Make OTP run on Java 11 #2812 Fixes surefire test failure during build #2816 Disable linking from already linked stops #2372 Add Way Property Set for the UK #2818 Remove Open Traffic prototype code #2698 Docs: improve configuration documentation Update onebusaway-gtfs to latest version from OBA project #2636 Remove the coupling to OneBusAway GTFS within OTP's internal model by creating new classes replacing the external classes #2494 Allow itineraries in response to be sorted by duration #2593 Fix reverse optimization bug #2653, #2411 increase GTFS-realtime feeds size limit from 64MB to 2G #2738 Fix XML response serialization #2685 Refactor InterleavedBidirectionalHeuristic #2671 Add \"Accept\" headers to GTFS-RT HTTP requests #2796 Fix minor test failure against BANO geocoder #2798 Fix frequency bounds checking #2540 Remove dependency on Conveyal jackson2-geojson Changed calculation of slope costs #2579 Replace Java built in serialization with faster Kryo #2681 Support OSM highway=razed tag #2660 Add bicimad bike rental updater #2503 Add Smoove citybikes updater #2515 Allow big GTFS-realtime feeds by increasing protobuf size limit to 2G #2739 Cannot transfer between stops at exactly the same location #2371 Improve documentation for mode routing parameter #2809 Switched to single license file, removing all OTP and OBA file license headers 1.3 (2018-08-03) Fix stop linking to only one edge of platform #2472 Log and allow changing number of HTTP handler threads Update Dutch base fare from 89 to 90 cents #2608 Add Dutch fare service #2571 Revise unit tests to use less memory Run all graph updater setup methods sequentially #2545 Allow vehicle rental systems with cars (stopgap parameter on bike rental) Bump R5 version to get newer gtfs-lib and FST serialization Move stopClusterMode parameter from routing config to build config #2558 Update encrypted Maven artifact signing key (it expired) Clean up logging Remove/update deprecated HTTPClient, add missing SSL ciphers #2451 Make maxTransfer options configurable through scripting API #2507 Fix scripts when entity IDs contain colons #2474 Add HTML report for stops more than 20m from linked road #2460 Update fares in NycFareServiceImpl #2466 Compact legs NPE fix #2449 #2490 Docs: elevation data configuration, USGS DEM files Docs: Update list of deployments Docs: API, list of deployments, usage stats and tutorials Docs: Update leadership committee listing following Boston Summit Docs: Update OTP logo (Thanks Kate Chanba!) 1.2 (2017-09-18) Add support for consuming GBFS bike-rental availability feeds. #2458 Add GBFS configuration example Add flag for including requested start/end time in maxHours in planner API. #2457 Add maxTransferDistance graph builder parameter Add option for filtering non-pickup stops in TransitIndex stop times functions. #2377 Support foot/bicycle=discouraged OSM tag. #2415 Improve linking of transit platforms to connecting access ways. #2422 / #2428 Fix bug when building graph with parent station transfers. #2404 / #2410 Fix bugs in park and ride search. #2424 Support different stop ID formats in field trip module Update URL in BANO geocoding module. #2438 / #2439 Add more debug information related to trips matching using GTFS-RT feed. #2432 Update default PATH_NOT_FOUND message to new wording developed w/ TriMet. #2355 Update Travis build configuration to not attempt GPG operations. #2441 Fix javadoc URL in scripting documentation. #2437 Automatically link to GitHub issues in Changelog. #2426 Expose FeedInfo objects in the Index API #2456 Changes to Puget Sound region fare calculation #2484 Fix coordinatates when clustering by parent station #2447 Allow setting OSM Way Properties from build-config.json #2389 Optionally compact (\"reverse-optimize\") results with complete reverse search #2449 Add updater for urbaninfrastructure city bikes #2448 Miscellaneous documentation updates 1.1 (2017-03-16) Deploy to Sonatype OSSRH and Maven Central Documentation updates including repo links New router-config stopClusterMode: clustering by parent station or geography #2364 Spanish and Portuguese UI Translations In TimeSurface API, serialize travel times to every point when detail=true Make OSM highway=corridor pedestrian routable Fix GraphIndex.stopTimesForStop to search on the request day rather than now Update GraphQL to latest version and improve support for complex arguments #2367 Add support for operationName to the graphql endpoint Fix findClosestStopsByWalking, properly set RoutingContext Fixed major routing problem where dead-end SimpleTransfers blocked walking paths #2414 Created Github issue template Avoid negative elevation figures: Compute ellipsoid-geoid offset and optionally apply to elevation calculations #2301 Fix VCub bike share updater using new API variable names. Fix spurious different-day warning #2399 Shutdown hook to gracefully shut down Grizzly #2384 Added headsign attribute for stoptimes in GraphQL #2224 Allow Cars on highway=*;bicycle=designated #2374 Expose PruneFloatingIslands parameters in build-config.json Lazy initialization of stop clusters where needed Include Agency/Route branding in responses Include turn-by-turn walking directions for transfer legs #1707 Output error when edge lengths are negative, and set them to 1mm Add disableAlertFiltering API flag #2351 Do not show arrival times at terminal stops in stop time viewer #2357 Index API now returns stop information URL, enabling hyperlinks in trip viewer #2352 Remove all unused model classes for index API #1301 Apply an interlining fix from 0.10 branch Allow quoted search phrases in the Lucene search #2279 Re-implement maxHours filter #2332 Properly set wheelchairAccessible on area edges Fixed file URL in test #2339 Add details field to fares, listing which legs each fare applies to #1699 1.0 (2016-09-09) Fix problem with missing embedded router-configs. Check whether trips have been banned when applying in-seat transfers (interlining). Load embedded config for existing graphs on disk. Apply max walk distance to transfers, not just initial and final walk. Remove Conveyal tiles from client (which was getting expensive), add free Carto/MapZen tiles. Fixed headsigns: in itineraries, headsign for a leg used to always be the last stop. Updated default map tile sets in the client because Mapquest is no longer gratis. Fix problem with empty list ??? #1873 Rewrite of intermediate places handling in GraphPathFinder. Original request is cloned for each intermediate path. Routes in GraphQL API Change \"type\" to \"mode\" and add \"type\" as route type to Route for GraphQL Add effective end date to alerts (from HSL). Rutebanken Citybike bike share. Correct TPEG transport modes TPEG 401 and 402 to be \"subway\". Ignore exceptions caused by errors in OSM linear rings. Updated to version 2.18 of Jersey to fix hanging threads in Grizzly. Removed confusing \"Busish\" and \"Trainish\" pseudo-modes. FareService for Seattle: allow specifying fares in GTFS instead of hard-coding them in Java. Senior/youth fare prices are given in an extra column in fare attributes. Per-trip fares are taken into consideration when calculating fares in this region. Update new linker to link to transitStops if no streets are found. Show the name supplied in the request for the origin/destination points in the response. Throw a trivialPath exception if start/end point are on the same edge. Switch to only use the new SimpleStreetLinker, even for search start and end points. Completely removed old linker classes. Changes for proper handling of wheelchairs and bicycles at start and end points. Properly handle null timetableSnapshots when there is no real-time data. 0.20 (2016-06-10) Re-enabled Enunciate, which works properly with OTP now. This means we have auto-generated API docs. Make headsign and block ID visible in the Stop Viewer. NYC fare service: filter out non-NYC agencies. Optionally log all requests to a file. Make max distance for in-seat transfers (interlining) configurable. Previously it was hardcoded at 200m. Polish translation for web client. Introduced bikeShareId in trip plans (separate from stopIds). Support for ShareBike bike rental system in Oslo, Drammen, Trondheim, Milan, Barcelona and Mexico City among others. Changed default waitAtBeginningFactor and timeouts. Show alert in client when itinerary departure date differs from search date. Exposed realtimeState in GraphQL responses. Fixed a routerConfig NullPointerException. Support for San Francisco bike share from leoromanovsky. GraphQL API for most transit data from hannesj. Disallow shortcuts through multiple StationStopEdges. Add support for airplanes (from HSL) Major simplification and correction of the longDistance heuristic, removed obsolete runState.options.heuristicWeight. Return default OSM level for ways that are not found. Profile routing: use earliest arrival objective function on-street, properly handle TrivialPathExceptions. Fixed ID matching when applying AlertPatches. Fixed banning of agencies in multi agency feeds. More coherent handling of feed IDs as scope for GTFS IDs. Added transit service start and end timestamps to BuildInfo. Handle embeded router configuration for POSTed graphs and zips for building. Simplified router-config handling. Properly lazy-initialize profile routing stopClusters. Added stop clusters to the Index API. Completely removed the ill-advised path parser system, which was too clever for its own good. Sort itineraries by total travel time rather than in-transit time. Rental bikes: allow loading generic KML. Removed the experimental TransportNetwork classes, which shared no code with the rest of OTP and were duplicated in the R5 project. There are still some elements that can be cleaned out when only R5 is used by Conveyal's analysis system. The broker code in OTP is now able to start up R5 workers for Analyst. Use the Conveyal fork of the OBA GTFS loader, so that we can add our own extensions to GTFS. Updated docs to offer Conveyal Maven repo as a place to get prebuilt OTP. 0.19.0 (2016-05-25) TODO 0.18.0 (2015-05-29) Ability to load elevation from projected GeoTIFF Clarified axis order for unprojected GeoTIFFs Stop viewer and car distance fixed in client Server-side localization improvements Proper names for intersections JSON config for loading bikeshare and park and ride lots from OSM More ways to fetch isochrones Fixed frequency-based routing in repeated RAPTOR Calculate graph envelope at build time not runtime Fixed slow excessive HashGrid search Readthedocs documentation updates 0.17.0 (2015-05-14) Allow fetching arrivals/departures over a particular time window Completely new spatial analysis implementation: repeated RAPTOR search at every minute in a departure time window More reproducible spatial analysis results across similar graphs, thanks to more consistent splitting of streets etc. Sigmoidal accessibility metric rolloff (rather than hard-edged cutoff) Correction of equirectangular projection used in spatial analysis Improved, simplified, deterministic linking of stops into the street network 0.16.0 (2015-05-07) Several improvements to OSM tag based traversal permissions Scripting documentation Accept TIFF files whose names end in .tiff not .tif Store distances (not times) in Analyst Samples to allow variable walk speed Fixed bug in graph auto-scanning Fixed client-side bug in first and last itinerary buttons OTP startup scripts no longer use wildcards Transit, bike rental, and parking linking done in one module Elevation tiles for the US can be fetched from Amazon S3 Bumped language level to Java 8 (lambda functions, method references, collection streams) 0.15.0 (2015-04-14) Fare module for Seattle JSON fare module and OSM street naming configuration Significant improvements to speed and result quality of Profile Routing Support for added and modified GTFS-RT trips (thanks Jaap Koelewijn of DAT Mobility and Plannerstack) Detailed edge lists in profile routing responses (for Transitive.js) Support for multiple access modes including bike rental in profile routing Fixes to graph reloading via web API Improved comments in code and documentation of PointSets Pulled MapDB GTFS loader out into a separate repo Working artifact version was 0.15.0-SNAPSHOT instead of 1.0.0-SNAPSHOT (anticipating frequent point releases) 0.14.0 (2015-03-28) JSON configuration of graph building and routers Began moving documentation (including this changelog) into the OTP repo and rewriting it page by page. It is built statically from Markdown using mkdocs and published on readthedocs. Street edge lists and bike rental station IDs in profile routing results (allows better rendering) Improved correctness of profile routing Qualified modes including rented bikes work in profile routing Simplification of qualified mode sets Elevation models are loaded from TIFFs in graph directory Tiles for differences between TimeSurfaces Restructured relationship between Routers and Graphs Various changes enabling use of Analyst features in a cluster computing environment. Removed several single-implementation interfaces, factories, services and other superfluous abstractions Various client fixes related to the transit index API Revised nearby stops logic and transfer generation to eliminate useless transfer edges New Index API endpoints for geometries, transfers etc. Isochrone generation fixes Default mode of operation is now \u201clong distance mode\u201d Process for finding alternative routes is now based on banning trips and retrying, while reusing the heuristic Optimization objective functions are swappable, and have been simplified and corrected All client Javascript librariess are now pulled from a CDN Dutch BAG and French BANO geocoders Bus to street matching improvements Complete MapDB based GTFS and OSM loader libraries (will become separate projects, not yet connected to OTP graph builder) API documentation generation working again Disable some time consuming graph building steps by default Finnish and Swedish translations Subway-specific JSON configuration options (street to platform time) Realtime fetch / streaming configurable via JSON Stairs reluctance is much higher when carrying a bike Graph visualizer routing progress animates when a search is triggered via the web API Assume WGS84 (spherical distance calculations) everywhere Removed custom motor vehicle (which was unmaintained and not documented) Ability to poll for bike rental locations only once at startup Stoptimes are fetched for a specific service day in index API Bicycle triangle support in profile routing Proper handling of multiple access modes with different speeds in profile routing Command line option to output OTP's version 0.13.0 (2014-12-05) Detect apparent errors in GTFS interlining Long distance mode: use a pure weight-based state comparison, and use trip-banning retrying logic to get multiple paths. This compromises correctness somewhat but brings search times back within reason for large regional graphs. Also, we create significantly less SimpleTransfers. Progress on GTFS reading and writing library (not yet used by OTP). Bug fixes for tiny street edges, time zones. Deployment of artifacts to maven.conveyal.com via S3. Handle park and ride lots that have roads running through them, but don't share nodes with those roads. 0.12.1 (2014-11-17) Fixed threading problem caused by graph visualization instrumentation #1611 Fixed 'unconnected areas' infinite loop #1605 0.12.0 (2014-11-11) Graph building from zipball of data sent over the wire OTP-specific GTFS loader library with error checking and recovery Bike and car park and ride improvements Stable hash codes for stop patterns and trips Bicycle safety and wheelchair access tile generators Newer versions of Grizzly, Jackson, and Enunciate (documentation generation now works) Redesigned HashGrid spatial index Significant reduction in graph size in memory and on disk Improved internationalization Ability to pause and step search in graph visualizer Additional graph visualizer modes for spotting overbranching Movement toward 1.0 web services API Kiss and Ride Complete removal of Spring Complete removal of Lombok CORS replaces JSONP Pointset classes for dealing with one-to-many calculations and accessibility calculations Experimental \"Profile routing\" which enumerates reasonable route combinations over a time range rather than exact itineraries Single-module Maven build (complete elimination of submodules) Alternate Gradle build script full internationalization of the map-based web client basic Lucene-based built-in geocoder 0.11.0 (2014-03-24) Built-in HTTP server layer, making it possible to distribute OTP as a standalone JAR \"Long-distance\" mode for large graphs, including bidirectional goal direction heuristic. Simplified Maven project structure with less submodules GTFS-RT trip update support, including streaming incremental data, which directly affects route optimization 0.10.0 (2014-03-18) This release was made to consolidate all the development that had occurred with a 0.9.x-SNAPSHOT Maven version. The changes were very significant and it was not appropriate to tag them as a minor bugfix release after the 0.9 tag. Though this release was performed at the same time as 0.11.0, it represents a much earlier stage in the development of OTP. 0.7.0 (2012-04-29) Bike rental support (thanks Laurent Gr\u00e9goire) Realtime bike rental availability feed support Updated to new version of One Bus Away GTFS/CSV, fixing timezone and string interning issues (thanks Brian Ferris) Bugfixes in area routing, OSM loading, nonexistant NED tiles, route short names Dutch and French language updates Catch negative edge weights due to broken GTFS Significant (10-20%) speedup by moving a field into StateData (thanks Laurent Gr\u00e9goire) 0.6.0 (2012-04-25) area routing more lenient parsing of times new directions icon set with SVG sources (thanks Laurent G) 0.5.4 (2012-04-06) catch 0 divisors in NED builder, preventing NaN propagation to edge lengths avoid repeated insertion of edges into edge lists, which are now threadsafe edge sets identity equality for edges bounding box check in UnifiedCoverage (speed up NED loading) Dutch API messages elevation override fix less verbose graph builder (be sure to check graphbuilder annotation summary) replacement streets given names geocoder bug fix (thanks Laurent Gregoire) git commit IDs included in MavenVersion, allowing clearer OTP/Graph version mismatch warnings fix problems with immediate reboarding and unexpected edges in itinerary builder favicon (thanks Joel Haasnoot) Legs in API response have TripId (for realtime information) Polish locale (thanks \u0141ukasz Witkowski) transfers.txt can define station paths, entry costs for stations allow loading a base graph into graphbuilder instead of starting from scratch 0.5.3 (2012-03-23) GTFS loader now loads feeds one-at-a-time, allowing per-feed configuration half-written graph files are now deleted on graph build error DST issue OTP-side fixes, tests adjusted to use timezones updated French translation fixed problem with loop ways in OSM graph coherency checking improved OSM floor number handling handle units in ele tags ferry icons (thanks Joel Haasnoot) mapbox streets tile layer is now the default complete Dutch translation 0.5.2 (2012-03-20) hop speed/distance checks, duplicate shape point filtering, etc. 0.5.1 (2012-03-16) more transit index features default agencyIDs now determined on a per-feed basis fixed fare overflow problem fixed bug in loop road turn conversion additional graphbuilder warnings and annotations fixed a batch of bugs found by fixbugs 0.5.0 (2012-03-09) stop codes, zones, and agency names in planner responses encapsulation of edge list modifications expanded edge and vertex type hierarchy use mapquest OSM server by default Turkish locale (thanks Hasan Tayyar Be\u015fik) German and Italian locales (thanks Gerardo Carrieri) bookmarkable trip URLs (thanks Matt Conway) elevator and OSM level support (thanks Matt Conway) BART/Muni fare service release and javadoc/apidoc publishing automation graph versioning based on Maven artifact version API for browsing graph internals improved stop linking optional island removal graphbuilder step and of course, lots of bugfixes 0.4.4 (2012-02-06) Release in anticipation of upcoming merges.","title":"Changelog"},{"location":"Changelog/#changelog","text":"The changelog list most feature changes between each release. The list is automatically created based on merged pull requests. Search GitHub issues and pull requests for smaller issues.","title":"Changelog"},{"location":"Changelog/#210-2022-03-17","text":"","title":"2.1.0 (2022-03-17)"},{"location":"Changelog/#notable-changes","text":"GBFS 2.2 is supported including \"form factors\" (bike, scooter, car) and floating vehicles (with no fixed station) Constrained Transfers (Netex interchanges / GTFS transfers.txt ) Transfers for bicycle and wheelchair users distinct from walking paths Support for GTFS-Flex v2 Support for frequency-based trips (GTFS frequencies.txt , does not exist in Netex) Many 1.5 features not fully implemented in 2.0 have been reintroduced Improved result quality relative to both 1.5 and 2.0: filtering of itineraries and selection of transfer points between routes Car and bicycle parking has been combined into vehicle parking (enhanced with real-time details like remaining parking spaces) New system for paging of routing results via cursor token Response times should be roughly stable since 2.0. Performance much improved over OTP1 for long searches, may be somewhat slower for short searches. Extremely depdendent on data set used, so test on your specific data. System integration tests for ongoing performance measurement","title":"Notable Changes"},{"location":"Changelog/#detailed-changes-by-pull-request","text":"Fix NullPointerException when a RealTime update do not match an existing TripPattern #3284 Support for versioning the configuration files #3282 Prioritize \"direct\" routes over transfers in group-filters #3309 Remove poor transit results for short trips, when walking is better #3331 GTFS Trips will by default not allow bikes if no explicit value is set #3359 . Improve the dynamic search window calculation. The configuration parameters minTransitTimeCoefficient and minWaitTimeCoefficient replace the old minTripTimeCoefficient parameter. #3366 Allow loops caused by turn restriction in street routes #3399 Apply turn restrictions when splitting edges. #3414 Add separate no-thru handling for bicycles #3410 Add German way property set #3359 Process OSM bicycle routes correctly #3359 Avoid turns across traffic on bicycles #3359 Remove request parameter driveOnRight and derive information from way property set #3359 Add basic support for routing using floating bikes #3370 Optimize which stops are used for transfers, using generalized-cost, wait-time and transfer priority. Partially implements #2788 Support for stay-seated and guaranteed transfers #3193 Fix reading of cached elevation files #3455 Added BikeRentalWithMostlyWalking filter #3446 Import GTFS-Flex v2 Flexible trips #3453 Add support for arriving at the destination with rented bicycles #3459 Allow IntersectionTraversalCostModel to be specified in the WayPropertySet #3472 Fix for traveling back in time when optimize transfers #3491 Transit reluctance per transit mode #3440 Allow the removal of P+R results consisting only of driving of walking #3515 Allow http headers to be specified for bike rental updaters #3533 Per-mode reluctance parameters are added so that itineraries with multiple modes may have varying reluctances. #3501 Add maxAreaNodes configuration parameter for changing an area visibility calculation limit (https://github.com/opentripplanner/OpenTripPlanner/issues/3534) Add maxAccessEgressDurationSecondsForMode to RoutingRequest #3560 Add bicycle safety report to report API #3563 Optimize Transfers performance issue #3513 Don't allow bicycle loops in A* #3574 Cancel individual stop on StopPattern instead of TripTimes #3575 Do not allow bicycle traversal on ways tagged with mtb:scale #3578 Changes to the StopTimes call #3576 Fix bug in optimize transfer service decorating path #3587 Remove non-GBFS bicycle rental updaters #3562 Remove possibility to import vehicle rental stations from OSM, make vehicle rental stations feed scoped #3601 When importing Netex, allow bicycles on ferries by default #3596 Safely catch some elevation interpolation exceptions #3412 Route not found in some conditions with boarding/alighting restrictions #3621 Load additional data from GBFS and expose it #3610 Allow transfers to use customizable request options #3324 Check boarding and alighting permissions in TransferGenerator #3641 Stoptimes should return tripId on the REST API. #3589 Handle non-symmetric transfers in RAPTOR #3634 . Order RAPTOR input data so that plans are deterministic #3580 Cost on transfer in Raptor #3617 Allow for combined NeTEx and GTFS data sources #3650 Generalized graph connectivity pruning #3426 Stop linking to area/platform edges obeys area boundaries and traverse modes #3201 Add service day mapping to REST API #3659 Generalized cost on transfer in Raptor #3629 Add two new filters for use within grouping filter #3638 Correct usage of boardSlackForMode / alightSlackForMode #3693 Do not parse pass-through information in GBFS mappers #3709 Vehicle rental updates #3632 add trolleybus & monorail support #3658 Do not create zero length StreetEdges #3716 Add pickup and dropoff booking info to REST API #3710 Use the whole duration of the filtered transit data for the raptor heuristic search #3664 Performance improvement for flex access/egress searches #3661 Add new routing errors for cases where all itineraries were filtered by post-processing #3628 Fix combination of flex access and constrained transfer #3726 Merge B+R and P+R functionality into vehicle parking #3480 Add cost to maximize wait-time and avoid back-travel in optimize transfers #3654 Calculate fares from itineraries not Raptor paths, calculate flex fares #3743 Logging first time instance reports it is ready to use #3733 Allow limiting the used vehicle rentals and parkings #3746 Add support for car and scooter rental modes #3706 Extra stop priority cost in optimized transfer service #3731 Remove old visibility graph library from walkable area builder #3753 Update GtfsRealtime and include severity, effect and cause from GTFS RT #3747 Handle miscellaneous service as BUS instead of crashing build #3755 Update all timers to micrometer instances #3744 Bugfix: ClassCastException when planning flex routes #3762 Add mode from parent StopPlace for Quays in Netex mapper #3751 Minor performance improvements #3767 Parallelise computing of trip pattern geometries #3766 Add flex stop to TripTimes, return geometries in GraphQL API #3757 Fix checking allowed boarding/alighting for unscheduled flex trips #3782 Calculating number of days to use in StopTimes-request #3742 Walkable area builder improvements #3765 Remove hardcoded alighting/boarding on first/last stop #3784 Add support for include-file-directive in config files. #3771 Remove build parameter 'useTransfersTxt' #3791 Add cursor-based paging #3759 Data overlay sandbox feature #3760 Add support for sandboxed realtime vehicle parking updaters #3796 Add reading and exposing of Netex submodes #3793 Fix: Account for wait-time in no-wait Raptor strategy #3798 Read in flex window from Netex feeds #3800 Fix NPE when routing on a graph without transit data. #3804 Read leg mode from trip, instead of route #3819 Use API mapping in snapshot tests #3823 Store stop indices in leg and use them to simplify logic in TripTimeShortHelper #3820 Include all trips in stopTimesForStop #3817 Store all alerts and add support for route_type and direction_id selectors #3780 Remove outdated realtime-update from TimetableSnapshot #3770 Contributing Guide #3769 OTP support for NeTEx branding #3829 Not allowed transfers and support for GTFS transfer points #3792 Simple implementation of horizontally moving elevators (Elevator way) #3750 fix: Avoid mixed path separators on Windows in Park API test #3845 Filter out elevator ways that are also implicit areas #3850 Dynamically compute additional search days #3824 Mode & submode filter for NeTEx Service Journeys #3844 Return correct heuristic values, when constrained transfers is turned on #3841 Adjust search window dynamically to fit the number of itineraries #3828 Implement minimum transfer time from GTFS transfers.txt #3830 Fix number format exception for elevator duration parsing OSM data #3871 Include generalizedCost in the optimized transfers wait-time cost #3864 Expose maxStopToShapeSnapDistance as build-config.json parameter #3874 Implement in-seat transfers per GTFS draft #3831 Add stairsTimeFactor to StreetEdge #3832 Make sure we keep the itinerary with the least number of transfers when grouping the itineraries #3833 Don't expect every pattern in a route to have the specified stop with constrained transfers #3868 Add support for creating constrained transfers from real-time generated patterns #3878 Account for stay seated transfers when calculating the number of transfers #3888 Add Hungarian translation #3861 Add support for \"via\" in NeTEx headsigns #3883 NeTEx mapping to StopTime.timepoint #3898 Optimize RAPTOR trip search by pre-calculating arrival/departure time arrays #3919 Make turn restrictions faster and thread-safe by moving them into StreetEdge #3899 Add routing using frequency trips #3916 Remove ET realtime override code #3912 Allow traversal of pathways without traversal time, distance or steps #3910","title":"Detailed changes by Pull Request"},{"location":"Changelog/#200-2020-11-27","text":"See the OTP2 Migration Guide on changes to the REST API. Sandbox for experimental features #2745 Bugfix for Missing platforms for stops in GTFS import causes a NPE #2804 Remove extra Djikstra implementations Remove redundant LineStrings in order to save memory #2795 NeTEx import support #2769 New Transit search algorithm, Raptor, replaces the AStar for all transit searches. Added NeTEx notices #2824 Make transfers and access/egress use effectiveWalkDistance to take slopes into account #2857 Add MultiModalStation and GroupOfStations to OTP model and added these to the NeTEx import #2813 Combined OSM loaders, removing several rarely used ones #2878 New Java Code Style (part of #2755 ) Cleanup and rename Graph Builder Annotations, now Data Import Issues #2871 Bugfix for graph building crashing on unsupported modes #2899 Add command line parameter for building partial graphs #2583 Refactor GenericLocation/AStar/RoutingContext to allow multiple start vertices #2887 New Transit search algorithm, Raptor, replaces the AStar for all transit searches. Update only the relevant parts of the TransitLayer each time an update is applied #2918 Ability to switch off the fare service #2912 . Limit the transit service period #2925 . Removed unwanted cost added for wait time between access and transit with RangeRaptor #2927 Dynamic search parameters, calculate raptor search-window when needed. #2931 Support for next/previous paging trip search results #2941 Fix mismatch in duration for walk legs, resulting in negative wait times #2955 NeTEx import now supports ServiceLinks #2951 Also check TripPatterns added by realtime when showing stoptimes for stop #2954 Copy geometries from previous TripPattern when realtime updates result in a TripPattern being replaced #2987 Support for the Norwegian language. Update pathways support to official GTFS specification #2923 Support for XML (de-)serialization is REMOVED from the REST API #3031 Refactor how to specify access/egress/direct/transit modes in the internal model and the Transmodel API #3011 Make agency id feed scoped #3035 Refactor kiss and ride to a more general car pickup mode #3063 Map NeTEx publicCode to OTP tripShortName and NeTEx private code to OTP internalPlanningCode #3088 Add MQTT transport for the GTFS-RT trip update updater #3094 Add FinlandWayPropertySetSource #3096 Map NeTEx publicCode to OTP tripShortName and NeTEx private code to OTP internalPlanningCode #3088 Reading and writing files(CONFIG, GRAPH, DEM, OSM, GTFS, NETEX, DATA_IMPORT_ISSUES) is changed. All files, except configuration files, are read from a data source. We support Google Cloud Storage and the local file system data sources for now, but plan to add at least support for AWS S3 #2891 Remove AlertPatcher #3134 Update DebugOutput to match new routing phases of OTP2 #3109 Filter transit itineraries with relative high cost #3157 Fix issue with colliding TripPattern ids after modifications form real-time updaters #3202 Fix: The updater config type is unknown: gtfs-http #3195 Fix: Problem building and loading the GTFS file in San Fransisco Bay Area #3195 Fix: The BusRouteStreetMatcher and TransitToTaggedStopsModule graph builder modules are not run if the graph is build in two steps, and add progress tracker to BusRouteStreetMatcher. #3195 Improvement: Insert project information like Maven version number into configuration files. #3254 Added pathway FeedScopedId as the route text to trip plan responses. #3287","title":"2.0.0 (2020-11-27)"},{"location":"Changelog/#ported-over-from-14-and-15","text":"Add application/x-protobuf to accepted protobuf content-types #2839 Make OTP run on Java 11 #2812 Fixes surefire test failure during build #2816 Disable linking from already linked stops #2372 Add Way Property Set for the UK #2818 Remove Open Traffic prototype code #2698 Docs: improve configuration documentation Update onebusaway-gtfs to latest version from OBA project #2636 Remove the coupling to OneBusAway GTFS within OTP's internal model by creating new classes replacing the external classes #2494 Allow itineraries in response to be sorted by duration #2593 Fix reverse optimization bug #2653, #2411 increase GTFS-realtime feeds size limit from 64MB to 2G #2738 Fix XML response serialization #2685 Refactor InterleavedBidirectionalHeuristic #2671 Add \"Accept\" headers to GTFS-RT HTTP requests #2796 Fix minor test failure against BANO geocoder #2798 Fix frequency bounds checking #2540 Remove dependency on Conveyal jackson2-geojson Changed calculation of slope costs #2579 Replace Java built in serialization with faster Kryo #2681 Support OSM highway=razed tag #2660 Add bicimad bike rental updater #2503 Add Smoove citybikes updater #2515 Allow big GTFS-realtime feeds by increasing protobuf size limit to 2G #2739 Cannot transfer between stops at exactly the same location #2371 Improve documentation for mode routing parameter #2809 Switched to single license file, removing all OTP and OBA file license headers","title":"Ported over from 1.4 and 1.5"},{"location":"Changelog/#13-2018-08-03","text":"Fix stop linking to only one edge of platform #2472 Log and allow changing number of HTTP handler threads Update Dutch base fare from 89 to 90 cents #2608 Add Dutch fare service #2571 Revise unit tests to use less memory Run all graph updater setup methods sequentially #2545 Allow vehicle rental systems with cars (stopgap parameter on bike rental) Bump R5 version to get newer gtfs-lib and FST serialization Move stopClusterMode parameter from routing config to build config #2558 Update encrypted Maven artifact signing key (it expired) Clean up logging Remove/update deprecated HTTPClient, add missing SSL ciphers #2451 Make maxTransfer options configurable through scripting API #2507 Fix scripts when entity IDs contain colons #2474 Add HTML report for stops more than 20m from linked road #2460 Update fares in NycFareServiceImpl #2466 Compact legs NPE fix #2449 #2490 Docs: elevation data configuration, USGS DEM files Docs: Update list of deployments Docs: API, list of deployments, usage stats and tutorials Docs: Update leadership committee listing following Boston Summit Docs: Update OTP logo (Thanks Kate Chanba!)","title":"1.3 (2018-08-03)"},{"location":"Changelog/#12-2017-09-18","text":"Add support for consuming GBFS bike-rental availability feeds. #2458 Add GBFS configuration example Add flag for including requested start/end time in maxHours in planner API. #2457 Add maxTransferDistance graph builder parameter Add option for filtering non-pickup stops in TransitIndex stop times functions. #2377 Support foot/bicycle=discouraged OSM tag. #2415 Improve linking of transit platforms to connecting access ways. #2422 / #2428 Fix bug when building graph with parent station transfers. #2404 / #2410 Fix bugs in park and ride search. #2424 Support different stop ID formats in field trip module Update URL in BANO geocoding module. #2438 / #2439 Add more debug information related to trips matching using GTFS-RT feed. #2432 Update default PATH_NOT_FOUND message to new wording developed w/ TriMet. #2355 Update Travis build configuration to not attempt GPG operations. #2441 Fix javadoc URL in scripting documentation. #2437 Automatically link to GitHub issues in Changelog. #2426 Expose FeedInfo objects in the Index API #2456 Changes to Puget Sound region fare calculation #2484 Fix coordinatates when clustering by parent station #2447 Allow setting OSM Way Properties from build-config.json #2389 Optionally compact (\"reverse-optimize\") results with complete reverse search #2449 Add updater for urbaninfrastructure city bikes #2448 Miscellaneous documentation updates","title":"1.2 (2017-09-18)"},{"location":"Changelog/#11-2017-03-16","text":"Deploy to Sonatype OSSRH and Maven Central Documentation updates including repo links New router-config stopClusterMode: clustering by parent station or geography #2364 Spanish and Portuguese UI Translations In TimeSurface API, serialize travel times to every point when detail=true Make OSM highway=corridor pedestrian routable Fix GraphIndex.stopTimesForStop to search on the request day rather than now Update GraphQL to latest version and improve support for complex arguments #2367 Add support for operationName to the graphql endpoint Fix findClosestStopsByWalking, properly set RoutingContext Fixed major routing problem where dead-end SimpleTransfers blocked walking paths #2414 Created Github issue template Avoid negative elevation figures: Compute ellipsoid-geoid offset and optionally apply to elevation calculations #2301 Fix VCub bike share updater using new API variable names. Fix spurious different-day warning #2399 Shutdown hook to gracefully shut down Grizzly #2384 Added headsign attribute for stoptimes in GraphQL #2224 Allow Cars on highway=*;bicycle=designated #2374 Expose PruneFloatingIslands parameters in build-config.json Lazy initialization of stop clusters where needed Include Agency/Route branding in responses Include turn-by-turn walking directions for transfer legs #1707 Output error when edge lengths are negative, and set them to 1mm Add disableAlertFiltering API flag #2351 Do not show arrival times at terminal stops in stop time viewer #2357 Index API now returns stop information URL, enabling hyperlinks in trip viewer #2352 Remove all unused model classes for index API #1301 Apply an interlining fix from 0.10 branch Allow quoted search phrases in the Lucene search #2279 Re-implement maxHours filter #2332 Properly set wheelchairAccessible on area edges Fixed file URL in test #2339 Add details field to fares, listing which legs each fare applies to #1699","title":"1.1 (2017-03-16)"},{"location":"Changelog/#10-2016-09-09","text":"Fix problem with missing embedded router-configs. Check whether trips have been banned when applying in-seat transfers (interlining). Load embedded config for existing graphs on disk. Apply max walk distance to transfers, not just initial and final walk. Remove Conveyal tiles from client (which was getting expensive), add free Carto/MapZen tiles. Fixed headsigns: in itineraries, headsign for a leg used to always be the last stop. Updated default map tile sets in the client because Mapquest is no longer gratis. Fix problem with empty list ??? #1873 Rewrite of intermediate places handling in GraphPathFinder. Original request is cloned for each intermediate path. Routes in GraphQL API Change \"type\" to \"mode\" and add \"type\" as route type to Route for GraphQL Add effective end date to alerts (from HSL). Rutebanken Citybike bike share. Correct TPEG transport modes TPEG 401 and 402 to be \"subway\". Ignore exceptions caused by errors in OSM linear rings. Updated to version 2.18 of Jersey to fix hanging threads in Grizzly. Removed confusing \"Busish\" and \"Trainish\" pseudo-modes. FareService for Seattle: allow specifying fares in GTFS instead of hard-coding them in Java. Senior/youth fare prices are given in an extra column in fare attributes. Per-trip fares are taken into consideration when calculating fares in this region. Update new linker to link to transitStops if no streets are found. Show the name supplied in the request for the origin/destination points in the response. Throw a trivialPath exception if start/end point are on the same edge. Switch to only use the new SimpleStreetLinker, even for search start and end points. Completely removed old linker classes. Changes for proper handling of wheelchairs and bicycles at start and end points. Properly handle null timetableSnapshots when there is no real-time data.","title":"1.0 (2016-09-09)"},{"location":"Changelog/#020-2016-06-10","text":"Re-enabled Enunciate, which works properly with OTP now. This means we have auto-generated API docs. Make headsign and block ID visible in the Stop Viewer. NYC fare service: filter out non-NYC agencies. Optionally log all requests to a file. Make max distance for in-seat transfers (interlining) configurable. Previously it was hardcoded at 200m. Polish translation for web client. Introduced bikeShareId in trip plans (separate from stopIds). Support for ShareBike bike rental system in Oslo, Drammen, Trondheim, Milan, Barcelona and Mexico City among others. Changed default waitAtBeginningFactor and timeouts. Show alert in client when itinerary departure date differs from search date. Exposed realtimeState in GraphQL responses. Fixed a routerConfig NullPointerException. Support for San Francisco bike share from leoromanovsky. GraphQL API for most transit data from hannesj. Disallow shortcuts through multiple StationStopEdges. Add support for airplanes (from HSL) Major simplification and correction of the longDistance heuristic, removed obsolete runState.options.heuristicWeight. Return default OSM level for ways that are not found. Profile routing: use earliest arrival objective function on-street, properly handle TrivialPathExceptions. Fixed ID matching when applying AlertPatches. Fixed banning of agencies in multi agency feeds. More coherent handling of feed IDs as scope for GTFS IDs. Added transit service start and end timestamps to BuildInfo. Handle embeded router configuration for POSTed graphs and zips for building. Simplified router-config handling. Properly lazy-initialize profile routing stopClusters. Added stop clusters to the Index API. Completely removed the ill-advised path parser system, which was too clever for its own good. Sort itineraries by total travel time rather than in-transit time. Rental bikes: allow loading generic KML. Removed the experimental TransportNetwork classes, which shared no code with the rest of OTP and were duplicated in the R5 project. There are still some elements that can be cleaned out when only R5 is used by Conveyal's analysis system. The broker code in OTP is now able to start up R5 workers for Analyst. Use the Conveyal fork of the OBA GTFS loader, so that we can add our own extensions to GTFS. Updated docs to offer Conveyal Maven repo as a place to get prebuilt OTP.","title":"0.20 (2016-06-10)"},{"location":"Changelog/#0190-2016-05-25","text":"TODO","title":"0.19.0 (2016-05-25)"},{"location":"Changelog/#0180-2015-05-29","text":"Ability to load elevation from projected GeoTIFF Clarified axis order for unprojected GeoTIFFs Stop viewer and car distance fixed in client Server-side localization improvements Proper names for intersections JSON config for loading bikeshare and park and ride lots from OSM More ways to fetch isochrones Fixed frequency-based routing in repeated RAPTOR Calculate graph envelope at build time not runtime Fixed slow excessive HashGrid search Readthedocs documentation updates","title":"0.18.0 (2015-05-29)"},{"location":"Changelog/#0170-2015-05-14","text":"Allow fetching arrivals/departures over a particular time window Completely new spatial analysis implementation: repeated RAPTOR search at every minute in a departure time window More reproducible spatial analysis results across similar graphs, thanks to more consistent splitting of streets etc. Sigmoidal accessibility metric rolloff (rather than hard-edged cutoff) Correction of equirectangular projection used in spatial analysis Improved, simplified, deterministic linking of stops into the street network","title":"0.17.0 (2015-05-14)"},{"location":"Changelog/#0160-2015-05-07","text":"Several improvements to OSM tag based traversal permissions Scripting documentation Accept TIFF files whose names end in .tiff not .tif Store distances (not times) in Analyst Samples to allow variable walk speed Fixed bug in graph auto-scanning Fixed client-side bug in first and last itinerary buttons OTP startup scripts no longer use wildcards Transit, bike rental, and parking linking done in one module Elevation tiles for the US can be fetched from Amazon S3 Bumped language level to Java 8 (lambda functions, method references, collection streams)","title":"0.16.0 (2015-05-07)"},{"location":"Changelog/#0150-2015-04-14","text":"Fare module for Seattle JSON fare module and OSM street naming configuration Significant improvements to speed and result quality of Profile Routing Support for added and modified GTFS-RT trips (thanks Jaap Koelewijn of DAT Mobility and Plannerstack) Detailed edge lists in profile routing responses (for Transitive.js) Support for multiple access modes including bike rental in profile routing Fixes to graph reloading via web API Improved comments in code and documentation of PointSets Pulled MapDB GTFS loader out into a separate repo Working artifact version was 0.15.0-SNAPSHOT instead of 1.0.0-SNAPSHOT (anticipating frequent point releases)","title":"0.15.0 (2015-04-14)"},{"location":"Changelog/#0140-2015-03-28","text":"JSON configuration of graph building and routers Began moving documentation (including this changelog) into the OTP repo and rewriting it page by page. It is built statically from Markdown using mkdocs and published on readthedocs. Street edge lists and bike rental station IDs in profile routing results (allows better rendering) Improved correctness of profile routing Qualified modes including rented bikes work in profile routing Simplification of qualified mode sets Elevation models are loaded from TIFFs in graph directory Tiles for differences between TimeSurfaces Restructured relationship between Routers and Graphs Various changes enabling use of Analyst features in a cluster computing environment. Removed several single-implementation interfaces, factories, services and other superfluous abstractions Various client fixes related to the transit index API Revised nearby stops logic and transfer generation to eliminate useless transfer edges New Index API endpoints for geometries, transfers etc. Isochrone generation fixes Default mode of operation is now \u201clong distance mode\u201d Process for finding alternative routes is now based on banning trips and retrying, while reusing the heuristic Optimization objective functions are swappable, and have been simplified and corrected All client Javascript librariess are now pulled from a CDN Dutch BAG and French BANO geocoders Bus to street matching improvements Complete MapDB based GTFS and OSM loader libraries (will become separate projects, not yet connected to OTP graph builder) API documentation generation working again Disable some time consuming graph building steps by default Finnish and Swedish translations Subway-specific JSON configuration options (street to platform time) Realtime fetch / streaming configurable via JSON Stairs reluctance is much higher when carrying a bike Graph visualizer routing progress animates when a search is triggered via the web API Assume WGS84 (spherical distance calculations) everywhere Removed custom motor vehicle (which was unmaintained and not documented) Ability to poll for bike rental locations only once at startup Stoptimes are fetched for a specific service day in index API Bicycle triangle support in profile routing Proper handling of multiple access modes with different speeds in profile routing Command line option to output OTP's version","title":"0.14.0 (2015-03-28)"},{"location":"Changelog/#0130-2014-12-05","text":"Detect apparent errors in GTFS interlining Long distance mode: use a pure weight-based state comparison, and use trip-banning retrying logic to get multiple paths. This compromises correctness somewhat but brings search times back within reason for large regional graphs. Also, we create significantly less SimpleTransfers. Progress on GTFS reading and writing library (not yet used by OTP). Bug fixes for tiny street edges, time zones. Deployment of artifacts to maven.conveyal.com via S3. Handle park and ride lots that have roads running through them, but don't share nodes with those roads.","title":"0.13.0 (2014-12-05)"},{"location":"Changelog/#0121-2014-11-17","text":"Fixed threading problem caused by graph visualization instrumentation #1611 Fixed 'unconnected areas' infinite loop #1605","title":"0.12.1 (2014-11-17)"},{"location":"Changelog/#0120-2014-11-11","text":"Graph building from zipball of data sent over the wire OTP-specific GTFS loader library with error checking and recovery Bike and car park and ride improvements Stable hash codes for stop patterns and trips Bicycle safety and wheelchair access tile generators Newer versions of Grizzly, Jackson, and Enunciate (documentation generation now works) Redesigned HashGrid spatial index Significant reduction in graph size in memory and on disk Improved internationalization Ability to pause and step search in graph visualizer Additional graph visualizer modes for spotting overbranching Movement toward 1.0 web services API Kiss and Ride Complete removal of Spring Complete removal of Lombok CORS replaces JSONP Pointset classes for dealing with one-to-many calculations and accessibility calculations Experimental \"Profile routing\" which enumerates reasonable route combinations over a time range rather than exact itineraries Single-module Maven build (complete elimination of submodules) Alternate Gradle build script full internationalization of the map-based web client basic Lucene-based built-in geocoder","title":"0.12.0 (2014-11-11)"},{"location":"Changelog/#0110-2014-03-24","text":"Built-in HTTP server layer, making it possible to distribute OTP as a standalone JAR \"Long-distance\" mode for large graphs, including bidirectional goal direction heuristic. Simplified Maven project structure with less submodules GTFS-RT trip update support, including streaming incremental data, which directly affects route optimization","title":"0.11.0 (2014-03-24)"},{"location":"Changelog/#0100-2014-03-18","text":"This release was made to consolidate all the development that had occurred with a 0.9.x-SNAPSHOT Maven version. The changes were very significant and it was not appropriate to tag them as a minor bugfix release after the 0.9 tag. Though this release was performed at the same time as 0.11.0, it represents a much earlier stage in the development of OTP.","title":"0.10.0 (2014-03-18)"},{"location":"Changelog/#070-2012-04-29","text":"Bike rental support (thanks Laurent Gr\u00e9goire) Realtime bike rental availability feed support Updated to new version of One Bus Away GTFS/CSV, fixing timezone and string interning issues (thanks Brian Ferris) Bugfixes in area routing, OSM loading, nonexistant NED tiles, route short names Dutch and French language updates Catch negative edge weights due to broken GTFS Significant (10-20%) speedup by moving a field into StateData (thanks Laurent Gr\u00e9goire)","title":"0.7.0 (2012-04-29)"},{"location":"Changelog/#060-2012-04-25","text":"area routing more lenient parsing of times new directions icon set with SVG sources (thanks Laurent G)","title":"0.6.0 (2012-04-25)"},{"location":"Changelog/#054-2012-04-06","text":"catch 0 divisors in NED builder, preventing NaN propagation to edge lengths avoid repeated insertion of edges into edge lists, which are now threadsafe edge sets identity equality for edges bounding box check in UnifiedCoverage (speed up NED loading) Dutch API messages elevation override fix less verbose graph builder (be sure to check graphbuilder annotation summary) replacement streets given names geocoder bug fix (thanks Laurent Gregoire) git commit IDs included in MavenVersion, allowing clearer OTP/Graph version mismatch warnings fix problems with immediate reboarding and unexpected edges in itinerary builder favicon (thanks Joel Haasnoot) Legs in API response have TripId (for realtime information) Polish locale (thanks \u0141ukasz Witkowski) transfers.txt can define station paths, entry costs for stations allow loading a base graph into graphbuilder instead of starting from scratch","title":"0.5.4 (2012-04-06)"},{"location":"Changelog/#053-2012-03-23","text":"GTFS loader now loads feeds one-at-a-time, allowing per-feed configuration half-written graph files are now deleted on graph build error DST issue OTP-side fixes, tests adjusted to use timezones updated French translation fixed problem with loop ways in OSM graph coherency checking improved OSM floor number handling handle units in ele tags ferry icons (thanks Joel Haasnoot) mapbox streets tile layer is now the default complete Dutch translation","title":"0.5.3 (2012-03-23)"},{"location":"Changelog/#052-2012-03-20","text":"hop speed/distance checks, duplicate shape point filtering, etc.","title":"0.5.2 (2012-03-20)"},{"location":"Changelog/#051-2012-03-16","text":"more transit index features default agencyIDs now determined on a per-feed basis fixed fare overflow problem fixed bug in loop road turn conversion additional graphbuilder warnings and annotations fixed a batch of bugs found by fixbugs","title":"0.5.1 (2012-03-16)"},{"location":"Changelog/#050-2012-03-09","text":"stop codes, zones, and agency names in planner responses encapsulation of edge list modifications expanded edge and vertex type hierarchy use mapquest OSM server by default Turkish locale (thanks Hasan Tayyar Be\u015fik) German and Italian locales (thanks Gerardo Carrieri) bookmarkable trip URLs (thanks Matt Conway) elevator and OSM level support (thanks Matt Conway) BART/Muni fare service release and javadoc/apidoc publishing automation graph versioning based on Maven artifact version API for browsing graph internals improved stop linking optional island removal graphbuilder step and of course, lots of bugfixes","title":"0.5.0 (2012-03-09)"},{"location":"Changelog/#044-2012-02-06","text":"Release in anticipation of upcoming merges.","title":"0.4.4 (2012-02-06)"},{"location":"Codestyle/","text":"Codestyle We use the following code conventions for Java and JavaScript . Java The OpenTripPlanner Java code style is revised in OTP2. We use the Google Java style guide, with a few modifications. Here is the original Google style guide: https://google.github.io/styleguide/javaguide.html IntellJ Code Style formatter If you use IntelliJ, import the provided intellij-code-style.xml . Open the Preferences from the menu and select Editor > Code Style . Then import the code-style xml document. Configure Scheme using Import Scheme > IntelliJ IDEA code style XML . Note that the IntelliJ formatter will not always format the code according to the coding standard. It struggle to do the line breaks properly. Hence, use it to format new code and to rearrange members, then manually fix any mistakes. Other IDEs We do not have support for other IDEs at the moment. If you use another editor and make one please feel free to share it. Code Style Our style differs in the following ways from the Google guide. Each point references the section of the original document that is modified. 4.5.1 We apply the same line breaking rules to parentheses as to curly braces. Any time the contents of the parentheses are not all placed on one line, we insert a line break after the opening paren, and place the closing one at the beginning of a new line. // int value = calculateSomeValue ( arg1 , arg2 , arg3 ); // Also Ok int value = calculateSomeValue ( arg1 , arg2 , arg3 ); // Avoid this int value = calculateSomeValue ( arg1 , arg2 , arg3 ); // and this int value = calculateSomeValue ( arg1 , arg2 , arg3 ) 4.6.1 We insert double empty lines before comments that introduce the highest level groupings of methods or fields within a class, for example /* private methods */ , /* symbolic constants */ . public foo() { } /* private methods */ private bar() ... 4.8.3 the final example is not allowed. All opening brackets or parens should be on the same line as the identifier or other construct that they follow. 4.8.5 All annotations on classes, fields, and methods should always have a newline after the last annotation, i.e. they should not appear on the same line as the identifier they annotate, and should only appear on the same line as other annotations. Series of multiple annotations may each appear on a separate line, or may all be grouped together on the same line. 4.8.6.1 On multi-line /* ... */ comments we do not begin the intermediate lines with asterisks * . 5.2.8 We only use single capital letters (single characters) for generic type parameters. 7.2 We do not begin Javadoc with summary fragments. This is because will no longer generate and publish Javadoc pages, the Javadoc will only be used within IDEs. 7.3.1 The item in the original document implies that trivial Javadoc like /** Returns the canonical name. */ should still be included. There is almost always something more to explain to someone who is seeing this method or class for the first time. Notes on breaking lines The eye scan the code much faster if there is less need of horizontal movement, so formatting the code becomes a balance on how long the lies should be and how to break it. Try to brake the code at the outer-most scope aligning expressions with the same scope. Consider to chop down all expressions with the same scope and indent them, do not align code further to the right than the indentation margin. // Conider this code: xxxx xxx = xxx + xxx * xxx - ( x.xxxx().xx().xxx() - xxx ) / xxx; // Break tha line as every operator, pharenphasis and method chanin. // This is a bit extrem, but illustrates the correct way to break the lines. xxxx xxx = xxx + xxx * xxx - ( x.xxxx() .xx() .xxx() - xxx ) / xxx ; // Prefered compromize xxxx xxx = xxx + xxx * xxx - ( x.xxxx().xx().xxx() - xxx ) / xxx // or xxxx xxx = xxx + xxx * xxx - ( x.xxxx().xx().xxx() - xxx ) / xxx // Right alignment not allowed xxxx xxx = xxx + xxx * xxx; // use indentation margin instead xxxx xxx = xxx + xxx * xxx; Sorting class members Some of the classes in OTP have a lot of fields and methods. Keeping members sorted reduce the merge conflicts. Adding fields and methods to the end of the list will cause merge conflicts more often than inserting methods and fields in an ordered list. Fields and methods can be sorted in \"feature\" sections or alphabetically, but stick to it and respect it when adding new methods and fields. The provided formatter will group class members in this order: Getter and Setter methods are kept together Overridden methods are kept together Dependent methods are sorted in a breadth-first order. Members are sorted like this: static final fields static fields static initializer final fields fields class initializer (avoid using it) Constructor static methods static getter and setters methods getter and setters enums interfaces static classes classes Each section of members are sorted by visibility: \u00b4public\u00b4 package private \u00b4protected\u00b4 \u00b4private\u00b4 JavaDoc Guidlines What to put in Javadoc: - On methods: - Side effects on instance state (is it a pure function) - Contract of the method - Input domain for which the logic is designed - Range of outputs produced from valid inputs - Is behavior undefined or will fail when conditions are not met - Are null values allowed as inputs - Will null values occur as outputs (what do they mean) - Invariants that hold if the preconditions are met - Concurrency - Is method thread-safe - Usage constraints for multi-threaded use - On classes: - Initialization and teardown process - Can instance be reused for multiple operations, or should it be discarded - Is it immutable or should anything be treated as immutable - Is it a utility class of static methods that should not be instantiated JavaScript As of #206, we follow Crockford's JavaScript code conventions . Further guidelines include: All .js source files should contain one class only Capitalize the class name, as well as the source file name (a la Java) Include the namespace definition in each and every file: otp.namespace(\"otp.configure\"); Include a class comment. For example, /** * Configure Class * * Purpose is to allow a generic configuration object to be read via AJAX/JSON, and inserted into an * Ext Store * The implementation is TriMet route map specific...but replacing ConfigureStore object (or member * variables) with another implementation, will give this widget flexibility for other uses beyond * the iMap. * * @class */ Note: There is still a lot of code following other style conventions, but please adhere to consistent style when you write new code, and help clean up and reformat code as you refactor.","title":"Codestyle"},{"location":"Codestyle/#codestyle","text":"We use the following code conventions for Java and JavaScript .","title":"Codestyle"},{"location":"Codestyle/#java","text":"The OpenTripPlanner Java code style is revised in OTP2. We use the Google Java style guide, with a few modifications. Here is the original Google style guide: https://google.github.io/styleguide/javaguide.html","title":"Java"},{"location":"Codestyle/#intellj-code-style-formatter","text":"If you use IntelliJ, import the provided intellij-code-style.xml . Open the Preferences from the menu and select Editor > Code Style . Then import the code-style xml document. Configure Scheme using Import Scheme > IntelliJ IDEA code style XML . Note that the IntelliJ formatter will not always format the code according to the coding standard. It struggle to do the line breaks properly. Hence, use it to format new code and to rearrange members, then manually fix any mistakes.","title":"IntellJ Code Style formatter"},{"location":"Codestyle/#other-ides","text":"We do not have support for other IDEs at the moment. If you use another editor and make one please feel free to share it.","title":"Other IDEs"},{"location":"Codestyle/#code-style","text":"Our style differs in the following ways from the Google guide. Each point references the section of the original document that is modified. 4.5.1 We apply the same line breaking rules to parentheses as to curly braces. Any time the contents of the parentheses are not all placed on one line, we insert a line break after the opening paren, and place the closing one at the beginning of a new line. // int value = calculateSomeValue ( arg1 , arg2 , arg3 ); // Also Ok int value = calculateSomeValue ( arg1 , arg2 , arg3 ); // Avoid this int value = calculateSomeValue ( arg1 , arg2 , arg3 ); // and this int value = calculateSomeValue ( arg1 , arg2 , arg3 ) 4.6.1 We insert double empty lines before comments that introduce the highest level groupings of methods or fields within a class, for example /* private methods */ , /* symbolic constants */ . public foo() { } /* private methods */ private bar() ... 4.8.3 the final example is not allowed. All opening brackets or parens should be on the same line as the identifier or other construct that they follow. 4.8.5 All annotations on classes, fields, and methods should always have a newline after the last annotation, i.e. they should not appear on the same line as the identifier they annotate, and should only appear on the same line as other annotations. Series of multiple annotations may each appear on a separate line, or may all be grouped together on the same line. 4.8.6.1 On multi-line /* ... */ comments we do not begin the intermediate lines with asterisks * . 5.2.8 We only use single capital letters (single characters) for generic type parameters. 7.2 We do not begin Javadoc with summary fragments. This is because will no longer generate and publish Javadoc pages, the Javadoc will only be used within IDEs. 7.3.1 The item in the original document implies that trivial Javadoc like /** Returns the canonical name. */ should still be included. There is almost always something more to explain to someone who is seeing this method or class for the first time.","title":"Code Style"},{"location":"Codestyle/#notes-on-breaking-lines","text":"The eye scan the code much faster if there is less need of horizontal movement, so formatting the code becomes a balance on how long the lies should be and how to break it. Try to brake the code at the outer-most scope aligning expressions with the same scope. Consider to chop down all expressions with the same scope and indent them, do not align code further to the right than the indentation margin. // Conider this code: xxxx xxx = xxx + xxx * xxx - ( x.xxxx().xx().xxx() - xxx ) / xxx; // Break tha line as every operator, pharenphasis and method chanin. // This is a bit extrem, but illustrates the correct way to break the lines. xxxx xxx = xxx + xxx * xxx - ( x.xxxx() .xx() .xxx() - xxx ) / xxx ; // Prefered compromize xxxx xxx = xxx + xxx * xxx - ( x.xxxx().xx().xxx() - xxx ) / xxx // or xxxx xxx = xxx + xxx * xxx - ( x.xxxx().xx().xxx() - xxx ) / xxx // Right alignment not allowed xxxx xxx = xxx + xxx * xxx; // use indentation margin instead xxxx xxx = xxx + xxx * xxx;","title":"Notes on breaking lines"},{"location":"Codestyle/#sorting-class-members","text":"Some of the classes in OTP have a lot of fields and methods. Keeping members sorted reduce the merge conflicts. Adding fields and methods to the end of the list will cause merge conflicts more often than inserting methods and fields in an ordered list. Fields and methods can be sorted in \"feature\" sections or alphabetically, but stick to it and respect it when adding new methods and fields. The provided formatter will group class members in this order: Getter and Setter methods are kept together Overridden methods are kept together Dependent methods are sorted in a breadth-first order. Members are sorted like this: static final fields static fields static initializer final fields fields class initializer (avoid using it) Constructor static methods static getter and setters methods getter and setters enums interfaces static classes classes Each section of members are sorted by visibility: \u00b4public\u00b4 package private \u00b4protected\u00b4 \u00b4private\u00b4","title":"Sorting class members"},{"location":"Codestyle/#javadoc-guidlines","text":"What to put in Javadoc: - On methods: - Side effects on instance state (is it a pure function) - Contract of the method - Input domain for which the logic is designed - Range of outputs produced from valid inputs - Is behavior undefined or will fail when conditions are not met - Are null values allowed as inputs - Will null values occur as outputs (what do they mean) - Invariants that hold if the preconditions are met - Concurrency - Is method thread-safe - Usage constraints for multi-threaded use - On classes: - Initialization and teardown process - Can instance be reused for multiple operations, or should it be discarded - Is it immutable or should anything be treated as immutable - Is it a utility class of static methods that should not be instantiated","title":"JavaDoc Guidlines"},{"location":"Codestyle/#javascript","text":"As of #206, we follow Crockford's JavaScript code conventions . Further guidelines include: All .js source files should contain one class only Capitalize the class name, as well as the source file name (a la Java) Include the namespace definition in each and every file: otp.namespace(\"otp.configure\"); Include a class comment. For example, /** * Configure Class * * Purpose is to allow a generic configuration object to be read via AJAX/JSON, and inserted into an * Ext Store * The implementation is TriMet route map specific...but replacing ConfigureStore object (or member * variables) with another implementation, will give this widget flexibility for other uses beyond * the iMap. * * @class */ Note: There is still a lot of code following other style conventions, but please adhere to consistent style when you write new code, and help clean up and reformat code as you refactor.","title":"JavaScript"},{"location":"Configuration/","text":"Configuring OpenTripPlanner Note: if you are familiar with OTP1 configuration and are migrating to OTP2, please read the OTP2 Migration Guide to learn what has changed. Base Directory On the OTP2 command line you must always specify a single directory after all the switches. This tells OTP2 where to look for any configuration files. By default OTP will also scan this directory for input files to build a graph (GTFS, OSM, elevation, and base street graphs) or the graph.obj file to load when starting a server. A typical OTP2 directory for a New York City graph might include the following: otp-config.json build-config.json router-config.json new-york-city-no-buildings.osm.pbf nyc-elevation.tiff long-island-rail-road.gtfs.zip mta-new-york-city-transit.gtfs.zip port-authority-of-new-york-new-jersey.gtfs.zip graph.obj You could have more than one of these directories if you are building separate graphs for separate regions. Each one should contain one or more GTFS feeds, a PBF OpenStreetMap file, some JSON configuration files, and any output files such as graph.obj . For convenience, especially if you work with only one graph at a time, you may want to place your OTP2 JAR file in this same directory. Note that file types are detected through a case-insensitive combination of file extension and words within the file name. GTFS file names must end in .zip and contain the letters gtfs , and OSM files must end in .pbf . It is also possible to provide a list of input files in the configuration, which will override the default behavior of scanning the base directory for input files. Scanning is overridden independently for each file type, and can point to remote cloud storage with arbitrary URIs. See the storage section for further details. Three Scopes of Configuration OTP is configured via three configuration JSON files which are read from the directory specified on its command line. We try to provide sensible defaults for every option, so all three of these files are optional, as are all the options within each file. Each configuration file corresponds to options that are relevant at a particular phase of OTP usage. Options and parameters that are taken into account during the graph building process will be \"baked into\" the graph, and cannot be changed later in a running server. These are specified in build-config.json . Other details of OTP operation can be modified without rebuilding the graph. These run-time configuration options are found in router-config.json . Finally, otp-config.json contains simple switches that enable or disable system-wide features. Configuration types The OTP configuration files use the JSON file format. OTP allows comments and unquoted field names in the JSON configuration files to be more human-friendly. OTP supports all the basic JSON types: nested objects {...} , arrays [] , numbers 789.0 and boolean true or false . In addition to these basic types some configuration parameters are parsed with some restrictions. In the documentation below we will refer to the following types: Type Description Examples boolean This is the Boolean JSON type. true or false number This is the Number JSON type. 1 , 5 , 3.14 string A quoted string. This is the String JSON type. \"This is a string!\" Type [] Array of of given Type. This is the Array JSON type. [ 1, 2, 3 ] double A decimal floating point number . 64 bit. 3.14 integer A decimal integer number . 32 bit. 1 , -7 , 2100200300 long A decimal integer number . 64 bit. -1234567890123456789 enum A fixed set of string literals. BicycleOptimize: \"QUICK\" , \"SAFE\" ... enum-map List of key/value pairs, where the key is a enum and the value can be any given type. { RAIL: 1.2, BUS: 2.3 } enum-set List of enum string values [ \"RAIL\", \"TRAM\" ] locale Language[\\_country[\\_variant]] . A Locale object represents a specific geographical, political, or cultural region. For more information see the Java 11 Locale . en_US , nn_NO date Local date. The format is YYYY-MM-DD (ISO-8601). 2020-09-21 date or period A local date , or a period relative to today. The local date has the format YYYY-MM-DD and the period has the format PnYnMnD or -PnYnMnD where n is a integer number. P1Y is one year from now, -P3M2D means 3 months and 2 days ago, and P1D means tomorrow. duration A duration is a amount of time. The format is PnDTnHnMnS or nDnHnMnS where n is a integer number. The D (days), H (hours), M (minutes) and S (seconds) are not case sensitive. 3h is 3 hours, 2m means 2 minutes, and 1d5h2m3s is 1 day, 5 hours, 2 minutes and 3 seconds. Use the \"PT\" form with negative values like -P2dT-1s and P-2dT1s (both is minus 2 days plus one second). regexp pattern A regular expression pattern used to match a sting. \"$^\" matches an empty string. \"gtfs\" matches \"A-*gtfs*-file.zip\" . \"$\\w{3})-.*\\.xml^\" matches a filename with 3 alpha-numeric characters in the beginning of the filename and .xml as file extension. uri An URI path to a resource like a file or a URL. Relative URIs are resolved relative to the OTP base path. \"gs://bucket/path/a.obj\" \"http://foo.bar/\" \"file:///Users/x/local/file\" \"myGraph.obj\" \"../street/streetGraph-${otp.serialization.version.id}.obj\" linear function A linear function with one input parameter(x) used to calculate a value. Usually used to calculate a limit. For example to calculate a limit in seconds to be 1 hour plus 2 times the value(x) use: 3600 + 2.0 x , to set an absolute value(3000) use: 3000 + 0x \"600 + 2.0 x\" System environment and project information substitution OTP support injecting system environment variables and project information parameters into the configuration. A pattern like ${VAR_NAME} in a configuration file is substituted with an environment variable with name VAR_NAME . The substitution is done BEFORE the JSON is parsed, so both json keys and values is subject to substitution. This is useful if you want OTPs version number to be part of the graph-file-name , or you want to inject credentials in a cloud based deployment. { s t orage : { gsCrede nt ials : \"${GCS_SERVICE_CREDENTIALS}\" , graph : \"file:///var/otp/graph-${otp.serialization.version.id}.obj\" , } } In the example above the environment variable GCS_SERVICE_CREDENTIALS on the local machine where OTP is deployed is injected into the config. Also, the OTP serialization version id is injected. The project information variables available are: maven.version maven.version.short maven.version.major maven.version.minor maven.version.patch maven.version.qualifier git.branch git.commit git.commit.timestamp graph.file.header otp.serialization.version.id Config version All three configuration files have an optional configVersion property. The property can be used to version the configuration in a deployment pipeline. The configVersion is not used by OTP in any way, but is logged at startup and is available as part of the server-info data in the REST API. The intended usage is to be able to check which version of the configuration the graph was build with and which version the router uses. In an deployment with many OTP instances it can be useful to ask an instance about the version, instead of tracking the deployment pipline backwards to find the version used. How you inject a version into the configuration file is up to you, but you can do it in your build-pipline, at deployment time or use system environment variable substituton. OTP Serialization version id and Graph.obj file header OTP has a OTP Serialization Version Id maintained in the pom.xml_ file. OTP store the id in the serialized Graph.obj file header, allowing OTP the check for compatibility issues when loading the graph. The header info is available to configuration substitution: ${graph.file.header} Will expand to: OpenTripPlannerGraph;0000007; ${otp.serialization.version.id} Will expand to: 7 The intended usage is to be able to have a graph build pipeline which \"knows\" which graph that matches OTP planner instances. For example, you may build new graphs for every OTP serialization version id in use by the planning OPT instances you have deploied and plan to deploy. This way you can roll forward and backward new OTP instances without worring about building new graphs. There are various ways to access this information. To get the Graph.obj serialization version id you can run the following bash command: - head -c 29 Graph.obj ==> OpenTripPlannerGraph;0000007; (file header) - head -c 28 Graph.obj | tail -c 7 ==> 0000007 (version id) The Maven pom.xml , the META-INF/MANIFEST.MF , the OTP command line( --serVerId ), log start-up messages and all OTP APIs can be used to get the OTP Serialization Version Id. Include file directive It is possible to inject the contents of another file into a configuration file. This makes it possible to keep parts of the configuration in separate files. To include the contents of a file, use ${includeFile:FILE_NAME} . The FILE_NAME must be the name of a file in the configuration directory. Relative paths are not supported. To allow both files (the configuration file and the injected file) to be valid JSON files, a special case is supported. If the include file directive is quoted, then the quotes are removed, if the text inserted is valid JSON (starts with { and ends with } ). Variable substitution is performed on configuration file after the include file directive; Hence variable substitution is also performed on the text in the injected file. Here is an example including variable substitution, assuming version 2.1.0 of OTP: // build-config.json { \"storage\" : \"${includeFile:storage.json}\" } // storage.json { \"streetGraph\" : \"street-graph-v${maven.version}.obj\" } The result will look like this: { \"storage\" : { \"streetGraph\" : \"street-graph-v2.1.0.obj\" } } System-wide Configuration Using the file otp-config.json you can enable or disable different APIs and experimental Sandbox Extensions . By default, all supported APIs are enabled and all sandbox features are disabled. So for most OTP2 use cases it is not necessary to create this file. Features that can be toggled in this file are generally only affect the routing phase of OTP2 usage, but for consistency all such \"feature flags\", even those that would affect graph building, are managed in this one file. See the OTPFeature Java class for an enumeration of all available features and their default settings. Here is an example: // otp-config.json { \"otpFeatures\" : { \"APIBikeRental\" : false , \"SandboxExampleAPIGraphStatistics\" : true } } OTP Features Here is a list of all features which can be toggled on/off. Feature Description Enabled by default Sandbox APIBikeRental Enable the bike rental endpoint yes no APIServerInfo Enable the server info endpoint yes no APIGraphInspectorTile Enable the inspector endpoint for graph information for inspection/debugging purpose yes no APIUpdaterStatus Enable endpoint for graph updaters status yes no OptimizeTransfers OTP will inspect all itineraries found and optimize where (which stops) the transfer will happen. Waiting time, priority and guaranteed transfers are taken into account. yes no MinimumTransferTimeIsDefinitive If the minimum transfer time is a lower bound (default) or the definitive time for the transfer. Set this to true if you want to set a transfer time lower than what OTP derives from OSM data. no no ParallelRouting Enable performing parts of the trip planning in parallel no no TransferConstraints Enforce transfers to happen according to the transfers.txt (GTFS) and Interchanges(NeTEx). Turing this off will increase the routing performance a little. yes no ActuatorAPI Enpoint for actuators (service health status) no yes GoogleCloudStorage Enable Google Cloud Storage integration no yes SandboxAPITransmodelApi Enable Entur Transmodel(NeTEx) GraphQL API no yes SandboxAPILegacyGraphQLApi Enable (GTFS) GraphQL API no yes SandboxAPIMapboxVectorTilesApi Enable Mapbox vector tiles API no yes SandboxAPIParkAndRideApi Enable park-and-ride endpoint no yes TransferAnalyzer Analyze transfers during graph build no yes FlexRouting Enable FLEX routing no yes FloatingBike Enable floating bike routing no yes","title":"Introduction"},{"location":"Configuration/#configuring-opentripplanner","text":"Note: if you are familiar with OTP1 configuration and are migrating to OTP2, please read the OTP2 Migration Guide to learn what has changed.","title":"Configuring OpenTripPlanner"},{"location":"Configuration/#base-directory","text":"On the OTP2 command line you must always specify a single directory after all the switches. This tells OTP2 where to look for any configuration files. By default OTP will also scan this directory for input files to build a graph (GTFS, OSM, elevation, and base street graphs) or the graph.obj file to load when starting a server. A typical OTP2 directory for a New York City graph might include the following: otp-config.json build-config.json router-config.json new-york-city-no-buildings.osm.pbf nyc-elevation.tiff long-island-rail-road.gtfs.zip mta-new-york-city-transit.gtfs.zip port-authority-of-new-york-new-jersey.gtfs.zip graph.obj You could have more than one of these directories if you are building separate graphs for separate regions. Each one should contain one or more GTFS feeds, a PBF OpenStreetMap file, some JSON configuration files, and any output files such as graph.obj . For convenience, especially if you work with only one graph at a time, you may want to place your OTP2 JAR file in this same directory. Note that file types are detected through a case-insensitive combination of file extension and words within the file name. GTFS file names must end in .zip and contain the letters gtfs , and OSM files must end in .pbf . It is also possible to provide a list of input files in the configuration, which will override the default behavior of scanning the base directory for input files. Scanning is overridden independently for each file type, and can point to remote cloud storage with arbitrary URIs. See the storage section for further details.","title":"Base Directory"},{"location":"Configuration/#three-scopes-of-configuration","text":"OTP is configured via three configuration JSON files which are read from the directory specified on its command line. We try to provide sensible defaults for every option, so all three of these files are optional, as are all the options within each file. Each configuration file corresponds to options that are relevant at a particular phase of OTP usage. Options and parameters that are taken into account during the graph building process will be \"baked into\" the graph, and cannot be changed later in a running server. These are specified in build-config.json . Other details of OTP operation can be modified without rebuilding the graph. These run-time configuration options are found in router-config.json . Finally, otp-config.json contains simple switches that enable or disable system-wide features.","title":"Three Scopes of Configuration"},{"location":"Configuration/#configuration-types","text":"The OTP configuration files use the JSON file format. OTP allows comments and unquoted field names in the JSON configuration files to be more human-friendly. OTP supports all the basic JSON types: nested objects {...} , arrays [] , numbers 789.0 and boolean true or false . In addition to these basic types some configuration parameters are parsed with some restrictions. In the documentation below we will refer to the following types: Type Description Examples boolean This is the Boolean JSON type. true or false number This is the Number JSON type. 1 , 5 , 3.14 string A quoted string. This is the String JSON type. \"This is a string!\" Type [] Array of of given Type. This is the Array JSON type. [ 1, 2, 3 ] double A decimal floating point number . 64 bit. 3.14 integer A decimal integer number . 32 bit. 1 , -7 , 2100200300 long A decimal integer number . 64 bit. -1234567890123456789 enum A fixed set of string literals. BicycleOptimize: \"QUICK\" , \"SAFE\" ... enum-map List of key/value pairs, where the key is a enum and the value can be any given type. { RAIL: 1.2, BUS: 2.3 } enum-set List of enum string values [ \"RAIL\", \"TRAM\" ] locale Language[\\_country[\\_variant]] . A Locale object represents a specific geographical, political, or cultural region. For more information see the Java 11 Locale . en_US , nn_NO date Local date. The format is YYYY-MM-DD (ISO-8601). 2020-09-21 date or period A local date , or a period relative to today. The local date has the format YYYY-MM-DD and the period has the format PnYnMnD or -PnYnMnD where n is a integer number. P1Y is one year from now, -P3M2D means 3 months and 2 days ago, and P1D means tomorrow. duration A duration is a amount of time. The format is PnDTnHnMnS or nDnHnMnS where n is a integer number. The D (days), H (hours), M (minutes) and S (seconds) are not case sensitive. 3h is 3 hours, 2m means 2 minutes, and 1d5h2m3s is 1 day, 5 hours, 2 minutes and 3 seconds. Use the \"PT\" form with negative values like -P2dT-1s and P-2dT1s (both is minus 2 days plus one second). regexp pattern A regular expression pattern used to match a sting. \"$^\" matches an empty string. \"gtfs\" matches \"A-*gtfs*-file.zip\" . \"$\\w{3})-.*\\.xml^\" matches a filename with 3 alpha-numeric characters in the beginning of the filename and .xml as file extension. uri An URI path to a resource like a file or a URL. Relative URIs are resolved relative to the OTP base path. \"gs://bucket/path/a.obj\" \"http://foo.bar/\" \"file:///Users/x/local/file\" \"myGraph.obj\" \"../street/streetGraph-${otp.serialization.version.id}.obj\" linear function A linear function with one input parameter(x) used to calculate a value. Usually used to calculate a limit. For example to calculate a limit in seconds to be 1 hour plus 2 times the value(x) use: 3600 + 2.0 x , to set an absolute value(3000) use: 3000 + 0x \"600 + 2.0 x\"","title":"Configuration types"},{"location":"Configuration/#system-environment-and-project-information-substitution","text":"OTP support injecting system environment variables and project information parameters into the configuration. A pattern like ${VAR_NAME} in a configuration file is substituted with an environment variable with name VAR_NAME . The substitution is done BEFORE the JSON is parsed, so both json keys and values is subject to substitution. This is useful if you want OTPs version number to be part of the graph-file-name , or you want to inject credentials in a cloud based deployment. { s t orage : { gsCrede nt ials : \"${GCS_SERVICE_CREDENTIALS}\" , graph : \"file:///var/otp/graph-${otp.serialization.version.id}.obj\" , } } In the example above the environment variable GCS_SERVICE_CREDENTIALS on the local machine where OTP is deployed is injected into the config. Also, the OTP serialization version id is injected. The project information variables available are: maven.version maven.version.short maven.version.major maven.version.minor maven.version.patch maven.version.qualifier git.branch git.commit git.commit.timestamp graph.file.header otp.serialization.version.id","title":"System environment and project information substitution"},{"location":"Configuration/#config-version","text":"All three configuration files have an optional configVersion property. The property can be used to version the configuration in a deployment pipeline. The configVersion is not used by OTP in any way, but is logged at startup and is available as part of the server-info data in the REST API. The intended usage is to be able to check which version of the configuration the graph was build with and which version the router uses. In an deployment with many OTP instances it can be useful to ask an instance about the version, instead of tracking the deployment pipline backwards to find the version used. How you inject a version into the configuration file is up to you, but you can do it in your build-pipline, at deployment time or use system environment variable substituton.","title":"Config version"},{"location":"Configuration/#otp-serialization-version-id-and-graphobj-file-header","text":"OTP has a OTP Serialization Version Id maintained in the pom.xml_ file. OTP store the id in the serialized Graph.obj file header, allowing OTP the check for compatibility issues when loading the graph. The header info is available to configuration substitution: ${graph.file.header} Will expand to: OpenTripPlannerGraph;0000007; ${otp.serialization.version.id} Will expand to: 7 The intended usage is to be able to have a graph build pipeline which \"knows\" which graph that matches OTP planner instances. For example, you may build new graphs for every OTP serialization version id in use by the planning OPT instances you have deploied and plan to deploy. This way you can roll forward and backward new OTP instances without worring about building new graphs. There are various ways to access this information. To get the Graph.obj serialization version id you can run the following bash command: - head -c 29 Graph.obj ==> OpenTripPlannerGraph;0000007; (file header) - head -c 28 Graph.obj | tail -c 7 ==> 0000007 (version id) The Maven pom.xml , the META-INF/MANIFEST.MF , the OTP command line( --serVerId ), log start-up messages and all OTP APIs can be used to get the OTP Serialization Version Id.","title":"OTP Serialization version id and Graph.obj file header"},{"location":"Configuration/#include-file-directive","text":"It is possible to inject the contents of another file into a configuration file. This makes it possible to keep parts of the configuration in separate files. To include the contents of a file, use ${includeFile:FILE_NAME} . The FILE_NAME must be the name of a file in the configuration directory. Relative paths are not supported. To allow both files (the configuration file and the injected file) to be valid JSON files, a special case is supported. If the include file directive is quoted, then the quotes are removed, if the text inserted is valid JSON (starts with { and ends with } ). Variable substitution is performed on configuration file after the include file directive; Hence variable substitution is also performed on the text in the injected file. Here is an example including variable substitution, assuming version 2.1.0 of OTP: // build-config.json { \"storage\" : \"${includeFile:storage.json}\" } // storage.json { \"streetGraph\" : \"street-graph-v${maven.version}.obj\" } The result will look like this: { \"storage\" : { \"streetGraph\" : \"street-graph-v2.1.0.obj\" } }","title":"Include file directive"},{"location":"Configuration/#system-wide-configuration","text":"Using the file otp-config.json you can enable or disable different APIs and experimental Sandbox Extensions . By default, all supported APIs are enabled and all sandbox features are disabled. So for most OTP2 use cases it is not necessary to create this file. Features that can be toggled in this file are generally only affect the routing phase of OTP2 usage, but for consistency all such \"feature flags\", even those that would affect graph building, are managed in this one file. See the OTPFeature Java class for an enumeration of all available features and their default settings. Here is an example: // otp-config.json { \"otpFeatures\" : { \"APIBikeRental\" : false , \"SandboxExampleAPIGraphStatistics\" : true } }","title":"System-wide Configuration"},{"location":"Configuration/#otp-features","text":"Here is a list of all features which can be toggled on/off. Feature Description Enabled by default Sandbox APIBikeRental Enable the bike rental endpoint yes no APIServerInfo Enable the server info endpoint yes no APIGraphInspectorTile Enable the inspector endpoint for graph information for inspection/debugging purpose yes no APIUpdaterStatus Enable endpoint for graph updaters status yes no OptimizeTransfers OTP will inspect all itineraries found and optimize where (which stops) the transfer will happen. Waiting time, priority and guaranteed transfers are taken into account. yes no MinimumTransferTimeIsDefinitive If the minimum transfer time is a lower bound (default) or the definitive time for the transfer. Set this to true if you want to set a transfer time lower than what OTP derives from OSM data. no no ParallelRouting Enable performing parts of the trip planning in parallel no no TransferConstraints Enforce transfers to happen according to the transfers.txt (GTFS) and Interchanges(NeTEx). Turing this off will increase the routing performance a little. yes no ActuatorAPI Enpoint for actuators (service health status) no yes GoogleCloudStorage Enable Google Cloud Storage integration no yes SandboxAPITransmodelApi Enable Entur Transmodel(NeTEx) GraphQL API no yes SandboxAPILegacyGraphQLApi Enable (GTFS) GraphQL API no yes SandboxAPIMapboxVectorTilesApi Enable Mapbox vector tiles API no yes SandboxAPIParkAndRideApi Enable park-and-ride endpoint no yes TransferAnalyzer Analyze transfers during graph build no yes FlexRouting Enable FLEX routing no yes FloatingBike Enable floating bike routing no yes","title":"OTP Features"},{"location":"Deployments/","text":"OpenTripPlanner Deployments Worldwide Official Production The following are known deployments of OTP in a government- or agency-sponsored production capacity: Norway (nationwide) Since November 2017, the national integrated ticketing agency Entur has prodvided a national journey planner which consumes schedule data in the EU standard NeTEx format with SIRI realtime updates. Entur has contributed greatly to the OTP2 effort and primarily uses OTP2 in production, handling peak loads in excess of 20 requests per second. Oslo, Norway Ruter provides a journey planner for the Oslo region . It has been in production since January 2016 and serves around 200,000 users per day. Finland (nationwide) The Helsinki Regional Transport Authority , the Finnish Transport Agency , and other Finnish cities have collaborated to create Digitransit , providing OTP-based trip planners, APIs, open data, Docker containers and open source code. Each member organisation runs its own instance of a shared codebase and deployment environment. Their source code is available on Github , including a new custom UI . This system also has a strong real-time component. Finland Intercity The Finnish intercity coach service Matkahuolto has developed a trip planner in partnership with Kyyti . Leipzig, Germany As of summer 2020 Leipzig Move has been using OpenTripPlanner. Portland, Oregon TriMet is the agency that originally started the OpenTripPlanner project. Their Regional Trip Planner is based on OTP and provides about 40,000 trip plans on a typical weekday. New York State The State Department of Transportation's transit trip planner provides itineraries for public transit systems throughout the state in a single unified OTP instance. Los Angeles, California The new metro.net trip planner . Atlanta, Georgia The Metropolitan Atlanta Rapid Transit Authority's (MARTA) trip planner and the Atlanta region's transit information hub atltransit.org both use OTP to power their website trip planners. Boston, Massachusetts The Massachusetts Bay Transportation Authority trip planner . Seattle, Washington The Sound Transit Trip Planner is based on OTP. OTP also powers the trip planning feature of the OneBusAway native apps in the Puget Sound region. Technical details are here . Tampa, Florida Hillsoborough Area Regional Transit uses an OpenTripPlanner server to power the trip planning feature of the OneBusAway native apps in their region. Technical details are here . Piemonte Region, Italy and the City of Torino built on OpenTripPlanner by 5T . Valencia, Spain from the Municipal Transport Company of Valencia S.A.U. Grenoble, France from SMTC, Grenoble Alpes m\u00e9tropole, l'\u00c9tat Fran\u00e7ais, the Rh\u00f4ne-alpes region, the Is\u00e8re council and the City of Grenoble. Rennes, France where the STAR network provides an OTP client for iOS , Android , Windows Phone et Web. Alen\u00e7on, France integrated urban and school bus network planner from R\u00e9unir Alen\u00e7on . Pozna\u0144, Poland from Urban Transport Authority of Pozna\u0144 (ZTM Poznan). Trento Province, Italy - ViaggiaTrento and ViaggiaRovereto were implemented as part of the SmartCampus Project , a research project founded by TrentoRise , UNITN , and FBK . University of South Florida (Tampa, Florida). The USF Maps App is a responsive web application for that helps university students, staff, and visitors find their way around the campus using multiple modes of transportation, including the USF Bull Runner campus shuttle, Share-A-Bull bike share, and pedestrian pathways. Open-sourced on Github . Independent Production The following OTP-based services are presented as production-quality deployments, but are not backed by an official transportation authority or government. OTP is also known to be used on the back end of several popular multi-city mobile trip planning applications. The Netherlands (nationwide) Plannerstack Foundation provides national scale trip planning APIs using OTP and other open source trip planners, based on OpenOV's extremely detailed open data including minutely real-time updates for every vehicle in the country. OTP Android by CUTR-USF and Vreixo Gonz\u00e1lez can find itineraries on many different OTP servers via a service discovery mechanism. ViviBus Bologna Bologna, Italy.","title":"Deployments"},{"location":"Deployments/#opentripplanner-deployments-worldwide","text":"","title":"OpenTripPlanner Deployments Worldwide"},{"location":"Deployments/#official-production","text":"The following are known deployments of OTP in a government- or agency-sponsored production capacity: Norway (nationwide) Since November 2017, the national integrated ticketing agency Entur has prodvided a national journey planner which consumes schedule data in the EU standard NeTEx format with SIRI realtime updates. Entur has contributed greatly to the OTP2 effort and primarily uses OTP2 in production, handling peak loads in excess of 20 requests per second. Oslo, Norway Ruter provides a journey planner for the Oslo region . It has been in production since January 2016 and serves around 200,000 users per day. Finland (nationwide) The Helsinki Regional Transport Authority , the Finnish Transport Agency , and other Finnish cities have collaborated to create Digitransit , providing OTP-based trip planners, APIs, open data, Docker containers and open source code. Each member organisation runs its own instance of a shared codebase and deployment environment. Their source code is available on Github , including a new custom UI . This system also has a strong real-time component. Finland Intercity The Finnish intercity coach service Matkahuolto has developed a trip planner in partnership with Kyyti . Leipzig, Germany As of summer 2020 Leipzig Move has been using OpenTripPlanner. Portland, Oregon TriMet is the agency that originally started the OpenTripPlanner project. Their Regional Trip Planner is based on OTP and provides about 40,000 trip plans on a typical weekday. New York State The State Department of Transportation's transit trip planner provides itineraries for public transit systems throughout the state in a single unified OTP instance. Los Angeles, California The new metro.net trip planner . Atlanta, Georgia The Metropolitan Atlanta Rapid Transit Authority's (MARTA) trip planner and the Atlanta region's transit information hub atltransit.org both use OTP to power their website trip planners. Boston, Massachusetts The Massachusetts Bay Transportation Authority trip planner . Seattle, Washington The Sound Transit Trip Planner is based on OTP. OTP also powers the trip planning feature of the OneBusAway native apps in the Puget Sound region. Technical details are here . Tampa, Florida Hillsoborough Area Regional Transit uses an OpenTripPlanner server to power the trip planning feature of the OneBusAway native apps in their region. Technical details are here . Piemonte Region, Italy and the City of Torino built on OpenTripPlanner by 5T . Valencia, Spain from the Municipal Transport Company of Valencia S.A.U. Grenoble, France from SMTC, Grenoble Alpes m\u00e9tropole, l'\u00c9tat Fran\u00e7ais, the Rh\u00f4ne-alpes region, the Is\u00e8re council and the City of Grenoble. Rennes, France where the STAR network provides an OTP client for iOS , Android , Windows Phone et Web. Alen\u00e7on, France integrated urban and school bus network planner from R\u00e9unir Alen\u00e7on . Pozna\u0144, Poland from Urban Transport Authority of Pozna\u0144 (ZTM Poznan). Trento Province, Italy - ViaggiaTrento and ViaggiaRovereto were implemented as part of the SmartCampus Project , a research project founded by TrentoRise , UNITN , and FBK . University of South Florida (Tampa, Florida). The USF Maps App is a responsive web application for that helps university students, staff, and visitors find their way around the campus using multiple modes of transportation, including the USF Bull Runner campus shuttle, Share-A-Bull bike share, and pedestrian pathways. Open-sourced on Github .","title":"Official Production"},{"location":"Deployments/#independent-production","text":"The following OTP-based services are presented as production-quality deployments, but are not backed by an official transportation authority or government. OTP is also known to be used on the back end of several popular multi-city mobile trip planning applications. The Netherlands (nationwide) Plannerstack Foundation provides national scale trip planning APIs using OTP and other open source trip planners, based on OpenOV's extremely detailed open data including minutely real-time updates for every vehicle in the country. OTP Android by CUTR-USF and Vreixo Gonz\u00e1lez can find itineraries on many different OTP servers via a service discovery mechanism. ViviBus Bologna Bologna, Italy.","title":"Independent Production"},{"location":"Developers-Guide/","text":"Developers Guide Quick setup A Quick guide to setting up the OpenTripPlanner project. You need Git, Maven and Java(JDK) and an IDE installed on your computer. You IDE might have JDK and Maven embedded, if so you may skip step 3. Clone OpenTripPlanner from GitHub. Checkout the desired branch git checkout dev-2.x Run maven package - this will download all dependencies, build the project and run tests. Open the project in your IDE. Import the intellij-code-style.xml (IntelliJ IDE). Working on OTP in an IDE Most people writing or modifying OTP code use an Integrated Development Environment (IDE). Some of the most popular IDEs for Java development are IntelliJ IDEA , Eclipse , and NetBeans . All three of these environments are good for working on OTP. IntelliJ is used by most OTP developers, and the only IDE we support with a code style formatter. You may choose another IDE, but Maven and Git integration is a plus since OTP is under Git version control and build with Maven. Many of the Core OTP developers use IntelliJ IDEA. It is an excellent IDE, and in my experience is quicker and more stable than the competition. IntelliJ IDEA is a commercial product, but there is an open source \"community edition\" that is completely sufficient for working on OTP. Rather than using the version control support in my IDE, I usually find it more straightforward to clone the OTP GitHub repository manually (on the command line or using some other Git interface tool), then import the resulting local OTP repository into my IDE as a Maven project. The IDE should then take care of fetching all the libraries OTP depends on, based on the Maven project description (POM file) in the base of the OTP repository. This step can take a long time because it involves downloading a lot of JAR files. When running your local copy of the OTP source within an IDE, all command line switches and configuration options will be identical to the ones used when running the OTP JAR from the command line (as described in the OpenTripPlanner Basic Tutorial and configuration reference ). The only difference is that you need to manually specify the main class. When you run a JAR from the command line, the JVM automatically knows which class contains the entry point into the program (the main function), but in IDEs you must create a \"run configuration\". Both IntelliJ and Eclipse have \"run\" menus, from which you can select an option to edit the run configurations. You want to create a configuration for a Java Application, specifying the main class org.opentripplanner.standalone.OTPMain . Unlike on the command line, the arguments to the JVM and to the main class you are running are specified separately. In the field for the VM options you'll want to put your maximum memory parameter ( -Xmx2G , or whatever limit you want to place on JVM memory usage). The rest of the parameters to OTP itself will go in a different field with a name like \"program arguments\". Contributing to the project OpenTripPlanner is a community based open source project, and we welcome all who wish to contribute. There are several ways to get involved: Join the developer mailing list Fix typos and improve the documentation within the /docs directory of the project (details below). File a bug or new feature request . Submit patches. If you're not yet a committer, please provide patches as pull requests citing the relevant issue. Even when you do have push access to the repository, pull requests are a good way to get feedback on changes. Branches and Branch Protection As of January 2019, we have begun work on OTP 2.x and are using a Git branching model derived from Gitflow . All development will occur on the dev-1.x and dev-2.x branches. Only release commits setting the Maven artifact version to a non-snapshot number should be pushed to the master branch of OTP. All other changes to master should result from fast-forward merges of a Github pull request from the dev-1.x branch. In turn, all changes to dev-1.x should result from a fast-forward merge of a Github pull request for a single feature, fix, or other change. These pull requests are subject to code review. We require two pull request approvals from OTP leadership committee members or designated code reviewers from two different organizations. We also have validation rules ensuring that the code compiles and all tests pass before pull requests can be merged. The dev-2.x branch is managed similarly to dev-1.x but because it's rapidly changing experimental code worked on by relatively few people, we require only one pull request approval from a different organization than the author. Merges will not occur into master from dev-2.x until that branch is sufficiently advanced and receives approval from the OTP project leadership committee. Issues and commits All commits should reference a specific issue number (this was formally decided in issue #175). For example, Simplify module X configuration #9999 . If no ticket exists for the feature or bug your code implements or fixes, you should create a new ticket prior to checking in, or ideally even prior to your development work since this provides a place to carry out implementation discussions (in the comments). GitHub will automatically update issues when commits are merged in: if your commit message includes the text fixes #123 , it will automatically append your message as a comment on the isse and close it. If you simply mention #123 in your message, your message will be appended to the issue but it will remain open. Many other expressions exist to close issues via commit messages. See the GitHub help page on this topic . Unit tests using real OSM data Sometimes it is useful to build a graph from actual OSM or GTFS data. Since building these graphs in a test can be quite slow they will be accepted in pull requests only if they conform to certain standards: Use the smallest possible regional extract - the OSM file should not contain more than a few hundred ways. Use osmium-extract to cut down a larger OSM file into a tiny subset of it. Strip out any unneeded information by using the osmium filter-tags as describe in Preparing OSM Code Comments As a matter of policy , all new methods, classes, and fields should include comments explaining what they are for and any other pertinent information. For Java code, the comments should use the JavaDoc conventions . It is best to provide comments that not only explain what you did but also why you did it while providing some context. Please avoid including trivial Javadoc or the empty Javadoc stubs added by IDEs, such as @param annotations with no description. Itinerary and API Snapshot Tests To test the itinerary generation, and the API there are snapshot test which save the result of the requests as *.snap JSON-like files. These are stored in git so that it is possible to compare to the expected result when running the tests. If the snapshots need to be recreated than running mvn clean -Pclean-test-snapshots will remove the existing *.snap files so that the next time the tests are run the snapshots will be recreated. The updated files may be committed after checking that the changes in the files are expected. Documentation OTP documentation is included directly in the OpenTripPlanner repository. This allows version control to be applied to documentation as well as program source code. All pull requests that change how OTP is used or configured should include changes to the documentation alongside code modifications. The documentation files are in Markdown format and are in the /docs directory under the root of the project. On every push to the master branch the documentation will be rebuilt and deployed as static pages to our subdomain of ReadTheDocs . MkDocs is a Python program and should run on any major platform. See http://www.mkdocs.org/ for information on how to install it and how to generate a live local preview of the documentation while you're working on writing it. In short: $ pip install mkdocs $ mkdocs serve The OTP REST API documentation is available online in the format of: http://dev.opentripplanner.org/apidoc/x.x.x/index.html For example, for v2.1.0: http://dev.opentripplanner.org/apidoc/2.1.0/index.html Debug layers Adding new renderer is very easy. You just need to create new class (preferably in org.opentripplanner.inspector package) which implements EdgeVertexRenderer. It is best if class name ends with Rendered. To implement this interface you need to write three functions renderEdge , renderVertex and getName . Both render functions accepts EdgeVisualAttributes object in which label of edge/vertex and color can be set. And both return true if edge/vertex should be rendered and false otherwise. getName function should return short descriptive name of the class and will be shown in layer chooser. For examples how to write renderers you can look into example renderers which are all in org.opentripplanner.inspector package. After your class is written you only need to add it to TileRenderManager: //This is how Wheelchair renderer is added renderers . put ( \"wheelchair\" , new EdgeVertexTileRenderer ( new WheelchairEdgeRenderer ())); wheelchair is internal layer key and should consist of a-zA-Z and -. By default all the tiles have cache headers to cache them for one hour. This can become problematic if you are changing renderers a lot. To disable this change GraphInspectorTileResource : //This lines CacheControl cc = new CacheControl (); cc . setMaxAge ( 3600 ); cc . setNoCache ( false ); //to this: CacheControl cc = new CacheControl (); cc . setNoCache ( true ); Date format Please use only ISO 8601 date format (YYYY-MM-DD) in documentation, comments, and throughout the project. This avoids the ambiguity that can result from differing local interpretations of date formats like 02/01/12. Code style The OTP code style is described on a separate style guide page . Continuous Integration The OpenTripPlanner project uses the Travis CI continuous integration system . Any time a change is pushed to the main OpenTripPlanner repository on GitHub, this server will compile and test the new code, providing feedback on the stability of the build. Changelog workflow The changelog file is generated from the pull-request(PR) title using the changelog workflow . The workflow runs after the PR is merged, and it changes, commits and pushes the Changelog.md . A secret personal access token is used to bypass the \"Require PR with 2 approvals\" rule. To exclude a PR from the changelog add [changelog skip] in the PR title. How-to update the CHANGELOG_TOKEN The CHANGELOG_TOKEN is used by the changelog workflow. It contains a Personal Access Token. The token must be generated by a Repository Owner and have the following rights ( Settings / Developer settings / Personal access tokens ): Release Process This section serves as a checklist for the person performing releases. Note that much of this mimics the actions taken by the Maven release plugin. Based on past experience, the Maven release plugin can fail at various points in the process leaving the repo in a confusing state. Taking each action manually is more tedious, but keeps eyes on each step and is less prone to failure. Releases are performed off the master branch, and are tagged with git annotated tags. OpenTripPlanner is released as Maven artifacts to Maven Central. These include compiled and source code JARs as well as a \"shaded\" JAR containing all dependencies, allowing stand-alone usage. This release process is handled by the Sonatype Nexus Staging plugin, configured in the OpenTripPlanner POM. We no longer trigger deployment of artifacts to Maven Central or deployment of documentation to AWS automatically in build scripts. These steps are prone to failure and require storing a lot of infrequently used secret information in the repo and environment variables on GitHub. Our releases are currently not very frequent so we just carry out these steps manually by following the checklist. Check that your local copy of the dev branch is up to date with no uncommitted changes git status git checkout dev-2.x git clean -df git pull Verify that all dependencies in the POM are non-SNAPSHOT versions Update docs/Changelog.md Lines should have been added or updated as each pull request was merged If you suspect any changes are not reflected in the Changelog, review the commit log and add any missing items Update the header at the top of the list from x.y.z-SNAPSHOT to just x.y.z (current date) Check in any changes, and push to Github Check on GH Actions that the build is currently passing Switch to the HEAD of master branch, and ensure it's up to date with no uncommitted changes git checkout master git status git clean -df git pull Merge the dev branch into master git merge dev-2.x Bump the SNAPSHOT version in the POM to the release version Edit version in POM, removing SNAPSHOT and increasing version numbers as needed (following semantic versioning) git add pom.xml git commit -m \"prepare release x.y.z\" Run a test build of the release locally, without deploying it mvn clean install site The install goal will sign the Maven artifacts so you need the GPG signing certificate set up You can also use the package goal instead of the install goal to avoid signing if you don't have the GPG certificate installed. All tests should pass This build will also create Enunciate API docs and Javadoc with the correct non-snapshot version number Deploy the documentation to AWS S3 You have to do this right after the test release build to ensure the right version number in the docs You will need AWSCLI tools ( sudo pip install -U awscli ) You will need AWS credentials with write access to the bucket s3://dev.opentripplanner.org aws s3 cp --recursive target/site/apidocs s3://dev.opentripplanner.org/javadoc/x.y.z --acl public-read aws s3 cp --recursive target/site/enunciate/apidocs s3://dev.opentripplanner.org/apidoc/x.y.z --acl public-read Check that docs are readable and show the correct version via the development documentation landing page . Finally, if everything looks good, tag and push this release to make it official git tag -a vX.Y.Z -m \"release X.Y.Z\" git push origin vX.Y.Z Note that only one commit may have a particular non-snapshot version in the POM (this is the commit that should be tagged as the release) Go to the GitHub tags page and use the ... button to mark the new tag as a release. Give the release a name like v2.1.0 (March 2022) Optionally add a very condensed version of the changelog in the description box, with only the 5-10 most significant changes that might affect someone's choice to upgrade. Currently, pushing the tag does not trigger deployment of release Maven artifacts. This must be done manually. It can conceivably be configured to happen in the Actions scripts when any tag is pushed. Deploy the build artifacts to Maven Central and GitHub While still on the tag commit, run mvn deploy after you have completed the local build as described above. This requires you to have the GPG keys and Maven repo credentials set up. Attach the JAR files produced in /target to the GitHub release page you just created. Set up next development iteration Add a new section header to docs/Changelog.md like x.y+1.0-SNAPSHOT (in progress) Edit minor version in pom.xml to x.y+1.0-SNAPSHOT git add pom.xml docs/Changelog.md git commit -m \"Prepare next development iteration x.y+1.0-SNAPSHOT\" git push Check that Maven artifact appears on Maven Central Directory listing of OTP releases on Maven Central It may take a while (half an hour) for releases to show up in the central repo after Travis uploads the artifacts Merge master back into dev (to sync up the Maven artifact version from the POM) git checkout dev-2.x git merge master git push Make sure the main documentation is built For some reason it doesn't always build automatically Go to builds of docs.opentripplanner.org Click \"build version: latest\" Email the OTP dev and users mailing lists Mention the new version number. Provide links to the new developer documentation. Provide links to the artifacts directory on Maven Central. Trigger build of latest OTP documentation on Readthedocs. Artifact Signing Maven release artifacts must be digitally signed to prove their origin. This is a safeguard against compromised code from a malicious third party being disguised as a trusted library. The OTP artifact signing key was created by Conveyal. We export only that signing subkey, with our company's main key blanked out. Therefore, even if someone managed to acquire the decrypted key file and the associated GPG passphrase, they would not have the main key. We could deactivate the signing key and create a new one, without the main key being compromised. OpenTripPlanner's POM is set up to sign artifacts in the verify phase, which means signing will happen for the install and deploy targets, but not the package target. When performing a local test build, if you do mvn clean install site it will test the signing process. If you do not have the certificate installed, you can instead to mvn clean package site to bypass signing, but this provides less certainty that everything is set up correctly for the CI-driven final release.","title":"Developers' Guide"},{"location":"Developers-Guide/#developers-guide","text":"","title":"Developers Guide"},{"location":"Developers-Guide/#quick-setup","text":"A Quick guide to setting up the OpenTripPlanner project. You need Git, Maven and Java(JDK) and an IDE installed on your computer. You IDE might have JDK and Maven embedded, if so you may skip step 3. Clone OpenTripPlanner from GitHub. Checkout the desired branch git checkout dev-2.x Run maven package - this will download all dependencies, build the project and run tests. Open the project in your IDE. Import the intellij-code-style.xml (IntelliJ IDE).","title":"Quick setup"},{"location":"Developers-Guide/#working-on-otp-in-an-ide","text":"Most people writing or modifying OTP code use an Integrated Development Environment (IDE). Some of the most popular IDEs for Java development are IntelliJ IDEA , Eclipse , and NetBeans . All three of these environments are good for working on OTP. IntelliJ is used by most OTP developers, and the only IDE we support with a code style formatter. You may choose another IDE, but Maven and Git integration is a plus since OTP is under Git version control and build with Maven. Many of the Core OTP developers use IntelliJ IDEA. It is an excellent IDE, and in my experience is quicker and more stable than the competition. IntelliJ IDEA is a commercial product, but there is an open source \"community edition\" that is completely sufficient for working on OTP. Rather than using the version control support in my IDE, I usually find it more straightforward to clone the OTP GitHub repository manually (on the command line or using some other Git interface tool), then import the resulting local OTP repository into my IDE as a Maven project. The IDE should then take care of fetching all the libraries OTP depends on, based on the Maven project description (POM file) in the base of the OTP repository. This step can take a long time because it involves downloading a lot of JAR files. When running your local copy of the OTP source within an IDE, all command line switches and configuration options will be identical to the ones used when running the OTP JAR from the command line (as described in the OpenTripPlanner Basic Tutorial and configuration reference ). The only difference is that you need to manually specify the main class. When you run a JAR from the command line, the JVM automatically knows which class contains the entry point into the program (the main function), but in IDEs you must create a \"run configuration\". Both IntelliJ and Eclipse have \"run\" menus, from which you can select an option to edit the run configurations. You want to create a configuration for a Java Application, specifying the main class org.opentripplanner.standalone.OTPMain . Unlike on the command line, the arguments to the JVM and to the main class you are running are specified separately. In the field for the VM options you'll want to put your maximum memory parameter ( -Xmx2G , or whatever limit you want to place on JVM memory usage). The rest of the parameters to OTP itself will go in a different field with a name like \"program arguments\".","title":"Working on OTP in an IDE"},{"location":"Developers-Guide/#contributing-to-the-project","text":"OpenTripPlanner is a community based open source project, and we welcome all who wish to contribute. There are several ways to get involved: Join the developer mailing list Fix typos and improve the documentation within the /docs directory of the project (details below). File a bug or new feature request . Submit patches. If you're not yet a committer, please provide patches as pull requests citing the relevant issue. Even when you do have push access to the repository, pull requests are a good way to get feedback on changes.","title":"Contributing to the project"},{"location":"Developers-Guide/#branches-and-branch-protection","text":"As of January 2019, we have begun work on OTP 2.x and are using a Git branching model derived from Gitflow . All development will occur on the dev-1.x and dev-2.x branches. Only release commits setting the Maven artifact version to a non-snapshot number should be pushed to the master branch of OTP. All other changes to master should result from fast-forward merges of a Github pull request from the dev-1.x branch. In turn, all changes to dev-1.x should result from a fast-forward merge of a Github pull request for a single feature, fix, or other change. These pull requests are subject to code review. We require two pull request approvals from OTP leadership committee members or designated code reviewers from two different organizations. We also have validation rules ensuring that the code compiles and all tests pass before pull requests can be merged. The dev-2.x branch is managed similarly to dev-1.x but because it's rapidly changing experimental code worked on by relatively few people, we require only one pull request approval from a different organization than the author. Merges will not occur into master from dev-2.x until that branch is sufficiently advanced and receives approval from the OTP project leadership committee.","title":"Branches and Branch Protection"},{"location":"Developers-Guide/#issues-and-commits","text":"All commits should reference a specific issue number (this was formally decided in issue #175). For example, Simplify module X configuration #9999 . If no ticket exists for the feature or bug your code implements or fixes, you should create a new ticket prior to checking in, or ideally even prior to your development work since this provides a place to carry out implementation discussions (in the comments). GitHub will automatically update issues when commits are merged in: if your commit message includes the text fixes #123 , it will automatically append your message as a comment on the isse and close it. If you simply mention #123 in your message, your message will be appended to the issue but it will remain open. Many other expressions exist to close issues via commit messages. See the GitHub help page on this topic .","title":"Issues and commits"},{"location":"Developers-Guide/#unit-tests-using-real-osm-data","text":"Sometimes it is useful to build a graph from actual OSM or GTFS data. Since building these graphs in a test can be quite slow they will be accepted in pull requests only if they conform to certain standards: Use the smallest possible regional extract - the OSM file should not contain more than a few hundred ways. Use osmium-extract to cut down a larger OSM file into a tiny subset of it. Strip out any unneeded information by using the osmium filter-tags as describe in Preparing OSM","title":"Unit tests using real OSM data"},{"location":"Developers-Guide/#code-comments","text":"As a matter of policy , all new methods, classes, and fields should include comments explaining what they are for and any other pertinent information. For Java code, the comments should use the JavaDoc conventions . It is best to provide comments that not only explain what you did but also why you did it while providing some context. Please avoid including trivial Javadoc or the empty Javadoc stubs added by IDEs, such as @param annotations with no description.","title":"Code Comments"},{"location":"Developers-Guide/#itinerary-and-api-snapshot-tests","text":"To test the itinerary generation, and the API there are snapshot test which save the result of the requests as *.snap JSON-like files. These are stored in git so that it is possible to compare to the expected result when running the tests. If the snapshots need to be recreated than running mvn clean -Pclean-test-snapshots will remove the existing *.snap files so that the next time the tests are run the snapshots will be recreated. The updated files may be committed after checking that the changes in the files are expected.","title":"Itinerary and API Snapshot Tests"},{"location":"Developers-Guide/#documentation","text":"OTP documentation is included directly in the OpenTripPlanner repository. This allows version control to be applied to documentation as well as program source code. All pull requests that change how OTP is used or configured should include changes to the documentation alongside code modifications. The documentation files are in Markdown format and are in the /docs directory under the root of the project. On every push to the master branch the documentation will be rebuilt and deployed as static pages to our subdomain of ReadTheDocs . MkDocs is a Python program and should run on any major platform. See http://www.mkdocs.org/ for information on how to install it and how to generate a live local preview of the documentation while you're working on writing it. In short: $ pip install mkdocs $ mkdocs serve The OTP REST API documentation is available online in the format of: http://dev.opentripplanner.org/apidoc/x.x.x/index.html For example, for v2.1.0: http://dev.opentripplanner.org/apidoc/2.1.0/index.html","title":"Documentation"},{"location":"Developers-Guide/#debug-layers","text":"Adding new renderer is very easy. You just need to create new class (preferably in org.opentripplanner.inspector package) which implements EdgeVertexRenderer. It is best if class name ends with Rendered. To implement this interface you need to write three functions renderEdge , renderVertex and getName . Both render functions accepts EdgeVisualAttributes object in which label of edge/vertex and color can be set. And both return true if edge/vertex should be rendered and false otherwise. getName function should return short descriptive name of the class and will be shown in layer chooser. For examples how to write renderers you can look into example renderers which are all in org.opentripplanner.inspector package. After your class is written you only need to add it to TileRenderManager: //This is how Wheelchair renderer is added renderers . put ( \"wheelchair\" , new EdgeVertexTileRenderer ( new WheelchairEdgeRenderer ())); wheelchair is internal layer key and should consist of a-zA-Z and -. By default all the tiles have cache headers to cache them for one hour. This can become problematic if you are changing renderers a lot. To disable this change GraphInspectorTileResource : //This lines CacheControl cc = new CacheControl (); cc . setMaxAge ( 3600 ); cc . setNoCache ( false ); //to this: CacheControl cc = new CacheControl (); cc . setNoCache ( true );","title":"Debug layers"},{"location":"Developers-Guide/#date-format","text":"Please use only ISO 8601 date format (YYYY-MM-DD) in documentation, comments, and throughout the project. This avoids the ambiguity that can result from differing local interpretations of date formats like 02/01/12.","title":"Date format"},{"location":"Developers-Guide/#code-style","text":"The OTP code style is described on a separate style guide page .","title":"Code style"},{"location":"Developers-Guide/#continuous-integration","text":"The OpenTripPlanner project uses the Travis CI continuous integration system . Any time a change is pushed to the main OpenTripPlanner repository on GitHub, this server will compile and test the new code, providing feedback on the stability of the build.","title":"Continuous Integration"},{"location":"Developers-Guide/#changelog-workflow","text":"The changelog file is generated from the pull-request(PR) title using the changelog workflow . The workflow runs after the PR is merged, and it changes, commits and pushes the Changelog.md . A secret personal access token is used to bypass the \"Require PR with 2 approvals\" rule. To exclude a PR from the changelog add [changelog skip] in the PR title.","title":"Changelog workflow"},{"location":"Developers-Guide/#how-to-update-the-changelog_token","text":"The CHANGELOG_TOKEN is used by the changelog workflow. It contains a Personal Access Token. The token must be generated by a Repository Owner and have the following rights ( Settings / Developer settings / Personal access tokens ):","title":"How-to update the CHANGELOG_TOKEN"},{"location":"Developers-Guide/#release-process","text":"This section serves as a checklist for the person performing releases. Note that much of this mimics the actions taken by the Maven release plugin. Based on past experience, the Maven release plugin can fail at various points in the process leaving the repo in a confusing state. Taking each action manually is more tedious, but keeps eyes on each step and is less prone to failure. Releases are performed off the master branch, and are tagged with git annotated tags. OpenTripPlanner is released as Maven artifacts to Maven Central. These include compiled and source code JARs as well as a \"shaded\" JAR containing all dependencies, allowing stand-alone usage. This release process is handled by the Sonatype Nexus Staging plugin, configured in the OpenTripPlanner POM. We no longer trigger deployment of artifacts to Maven Central or deployment of documentation to AWS automatically in build scripts. These steps are prone to failure and require storing a lot of infrequently used secret information in the repo and environment variables on GitHub. Our releases are currently not very frequent so we just carry out these steps manually by following the checklist. Check that your local copy of the dev branch is up to date with no uncommitted changes git status git checkout dev-2.x git clean -df git pull Verify that all dependencies in the POM are non-SNAPSHOT versions Update docs/Changelog.md Lines should have been added or updated as each pull request was merged If you suspect any changes are not reflected in the Changelog, review the commit log and add any missing items Update the header at the top of the list from x.y.z-SNAPSHOT to just x.y.z (current date) Check in any changes, and push to Github Check on GH Actions that the build is currently passing Switch to the HEAD of master branch, and ensure it's up to date with no uncommitted changes git checkout master git status git clean -df git pull Merge the dev branch into master git merge dev-2.x Bump the SNAPSHOT version in the POM to the release version Edit version in POM, removing SNAPSHOT and increasing version numbers as needed (following semantic versioning) git add pom.xml git commit -m \"prepare release x.y.z\" Run a test build of the release locally, without deploying it mvn clean install site The install goal will sign the Maven artifacts so you need the GPG signing certificate set up You can also use the package goal instead of the install goal to avoid signing if you don't have the GPG certificate installed. All tests should pass This build will also create Enunciate API docs and Javadoc with the correct non-snapshot version number Deploy the documentation to AWS S3 You have to do this right after the test release build to ensure the right version number in the docs You will need AWSCLI tools ( sudo pip install -U awscli ) You will need AWS credentials with write access to the bucket s3://dev.opentripplanner.org aws s3 cp --recursive target/site/apidocs s3://dev.opentripplanner.org/javadoc/x.y.z --acl public-read aws s3 cp --recursive target/site/enunciate/apidocs s3://dev.opentripplanner.org/apidoc/x.y.z --acl public-read Check that docs are readable and show the correct version via the development documentation landing page . Finally, if everything looks good, tag and push this release to make it official git tag -a vX.Y.Z -m \"release X.Y.Z\" git push origin vX.Y.Z Note that only one commit may have a particular non-snapshot version in the POM (this is the commit that should be tagged as the release) Go to the GitHub tags page and use the ... button to mark the new tag as a release. Give the release a name like v2.1.0 (March 2022) Optionally add a very condensed version of the changelog in the description box, with only the 5-10 most significant changes that might affect someone's choice to upgrade. Currently, pushing the tag does not trigger deployment of release Maven artifacts. This must be done manually. It can conceivably be configured to happen in the Actions scripts when any tag is pushed. Deploy the build artifacts to Maven Central and GitHub While still on the tag commit, run mvn deploy after you have completed the local build as described above. This requires you to have the GPG keys and Maven repo credentials set up. Attach the JAR files produced in /target to the GitHub release page you just created. Set up next development iteration Add a new section header to docs/Changelog.md like x.y+1.0-SNAPSHOT (in progress) Edit minor version in pom.xml to x.y+1.0-SNAPSHOT git add pom.xml docs/Changelog.md git commit -m \"Prepare next development iteration x.y+1.0-SNAPSHOT\" git push Check that Maven artifact appears on Maven Central Directory listing of OTP releases on Maven Central It may take a while (half an hour) for releases to show up in the central repo after Travis uploads the artifacts Merge master back into dev (to sync up the Maven artifact version from the POM) git checkout dev-2.x git merge master git push Make sure the main documentation is built For some reason it doesn't always build automatically Go to builds of docs.opentripplanner.org Click \"build version: latest\" Email the OTP dev and users mailing lists Mention the new version number. Provide links to the new developer documentation. Provide links to the artifacts directory on Maven Central. Trigger build of latest OTP documentation on Readthedocs.","title":"Release Process"},{"location":"Developers-Guide/#artifact-signing","text":"Maven release artifacts must be digitally signed to prove their origin. This is a safeguard against compromised code from a malicious third party being disguised as a trusted library. The OTP artifact signing key was created by Conveyal. We export only that signing subkey, with our company's main key blanked out. Therefore, even if someone managed to acquire the decrypted key file and the associated GPG passphrase, they would not have the main key. We could deactivate the signing key and create a new one, without the main key being compromised. OpenTripPlanner's POM is set up to sign artifacts in the verify phase, which means signing will happen for the install and deploy targets, but not the package target. When performing a local test build, if you do mvn clean install site it will test the signing process. If you do not have the certificate installed, you can instead to mvn clean package site to bypass signing, but this provides less certainty that everything is set up correctly for the CI-driven final release.","title":"Artifact Signing"},{"location":"Getting-OTP/","text":"Getting OpenTripPlanner Pre-built JARs OpenTripPlanner is distributed as a single stand-alone runnable JAR file. We create a tag and release page on GitHub for each release version, and also deploy them to the Maven Central repository. You can go to the release pages on GitHub or the OTP directory at Maven Central , navigate to the highest version number, and download the file whose name ends with shaded.jar . Note that version numbers like v2.1.0-rc1 or v2.1.0-SNAPSHOT refer to development builds before the release version v2.1.0 . The existence of a build vX.Y.Z-SNAPSHOT does not mean that vX.Y.Z has been released yet. We use the Github Actions CI system to build OTP every time a change is made. You can find the JARs resulting from those builds in the Github Packages repository . It can be harder to find the specific version you're looking for here, so we recommend using the release pages or Maven Central as described above. Building from Source You may also choose to build OTP from its source code. If you will be modifying OTP you will need to know how to rebuild it (though your IDE may take care of this build cycle for you). If you have the right software installed, building OTP locally from its source code is not particularly difficult. You should only need the following software: Git, a version control system Java Development Kit, preferably version 11 Maven, a build and dependency management system You will also need a reliable internet connection so Maven can fetch all of OTP's dependencies (the libraries it uses). Once you have these packages installed, create and/or switch to the directory where you will keep your Git repositories and make a local copy of the OTP source code: mkdir git cd git git clone git@github.com:opentripplanner/OpenTripPlanner.git Then change to the newly cloned OpenTripPlanner repository directory and start a build: cd OpenTripPlanner mvn clean package Maven should then be able to download all the libraries and other dependencies necessary to compile OTP. If all goes well you should see a success message like the following: [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 42.164s [INFO] Finished at: Tue Feb 18 19:35:48 CET 2014 [INFO] Final Memory: 88M/695M [INFO] ------------------------------------------------------------------------ This build process should produce a JAR file called otp-x.y.z-shaded.jar in the target/ directory which contains all the compiled OTP classes and their dependencies (the external libraries they use). The shell script called 'otp' in the root of the cloned repository will start the main class of that JAR file under a Java virtual machine, so after the Maven build completes you should be able to run ./otp --help and see an OTP help message including command line options. Due to the way Maven works, this script is not executable by default, so you will need to do chmod u+x ./otp before you run it to mark it as executable. The words \"clean package\" are the build steps you want to run. You're telling maven to clean up any extraneous junk in the directory, then perform all the build steps, including compilation, up to and including \"package\", which bundles the compiled program into a single JAR file for distribution. If you have just cloned OTP you will be working with the default \"master\" branch, where most active development occurs. This is not the most stable or deployment-ready code available. To avoid newly minted bugs or undocumented behavior, you can use Git to check out a specific release (tag or branch) of OTP to work with. The Maven build also includes many time-consuming integration tests. When working with a stable release of OTP, you may want to turn them off by adding the switch: -DskipTests . For example, you could do the following: cd OpenTripPlanner git checkout v2.0.0 git clean -df mvn clean package -DskipTests Please note that the build process creates two distinct versions of the OTP JAR file. The one ending in -shaded.jar is much bigger because it contains copies of all the external libraries that OTP uses. It serves as a stand-alone runnable distribution of OTP. The one with a version number but without the word shaded contains only OTP itself, without any external dependencies. This JAR is useful when OTP is included as a component in some other project, where we want the dependency management system to gather all the external libraries automatically. Maven Repository OpenTripPlanner is a Maven project. Maven is a combined build and dependency management system: it fetches all the external libraries that OTP uses, runs all the commands to compile the OTP source code into runnable form, performs tests, and can then deploy the final \"artifact\" (the runnable JAR file) to the Maven repository, from which it can be automatically included in other Java projects. This repository is machine-readable (by Maven or other build systems) and also provides human readable directory listings via HTTP. You can fetch an OTP JAR from this repository by constructing the proper URL for the release you want. For example, release 2.1.0 will be found at https://repo1.maven.org/maven2/org/opentripplanner/otp/2.1.0/otp-2.1.0-shaded.jar . To make use of OTP in another Maven project, you must specify it as a dependency in that project's pom.xml : <dependency> <groupId> org.opentripplanner </groupId> <artifactId> otp </artifactId> <version> 2.0.0 </version> </dependency> After each successful build, the Travis continuous integration system deploys the final OTP \"artifact\" (the runnable JAR) to our Maven repository as a \"SNAPSHOT\" build. This means that a Maven project depending on OTP as a library can always fetch the latest work in progress by specifying a snapshot artifact: <repositories> <repository> <id> ossrh_snapshots </id> <name> Sonatype OSSRH Shapshot Repository </name> <url> https://oss.sonatype.org/content/repositories/snapshots/ </url> </repository> </repositories> <dependency> <groupId> org.opentripplanner </groupId> <artifactId> otp </artifactId> <version> 2.1.0-SNAPSHOT </version> </dependency>","title":"Getting OTP"},{"location":"Getting-OTP/#getting-opentripplanner","text":"","title":"Getting OpenTripPlanner"},{"location":"Getting-OTP/#pre-built-jars","text":"OpenTripPlanner is distributed as a single stand-alone runnable JAR file. We create a tag and release page on GitHub for each release version, and also deploy them to the Maven Central repository. You can go to the release pages on GitHub or the OTP directory at Maven Central , navigate to the highest version number, and download the file whose name ends with shaded.jar . Note that version numbers like v2.1.0-rc1 or v2.1.0-SNAPSHOT refer to development builds before the release version v2.1.0 . The existence of a build vX.Y.Z-SNAPSHOT does not mean that vX.Y.Z has been released yet. We use the Github Actions CI system to build OTP every time a change is made. You can find the JARs resulting from those builds in the Github Packages repository . It can be harder to find the specific version you're looking for here, so we recommend using the release pages or Maven Central as described above.","title":"Pre-built JARs"},{"location":"Getting-OTP/#building-from-source","text":"You may also choose to build OTP from its source code. If you will be modifying OTP you will need to know how to rebuild it (though your IDE may take care of this build cycle for you). If you have the right software installed, building OTP locally from its source code is not particularly difficult. You should only need the following software: Git, a version control system Java Development Kit, preferably version 11 Maven, a build and dependency management system You will also need a reliable internet connection so Maven can fetch all of OTP's dependencies (the libraries it uses). Once you have these packages installed, create and/or switch to the directory where you will keep your Git repositories and make a local copy of the OTP source code: mkdir git cd git git clone git@github.com:opentripplanner/OpenTripPlanner.git Then change to the newly cloned OpenTripPlanner repository directory and start a build: cd OpenTripPlanner mvn clean package Maven should then be able to download all the libraries and other dependencies necessary to compile OTP. If all goes well you should see a success message like the following: [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 42.164s [INFO] Finished at: Tue Feb 18 19:35:48 CET 2014 [INFO] Final Memory: 88M/695M [INFO] ------------------------------------------------------------------------ This build process should produce a JAR file called otp-x.y.z-shaded.jar in the target/ directory which contains all the compiled OTP classes and their dependencies (the external libraries they use). The shell script called 'otp' in the root of the cloned repository will start the main class of that JAR file under a Java virtual machine, so after the Maven build completes you should be able to run ./otp --help and see an OTP help message including command line options. Due to the way Maven works, this script is not executable by default, so you will need to do chmod u+x ./otp before you run it to mark it as executable. The words \"clean package\" are the build steps you want to run. You're telling maven to clean up any extraneous junk in the directory, then perform all the build steps, including compilation, up to and including \"package\", which bundles the compiled program into a single JAR file for distribution. If you have just cloned OTP you will be working with the default \"master\" branch, where most active development occurs. This is not the most stable or deployment-ready code available. To avoid newly minted bugs or undocumented behavior, you can use Git to check out a specific release (tag or branch) of OTP to work with. The Maven build also includes many time-consuming integration tests. When working with a stable release of OTP, you may want to turn them off by adding the switch: -DskipTests . For example, you could do the following: cd OpenTripPlanner git checkout v2.0.0 git clean -df mvn clean package -DskipTests Please note that the build process creates two distinct versions of the OTP JAR file. The one ending in -shaded.jar is much bigger because it contains copies of all the external libraries that OTP uses. It serves as a stand-alone runnable distribution of OTP. The one with a version number but without the word shaded contains only OTP itself, without any external dependencies. This JAR is useful when OTP is included as a component in some other project, where we want the dependency management system to gather all the external libraries automatically.","title":"Building from Source"},{"location":"Getting-OTP/#maven-repository","text":"OpenTripPlanner is a Maven project. Maven is a combined build and dependency management system: it fetches all the external libraries that OTP uses, runs all the commands to compile the OTP source code into runnable form, performs tests, and can then deploy the final \"artifact\" (the runnable JAR file) to the Maven repository, from which it can be automatically included in other Java projects. This repository is machine-readable (by Maven or other build systems) and also provides human readable directory listings via HTTP. You can fetch an OTP JAR from this repository by constructing the proper URL for the release you want. For example, release 2.1.0 will be found at https://repo1.maven.org/maven2/org/opentripplanner/otp/2.1.0/otp-2.1.0-shaded.jar . To make use of OTP in another Maven project, you must specify it as a dependency in that project's pom.xml : <dependency> <groupId> org.opentripplanner </groupId> <artifactId> otp </artifactId> <version> 2.0.0 </version> </dependency> After each successful build, the Travis continuous integration system deploys the final OTP \"artifact\" (the runnable JAR) to our Maven repository as a \"SNAPSHOT\" build. This means that a Maven project depending on OTP as a library can always fetch the latest work in progress by specifying a snapshot artifact: <repositories> <repository> <id> ossrh_snapshots </id> <name> Sonatype OSSRH Shapshot Repository </name> <url> https://oss.sonatype.org/content/repositories/snapshots/ </url> </repository> </repositories> <dependency> <groupId> org.opentripplanner </groupId> <artifactId> otp </artifactId> <version> 2.1.0-SNAPSHOT </version> </dependency>","title":"Maven Repository"},{"location":"Governance/","text":"Project Governance OpenTripPlanner is a member project of the Software Freedom Conservancy . Development of OpenTripPlanner is managed by a Project Leadership Committee (PLC) which makes decisions by simple majority vote. The current members of this committee are (in alphabetical order): Name Affiliation Sean Barbeau University of South Florida Sheldon Brown Cambridge Systematics Andrew Byrd Conveyal Thomas Craig CALACT ITS4US Drew Dara-Abrams Interline David Emory IBI Group Thomas Gran Entur (Norway) Tuukka Hastrup Transpordiamet (Estonia) Joel Lappalainan Digitransit (Finland) Frank Purcell TriMet (Portland, Oregon) David Turner ex- OpenPlans The PLC holds a quarterly video conference on the first Tuesday of June, September, December, and March. An agenda is prepared as a collaborative document in advance of each quarterly meeting. These meetings are held at 8AM US Pacific time to accommodate members in the US Pacific, US Eastern, and Central European time zones. We take care to avoid a governance system that is too conceptual or process-heavy. The main goal is to have regular agenda-driven meetings that yield clear decisions and action items assigned to specific people. The committee should ideally be composed of active, professional contributors to the OpenTripPlanner project, including representatives of organizations that host official public deployments of OTP. We enfore a policy on the review and merging of new changes to the OTP system, guided by a roadmap maintained by the committee. All changes must be reviewed and approved by at least two people from two different organizations. The list of approved reviewers is the PLC Github group, visible here https://github.com/orgs/opentripplanner/teams/plc/members","title":"Governance"},{"location":"Governance/#project-governance","text":"OpenTripPlanner is a member project of the Software Freedom Conservancy . Development of OpenTripPlanner is managed by a Project Leadership Committee (PLC) which makes decisions by simple majority vote. The current members of this committee are (in alphabetical order): Name Affiliation Sean Barbeau University of South Florida Sheldon Brown Cambridge Systematics Andrew Byrd Conveyal Thomas Craig CALACT ITS4US Drew Dara-Abrams Interline David Emory IBI Group Thomas Gran Entur (Norway) Tuukka Hastrup Transpordiamet (Estonia) Joel Lappalainan Digitransit (Finland) Frank Purcell TriMet (Portland, Oregon) David Turner ex- OpenPlans The PLC holds a quarterly video conference on the first Tuesday of June, September, December, and March. An agenda is prepared as a collaborative document in advance of each quarterly meeting. These meetings are held at 8AM US Pacific time to accommodate members in the US Pacific, US Eastern, and Central European time zones. We take care to avoid a governance system that is too conceptual or process-heavy. The main goal is to have regular agenda-driven meetings that yield clear decisions and action items assigned to specific people. The committee should ideally be composed of active, professional contributors to the OpenTripPlanner project, including representatives of organizations that host official public deployments of OTP. We enfore a policy on the review and merging of new changes to the OTP system, guided by a roadmap maintained by the committee. All changes must be reviewed and approved by at least two people from two different organizations. The list of approved reviewers is the PLC Github group, visible here https://github.com/orgs/opentripplanner/teams/plc/members","title":"Project Governance"},{"location":"History/","text":"OpenTripPlanner Project History OpenTripPlanner 1 OpenTripPlanner was seeded by Portland, Oregon's transit agency TriMet with a Regional Travel Options grant and opened with a 3-day Kick-Off Workshop in July of 2009 bringing together transit agencies and the authors of the major open source transit passenger information software of the day: David Emory of FivePoints, Brian Ferris of OneBusAway , and Brandon Martin-Anderson of Graphserver . From 2009 through 2012, development was coordinated by New York nonprofit OpenPlans . In 2011 a second workshop was held to mark the end of the first phase of development. TriMet's 2009-2011 OTP Final Report summarizes progress at that point. The project has since grown to encompass a global community of users and developers. By early 2013, OpenTripPlanner had become the primary trip planning software used by TriMet in the Portland regional trip planner and was backing several popular mobile applications. Public-facing OpenTripPlanner instances were available in at least ten countries throughout the world. At this point the OpenPlans transportation software team became the independent consultancy Conveyal . The original OpenTripPlanner development team from OpenPlans still actively participates in programming, design, and community coordination via the mailing list and their roles on the OTP Project Leadership Committee . In summer of 2013, the OpenTripPlanner project was accepted for membership in the Software Freedom Conservancy (SFC) . SFC handles the legal and financial details common to many open source projects. In 2013-2014 OpenTripPlanner was a focal point in the Dutch Transport Ministry's Beter Benutten Multimodale Reisinformatie (Better Utilization: Multimodal Travel Information) project which encouraged investment in trip planning platforms and services. Five companies worked together to improve OpenTripPlanner performance in large regional transport networks and add support for streaming real-time data, making itineraries reflect service modifications and delays only seconds after vehicles report their positions. Another consortium embarked on a full rewrite of the trip planning core called RRRR (or R4) , a proof of concept validating extremely efficient routing techniques and serving as an early prototype for OTP2. In the fall of 2014, Arlington, Virginia launched a new commute planning site for the Washington, DC metropolitan area, depending on OpenTripPlanner to weigh the costs and benefits of various travel options. In 2015 the New York State department of transportation's 511 transit trip planner began using OTP to provide itineraries for public transit systems throughout the state from a single unified OTP instance. Starting in early 2016, the regional transport authorities of Helsinki, Finland (HSL) and Oslo, Norway (Ruter) began using a completely open source passenger information system based on OpenTripPlanner. National-scale OpenTripPlanner instances were also created in Finland and Norway. After seven years of hard work and almost 10,000 commits from over 100 contributors around the world, OTP version 1.0 was released on 9 September 2016. OpenTripPlanner 2 The OTP community has a long history with round-based routing algorithms. FivePoints, one of the predecessor projects to OTP, used a round-based method several years before the now-familiar Raptor algorithm was published in an influential paper . OpenPlans carried out experiments with routing innovations like Raptor and contraction hierarchies as they emerged in the academic literature. Research and development work on OTP scalability has focused on round-based tabular approaches since the MMRI pre-commercial procurement projects of 2013-2014. Conveyal built its high-performance transportation network analysis system around its R5 router . So in strategy discussions, the expected technical direction was clear. In the second quarter of 2018, Ruter and Entur took the lead on finally integrating a new round-based transit routing engine inspired by R5 into OTP. They also began adding support for importing EU-standard Netex data, making it possible for passenger information services in Europe to achieve regulatory compliance with a fully open source software stack. In June 2018, at the first OTP international summit hosted by Cambridge Systematics in Boston, the project leadership committee officially approved this roadmap toward OTP2. In April of 2019, the second OTP international summit was hosted by Entur in Oslo. Encouraged by the crowd of participants from across the Nordic countries and North America, work on OTP2 continued unabated through 2019, 2020, and 2021 with twice-weekly videoconferences bringing together software developers from across the world. Videos of the full April 2019 OTP summit and the October 2019 OTP webinar are available. OTP2 went into feature freeze in September 2020, and the 2.0 release occurred at the end of November 2020. OTP2 is now seeing production use for a subset of requests in several national-scale trip planners. The project leadership committee is exploring the creation of an OTP1 working group to ensure follow-up maintenance of the final version of OTP1.","title":"History"},{"location":"History/#opentripplanner-project-history","text":"","title":"OpenTripPlanner Project History"},{"location":"History/#opentripplanner-1","text":"OpenTripPlanner was seeded by Portland, Oregon's transit agency TriMet with a Regional Travel Options grant and opened with a 3-day Kick-Off Workshop in July of 2009 bringing together transit agencies and the authors of the major open source transit passenger information software of the day: David Emory of FivePoints, Brian Ferris of OneBusAway , and Brandon Martin-Anderson of Graphserver . From 2009 through 2012, development was coordinated by New York nonprofit OpenPlans . In 2011 a second workshop was held to mark the end of the first phase of development. TriMet's 2009-2011 OTP Final Report summarizes progress at that point. The project has since grown to encompass a global community of users and developers. By early 2013, OpenTripPlanner had become the primary trip planning software used by TriMet in the Portland regional trip planner and was backing several popular mobile applications. Public-facing OpenTripPlanner instances were available in at least ten countries throughout the world. At this point the OpenPlans transportation software team became the independent consultancy Conveyal . The original OpenTripPlanner development team from OpenPlans still actively participates in programming, design, and community coordination via the mailing list and their roles on the OTP Project Leadership Committee . In summer of 2013, the OpenTripPlanner project was accepted for membership in the Software Freedom Conservancy (SFC) . SFC handles the legal and financial details common to many open source projects. In 2013-2014 OpenTripPlanner was a focal point in the Dutch Transport Ministry's Beter Benutten Multimodale Reisinformatie (Better Utilization: Multimodal Travel Information) project which encouraged investment in trip planning platforms and services. Five companies worked together to improve OpenTripPlanner performance in large regional transport networks and add support for streaming real-time data, making itineraries reflect service modifications and delays only seconds after vehicles report their positions. Another consortium embarked on a full rewrite of the trip planning core called RRRR (or R4) , a proof of concept validating extremely efficient routing techniques and serving as an early prototype for OTP2. In the fall of 2014, Arlington, Virginia launched a new commute planning site for the Washington, DC metropolitan area, depending on OpenTripPlanner to weigh the costs and benefits of various travel options. In 2015 the New York State department of transportation's 511 transit trip planner began using OTP to provide itineraries for public transit systems throughout the state from a single unified OTP instance. Starting in early 2016, the regional transport authorities of Helsinki, Finland (HSL) and Oslo, Norway (Ruter) began using a completely open source passenger information system based on OpenTripPlanner. National-scale OpenTripPlanner instances were also created in Finland and Norway. After seven years of hard work and almost 10,000 commits from over 100 contributors around the world, OTP version 1.0 was released on 9 September 2016.","title":"OpenTripPlanner 1"},{"location":"History/#opentripplanner-2","text":"The OTP community has a long history with round-based routing algorithms. FivePoints, one of the predecessor projects to OTP, used a round-based method several years before the now-familiar Raptor algorithm was published in an influential paper . OpenPlans carried out experiments with routing innovations like Raptor and contraction hierarchies as they emerged in the academic literature. Research and development work on OTP scalability has focused on round-based tabular approaches since the MMRI pre-commercial procurement projects of 2013-2014. Conveyal built its high-performance transportation network analysis system around its R5 router . So in strategy discussions, the expected technical direction was clear. In the second quarter of 2018, Ruter and Entur took the lead on finally integrating a new round-based transit routing engine inspired by R5 into OTP. They also began adding support for importing EU-standard Netex data, making it possible for passenger information services in Europe to achieve regulatory compliance with a fully open source software stack. In June 2018, at the first OTP international summit hosted by Cambridge Systematics in Boston, the project leadership committee officially approved this roadmap toward OTP2. In April of 2019, the second OTP international summit was hosted by Entur in Oslo. Encouraged by the crowd of participants from across the Nordic countries and North America, work on OTP2 continued unabated through 2019, 2020, and 2021 with twice-weekly videoconferences bringing together software developers from across the world. Videos of the full April 2019 OTP summit and the October 2019 OTP webinar are available. OTP2 went into feature freeze in September 2020, and the 2.0 release occurred at the end of November 2020. OTP2 is now seeing production use for a subset of requests in several national-scale trip planners. The project leadership committee is exploring the creation of an OTP1 working group to ensure follow-up maintenance of the final version of OTP1.","title":"OpenTripPlanner 2"},{"location":"Interfaces-Data-Sources/","text":"OTP Interfaces (APIs) and Data Sources Input Formats At the core of OpenTripPlanner is a library of Java code that finds efficient paths through multi-modal transportation networks built from OpenStreetMap and GTFS data. It can also receive GTFS-RT (realtime) data... In addition to GTFS, OTP2 can also load data in the Nordic Profile of Netex, the EU-standard transit data interchange format. The upcoming EU-wide profile was heavily influenced by the Nordic Profile and uses the same schema, so eventual support for the full the EU profile is a possibility. GTFS and Netex data are converted into OTP's own internal model which is a superset of both. It is therefore possible to mix Netex and GTFS data, and potentially even data from other sources. Interfaces to Services (APIs) Several different services are built upon this routing library, and expose APIs: The OTP Routing API is a RESTful web service that responds to journey planning requests with itineraries in a JSON or XML representation. You can combine this API with OTP's standard Javascript front end to provide users with trip planning functionality in a familiar map interface, or write your own applications that talk directly to the API. The OTP Transit Index API is another RESTful web service that provides information derived from the input GTFS feed(s). Examples include routes serving a particular stop, upcoming vehicles at a particular stop, upcoming stops on a given trip, etc. More complex transit data requests can be formulated using a GraphQL API. Sandbox APIs Additional experimental APIs are provided by sandbox extensions : The Actuator API provides endpoints for checking the health status of the OTP instance. It can be useful when running OTP in a container. The Transmodel GraphQL API is the Transmodel API (version 3) used at Entur in production(Sep, 2020). The HSL Legacy GraphQL API is the HSL's GraphQL API used by the Digitransit project.","title":"Interfaces and Data Sources"},{"location":"Interfaces-Data-Sources/#otp-interfaces-apis-and-data-sources","text":"","title":"OTP Interfaces (APIs) and Data Sources"},{"location":"Interfaces-Data-Sources/#input-formats","text":"At the core of OpenTripPlanner is a library of Java code that finds efficient paths through multi-modal transportation networks built from OpenStreetMap and GTFS data. It can also receive GTFS-RT (realtime) data... In addition to GTFS, OTP2 can also load data in the Nordic Profile of Netex, the EU-standard transit data interchange format. The upcoming EU-wide profile was heavily influenced by the Nordic Profile and uses the same schema, so eventual support for the full the EU profile is a possibility. GTFS and Netex data are converted into OTP's own internal model which is a superset of both. It is therefore possible to mix Netex and GTFS data, and potentially even data from other sources.","title":"Input Formats"},{"location":"Interfaces-Data-Sources/#interfaces-to-services-apis","text":"Several different services are built upon this routing library, and expose APIs: The OTP Routing API is a RESTful web service that responds to journey planning requests with itineraries in a JSON or XML representation. You can combine this API with OTP's standard Javascript front end to provide users with trip planning functionality in a familiar map interface, or write your own applications that talk directly to the API. The OTP Transit Index API is another RESTful web service that provides information derived from the input GTFS feed(s). Examples include routes serving a particular stop, upcoming vehicles at a particular stop, upcoming stops on a given trip, etc. More complex transit data requests can be formulated using a GraphQL API.","title":"Interfaces to Services (APIs)"},{"location":"Interfaces-Data-Sources/#sandbox-apis","text":"Additional experimental APIs are provided by sandbox extensions : The Actuator API provides endpoints for checking the health status of the OTP instance. It can be useful when running OTP in a container. The Transmodel GraphQL API is the Transmodel API (version 3) used at Entur in production(Sep, 2020). The HSL Legacy GraphQL API is the HSL's GraphQL API used by the Digitransit project.","title":"Sandbox APIs"},{"location":"Localization/","text":"Localization NOTE: This documentation pertains to the client included in the main OTP repository. THIS BUILT-IN OTP CLIENT IS PROVIDED FOR TEST AND DEBUGGING PURPOSES. IT IS NOT MEANT FOR PRODUCTION USE. This page contains instructions for both developers and translators on how to make the OTP interface usable by people who speak different languages. Developers will need to take certain steps to mark translatable strings within the source code. Translators will need to edit specific files within the project to create or revise the translation for their language. In OTP we use gettext for localization, for the following reasons: Plural suport Context support Automatic extraction of translatable strings from source code Translator comments support Source references (we can see where each translated string is used in the source code) In the Javascript UI the i18next library is used. Three types of files are used in the OTP localization process: The .pot file is the message template. It is a starting point for creating new .po files. .po files are created and edited by translators based on the .pot file. .json files are generated from the .po files for each language. .js files are localization configuration files which specify units and time/date formats. Only the .po and .js files are directly edited. The .pot file is created from an automated analysis of annotated source code. The .json files are also automatically generated as an easy way for the Javascript UI to consume the contents of the .po files. All translation files are in the directory /src/client/i18n . For Software Developers: Adding New Strings When you add a string to Javascript source that will be seen by the end user, wherever that string is referenced you should surround it with a call to a special function. The name of the function depends on what kind of string it is: basic string: _tr('string', parameters) basic string with context: ngettext('context', 'string') string with plural: ngettext('singular', 'plural', quantity) string with plural and context: npgettext('context', 'singular', 'plural', quantity) For more detail, see Sprintf parameters . A \"context\" is any string (preferably short and without whitespace) that is used to disambiguate the translation of the main string. It is used when developers get input from translators that some string should be translated in different ways in different parts of the program. Each of those distinct places will be assigned a different context string. When you add strings to the source code, if you think that translators might not understand how the string is used or what parameters it requires, add translator comments like this: //TRANSLATORS: Start: location at [time date] (Used in print itinerary //when do you start your trip) html += '<h3>' + _tr ( 'Start: %s at %s' , this . getStartLocationStr (), this . getStartTimeStr ()) + '</h3>' ; Translator comments must always start with TRANSLATORS: and must be in the line immediately before translated string. Otherwise they won't be extracted together with the string. Examples: Basic translated string //TRANSLATORS: Board Public transit route name (agency name //Stop ID ) start time html += '<li><b>' + _tr ( 'Board' ) + '</b>: ' + leg . from . name + ' (' + leg . from . stopId . agencyId + ' Stop ID #' + //With named sprintf parameters (our preferred option) //TRANSLATORS: Start: location at [time date] (Used in print itinerary //when do you start your trip) html += '<h3>' + _tr ( 'Start: %(location)s at %(time_date)s' , { 'location' : this . getStartLocationStr (), 'time_date' : this . getStartTimeStr ()}) + '</h3>' ; //With positional sprintf parameters (to be avoided because word order changes between languages) html += '<h3>' + _tr ( 'End: %1$s at %2$s' , this . getEndLocationStr (), this . getEndTimeStr ()) + '</h3>' ; Normal string with context if ( leg . headsign ) html += pgettext ( \"bus_direction\" , \" to \" ) + leg . headsign ; //same string could be different translation //TRANSLATORS: [distance] to [name of destination] html += \" \" + otp . util . Itin . distanceString ( leg . distance ) + pgettext ( \"direction\" , \" to \" ) + leg . to . name ; Plural strings //TRANSLATORS: widget title this . setTitle ( ngettext ( \"%d Itinerary Returned\" , \"%d Itineraries Returned\" , this . itineraries . length )); If you add new strings to the source code, it is good practice to also update the translation template and the translations but it is not mandatory (these can be updated later). It is also recommended to include \"i18n string change\" in the commit message. Updating translations Translations are updated with the help of Babel and i18next-conv (xgettext doesn't yet have great Javascript support). Babel is used to extract strings from the Javascript source code into the shared .POT translation template, and also for updating the existing .PO language translations when new strings are introduced in the template. i18next-conv is used to convert the .PO translation files for the individual languages to .json files which are used by the Javascript translation library. Installing Babel You can install it from your operating system's package repository (if available) or you can use virtualenv . Install virtualenv (This depends on your operating system) Create virtualenv with name .venv in directory where src and other files resides (Root OpenTripPlanner directory). virtualenv2 .venv (python 2) or python3 -m venv .venv (python 3) Use virtualenv source .venv/bin/activate Install babel pip install babel If you didn't install babel from virtualenv in root OpenTripPlanner directory you have to add path to babel in Makefile. change PYBABEL variable to path to pybabel. Installing i18next-conv i18next-conv requires nodejs . Once you have NodeJS installed, use npm install i18next-conv to install i18next-conv in the same directory where you created virtualenv. Updating the .pot Template In the root of the OTP repo, run make . The commands in the Makefile will extract the translatable strings from the Javascript files and update the translation template messages.pot , as well as the .po translation files for all the different languages. Once this is done, you can translate the new strings in the .po files. After saving the updated .po file, run make update_js to transform to PO files into .json , which is used at runtime by the Javascript translation library. After you rebuild OTP, all new strings should be visible in the UI. For Translators: Creating New Translations The following can get a bit technical. If you want to do a translation but don't want to / know how to install all this software, post to the opentripplanner-dev mailing list stating what language you want to translate, and someone will make you a corresponding .po file. Creating a New Translation File New .po files are created from the .pot template with the help of msginit , which is run like this: msginit init -l <LAN> -i messages.pot -o <LAN>.po , where <LAN> is a culture code. New .po files can also be created with the help of Poedit . All translation files should be placed in the directory /src/client/i18n . Please use the ISO language code as the culture code (e.g. fr.po for French). We will append country codes in the following limited circumstances: British versus US English ( en_GB.po and en_US.po ) Brazilian Portuguese pt_BR.po , as opposed to pt.po for European Portuguese Chinese: zh_TW.po for traditional characters as used in e.g. Taiwan and Hong Kong, and zh_CN.po for simplified characters as used in mainland China, Singapore, etc. These conventions are based on the Launchpad Translation page. In Linux you can see the culture codes for all the locales you have installed with the command locale -a . A list of culture codes is also availible here . Performing the Translation Configuration Copy the locale configuration script English.js from /src/client/js/otp/locale to YourLanguage.js and customize it to your language. Change the name, units, locale_short and datepicker_locale_short values. Translate infoWidgets and localize the time/date formats. Then take the following steps: Add the culture code to the LANGS variable in the Makefile` Add the new YourLanguage.js to the locales variable in /src/client/js/otp/config.js Add a new datepicker translation to /src/client/js/lib/jquery-ui/i18n Load the new datepicker translation and YourLanguage.js in /src/client/index.html Translating Strings For translating the strings themselves, you can use any program that supports gettext files. You can in theory use any text editor, but programs or plugins purpose-built for translating are recommended. Most of them support checking parameter correctness, translation memory, web translating services etc. to make the task easier. Here are some such programs (all free and open source): Poedit For Linux, Windows, and Mac. Use a version newer then 1.5. This is the recommended choice for getting started with localization. It supports translation memory and file context. Web Poedit Usable from within a web browser, you don't have to install or register Gted A plugin for the Eclipse IDE. Lokalize Runs under KDE on Linux, has some Windows support. Supports translation memory and file context. Virtaal For Linux, Windows, and beta for Mac. Supports Google and Microsoft web translation and other translation memory services. All these programs support setting a string to \"fuzzy\", marking that it needs review etc. in case you translate something but aren't sure of it's correctness. Sometimes those flags are set automatically if the original string was changed and translators must check if the translation is still correct. Caveats Be careful when translating that the translated strings have the same format as the original. If spaces appear at the start or end of the strings, they must also appear in the translation. The order of unnamed (positional) parameters may change depending on the target language. You can also leave parameter out of the translation if it is irrelevant in the target language.","title":"Localization"},{"location":"Localization/#localization","text":"NOTE: This documentation pertains to the client included in the main OTP repository. THIS BUILT-IN OTP CLIENT IS PROVIDED FOR TEST AND DEBUGGING PURPOSES. IT IS NOT MEANT FOR PRODUCTION USE. This page contains instructions for both developers and translators on how to make the OTP interface usable by people who speak different languages. Developers will need to take certain steps to mark translatable strings within the source code. Translators will need to edit specific files within the project to create or revise the translation for their language. In OTP we use gettext for localization, for the following reasons: Plural suport Context support Automatic extraction of translatable strings from source code Translator comments support Source references (we can see where each translated string is used in the source code) In the Javascript UI the i18next library is used. Three types of files are used in the OTP localization process: The .pot file is the message template. It is a starting point for creating new .po files. .po files are created and edited by translators based on the .pot file. .json files are generated from the .po files for each language. .js files are localization configuration files which specify units and time/date formats. Only the .po and .js files are directly edited. The .pot file is created from an automated analysis of annotated source code. The .json files are also automatically generated as an easy way for the Javascript UI to consume the contents of the .po files. All translation files are in the directory /src/client/i18n .","title":"Localization"},{"location":"Localization/#for-software-developers-adding-new-strings","text":"When you add a string to Javascript source that will be seen by the end user, wherever that string is referenced you should surround it with a call to a special function. The name of the function depends on what kind of string it is: basic string: _tr('string', parameters) basic string with context: ngettext('context', 'string') string with plural: ngettext('singular', 'plural', quantity) string with plural and context: npgettext('context', 'singular', 'plural', quantity) For more detail, see Sprintf parameters . A \"context\" is any string (preferably short and without whitespace) that is used to disambiguate the translation of the main string. It is used when developers get input from translators that some string should be translated in different ways in different parts of the program. Each of those distinct places will be assigned a different context string. When you add strings to the source code, if you think that translators might not understand how the string is used or what parameters it requires, add translator comments like this: //TRANSLATORS: Start: location at [time date] (Used in print itinerary //when do you start your trip) html += '<h3>' + _tr ( 'Start: %s at %s' , this . getStartLocationStr (), this . getStartTimeStr ()) + '</h3>' ; Translator comments must always start with TRANSLATORS: and must be in the line immediately before translated string. Otherwise they won't be extracted together with the string.","title":"For Software Developers: Adding New Strings"},{"location":"Localization/#examples","text":"","title":"Examples:"},{"location":"Localization/#basic-translated-string","text":"//TRANSLATORS: Board Public transit route name (agency name //Stop ID ) start time html += '<li><b>' + _tr ( 'Board' ) + '</b>: ' + leg . from . name + ' (' + leg . from . stopId . agencyId + ' Stop ID #' + //With named sprintf parameters (our preferred option) //TRANSLATORS: Start: location at [time date] (Used in print itinerary //when do you start your trip) html += '<h3>' + _tr ( 'Start: %(location)s at %(time_date)s' , { 'location' : this . getStartLocationStr (), 'time_date' : this . getStartTimeStr ()}) + '</h3>' ; //With positional sprintf parameters (to be avoided because word order changes between languages) html += '<h3>' + _tr ( 'End: %1$s at %2$s' , this . getEndLocationStr (), this . getEndTimeStr ()) + '</h3>' ;","title":"Basic translated string"},{"location":"Localization/#normal-string-with-context","text":"if ( leg . headsign ) html += pgettext ( \"bus_direction\" , \" to \" ) + leg . headsign ; //same string could be different translation //TRANSLATORS: [distance] to [name of destination] html += \" \" + otp . util . Itin . distanceString ( leg . distance ) + pgettext ( \"direction\" , \" to \" ) + leg . to . name ;","title":"Normal string with context"},{"location":"Localization/#plural-strings","text":"//TRANSLATORS: widget title this . setTitle ( ngettext ( \"%d Itinerary Returned\" , \"%d Itineraries Returned\" , this . itineraries . length )); If you add new strings to the source code, it is good practice to also update the translation template and the translations but it is not mandatory (these can be updated later). It is also recommended to include \"i18n string change\" in the commit message.","title":"Plural strings"},{"location":"Localization/#updating-translations","text":"Translations are updated with the help of Babel and i18next-conv (xgettext doesn't yet have great Javascript support). Babel is used to extract strings from the Javascript source code into the shared .POT translation template, and also for updating the existing .PO language translations when new strings are introduced in the template. i18next-conv is used to convert the .PO translation files for the individual languages to .json files which are used by the Javascript translation library.","title":"Updating translations"},{"location":"Localization/#installing-babel","text":"You can install it from your operating system's package repository (if available) or you can use virtualenv . Install virtualenv (This depends on your operating system) Create virtualenv with name .venv in directory where src and other files resides (Root OpenTripPlanner directory). virtualenv2 .venv (python 2) or python3 -m venv .venv (python 3) Use virtualenv source .venv/bin/activate Install babel pip install babel If you didn't install babel from virtualenv in root OpenTripPlanner directory you have to add path to babel in Makefile. change PYBABEL variable to path to pybabel.","title":"Installing Babel"},{"location":"Localization/#installing-i18next-conv","text":"i18next-conv requires nodejs . Once you have NodeJS installed, use npm install i18next-conv to install i18next-conv in the same directory where you created virtualenv.","title":"Installing i18next-conv"},{"location":"Localization/#updating-the-pot-template","text":"In the root of the OTP repo, run make . The commands in the Makefile will extract the translatable strings from the Javascript files and update the translation template messages.pot , as well as the .po translation files for all the different languages. Once this is done, you can translate the new strings in the .po files. After saving the updated .po file, run make update_js to transform to PO files into .json , which is used at runtime by the Javascript translation library. After you rebuild OTP, all new strings should be visible in the UI.","title":"Updating the .pot Template"},{"location":"Localization/#for-translators-creating-new-translations","text":"The following can get a bit technical. If you want to do a translation but don't want to / know how to install all this software, post to the opentripplanner-dev mailing list stating what language you want to translate, and someone will make you a corresponding .po file.","title":"For Translators: Creating New Translations"},{"location":"Localization/#creating-a-new-translation-file","text":"New .po files are created from the .pot template with the help of msginit , which is run like this: msginit init -l <LAN> -i messages.pot -o <LAN>.po , where <LAN> is a culture code. New .po files can also be created with the help of Poedit . All translation files should be placed in the directory /src/client/i18n . Please use the ISO language code as the culture code (e.g. fr.po for French). We will append country codes in the following limited circumstances: British versus US English ( en_GB.po and en_US.po ) Brazilian Portuguese pt_BR.po , as opposed to pt.po for European Portuguese Chinese: zh_TW.po for traditional characters as used in e.g. Taiwan and Hong Kong, and zh_CN.po for simplified characters as used in mainland China, Singapore, etc. These conventions are based on the Launchpad Translation page. In Linux you can see the culture codes for all the locales you have installed with the command locale -a . A list of culture codes is also availible here .","title":"Creating a New Translation File"},{"location":"Localization/#performing-the-translation","text":"","title":"Performing the Translation"},{"location":"Localization/#configuration","text":"Copy the locale configuration script English.js from /src/client/js/otp/locale to YourLanguage.js and customize it to your language. Change the name, units, locale_short and datepicker_locale_short values. Translate infoWidgets and localize the time/date formats. Then take the following steps: Add the culture code to the LANGS variable in the Makefile` Add the new YourLanguage.js to the locales variable in /src/client/js/otp/config.js Add a new datepicker translation to /src/client/js/lib/jquery-ui/i18n Load the new datepicker translation and YourLanguage.js in /src/client/index.html","title":"Configuration"},{"location":"Localization/#translating-strings","text":"For translating the strings themselves, you can use any program that supports gettext files. You can in theory use any text editor, but programs or plugins purpose-built for translating are recommended. Most of them support checking parameter correctness, translation memory, web translating services etc. to make the task easier. Here are some such programs (all free and open source): Poedit For Linux, Windows, and Mac. Use a version newer then 1.5. This is the recommended choice for getting started with localization. It supports translation memory and file context. Web Poedit Usable from within a web browser, you don't have to install or register Gted A plugin for the Eclipse IDE. Lokalize Runs under KDE on Linux, has some Windows support. Supports translation memory and file context. Virtaal For Linux, Windows, and beta for Mac. Supports Google and Microsoft web translation and other translation memory services. All these programs support setting a string to \"fuzzy\", marking that it needs review etc. in case you translate something but aren't sure of it's correctness. Sometimes those flags are set automatically if the original string was changed and translators must check if the translation is still correct.","title":"Translating Strings"},{"location":"Localization/#caveats","text":"Be careful when translating that the translated strings have the same format as the original. If spaces appear at the start or end of the strings, they must also appear in the translation. The order of unnamed (positional) parameters may change depending on the target language. You can also leave parameter out of the translation if it is irrelevant in the target language.","title":"Caveats"},{"location":"Netex-Norway/","text":"Using European Data Standards Building with Netex Data One important new feature of OTP2 is the ability to load Netex data. Netex is a European specification for transit data exchange , comparable in purpose to GTFS but broader in scope. An EU directive aims to have all EU countries sharing Netex data by the end of 2019. Different countries are currently using different incompatible \"profiles\" of Netex, but an effort is underway to converge on a single European standard profile. This is based in large part on the Norwegian profile, and Norway's national passenger information and ticketing agency Entur has contributed the OTP2 Netex loading code. Therefore if you'd like to try loading Netex data, Norway is a good place to start. The Norwegian Netex data can be downloaded from the Entur developer pages . There is a column of Netex download links partway down the page, and the first row is for all of Norway. Full OSM data for Norway can be downloaded from the Geofabrik Norway downloads page . Get the norway-latest.osm.pbf file, which can then be filtered to remove buildings and other unused data before loading into OTP using a command like the one below. This filtering step can be skipped if you don't have the necessary Osmium tools installed. osmium tags-filter norway-latest.osm.pbf w/highway w/public_transport=platform w/railway=platform w/park_ride=yes r/type=restriction -o norway-filtered.osm.pbf -f pbf,add_metadata=false,pbf_dense_nodes=true Be sure to move the original unfiltered file out of your graph inputs directory (or rename it with a suffix like norway-latest.osm.pbf.ignore ) otherwise OTP2 will try to include both the filtered and unfiltered OSM data in your graph. The build-config.json for a Norwegian graph using Netex data looks like this: { \"areaVisibility\" : true , \"parentStopLinking\" : true , \"platformEntriesLinking\" : true , \"osmWayPropertySet\" : \"norway\" , \"islandWithoutStopsMaxSize\" : 5 , \"islandWithStopsMaxSize\" : 5 , \"dataImportReport\" : true , \"netex\" : { \"moduleFilePattern\" : \".*-netex\\\\.zip\" , \"sharedFilePattern\" : \"_stops.xml\" , \"sharedGroupFilePattern\" : \"_(\\\\w{3})(_flexible)?_shared_data.xml\" , \"groupFilePattern\" : \"(\\\\w{3})_.*\\\\.xml\" , \"netexFeedId\" : \"EN\" , \"ferryIdsNotAllowedForBicycle\" : [ \"NYC:Line:1\" , \"NYC:Line:012fc5c4-131b-4dfc-8160-4e49136e531a\" , \"NYC:Line:8bfef12a-ac98-4376-8a2a-eb5a336d107b\" ] } } Note the special section specifying how to find Netex XML files within the single ZIP archive you downloaded. Once you have the graph inputs (the OSM PBF file, the Netex ZIP file, and the build-config.json ) saved together in a directory, you can instruct OTP2 to build a graph from these inputs: java -Xmx10G otp2.jar --build --save /path/to/graph/inputs This should produce a file graph.obj in the same directory as your inputs. Building this Norway graph takes approximately 16 minutes (without elevation data, as configured above), and can be done within 10GB of heap memory (JVM switch -Xmx10G ). Increasing that to 12 or 14GB might speed it up a bit if you have the space. The Graph file it produces is just under 600MB. The server will take about 30 seconds to load this Graph and start up, and will consume about 4GB of heap memory under light use. You can then start up an OTP server with a command like this: java -Xmx6G otp2.jar --load /path/to/graph Once the server is started up, go to http://localhost:8080 in a browser to try out your server using OTP's built in testing web client. Try some long trips like Oslo to Bergen and see if you can get long distance trains and flights as alternatives. You might need to increase the walking limit above its very low default value. Adding SIRI Realtime Data Another important feature in OTP2 is the ability to use SIRI realtime data . Within the EU data standards, SIRI is analogous to GTFS-RT: a way to apply realtime updates on top of schedule data. While technically a distinct specification from Netex, both Netex and SIRI use the Transmodel vocabulary, allowing SIRI messages to reference entities in Netex schedule data. Like GTFS-RT, SIRI is consumed by OTP2 using \"graph updaters\" which are configured in the router-config.json file, which is placed in the same directory as the graph.obj file and loaded at server startup. { \"updaters\" : [ { \"type\" : \"siri-sx-updater\" , \"frequencySec\" : 60 , \"url\" : \"https://api.example.com/siri\" , \"feedId\" : \"siri-sx\" , \"blockReadinessUntilInitialized\" : true }, { \"type\" : \"siri-et-updater\" , \"frequencySec\" : 20 , \"previewIntervalMinutes\" : 180 , \"url\" : \"https://api.example.com/siri\" , \"feedId\" : \"siri-et\" , \"blockReadinessUntilInitialized\" : true }, { \"type\" : \"siri-vm-updater\" , \"frequencySec\" : 60 , \"url\" : \"https://api.example.com/siri\" , \"feedId\" : \"siri-vm\" , \"blockReadinessUntilInitialized\" : true }, { \"type\" : \"raptor-transit-layer\" , \"updateIntervalSeconds\" : 20 } ] } The first three updaters fetch three different kinds of SIRI data: Situation Exchange (SX, text notices analogous to GTFS-RT Alerts) Estimated Timetable (ET, predicted arrival times analogous to GTFS-RT TripUpdates) Vehicle Monitoring (VM, location and status of vehicles analogous to GTFS-RT VehiclePositions) These updaters can handle differential updates, but they use a polling approach rather than the message-oriented streaming approach of the GTFS-RT Websocket updater. The server keeps track of clients, sending only the things that have changed since the last polling operation. Note that between these SIRI updaters and the GTFS-RT Websocket updater, we now have both polling and streaming examples of GTFS-RT \"incrementality\" semantics, so should be able to finalize that part of the specification. The final updater regularly performs a copy of the realtime data into a format suitable for use by OTP2's new Raptor router. Without this updater the realtime data will be received and cataloged, but not visible to the router.","title":"Netex and SIRI"},{"location":"Netex-Norway/#using-european-data-standards","text":"","title":"Using European Data Standards"},{"location":"Netex-Norway/#building-with-netex-data","text":"One important new feature of OTP2 is the ability to load Netex data. Netex is a European specification for transit data exchange , comparable in purpose to GTFS but broader in scope. An EU directive aims to have all EU countries sharing Netex data by the end of 2019. Different countries are currently using different incompatible \"profiles\" of Netex, but an effort is underway to converge on a single European standard profile. This is based in large part on the Norwegian profile, and Norway's national passenger information and ticketing agency Entur has contributed the OTP2 Netex loading code. Therefore if you'd like to try loading Netex data, Norway is a good place to start. The Norwegian Netex data can be downloaded from the Entur developer pages . There is a column of Netex download links partway down the page, and the first row is for all of Norway. Full OSM data for Norway can be downloaded from the Geofabrik Norway downloads page . Get the norway-latest.osm.pbf file, which can then be filtered to remove buildings and other unused data before loading into OTP using a command like the one below. This filtering step can be skipped if you don't have the necessary Osmium tools installed. osmium tags-filter norway-latest.osm.pbf w/highway w/public_transport=platform w/railway=platform w/park_ride=yes r/type=restriction -o norway-filtered.osm.pbf -f pbf,add_metadata=false,pbf_dense_nodes=true Be sure to move the original unfiltered file out of your graph inputs directory (or rename it with a suffix like norway-latest.osm.pbf.ignore ) otherwise OTP2 will try to include both the filtered and unfiltered OSM data in your graph. The build-config.json for a Norwegian graph using Netex data looks like this: { \"areaVisibility\" : true , \"parentStopLinking\" : true , \"platformEntriesLinking\" : true , \"osmWayPropertySet\" : \"norway\" , \"islandWithoutStopsMaxSize\" : 5 , \"islandWithStopsMaxSize\" : 5 , \"dataImportReport\" : true , \"netex\" : { \"moduleFilePattern\" : \".*-netex\\\\.zip\" , \"sharedFilePattern\" : \"_stops.xml\" , \"sharedGroupFilePattern\" : \"_(\\\\w{3})(_flexible)?_shared_data.xml\" , \"groupFilePattern\" : \"(\\\\w{3})_.*\\\\.xml\" , \"netexFeedId\" : \"EN\" , \"ferryIdsNotAllowedForBicycle\" : [ \"NYC:Line:1\" , \"NYC:Line:012fc5c4-131b-4dfc-8160-4e49136e531a\" , \"NYC:Line:8bfef12a-ac98-4376-8a2a-eb5a336d107b\" ] } } Note the special section specifying how to find Netex XML files within the single ZIP archive you downloaded. Once you have the graph inputs (the OSM PBF file, the Netex ZIP file, and the build-config.json ) saved together in a directory, you can instruct OTP2 to build a graph from these inputs: java -Xmx10G otp2.jar --build --save /path/to/graph/inputs This should produce a file graph.obj in the same directory as your inputs. Building this Norway graph takes approximately 16 minutes (without elevation data, as configured above), and can be done within 10GB of heap memory (JVM switch -Xmx10G ). Increasing that to 12 or 14GB might speed it up a bit if you have the space. The Graph file it produces is just under 600MB. The server will take about 30 seconds to load this Graph and start up, and will consume about 4GB of heap memory under light use. You can then start up an OTP server with a command like this: java -Xmx6G otp2.jar --load /path/to/graph Once the server is started up, go to http://localhost:8080 in a browser to try out your server using OTP's built in testing web client. Try some long trips like Oslo to Bergen and see if you can get long distance trains and flights as alternatives. You might need to increase the walking limit above its very low default value.","title":"Building with Netex Data"},{"location":"Netex-Norway/#adding-siri-realtime-data","text":"Another important feature in OTP2 is the ability to use SIRI realtime data . Within the EU data standards, SIRI is analogous to GTFS-RT: a way to apply realtime updates on top of schedule data. While technically a distinct specification from Netex, both Netex and SIRI use the Transmodel vocabulary, allowing SIRI messages to reference entities in Netex schedule data. Like GTFS-RT, SIRI is consumed by OTP2 using \"graph updaters\" which are configured in the router-config.json file, which is placed in the same directory as the graph.obj file and loaded at server startup. { \"updaters\" : [ { \"type\" : \"siri-sx-updater\" , \"frequencySec\" : 60 , \"url\" : \"https://api.example.com/siri\" , \"feedId\" : \"siri-sx\" , \"blockReadinessUntilInitialized\" : true }, { \"type\" : \"siri-et-updater\" , \"frequencySec\" : 20 , \"previewIntervalMinutes\" : 180 , \"url\" : \"https://api.example.com/siri\" , \"feedId\" : \"siri-et\" , \"blockReadinessUntilInitialized\" : true }, { \"type\" : \"siri-vm-updater\" , \"frequencySec\" : 60 , \"url\" : \"https://api.example.com/siri\" , \"feedId\" : \"siri-vm\" , \"blockReadinessUntilInitialized\" : true }, { \"type\" : \"raptor-transit-layer\" , \"updateIntervalSeconds\" : 20 } ] } The first three updaters fetch three different kinds of SIRI data: Situation Exchange (SX, text notices analogous to GTFS-RT Alerts) Estimated Timetable (ET, predicted arrival times analogous to GTFS-RT TripUpdates) Vehicle Monitoring (VM, location and status of vehicles analogous to GTFS-RT VehiclePositions) These updaters can handle differential updates, but they use a polling approach rather than the message-oriented streaming approach of the GTFS-RT Websocket updater. The server keeps track of clients, sending only the things that have changed since the last polling operation. Note that between these SIRI updaters and the GTFS-RT Websocket updater, we now have both polling and streaming examples of GTFS-RT \"incrementality\" semantics, so should be able to finalize that part of the specification. The final updater regularly performs a copy of the realtime data into a format suitable for use by OTP2's new Raptor router. Without this updater the realtime data will be received and cataloged, but not visible to the router.","title":"Adding SIRI Realtime Data"},{"location":"OTP2-MigrationGuide/","text":"How to migrate from OTP1 to OTP2 Command Line The OTP2 command line parameters are different than in OTP1. Use the --help option to get the current documentation, and look at Basic Tutorial - Starting OTP for examples. The possibility to build the graph in 2 steps (streets then transit) is new in OTP2. OTP2 does not support routing on more than one separate transportation network with a single server (referred to as multiple \"routers\" in OTP1). File Loading OTP1 reads and writes all files on the local filesystem, and no other data-source is supported. In OTP2 we support accessing cloud storage. So far support for Google Cloud Storage has been added and we plan to add support for AWS S3 as well. Config files ( otp-config.json, build-config.json, router-config.json ) must be read from the local file system, while other files can be read/written from either the local filesystem or cloud storage. OTP2 supports mixing any supported data sources. OTP1 loads input data files ( DEM, OSM, GTFS, NeTEx ) based on the suffix (file extension). But for GTFS files OTP1 also opens the zip-file and looks for stops.txt . OTP2 identifies GTFS files by the name only: it will detect any zip-file or directory that contains \"gtfs\" as part of the name. All file types in OTP2 are resolved by matching the name with a regexp pattern. You can configure the patterns in the build-config.json if the defaults do not suit you. OTP2 does not support multiple routers (separate named networks to route on), but you can load as many GTFS and/or NeTEx feeds as you want into a single routable network in a single instance of OTP2. Build Config OTP will log all unrecognized parameters when starting up. Make sure to investigate all log events of this type: 16:18:46.911 WARN (NodeAdapter.java:413) Unexpected config parameter: 'fetchElevationUS:false' in 'build-config.json'. Is the spelling correct? New parameters configVersion Optional parameter which can be used to version the build config file. Since v2.1 dataOverlay Config for the DataOverlay Sandbox module. Since v2.1 maxAreaNodes Visibility calculations will not be done for areas with more nodes than this limit. Since v2.1 maxJourneyDuration This limits the patterns we consider in the transit search. See RoutingRequest . Since v2.1 maxStopToShapeSnapDistance Used for mapping route geometry shapes. Since v2.1 transferRequests Pre-calculate transfers. Since v2.1 transitServiceStart Limit the import of transit services to the given start date. Default: -P1Y . Since v2.0 transitServiceEnd Limit the import of transit services to the given end date. Inclusive . Default: P3Y . Since v2.0 Parameters whose names were changed alightTimes to routingDefaults.alightSlackByMode . Since v2.0 boardTimes to routingDefaults.boardSlackByMode . Since v2.0 htmlAnnotations to dataImportReport . Since v2.0 maxHtmlAnnotationsPerFile to maxDataImportIssuesPerFile . Since v2.0 maxTransferDistance to maxTransferDurationSeconds . Since v2.1 These parameters are no longer supported fetchElevationUS . Since v2.1 parentStopLinking . Since v2.0 staticBikeRental . Since v2.1 stationTransfers . Since v2.0 stopClusterMode . Since v2.0 useTransfersTxt . Since v2.1 OTP2 records the \"parentStation\" relationship between stops and stations in its internal transit model, based on the GTFS and/or NeTEx input. This enables OTP to search from all stop in a station without walking/waiting when the request from/to input field is a station id. There is no way to automatically infer this parent station relationship based on geographic proximity in OTP2. Transfers in OTP2 are generated based on the stop location and the OSM data or GTFS Pathways. In future versions of OTP2 we also want to support generating simple transfers based on \"line-of-sight\" if no pathways or OSM data exist. See issue #3204 . Cleaning and patching input data is NOT a core feature of OTP, but anyone is welcome to implement a sandbox plugin to patch data. So, if any of the features above are needed they can be ported from OTP1 into an OTP2 sandbox feature. Router Config See the Router Configuration for a description of the new and existing routing parameters. New parameters flex Add configuration for flex services (sandbox feature). Since v2.1 configVersion Optional parameter which can be used to version the build config file. Since v2.1 streetRoutingTimeout Maximum time limit for street route queries. Replace the old timeout . Since v2.0 transit A set of parameters to tune the Raptor transit router. Since v2.0, changed in v2.1 itineraryFilters Configure itinerary filters that may modify itineraries, sort them, and filter away less preferable results. Since v2.0, changed in v2.1 transferOptimization Configure the new transfer optimization feature. Since 2.1 These parameters are no longer supported timeout Replaced by streetRoutingTimeout . Since v2.0 timeouts OTP1 searches the graph many times. OTP2 finds multiple results in a single search so there is no longer a need for this parameter. Since v2.0 boardTimes is replaced by request parameter boardSlack and boardSlackForMode . Since v2.0 alightTimes is replaced by request parameter alightSlack and alightSlackForMode . Since v2.0 REST API Trip Planning Support for XML as a request/response format is removed. The only supported format is JSON. Some of these parameters may only be available as defaultRequest configuration parameters. Query parameter changes A lot of the query parameters in the REST API are ignored/deprecated, see the RoutingRequest and the RoutingResource class for the documentation on what is now supported in OTP2. Parameters missing in OTP2 but intended to be reintroduced startingTransitTripId - ability to plan a trip from on board a vehicle intermediatePlaces - ability to specify intermediate destinations along the route. It is not certain when this will be implemented. nonpreferredTransferCost , (un)preferredRoutes , (un)preferredAgencies - these help diversify or customize the trips and operators visible in results. Due to the new transit routing algorithm, Entur plans to completely rewrite these features, accounting for market-neutrality requirements and showing relevant trips and operators in local vs. intercity trips. Some features in OTP1 will not be present upon launch in OTP2, and they are proposed to be removed permanently from OTP2, but may require some development to support valid important cases: maxWalkDistance , maxTransferWalkDistance , & maxWait - these parameters impose hard limits and are no longer the preferred way to reduce the amount of walking or waiting in returned itineraries. In OTP2 the goal is to control this with walkReluctance and waitReluctance . Internally some limits on walking and waiting do still exist, but they are set quite high so trips with long walking or waiting times are still considered. Note that unlike in OTP1, if you do set your own max walk or wait time on an API request, it will apply to both transit searches and non-transit searches. maxHours & useRequestedDateTimeInMaxHours - This is replaced by searchWindow , which limits the arrival or departure window of the trip worstTime - This factor returns the \u201cworst\u201d trip in a depart after/arrive by search, i.e. the latest or earliest trip available. It is not a priority for current OTP2 users but could be added as a filter. waitAtBeginningFactor - No longer necessary to weight the initial wait differently based on the the Range Raptor search algorithm, which no longer prefers a departure at one valid time over another. Filtering could be implemented on top of Raptor to show certain departure times before others. pathComparator - The ability to set a sort order based on departure or arrival should be the domain of the API rather than the search. startingTransitStopId - this is redundant, as the same thing can be achieved with fromPlace onlyTransitTrips - it is now possible to specify access, egress, transit and direct modes separately, making this parameter unnecessary. Parameters that have changed numItineraries The parameter is no longer used to terminate the request when the numItineraries is found, instead the new searchWindow parameter should be used to limit the search. In OTP2 it crops the list of itineraries AFTER the search is complete. This parameter is a post search filter function. The best option is to configure this on the server side and not use it as a client side input parameter. A side effect from reducing the result is that OTP2 cannot guarantee to find all pareto-optimal itineraries when paging. Also, a large search-window and a small numItineraries waste computer CPU calculation time. Consider tuning the searchWindow instead of setting this to a small value. Since 2.0 modes The REST API is unchanged, but is mapped into a new structure in the RoutingRequest. This means not all combinations of non-transit modes that were available in OTP1 are also available in OTP2. Since 2.0 preferredAgencies , unpreferredAgencies , bannedAgencies and whiteListedAgencies use feed-scoped ids. If you are using the ids directly from the Index API, no changes are needed. Since 2.0 maxTransferDistance , replaced by maxTransferDurationSeconds Since 2.1 New parameters in OTP2 alightSlackByMode How much time alighting a vehicle takes for each given mode. Since 2.0 allowedVehicleRentalNetworks and bannedVehicleRentalNetworks . Since 2.1 bikeReluctance , bikeWalkingReluctance , bikeWalkingSpeed , carReluctance , and walkingBike Add explicit bike / bike-walking / car / walk reluctance. Since 2.1 boardSlackByMode How much time ride a vehicle takes for each given mode. Since 2.0 carPickupCost and carPickupTime . Add a cost/time for CarPickup changes when a pickup or drop off takes place. Since 2.1 maxAccessEgressDurationSecondsForMode Limit access/egress per street mode. Since 2.0 parkAndRideDurationRatio Filter for park and ride with long walk. Since 2.1 requiredVehicleParkingTags and bannedVehicleParkingTags . Since 2.1 searchWindow Limit the departure window or arrival window for the routing search. Since 2.0 stairsTimeFactor Add a penalty to the time it takes to walk up and down stairs. Since 2.1 These parameters are no longer supported maxHours Since 2.1 maxPreTransitTime Since 2.1 maxWeight Since 2.1 driveOnRight You can specify the driving direction in your way property set. Since 2.1 Paging In OTP1 most clients provided a way to break results into pages by looking at the trips returned and issuing another request, supplying something like the last-depature-time + 1 minute to the next request. This yields another batch of trips to show to the user. In OTP2 the recommended way to do this is to use the new TripPlan metadata returned by the router call. In OTP 2.0 the server returned a set of parameters( searchWindowUsed , nextDateTime , and prevDateTime ), but in OTP 2.1 we have switched to a token-based approach to paging. In the response there is a next/previous cursor. Duplicate the request and set the new pageCursor to go the next/previous page. Response changes agencyId in the leg is now feed-scoped and similarly to other ids, is prefixed with <FEED_ID>: debugOutput in TripPlan has changed due to the different algorithms used in OTP version 1.x and 2.x. The totalTime is left as is, directStreetRouterTime , transitRouterTime , filteringTime and renderingTime are new fields. effectiveEndDate is added to the Alert s Changes to the Index API Error handling is improved, this is now consistently applied and uses build in framework support. The HTTP 400 and 404 response now contains a detailed error message in plain text targeted developers to help understanding why the 400 or 404 was returned. Route Deprecated 'routeBikesAllowed' field removed. sortOrder will be empty (missing) when empty, NOT -999 as before. To access or references TripPattern use tripPatternId , not code . In OTP1 the code was used. The code was the same as the id without the feedId prefix. The code is removed from OTP2. Clients may not be affected by this change, unless they toke advantage of the semantics in the old code . The mode field is added to Route , it should probebly replace the type (unchanged). The RouteShort is not chencged - it has the mode field. Pattern (or TripPattern ) The semantics of the id should NOT be used to access other related entities like Route , the routeId is added to TripPatternShort to allow navigation to Route. Trip The deprecated tripBikesAllowed is removed. The routeId replace route . The route is no longer part of the trip. To obtain the Route object call the Index API with the routeId. Stop The new stationId is a feed-scoped-id to the parent station. It should be used instead of the deprecated ~~parentStation~~. StopShort The new stationId is a feed-scoped-id to the parent station. It should be used instead of the deprecated ~~cluster~~. Agency The id is now feed-scoped and similarly to other ids, is prefixed with <FEED_ID>: Alert effectiveEndDate is added to show the end time of the alert validity. ServerInfo The returned data structure is changed and more info is available. AlertPatcher The AlertPatcher, which was under the /patch path, is removed. In order to update alerts, please use a GTFS-RT Service Alert updater instead. An example of a simple service for producing static GTFS-RT Service Alert feed from JSON is manual-gtfsrt . Querying for alerts has been moved under the index API, where /alerts can be appended to stop, route, trip and pattern. Analyst The analyst API endpoints have been removed. Scripting The scripting API endpoint has been removed. Updaters Floating bikes have been disabled by default in the GbfsBikeRentalDataSource unless explicitly turned on via OTPFeature. Allow http headers to be configured for bike rental updaters The following bike updaters have been removed: b-cycle , bicimad , bixi , city-bikes , and citi-bike-nyc , jcdecaux , keolis-rennes , kml , next-bike , ov-fiets , sf-bay-area , share-bike , smoove , uip-bike , and vcub . Use the standard gtfs updater instead, or reintroduce your custom updater as a Sandbox module.","title":"OTP2 migration guide"},{"location":"OTP2-MigrationGuide/#how-to-migrate-from-otp1-to-otp2","text":"","title":"How to migrate from OTP1 to OTP2"},{"location":"OTP2-MigrationGuide/#command-line","text":"The OTP2 command line parameters are different than in OTP1. Use the --help option to get the current documentation, and look at Basic Tutorial - Starting OTP for examples. The possibility to build the graph in 2 steps (streets then transit) is new in OTP2. OTP2 does not support routing on more than one separate transportation network with a single server (referred to as multiple \"routers\" in OTP1).","title":"Command Line"},{"location":"OTP2-MigrationGuide/#file-loading","text":"OTP1 reads and writes all files on the local filesystem, and no other data-source is supported. In OTP2 we support accessing cloud storage. So far support for Google Cloud Storage has been added and we plan to add support for AWS S3 as well. Config files ( otp-config.json, build-config.json, router-config.json ) must be read from the local file system, while other files can be read/written from either the local filesystem or cloud storage. OTP2 supports mixing any supported data sources. OTP1 loads input data files ( DEM, OSM, GTFS, NeTEx ) based on the suffix (file extension). But for GTFS files OTP1 also opens the zip-file and looks for stops.txt . OTP2 identifies GTFS files by the name only: it will detect any zip-file or directory that contains \"gtfs\" as part of the name. All file types in OTP2 are resolved by matching the name with a regexp pattern. You can configure the patterns in the build-config.json if the defaults do not suit you. OTP2 does not support multiple routers (separate named networks to route on), but you can load as many GTFS and/or NeTEx feeds as you want into a single routable network in a single instance of OTP2.","title":"File Loading"},{"location":"OTP2-MigrationGuide/#build-config","text":"OTP will log all unrecognized parameters when starting up. Make sure to investigate all log events of this type: 16:18:46.911 WARN (NodeAdapter.java:413) Unexpected config parameter: 'fetchElevationUS:false' in 'build-config.json'. Is the spelling correct?","title":"Build Config"},{"location":"OTP2-MigrationGuide/#new-parameters","text":"configVersion Optional parameter which can be used to version the build config file. Since v2.1 dataOverlay Config for the DataOverlay Sandbox module. Since v2.1 maxAreaNodes Visibility calculations will not be done for areas with more nodes than this limit. Since v2.1 maxJourneyDuration This limits the patterns we consider in the transit search. See RoutingRequest . Since v2.1 maxStopToShapeSnapDistance Used for mapping route geometry shapes. Since v2.1 transferRequests Pre-calculate transfers. Since v2.1 transitServiceStart Limit the import of transit services to the given start date. Default: -P1Y . Since v2.0 transitServiceEnd Limit the import of transit services to the given end date. Inclusive . Default: P3Y . Since v2.0","title":"New parameters"},{"location":"OTP2-MigrationGuide/#parameters-whose-names-were-changed","text":"alightTimes to routingDefaults.alightSlackByMode . Since v2.0 boardTimes to routingDefaults.boardSlackByMode . Since v2.0 htmlAnnotations to dataImportReport . Since v2.0 maxHtmlAnnotationsPerFile to maxDataImportIssuesPerFile . Since v2.0 maxTransferDistance to maxTransferDurationSeconds . Since v2.1","title":"Parameters whose names were changed"},{"location":"OTP2-MigrationGuide/#these-parameters-are-no-longer-supported","text":"fetchElevationUS . Since v2.1 parentStopLinking . Since v2.0 staticBikeRental . Since v2.1 stationTransfers . Since v2.0 stopClusterMode . Since v2.0 useTransfersTxt . Since v2.1 OTP2 records the \"parentStation\" relationship between stops and stations in its internal transit model, based on the GTFS and/or NeTEx input. This enables OTP to search from all stop in a station without walking/waiting when the request from/to input field is a station id. There is no way to automatically infer this parent station relationship based on geographic proximity in OTP2. Transfers in OTP2 are generated based on the stop location and the OSM data or GTFS Pathways. In future versions of OTP2 we also want to support generating simple transfers based on \"line-of-sight\" if no pathways or OSM data exist. See issue #3204 . Cleaning and patching input data is NOT a core feature of OTP, but anyone is welcome to implement a sandbox plugin to patch data. So, if any of the features above are needed they can be ported from OTP1 into an OTP2 sandbox feature.","title":"These parameters are no longer supported"},{"location":"OTP2-MigrationGuide/#router-config","text":"See the Router Configuration for a description of the new and existing routing parameters.","title":"Router Config"},{"location":"OTP2-MigrationGuide/#new-parameters_1","text":"flex Add configuration for flex services (sandbox feature). Since v2.1 configVersion Optional parameter which can be used to version the build config file. Since v2.1 streetRoutingTimeout Maximum time limit for street route queries. Replace the old timeout . Since v2.0 transit A set of parameters to tune the Raptor transit router. Since v2.0, changed in v2.1 itineraryFilters Configure itinerary filters that may modify itineraries, sort them, and filter away less preferable results. Since v2.0, changed in v2.1 transferOptimization Configure the new transfer optimization feature. Since 2.1","title":"New parameters"},{"location":"OTP2-MigrationGuide/#these-parameters-are-no-longer-supported_1","text":"timeout Replaced by streetRoutingTimeout . Since v2.0 timeouts OTP1 searches the graph many times. OTP2 finds multiple results in a single search so there is no longer a need for this parameter. Since v2.0 boardTimes is replaced by request parameter boardSlack and boardSlackForMode . Since v2.0 alightTimes is replaced by request parameter alightSlack and alightSlackForMode . Since v2.0","title":"These parameters are no longer supported"},{"location":"OTP2-MigrationGuide/#rest-api","text":"","title":"REST API"},{"location":"OTP2-MigrationGuide/#trip-planning","text":"Support for XML as a request/response format is removed. The only supported format is JSON. Some of these parameters may only be available as defaultRequest configuration parameters.","title":"Trip Planning"},{"location":"OTP2-MigrationGuide/#query-parameter-changes","text":"A lot of the query parameters in the REST API are ignored/deprecated, see the RoutingRequest and the RoutingResource class for the documentation on what is now supported in OTP2.","title":"Query parameter changes"},{"location":"OTP2-MigrationGuide/#parameters-missing-in-otp2-but-intended-to-be-reintroduced","text":"startingTransitTripId - ability to plan a trip from on board a vehicle intermediatePlaces - ability to specify intermediate destinations along the route. It is not certain when this will be implemented. nonpreferredTransferCost , (un)preferredRoutes , (un)preferredAgencies - these help diversify or customize the trips and operators visible in results. Due to the new transit routing algorithm, Entur plans to completely rewrite these features, accounting for market-neutrality requirements and showing relevant trips and operators in local vs. intercity trips. Some features in OTP1 will not be present upon launch in OTP2, and they are proposed to be removed permanently from OTP2, but may require some development to support valid important cases: maxWalkDistance , maxTransferWalkDistance , & maxWait - these parameters impose hard limits and are no longer the preferred way to reduce the amount of walking or waiting in returned itineraries. In OTP2 the goal is to control this with walkReluctance and waitReluctance . Internally some limits on walking and waiting do still exist, but they are set quite high so trips with long walking or waiting times are still considered. Note that unlike in OTP1, if you do set your own max walk or wait time on an API request, it will apply to both transit searches and non-transit searches. maxHours & useRequestedDateTimeInMaxHours - This is replaced by searchWindow , which limits the arrival or departure window of the trip worstTime - This factor returns the \u201cworst\u201d trip in a depart after/arrive by search, i.e. the latest or earliest trip available. It is not a priority for current OTP2 users but could be added as a filter. waitAtBeginningFactor - No longer necessary to weight the initial wait differently based on the the Range Raptor search algorithm, which no longer prefers a departure at one valid time over another. Filtering could be implemented on top of Raptor to show certain departure times before others. pathComparator - The ability to set a sort order based on departure or arrival should be the domain of the API rather than the search. startingTransitStopId - this is redundant, as the same thing can be achieved with fromPlace onlyTransitTrips - it is now possible to specify access, egress, transit and direct modes separately, making this parameter unnecessary.","title":"Parameters missing in OTP2 but intended to be reintroduced"},{"location":"OTP2-MigrationGuide/#parameters-that-have-changed","text":"numItineraries The parameter is no longer used to terminate the request when the numItineraries is found, instead the new searchWindow parameter should be used to limit the search. In OTP2 it crops the list of itineraries AFTER the search is complete. This parameter is a post search filter function. The best option is to configure this on the server side and not use it as a client side input parameter. A side effect from reducing the result is that OTP2 cannot guarantee to find all pareto-optimal itineraries when paging. Also, a large search-window and a small numItineraries waste computer CPU calculation time. Consider tuning the searchWindow instead of setting this to a small value. Since 2.0 modes The REST API is unchanged, but is mapped into a new structure in the RoutingRequest. This means not all combinations of non-transit modes that were available in OTP1 are also available in OTP2. Since 2.0 preferredAgencies , unpreferredAgencies , bannedAgencies and whiteListedAgencies use feed-scoped ids. If you are using the ids directly from the Index API, no changes are needed. Since 2.0 maxTransferDistance , replaced by maxTransferDurationSeconds Since 2.1","title":"Parameters that have changed"},{"location":"OTP2-MigrationGuide/#new-parameters-in-otp2","text":"alightSlackByMode How much time alighting a vehicle takes for each given mode. Since 2.0 allowedVehicleRentalNetworks and bannedVehicleRentalNetworks . Since 2.1 bikeReluctance , bikeWalkingReluctance , bikeWalkingSpeed , carReluctance , and walkingBike Add explicit bike / bike-walking / car / walk reluctance. Since 2.1 boardSlackByMode How much time ride a vehicle takes for each given mode. Since 2.0 carPickupCost and carPickupTime . Add a cost/time for CarPickup changes when a pickup or drop off takes place. Since 2.1 maxAccessEgressDurationSecondsForMode Limit access/egress per street mode. Since 2.0 parkAndRideDurationRatio Filter for park and ride with long walk. Since 2.1 requiredVehicleParkingTags and bannedVehicleParkingTags . Since 2.1 searchWindow Limit the departure window or arrival window for the routing search. Since 2.0 stairsTimeFactor Add a penalty to the time it takes to walk up and down stairs. Since 2.1","title":"New parameters in OTP2"},{"location":"OTP2-MigrationGuide/#these-parameters-are-no-longer-supported_2","text":"maxHours Since 2.1 maxPreTransitTime Since 2.1 maxWeight Since 2.1 driveOnRight You can specify the driving direction in your way property set. Since 2.1","title":"These parameters are no longer supported"},{"location":"OTP2-MigrationGuide/#paging","text":"In OTP1 most clients provided a way to break results into pages by looking at the trips returned and issuing another request, supplying something like the last-depature-time + 1 minute to the next request. This yields another batch of trips to show to the user. In OTP2 the recommended way to do this is to use the new TripPlan metadata returned by the router call. In OTP 2.0 the server returned a set of parameters( searchWindowUsed , nextDateTime , and prevDateTime ), but in OTP 2.1 we have switched to a token-based approach to paging. In the response there is a next/previous cursor. Duplicate the request and set the new pageCursor to go the next/previous page.","title":"Paging"},{"location":"OTP2-MigrationGuide/#response-changes","text":"agencyId in the leg is now feed-scoped and similarly to other ids, is prefixed with <FEED_ID>: debugOutput in TripPlan has changed due to the different algorithms used in OTP version 1.x and 2.x. The totalTime is left as is, directStreetRouterTime , transitRouterTime , filteringTime and renderingTime are new fields. effectiveEndDate is added to the Alert s","title":"Response changes"},{"location":"OTP2-MigrationGuide/#changes-to-the-index-api","text":"Error handling is improved, this is now consistently applied and uses build in framework support. The HTTP 400 and 404 response now contains a detailed error message in plain text targeted developers to help understanding why the 400 or 404 was returned. Route Deprecated 'routeBikesAllowed' field removed. sortOrder will be empty (missing) when empty, NOT -999 as before. To access or references TripPattern use tripPatternId , not code . In OTP1 the code was used. The code was the same as the id without the feedId prefix. The code is removed from OTP2. Clients may not be affected by this change, unless they toke advantage of the semantics in the old code . The mode field is added to Route , it should probebly replace the type (unchanged). The RouteShort is not chencged - it has the mode field. Pattern (or TripPattern ) The semantics of the id should NOT be used to access other related entities like Route , the routeId is added to TripPatternShort to allow navigation to Route. Trip The deprecated tripBikesAllowed is removed. The routeId replace route . The route is no longer part of the trip. To obtain the Route object call the Index API with the routeId. Stop The new stationId is a feed-scoped-id to the parent station. It should be used instead of the deprecated ~~parentStation~~. StopShort The new stationId is a feed-scoped-id to the parent station. It should be used instead of the deprecated ~~cluster~~. Agency The id is now feed-scoped and similarly to other ids, is prefixed with <FEED_ID>: Alert effectiveEndDate is added to show the end time of the alert validity.","title":"Changes to the Index API"},{"location":"OTP2-MigrationGuide/#serverinfo","text":"The returned data structure is changed and more info is available.","title":"ServerInfo"},{"location":"OTP2-MigrationGuide/#alertpatcher","text":"The AlertPatcher, which was under the /patch path, is removed. In order to update alerts, please use a GTFS-RT Service Alert updater instead. An example of a simple service for producing static GTFS-RT Service Alert feed from JSON is manual-gtfsrt . Querying for alerts has been moved under the index API, where /alerts can be appended to stop, route, trip and pattern.","title":"AlertPatcher"},{"location":"OTP2-MigrationGuide/#analyst","text":"The analyst API endpoints have been removed.","title":"Analyst"},{"location":"OTP2-MigrationGuide/#scripting","text":"The scripting API endpoint has been removed.","title":"Scripting"},{"location":"OTP2-MigrationGuide/#updaters","text":"Floating bikes have been disabled by default in the GbfsBikeRentalDataSource unless explicitly turned on via OTPFeature. Allow http headers to be configured for bike rental updaters The following bike updaters have been removed: b-cycle , bicimad , bixi , city-bikes , and citi-bike-nyc , jcdecaux , keolis-rennes , kml , next-bike , ov-fiets , sf-bay-area , share-bike , smoove , uip-bike , and vcub . Use the standard gtfs updater instead, or reintroduce your custom updater as a Sandbox module.","title":"Updaters"},{"location":"Preparing-OSM/","text":"Cropping OSM data Services producing automated extracts of OSM data like Geofabrik or Interline Extracts are limited to predefined areas. You'll often need to download an extract for a country or region larger than your true analysis area, then cut it down to size. Excessively large OSM data can lead to significant increases in computation time and complexity, both while building the graph and handling trip planning requests. You may want to crop the OSM data if they cover an area significantly larger than your transit network. Several command line tools are able to perform these cropping operations: Osmosis is a multi-platform Java tool that works on Windows, Linux, and MacOS but is relatively slow, OSMConvert is a fast tool pre-built for Windows and Linux and available on MacOS and Linux distributions as part of osmctools package. Osmium-Tool is a personal favorite that is extremely fast but only straightforward to install on Linux and MacOS platforms. Below are some example crop commands for these different tools: Osmosis: osmosis --rb input.osm.pbf --bounding-box left=4.34 right=5.84 bottom=43.10 top=43.97 --wb cropped.osm.pbf OsmConvert: osmconvert input.osm.pbf -b=-77.255859375,38.77764022307335,-76.81365966796875,39.02345139405933 --complete-ways -o=cropped.osm.pbf Osmium: osmium extract --strategy complete_ways --bbox 2.25,48.81,2.42,48.91 input.osm.pbf -o cropped.osm.pbf The latter two commands expect bounding boxes to be specified in the format min_lon,min_lat,max_lon,max_lat . We frequently find bounding boxes using the convenient Klokantech bounding box tool . Selecting the \"CSV\" format in the lower left will give exactly the format expected by these tools. Filtering OSM data The OSM database contains a lot of other data besides the roads, paths, and public transportation platform data we need for accessibility analysis. As of this writing, according to TagInfo 59% of the ways in OSM are buildings, and only 23% are roads or paths. Buildings frequently have more complex shapes than roads, and objects like waterways or political boundaries can be very large in size. It has been jokingly said that OSM should be renamed \"OpenBuildingMap\" rather than \"OpenStreetMap\". Removing unneeded data will reduce file sizes, facilitating copying or moving files around and reducing the size of project backups and archives. It may also speed up the processing stage where the OSM data is converted into a routable street network. Several command line tools exist to filter OSM data. Command line tools for this purpose include Osmosis and Osmium-Tool . Osmium-Tool is extremely fast but is only straightforward to install on Linux and MacOS platforms. Osmosis is often slower at filtering but will also work on Windows as it's a multi-platform Java application. OSMFilter cannot work with PBF format files so we rarely use it. Below are some example commands for retaining only OSM data useful for accessibility analysis. Here are some example commands: Osmosis: osmosis --rb input.osm.pbf --tf reject-ways building=* --tf reject-ways waterway=* --tf reject-ways landuse=* --tf reject-ways natural=* --used-node --wb filtered.osm.pbf Osmium-Tool: osmium tags-filter input.osm.pbf w/highway w/public_transport=platform w/railway=platform w/park_ride=yes r/type=restriction r/type=route -o filtered.osm.pbf -f pbf,add_metadata=false","title":"Preparing OSM Data"},{"location":"Preparing-OSM/#cropping-osm-data","text":"Services producing automated extracts of OSM data like Geofabrik or Interline Extracts are limited to predefined areas. You'll often need to download an extract for a country or region larger than your true analysis area, then cut it down to size. Excessively large OSM data can lead to significant increases in computation time and complexity, both while building the graph and handling trip planning requests. You may want to crop the OSM data if they cover an area significantly larger than your transit network. Several command line tools are able to perform these cropping operations: Osmosis is a multi-platform Java tool that works on Windows, Linux, and MacOS but is relatively slow, OSMConvert is a fast tool pre-built for Windows and Linux and available on MacOS and Linux distributions as part of osmctools package. Osmium-Tool is a personal favorite that is extremely fast but only straightforward to install on Linux and MacOS platforms. Below are some example crop commands for these different tools: Osmosis: osmosis --rb input.osm.pbf --bounding-box left=4.34 right=5.84 bottom=43.10 top=43.97 --wb cropped.osm.pbf OsmConvert: osmconvert input.osm.pbf -b=-77.255859375,38.77764022307335,-76.81365966796875,39.02345139405933 --complete-ways -o=cropped.osm.pbf Osmium: osmium extract --strategy complete_ways --bbox 2.25,48.81,2.42,48.91 input.osm.pbf -o cropped.osm.pbf The latter two commands expect bounding boxes to be specified in the format min_lon,min_lat,max_lon,max_lat . We frequently find bounding boxes using the convenient Klokantech bounding box tool . Selecting the \"CSV\" format in the lower left will give exactly the format expected by these tools.","title":"Cropping OSM data"},{"location":"Preparing-OSM/#filtering-osm-data","text":"The OSM database contains a lot of other data besides the roads, paths, and public transportation platform data we need for accessibility analysis. As of this writing, according to TagInfo 59% of the ways in OSM are buildings, and only 23% are roads or paths. Buildings frequently have more complex shapes than roads, and objects like waterways or political boundaries can be very large in size. It has been jokingly said that OSM should be renamed \"OpenBuildingMap\" rather than \"OpenStreetMap\". Removing unneeded data will reduce file sizes, facilitating copying or moving files around and reducing the size of project backups and archives. It may also speed up the processing stage where the OSM data is converted into a routable street network. Several command line tools exist to filter OSM data. Command line tools for this purpose include Osmosis and Osmium-Tool . Osmium-Tool is extremely fast but is only straightforward to install on Linux and MacOS platforms. Osmosis is often slower at filtering but will also work on Windows as it's a multi-platform Java application. OSMFilter cannot work with PBF format files so we rarely use it. Below are some example commands for retaining only OSM data useful for accessibility analysis. Here are some example commands: Osmosis: osmosis --rb input.osm.pbf --tf reject-ways building=* --tf reject-ways waterway=* --tf reject-ways landuse=* --tf reject-ways natural=* --used-node --wb filtered.osm.pbf Osmium-Tool: osmium tags-filter input.osm.pbf w/highway w/public_transport=platform w/railway=platform w/park_ride=yes r/type=restriction r/type=route -o filtered.osm.pbf -f pbf,add_metadata=false","title":"Filtering OSM data"},{"location":"RouterConfiguration/","text":"Router configuration This section covers all options that can be set for each router using the router-config.json file. These options can be applied by the OTP server without rebuilding the graph. config key description value type value default notes routingDefaults Default routing parameters, which will be applied to every request object see routing defaults streetRoutingTimeout maximum time limit for street route queries double null units: seconds; see timeout requestLogFile Path to a plain-text file where requests will be logged string null see logging incoming requests transit Transit tuning parameters TransitRoutingConfig see Tuning transit routing updaters configure real-time updaters, such as GTFS-realtime feeds object null see configuring real-time updaters transmodelApi configure Entur Transmodel API ( Sandbox ) object null See the code for parameters, no doc provided. Routing defaults There are many trip planning options used in the OTP web API, and more exist internally that are not exposed via the API. You may want to change the default value for some of these parameters, i.e. the value which will be applied unless it is overridden in a web API request. A full list of them can be found in the RoutingRequest . Any public field or setter method in this class can be given a default value using the routingDefaults section of router-config.json as follows: // router-config.json { \"routingDefaults\" : { \"walkSpeed\" : 2.0 , \"stairsReluctance\" : 4.0 , \"carDropoffTime\" : 240 } } Tuning transfer optimization The main purpose of transfer optimization is to handle cases where it is possible to transfer between two routes at more than one point (pair of stops). The transfer optimization ensures that transfers occur at the best possible location. By post-processing all paths returned by the router, OTP can apply sophisticated calculations that are too slow or not algorithmically valid within Raptor. Transfers are optimized before the paths are passed to the itinerary-filter-chain. For a detailed description of the design and the optimization calculations see the design documentation (dev-2.x latest). Transfer optimization configuration To toggle transfer optimization on or off use the OTPFeature OptimizeTransfers (default is on). You should leave this on unless there is a critical issue with it. The OTPFeature GuaranteedTransfers will toggle on and off the priority optimization (part of OptimizeTransfers). The optimized transfer service will try to, in order: Use transfer priority. This includes stay-seated and guaranteed transfers. Use the transfers with the best distribution of the wait-time, and avoid very short transfers. Avoid back-travel Boost stop-priority to select preferred and recommended stops. If two paths have the same transfer priority level, then we break the tie by looking at waiting times. The goal is to maximize the wait-time for each stop, avoiding situations where there is little time available to make the transfer. This is balanced with the generalized-cost. The cost is adjusted with a new cost for wait-time (optimized-wait-time-cost). The defaults should work fine, but if you have results with short wait-times dominating a better option or \"back-travel\", then try to increase the minSafeWaitTimeFactor , backTravelWaitTimeFactor and/or extraStopBoardAlightCostsFactor . // router-config.json { \"routingDefaults\" : { \"transferOptimization\" : { \"optimizeTransferWaitTime\" : true , \"minSafeWaitTimeFactor\" : 5.0 , \"backTravelWaitTimeFactor\" : 1.0 , \"extraStopBoardAlightCostsFactor\" : 2.5 } } } See the TransferOptimizationParameters (dev-2.x latest) for a description of these parameters. Tuning itinerary filtering Nested inside routingDefaults { itineraryFilters{...} } in router-config.json . The purpose of the itinerary filter chain is to post process the result returned by the routing search. The filters may modify itineraries, sort them, and filter away less preferable results. OTP2 may produce numerous pareto-optimal results when using time , number-of-transfers and generalized-cost as criteria. Use the parameters listed here to reduce/filter the itineraries return by the search engine before returning the results to client. There is also a few mandatory none configurable filters removing none optimal results. You may see these filters pop-up in the filter debugging. config key description value type value default debug Enable this to attach a system notice to itineraries instead of removing them. This is very convenient when tuning the filters. boolean false groupSimilarityKeepOne Pick ONE itinerary from each group after putting itineraries that is 85% similar together. double 0.85 (85%) groupSimilarityKeepThree Reduce the number of itineraries to three itineraries by reducing each group of itineraries grouped by 68% similarity. double 0.68 (68%) groupedOtherThanSameLegsMaxCostMultiplier Filter grouped itineraries, where the non-grouped legs are more expensive than in the lowest cost one. double 2.0 (2x cost) transitGeneralizedCostLimit A relative maximum limit for the generalized cost for transit itineraries. The limit is a linear function of the minimum generalized-cost. The function is used to calculate a max-limit. The max-limit is then used to to filter by generalized-cost. Transit itineraries with a cost higher than the max-limit is dropped from the result set. None transit itineraries is excluded from the filter. To set a filter to be 1 hour plus 2 times the best cost use: 3600 + 2.0 x . To set an absolute value(3000s) use: 3000 + 0x linear function 3600 + 2.0 x nonTransitGeneralizedCostLimit A relative maximum limit for the generalized cost for non-transit itineraries. The max limit is calculated using ALL itineraries, but only non-transit itineraries will be filtered out. The limit is a linear function of the minimum generalized-cost. The function is used to calculate a max-limit. The max-limit is then used to to filter by generalized-cost. Non-transit itineraries with a cost higher than the max-limit is dropped from the result set. To set a filter to be 1 hour plus 2 times the best cost use: 3600 + 2.0 x . To set an absolute value(3000s) use: 3000 + 0x linear function 3600 + 2.0 x bikeRentalDistanceRatio For routes that consist only of bike rental and walking what is the minimum fraction of distance of the bike rental leg. This filters out results that consist of a long walk plus a relatively short bike rental leg. A value of 0.3 means that a minimum of 30% of the total distance must be spent on the bike in order for the result to be included. double 0.0 parkAndRideDurationRatio For P+R routes that consist only of driving and walking what is the minimum fraction of time of the driving leg. This filters out results that consist of driving plus a very long walk leg at the end. A value of 0.3 means that a minimum of 30% of the total time must be spent in the car in order for the result to be included. However, if there is only a single result, it is never filtered. double 0.0 Group by similarity filters The group-by-filter is a bit complex, but should be simple to use. Set debug=true and experiment with searchWindow and the three group-by parameters( groupSimilarityKeepOne , groupSimilarityKeepThree and groupedOtherThanSameLegsMaxCostMultiplier ). The group-by-filter work by grouping itineraries together and then reducing the number of itineraries in each group, keeping the itinerary/itineraries with the best itinerary generalized-cost . The group-by function first pick all transit legs that account for more than N% of the itinerary based on distance traveled. This become the group-key. Two keys are the same if all legs in one of the keys also exist in the other. Note, one key may have a lager set of legs than the other, but they can still be the same. When comparing two legs we compare the tripId and make sure the legs overlap in place and time. Two legs are the same if both legs ride at least a common subsection of the same trip. The keepOne filter will keep ONE itinerary in each group. The keepThree keeps 3 itineraries for each group. The grouped itineraries can be further reduced by using groupedOtherThanSameLegsMaxCostMultiplier . This parameter filters out itineraries, where the legs that are not common for all the grouped itineraries have a much higher cost, than the lowest in the group. By default, it filters out itineraries that are at least double in cost for the non-grouped legs. Drive-to-transit routing defaults When using the \"park and ride\" or \"kiss and ride\" modes (drive to transit), the initial driving time to reach a transit stop or park and ride facility is constrained. You can set a drive time limit in seconds by adding a line like maxPreTransitTime = 1200 to the routingDefaults section. If the limit is too high on a very large street graph, routing performance may suffer. Boarding and alighting times Sometimes there is a need to configure a longer ride or alighting times for specific modes, such as airplanes or ferries, where the check-in process needs to be done in good time before ride. The ride time is added to the time when going from the stop (offboard) vertex to the onboard vertex, and the alight time is added vice versa. The times are configured as seconds needed for the ride and alighting processes in router-config.json as follows: // router-config.json { \"routingDefaults\" : { \"boardSlackForMode\" : { \"AIRPLANE\" : 2700 }, \"alightSlackForMode\" : { \"AIRPLANE\" : 1200 } } } Timeout In OTP1 path searches sometimes toke a long time to complete. With the new Raptor algorithm this not the case anymore. The street part of the routing may still take a long time if searching very long distances. You can set the street routing timeout to avoid tying up server resources on pointless searches and ensure that your users receive a timely response. You can also limit the max distance to search for WALK, BIKE and CAR. When a search times out, a WARN level log entry is made with information that can help identify problematic searches and improve our routing methods. There are no timeouts for the transit part of the routing search, instead configure a reasonable dynamic search-window. To set the street routing timeout use the following config: // router-config.json { \"streetRoutingTimeout\" : 5.5 } This specifies a timeout in (optionally fractional) seconds. The search abort after this many seconds and any paths found are returned to the client. maxAccessEgressDurationSecondsForMode Override the settings in maxAccessEgressDurationSeconds for specific street modes. This is done because some street modes searches are much more resource intensive than others. // router-config.json \"maxAccessEgressDurationSecondsForMode\" : { \"BIKE_RENTAL\" : 1200 } This will limit only the BIKE_RENTAL mode to 1200 seconds, while keeping the default limit for all other access/egress modes. Logging incoming requests You can log some characteristics of trip planning requests in a file for later analysis. Some transit agencies and operators find this information useful for identifying existing or unmet transportation demand. Logging will be performed only if you specify a log file name in the router config: // router-config.json { \"requestLogFile\" : \"/var/otp/request.log\" } Each line in the resulting log file will look like this: 2016-04-19T18:23:13.486 0:0:0:0:0:0:0:1 ARRIVE 2016-04-07T00:17 WALK,BUS,CABLE_CAR,TRANSIT,BUSISH 45.559737193889966 -122.64999389648438 45.525592487765635 -122.39044189453124 6095 3 5864 3 6215 3 The fields separated by whitespace are (in order): Date and time the request was received IP address of the user Arrive or depart search The arrival or departure time A comma-separated list of all transport modes selected Origin latitude and longitude Destination latitude and longitude Finally, for each itinerary returned to the user, there is a travel duration in seconds and the number of transit vehicles used in that itinerary. Tuning transit routing Nested inside transit {...} in router-config.json . Some of these parameters for tuning transit routing is only available through configuration and cannot be set in the routing request. These parameters work together with the default routing request and the actual routing request. config key description value type value default maxNumberOfTransfers Use this parameter to allocate enough space for Raptor. Set it to the maximum number of transfers for any given itinerary expected to be found within the entire transit network. The memory overhead of setting this higher than the maximum number of transfers is very little so it is better to set it too high then to low. int 12 scheduledTripBinarySearchThreshold The threshold is used to determine when to perform a binary trip schedule search to reduce the number of trips departure time lookups and comparisons. When testing with data from Entur and all of Norway as a Graph, the optimal value was around 50. Changing this may improve the performance with just a few percent. int 50 iterationDepartureStepInSeconds Step for departure times between each RangeRaptor iterations. A transit network usually uses minute resolution for its depature and arrival times. To match that, set this variable to 60 seconds. int 60 searchThreadPoolSize Split a travel search in smaller jobs and run them in parallel to improve performance. Use this parameter to set the total number of executable threads available across all searches. Multiple searches can run in parallel - this parameter have no effect with regard to that. If 0, no extra threads are started and the search is done in one thread. int 0 dynamicSearchWindow The dynamic search window coefficients used to calculate the EDT(earliest-departure-time), LAT(latest-arrival-time) and SW(raptor-search-window) using heuristics. object null stopTransferCost Use this to set a stop transfer cost for the given TransferPriority . The cost is applied to boarding and alighting at all stops. All stops have a transfer cost priority set, the default is ALLOWED . The stopTransferCost parameter is optional, but if listed all values must be set. enum map null transferCacheMaxSize The maximum number of distinct transfers parameters ( RoutingRequest s) to cache pre-calculated transfers for. If too low, requests may be slower. If too high, more memory may be used then required. int 25 pagingSearchWindowAdjustments The provided array of durations is used to increase the search-window for the next/previous page when the current page return few options. If ZERO results is returned the first duration in the list is used, if ONE result is returned then the second duration is used and so on. The duration is added to the existing search-window and inserted into the next and previous page cursor. See JavaDoc for TransitTuningParameters#pagingSearchWindowAdjustments for more info. duration[] [\"4h\", \"2h\", \"1h\", \"30m\", \"20m\", \"10m\"] Tuning transit routing - Dynamic search window Nested inside transit : { dynamicSearchWindow : { ... } } in router-config.json . config key description value type value default minTransitTimeCoefficient The coefficient to multiply with minimum transit time found using a heuristic search. This scaled value is added to the minWinTimeMinutes . A value between 0.0 to 3.0 is expected to give ok results. double 0.5 minWaitTimeCoefficient The coefficient to multiply with a minimum wait time estimated based on the heuristic search. This will increase the search-window in low transit frequency areas. This value is added to the minWinTimeMinutes . A value between 0.0 to 1.0 is expected to give ok results. double 0.5 minWinTimeMinutes The constant minimum number of minutes for a raptor search window. Use a value between 20-180 minutes in a normal deployment. int 40 maxWinTimeMinutes Set an upper limit to the calculation of the dynamic search window to prevent exceptionable cases to cause very long search windows. Long search windows consumes a lot of resources and may take a long time. Use this parameter to tune the desired maximum search time. int 180 (3 hours) stepMinutes The search window is rounded of to the closest multiplication of N minutes. If N=10 minutes, the search-window can be 10, 20, 30 ... minutes. It the computed search-window is 5 minutes and 17 seconds it will be rounded up to 10 minutes. int 10 Tuning transit routing - Stop transfer cost Nested inside transit : { stopTransferCost : { ... } } in router-config.json . This cost is in addition to other costs like boardCost and indirect cost from waiting (board-/alight-/transfer slack). You should account for this when you tune the routing search parameters. If not set the stopTransferCost is ignored. This is only available for NeTEx imported Stops. The cost is a scalar, but is equivalent to the felt cost of riding a transit trip for 1 second. config key description value type DISCOURAGED Use a very high cost like 72 000 to eliminate transfers ath the stop if not the only option. int ALLOWED Allowed, but not recommended. Use something like 150 . int RECOMMENDED Use a small cost penalty like 60 . int PREFERRED The best place to do transfers. Should be set to 0 (zero). int Use values in a range from 0 to 100 000 . All key/value pairs are required if the stopTransferCost is listed. Transit example // router-config.json { \"transit\" : { \"maxNumberOfTransfers\" : 12 , \"scheduledTripBinarySearchThreshold\" : 50 , \"iterationDepartureStepInSeconds\" : 60 , \"searchThreadPoolSize\" : 0 , \"dynamicSearchWindow\" : { \"minTransitTimeCoefficient\" : 0.5 , \"minWaitTimeCoefficient\" : 0.5 , \"minTimeMinutes\" : 30 , \"maxLengthMinutes\" : 360 , \"stepMinutes\" : 10 }, \"stopTransferCost\" : { \"DISCOURAGED\" : 72000 , \"ALLOWED\" : 150 , \"RECOMMENDED\" : 60 , \"PREFERRED\" : 0 } } } Real-time data GTFS feeds contain schedule data that is is published by an agency or operator in advance. The feed does not account for unexpected service changes or traffic disruptions that occur from day to day. Thus, this kind of data is also referred to as 'static' data or 'theoretical' arrival and departure times. GTFS-Realtime The GTFS-RT spec complements GTFS with three additional kinds of feeds. In contrast to the base GTFS schedule feed, they provide real-time updates ( 'dynamic' data) and are are updated from minute to minute. Alerts are text messages attached to GTFS objects, informing riders of disruptions and changes. TripUpdates report on the status of scheduled trips as they happen, providing observed and predicted arrival and departure times for the remainder of the trip. VehiclePositions give the location of some or all vehicles currently in service, in terms of geographic coordinates or position relative to their scheduled stops. Vehicle rental systems using GBFS Besides GTFS-RT transit data, OTP can also fetch real-time data about vehicle rental networks including the number of bikes and free parking spaces at each station. We support vehicle rental systems from using GBFS feed format. Vehicle parking (sandbox feature) Vehicle parking options and configuration is documented in its sandbox documentation . Configuring real-time updaters Real-time data can be provided using either a pull or push system. In a pull configuration, the GTFS-RT consumer polls the real-time provider over HTTP. That is to say, OTP fetches a file from a web server every few minutes. In the push configuration, the consumer opens a persistent connection to the GTFS-RT provider, which then sends incremental updates immediately as they become available. OTP can use both approaches. The OneBusAway GTFS-realtime exporter project provides this kind of streaming, incremental updates over a websocket rather than a single large file. Real-time data sources are configured in router-config.json . The updaters section is an array of JSON objects, each of which has a type field and other configuration fields specific to that type. Common to all updater entries that connect to a network resource is the url field. // router-config.json { // Routing defaults are any public field or setter in the Java class // org.opentripplanner.routing.api.request.RoutingRequest \"routingDefaults\" : { \"numItineraries\" : 6 , \"walkSpeed\" : 2.0 , \"stairsReluctance\" : 4.0 , \"carDropoffTime\" : 240 }, \"updaters\" : [ // GTFS-RT service alerts (frequent polling) { \"type\" : \"real-time-alerts\" , \"frequencySec\" : 30 , \"url\" : \"http://developer.trimet.org/ws/V1/FeedSpecAlerts/appID/0123456789ABCDEF\" , \"feedId\" : \"TriMet\" }, //<!--- Tampa Area GBFS bike share --> { \"type\" : \"vehicle-rental\" , \"frequencySec\" : 300 , \"sourceType\" : \"gbfs\" , \"url\" : \"http://coast.socialbicycles.com/opendata/gbfs.json\" }, // Vehicle parking availability { \"type\" : \"vehicle-parking\" }, // Polling for GTFS-RT TripUpdates) { \"type\" : \"stop-time-updater\" , \"frequencySec\" : 60 , // this is either http or file... shouldn't it default to http or guess from the presence of a URL? \"sourceType\" : \"gtfs-http\" , \"url\" : \"http://developer.trimet.org/ws/V1/TripUpdate/appID/0123456789ABCDEF\" , \"feedId\" : \"TriMet\" }, // Streaming differential GTFS-RT TripUpdates over websockets { \"type\" : \"websocket-gtfs-rt-updater\" } ] } GBFS Configuration GBFS is used for a variety of shared mobility services, with partial support for both v1 and v2.2 ( list of known GBFS feeds ). To add a GBFS feed to the router add one entry in the updater field of router-config.json in the format: // router-config.json { \"type\" : \"vehicle-rental\" , \"sourceType\" : \"gbfs\" , // frequency in seconds in which the GBFS service will be polled \"frequencySec\" : 60 , // The URL of the GBFS feed auto-discovery file \"url\" : \"http://coast.socialbicycles.com/opendata/gbfs.json\" , // Optionally specify the language version of the feed to use. If no language is set, the first language in the feed is used. \"language\" : \"en\" , // if it should be possible to arrive at the destination with a rented bicycle, without dropping it off \"allowKeepingRentedBicycleAtDestination\" : true } Arriving with rental bikes at the destination In some cases it may be useful to not drop off the rented bicycle before arriving at the destination. This is useful if bicycles may only be rented for round trips, or the destination is an intermediate place. For this to be possible three things need to be configured: In the updater configuration allowKeepingRentedBicycleAtDestination should be set to true . allowKeepingRentedBicycleAtDestination should also be set for each request, either using routing defaults , or per-request. If keeping the bicycle at the destination should be discouraged, then keepingRentedBicycleAtDestinationCost (default: 0 ) may also be set in the routing defaults . Vehicle Rental Service Directory configuration (sandbox feature) To configure and url for the VehicleRentalServiceDirectory . // router-config.json { \"vehicleRentalServiceDirectory\" : { \"url\" : \"https://api.dev.entur.io/mobility/v1/bikes\" } } Configure using command-line arguments Certain settings can be provided on the command line, when starting OpenTripPlanner. See the CommandLineParameters class for a full list of arguments .","title":"Router"},{"location":"RouterConfiguration/#router-configuration","text":"This section covers all options that can be set for each router using the router-config.json file. These options can be applied by the OTP server without rebuilding the graph. config key description value type value default notes routingDefaults Default routing parameters, which will be applied to every request object see routing defaults streetRoutingTimeout maximum time limit for street route queries double null units: seconds; see timeout requestLogFile Path to a plain-text file where requests will be logged string null see logging incoming requests transit Transit tuning parameters TransitRoutingConfig see Tuning transit routing updaters configure real-time updaters, such as GTFS-realtime feeds object null see configuring real-time updaters transmodelApi configure Entur Transmodel API ( Sandbox ) object null See the code for parameters, no doc provided.","title":"Router configuration"},{"location":"RouterConfiguration/#routing-defaults","text":"There are many trip planning options used in the OTP web API, and more exist internally that are not exposed via the API. You may want to change the default value for some of these parameters, i.e. the value which will be applied unless it is overridden in a web API request. A full list of them can be found in the RoutingRequest . Any public field or setter method in this class can be given a default value using the routingDefaults section of router-config.json as follows: // router-config.json { \"routingDefaults\" : { \"walkSpeed\" : 2.0 , \"stairsReluctance\" : 4.0 , \"carDropoffTime\" : 240 } }","title":"Routing defaults"},{"location":"RouterConfiguration/#tuning-transfer-optimization","text":"The main purpose of transfer optimization is to handle cases where it is possible to transfer between two routes at more than one point (pair of stops). The transfer optimization ensures that transfers occur at the best possible location. By post-processing all paths returned by the router, OTP can apply sophisticated calculations that are too slow or not algorithmically valid within Raptor. Transfers are optimized before the paths are passed to the itinerary-filter-chain. For a detailed description of the design and the optimization calculations see the design documentation (dev-2.x latest).","title":"Tuning transfer optimization"},{"location":"RouterConfiguration/#transfer-optimization-configuration","text":"To toggle transfer optimization on or off use the OTPFeature OptimizeTransfers (default is on). You should leave this on unless there is a critical issue with it. The OTPFeature GuaranteedTransfers will toggle on and off the priority optimization (part of OptimizeTransfers). The optimized transfer service will try to, in order: Use transfer priority. This includes stay-seated and guaranteed transfers. Use the transfers with the best distribution of the wait-time, and avoid very short transfers. Avoid back-travel Boost stop-priority to select preferred and recommended stops. If two paths have the same transfer priority level, then we break the tie by looking at waiting times. The goal is to maximize the wait-time for each stop, avoiding situations where there is little time available to make the transfer. This is balanced with the generalized-cost. The cost is adjusted with a new cost for wait-time (optimized-wait-time-cost). The defaults should work fine, but if you have results with short wait-times dominating a better option or \"back-travel\", then try to increase the minSafeWaitTimeFactor , backTravelWaitTimeFactor and/or extraStopBoardAlightCostsFactor . // router-config.json { \"routingDefaults\" : { \"transferOptimization\" : { \"optimizeTransferWaitTime\" : true , \"minSafeWaitTimeFactor\" : 5.0 , \"backTravelWaitTimeFactor\" : 1.0 , \"extraStopBoardAlightCostsFactor\" : 2.5 } } } See the TransferOptimizationParameters (dev-2.x latest) for a description of these parameters.","title":"Transfer optimization configuration"},{"location":"RouterConfiguration/#tuning-itinerary-filtering","text":"Nested inside routingDefaults { itineraryFilters{...} } in router-config.json . The purpose of the itinerary filter chain is to post process the result returned by the routing search. The filters may modify itineraries, sort them, and filter away less preferable results. OTP2 may produce numerous pareto-optimal results when using time , number-of-transfers and generalized-cost as criteria. Use the parameters listed here to reduce/filter the itineraries return by the search engine before returning the results to client. There is also a few mandatory none configurable filters removing none optimal results. You may see these filters pop-up in the filter debugging. config key description value type value default debug Enable this to attach a system notice to itineraries instead of removing them. This is very convenient when tuning the filters. boolean false groupSimilarityKeepOne Pick ONE itinerary from each group after putting itineraries that is 85% similar together. double 0.85 (85%) groupSimilarityKeepThree Reduce the number of itineraries to three itineraries by reducing each group of itineraries grouped by 68% similarity. double 0.68 (68%) groupedOtherThanSameLegsMaxCostMultiplier Filter grouped itineraries, where the non-grouped legs are more expensive than in the lowest cost one. double 2.0 (2x cost) transitGeneralizedCostLimit A relative maximum limit for the generalized cost for transit itineraries. The limit is a linear function of the minimum generalized-cost. The function is used to calculate a max-limit. The max-limit is then used to to filter by generalized-cost. Transit itineraries with a cost higher than the max-limit is dropped from the result set. None transit itineraries is excluded from the filter. To set a filter to be 1 hour plus 2 times the best cost use: 3600 + 2.0 x . To set an absolute value(3000s) use: 3000 + 0x linear function 3600 + 2.0 x nonTransitGeneralizedCostLimit A relative maximum limit for the generalized cost for non-transit itineraries. The max limit is calculated using ALL itineraries, but only non-transit itineraries will be filtered out. The limit is a linear function of the minimum generalized-cost. The function is used to calculate a max-limit. The max-limit is then used to to filter by generalized-cost. Non-transit itineraries with a cost higher than the max-limit is dropped from the result set. To set a filter to be 1 hour plus 2 times the best cost use: 3600 + 2.0 x . To set an absolute value(3000s) use: 3000 + 0x linear function 3600 + 2.0 x bikeRentalDistanceRatio For routes that consist only of bike rental and walking what is the minimum fraction of distance of the bike rental leg. This filters out results that consist of a long walk plus a relatively short bike rental leg. A value of 0.3 means that a minimum of 30% of the total distance must be spent on the bike in order for the result to be included. double 0.0 parkAndRideDurationRatio For P+R routes that consist only of driving and walking what is the minimum fraction of time of the driving leg. This filters out results that consist of driving plus a very long walk leg at the end. A value of 0.3 means that a minimum of 30% of the total time must be spent in the car in order for the result to be included. However, if there is only a single result, it is never filtered. double 0.0","title":"Tuning itinerary filtering"},{"location":"RouterConfiguration/#group-by-similarity-filters","text":"The group-by-filter is a bit complex, but should be simple to use. Set debug=true and experiment with searchWindow and the three group-by parameters( groupSimilarityKeepOne , groupSimilarityKeepThree and groupedOtherThanSameLegsMaxCostMultiplier ). The group-by-filter work by grouping itineraries together and then reducing the number of itineraries in each group, keeping the itinerary/itineraries with the best itinerary generalized-cost . The group-by function first pick all transit legs that account for more than N% of the itinerary based on distance traveled. This become the group-key. Two keys are the same if all legs in one of the keys also exist in the other. Note, one key may have a lager set of legs than the other, but they can still be the same. When comparing two legs we compare the tripId and make sure the legs overlap in place and time. Two legs are the same if both legs ride at least a common subsection of the same trip. The keepOne filter will keep ONE itinerary in each group. The keepThree keeps 3 itineraries for each group. The grouped itineraries can be further reduced by using groupedOtherThanSameLegsMaxCostMultiplier . This parameter filters out itineraries, where the legs that are not common for all the grouped itineraries have a much higher cost, than the lowest in the group. By default, it filters out itineraries that are at least double in cost for the non-grouped legs.","title":"Group by similarity filters"},{"location":"RouterConfiguration/#drive-to-transit-routing-defaults","text":"When using the \"park and ride\" or \"kiss and ride\" modes (drive to transit), the initial driving time to reach a transit stop or park and ride facility is constrained. You can set a drive time limit in seconds by adding a line like maxPreTransitTime = 1200 to the routingDefaults section. If the limit is too high on a very large street graph, routing performance may suffer.","title":"Drive-to-transit routing defaults"},{"location":"RouterConfiguration/#boarding-and-alighting-times","text":"Sometimes there is a need to configure a longer ride or alighting times for specific modes, such as airplanes or ferries, where the check-in process needs to be done in good time before ride. The ride time is added to the time when going from the stop (offboard) vertex to the onboard vertex, and the alight time is added vice versa. The times are configured as seconds needed for the ride and alighting processes in router-config.json as follows: // router-config.json { \"routingDefaults\" : { \"boardSlackForMode\" : { \"AIRPLANE\" : 2700 }, \"alightSlackForMode\" : { \"AIRPLANE\" : 1200 } } }","title":"Boarding and alighting times"},{"location":"RouterConfiguration/#timeout","text":"In OTP1 path searches sometimes toke a long time to complete. With the new Raptor algorithm this not the case anymore. The street part of the routing may still take a long time if searching very long distances. You can set the street routing timeout to avoid tying up server resources on pointless searches and ensure that your users receive a timely response. You can also limit the max distance to search for WALK, BIKE and CAR. When a search times out, a WARN level log entry is made with information that can help identify problematic searches and improve our routing methods. There are no timeouts for the transit part of the routing search, instead configure a reasonable dynamic search-window. To set the street routing timeout use the following config: // router-config.json { \"streetRoutingTimeout\" : 5.5 } This specifies a timeout in (optionally fractional) seconds. The search abort after this many seconds and any paths found are returned to the client.","title":"Timeout"},{"location":"RouterConfiguration/#maxaccessegressdurationsecondsformode","text":"Override the settings in maxAccessEgressDurationSeconds for specific street modes. This is done because some street modes searches are much more resource intensive than others. // router-config.json \"maxAccessEgressDurationSecondsForMode\" : { \"BIKE_RENTAL\" : 1200 } This will limit only the BIKE_RENTAL mode to 1200 seconds, while keeping the default limit for all other access/egress modes.","title":"maxAccessEgressDurationSecondsForMode"},{"location":"RouterConfiguration/#logging-incoming-requests","text":"You can log some characteristics of trip planning requests in a file for later analysis. Some transit agencies and operators find this information useful for identifying existing or unmet transportation demand. Logging will be performed only if you specify a log file name in the router config: // router-config.json { \"requestLogFile\" : \"/var/otp/request.log\" } Each line in the resulting log file will look like this: 2016-04-19T18:23:13.486 0:0:0:0:0:0:0:1 ARRIVE 2016-04-07T00:17 WALK,BUS,CABLE_CAR,TRANSIT,BUSISH 45.559737193889966 -122.64999389648438 45.525592487765635 -122.39044189453124 6095 3 5864 3 6215 3 The fields separated by whitespace are (in order): Date and time the request was received IP address of the user Arrive or depart search The arrival or departure time A comma-separated list of all transport modes selected Origin latitude and longitude Destination latitude and longitude Finally, for each itinerary returned to the user, there is a travel duration in seconds and the number of transit vehicles used in that itinerary.","title":"Logging incoming requests"},{"location":"RouterConfiguration/#tuning-transit-routing","text":"Nested inside transit {...} in router-config.json . Some of these parameters for tuning transit routing is only available through configuration and cannot be set in the routing request. These parameters work together with the default routing request and the actual routing request. config key description value type value default maxNumberOfTransfers Use this parameter to allocate enough space for Raptor. Set it to the maximum number of transfers for any given itinerary expected to be found within the entire transit network. The memory overhead of setting this higher than the maximum number of transfers is very little so it is better to set it too high then to low. int 12 scheduledTripBinarySearchThreshold The threshold is used to determine when to perform a binary trip schedule search to reduce the number of trips departure time lookups and comparisons. When testing with data from Entur and all of Norway as a Graph, the optimal value was around 50. Changing this may improve the performance with just a few percent. int 50 iterationDepartureStepInSeconds Step for departure times between each RangeRaptor iterations. A transit network usually uses minute resolution for its depature and arrival times. To match that, set this variable to 60 seconds. int 60 searchThreadPoolSize Split a travel search in smaller jobs and run them in parallel to improve performance. Use this parameter to set the total number of executable threads available across all searches. Multiple searches can run in parallel - this parameter have no effect with regard to that. If 0, no extra threads are started and the search is done in one thread. int 0 dynamicSearchWindow The dynamic search window coefficients used to calculate the EDT(earliest-departure-time), LAT(latest-arrival-time) and SW(raptor-search-window) using heuristics. object null stopTransferCost Use this to set a stop transfer cost for the given TransferPriority . The cost is applied to boarding and alighting at all stops. All stops have a transfer cost priority set, the default is ALLOWED . The stopTransferCost parameter is optional, but if listed all values must be set. enum map null transferCacheMaxSize The maximum number of distinct transfers parameters ( RoutingRequest s) to cache pre-calculated transfers for. If too low, requests may be slower. If too high, more memory may be used then required. int 25 pagingSearchWindowAdjustments The provided array of durations is used to increase the search-window for the next/previous page when the current page return few options. If ZERO results is returned the first duration in the list is used, if ONE result is returned then the second duration is used and so on. The duration is added to the existing search-window and inserted into the next and previous page cursor. See JavaDoc for TransitTuningParameters#pagingSearchWindowAdjustments for more info. duration[] [\"4h\", \"2h\", \"1h\", \"30m\", \"20m\", \"10m\"]","title":"Tuning transit routing"},{"location":"RouterConfiguration/#tuning-transit-routing-dynamic-search-window","text":"Nested inside transit : { dynamicSearchWindow : { ... } } in router-config.json . config key description value type value default minTransitTimeCoefficient The coefficient to multiply with minimum transit time found using a heuristic search. This scaled value is added to the minWinTimeMinutes . A value between 0.0 to 3.0 is expected to give ok results. double 0.5 minWaitTimeCoefficient The coefficient to multiply with a minimum wait time estimated based on the heuristic search. This will increase the search-window in low transit frequency areas. This value is added to the minWinTimeMinutes . A value between 0.0 to 1.0 is expected to give ok results. double 0.5 minWinTimeMinutes The constant minimum number of minutes for a raptor search window. Use a value between 20-180 minutes in a normal deployment. int 40 maxWinTimeMinutes Set an upper limit to the calculation of the dynamic search window to prevent exceptionable cases to cause very long search windows. Long search windows consumes a lot of resources and may take a long time. Use this parameter to tune the desired maximum search time. int 180 (3 hours) stepMinutes The search window is rounded of to the closest multiplication of N minutes. If N=10 minutes, the search-window can be 10, 20, 30 ... minutes. It the computed search-window is 5 minutes and 17 seconds it will be rounded up to 10 minutes. int 10","title":"Tuning transit routing - Dynamic search window"},{"location":"RouterConfiguration/#tuning-transit-routing-stop-transfer-cost","text":"Nested inside transit : { stopTransferCost : { ... } } in router-config.json . This cost is in addition to other costs like boardCost and indirect cost from waiting (board-/alight-/transfer slack). You should account for this when you tune the routing search parameters. If not set the stopTransferCost is ignored. This is only available for NeTEx imported Stops. The cost is a scalar, but is equivalent to the felt cost of riding a transit trip for 1 second. config key description value type DISCOURAGED Use a very high cost like 72 000 to eliminate transfers ath the stop if not the only option. int ALLOWED Allowed, but not recommended. Use something like 150 . int RECOMMENDED Use a small cost penalty like 60 . int PREFERRED The best place to do transfers. Should be set to 0 (zero). int Use values in a range from 0 to 100 000 . All key/value pairs are required if the stopTransferCost is listed.","title":"Tuning transit routing - Stop transfer cost"},{"location":"RouterConfiguration/#transit-example","text":"// router-config.json { \"transit\" : { \"maxNumberOfTransfers\" : 12 , \"scheduledTripBinarySearchThreshold\" : 50 , \"iterationDepartureStepInSeconds\" : 60 , \"searchThreadPoolSize\" : 0 , \"dynamicSearchWindow\" : { \"minTransitTimeCoefficient\" : 0.5 , \"minWaitTimeCoefficient\" : 0.5 , \"minTimeMinutes\" : 30 , \"maxLengthMinutes\" : 360 , \"stepMinutes\" : 10 }, \"stopTransferCost\" : { \"DISCOURAGED\" : 72000 , \"ALLOWED\" : 150 , \"RECOMMENDED\" : 60 , \"PREFERRED\" : 0 } } }","title":"Transit example"},{"location":"RouterConfiguration/#real-time-data","text":"GTFS feeds contain schedule data that is is published by an agency or operator in advance. The feed does not account for unexpected service changes or traffic disruptions that occur from day to day. Thus, this kind of data is also referred to as 'static' data or 'theoretical' arrival and departure times.","title":"Real-time data"},{"location":"RouterConfiguration/#gtfs-realtime","text":"The GTFS-RT spec complements GTFS with three additional kinds of feeds. In contrast to the base GTFS schedule feed, they provide real-time updates ( 'dynamic' data) and are are updated from minute to minute. Alerts are text messages attached to GTFS objects, informing riders of disruptions and changes. TripUpdates report on the status of scheduled trips as they happen, providing observed and predicted arrival and departure times for the remainder of the trip. VehiclePositions give the location of some or all vehicles currently in service, in terms of geographic coordinates or position relative to their scheduled stops.","title":"GTFS-Realtime"},{"location":"RouterConfiguration/#vehicle-rental-systems-using-gbfs","text":"Besides GTFS-RT transit data, OTP can also fetch real-time data about vehicle rental networks including the number of bikes and free parking spaces at each station. We support vehicle rental systems from using GBFS feed format.","title":"Vehicle rental systems using GBFS"},{"location":"RouterConfiguration/#vehicle-parking-sandbox-feature","text":"Vehicle parking options and configuration is documented in its sandbox documentation .","title":"Vehicle parking (sandbox feature)"},{"location":"RouterConfiguration/#configuring-real-time-updaters","text":"Real-time data can be provided using either a pull or push system. In a pull configuration, the GTFS-RT consumer polls the real-time provider over HTTP. That is to say, OTP fetches a file from a web server every few minutes. In the push configuration, the consumer opens a persistent connection to the GTFS-RT provider, which then sends incremental updates immediately as they become available. OTP can use both approaches. The OneBusAway GTFS-realtime exporter project provides this kind of streaming, incremental updates over a websocket rather than a single large file. Real-time data sources are configured in router-config.json . The updaters section is an array of JSON objects, each of which has a type field and other configuration fields specific to that type. Common to all updater entries that connect to a network resource is the url field. // router-config.json { // Routing defaults are any public field or setter in the Java class // org.opentripplanner.routing.api.request.RoutingRequest \"routingDefaults\" : { \"numItineraries\" : 6 , \"walkSpeed\" : 2.0 , \"stairsReluctance\" : 4.0 , \"carDropoffTime\" : 240 }, \"updaters\" : [ // GTFS-RT service alerts (frequent polling) { \"type\" : \"real-time-alerts\" , \"frequencySec\" : 30 , \"url\" : \"http://developer.trimet.org/ws/V1/FeedSpecAlerts/appID/0123456789ABCDEF\" , \"feedId\" : \"TriMet\" }, //<!--- Tampa Area GBFS bike share --> { \"type\" : \"vehicle-rental\" , \"frequencySec\" : 300 , \"sourceType\" : \"gbfs\" , \"url\" : \"http://coast.socialbicycles.com/opendata/gbfs.json\" }, // Vehicle parking availability { \"type\" : \"vehicle-parking\" }, // Polling for GTFS-RT TripUpdates) { \"type\" : \"stop-time-updater\" , \"frequencySec\" : 60 , // this is either http or file... shouldn't it default to http or guess from the presence of a URL? \"sourceType\" : \"gtfs-http\" , \"url\" : \"http://developer.trimet.org/ws/V1/TripUpdate/appID/0123456789ABCDEF\" , \"feedId\" : \"TriMet\" }, // Streaming differential GTFS-RT TripUpdates over websockets { \"type\" : \"websocket-gtfs-rt-updater\" } ] }","title":"Configuring real-time updaters"},{"location":"RouterConfiguration/#gbfs-configuration","text":"GBFS is used for a variety of shared mobility services, with partial support for both v1 and v2.2 ( list of known GBFS feeds ). To add a GBFS feed to the router add one entry in the updater field of router-config.json in the format: // router-config.json { \"type\" : \"vehicle-rental\" , \"sourceType\" : \"gbfs\" , // frequency in seconds in which the GBFS service will be polled \"frequencySec\" : 60 , // The URL of the GBFS feed auto-discovery file \"url\" : \"http://coast.socialbicycles.com/opendata/gbfs.json\" , // Optionally specify the language version of the feed to use. If no language is set, the first language in the feed is used. \"language\" : \"en\" , // if it should be possible to arrive at the destination with a rented bicycle, without dropping it off \"allowKeepingRentedBicycleAtDestination\" : true }","title":"GBFS Configuration"},{"location":"RouterConfiguration/#arriving-with-rental-bikes-at-the-destination","text":"In some cases it may be useful to not drop off the rented bicycle before arriving at the destination. This is useful if bicycles may only be rented for round trips, or the destination is an intermediate place. For this to be possible three things need to be configured: In the updater configuration allowKeepingRentedBicycleAtDestination should be set to true . allowKeepingRentedBicycleAtDestination should also be set for each request, either using routing defaults , or per-request. If keeping the bicycle at the destination should be discouraged, then keepingRentedBicycleAtDestinationCost (default: 0 ) may also be set in the routing defaults .","title":"Arriving with rental bikes at the destination"},{"location":"RouterConfiguration/#vehicle-rental-service-directory-configuration-sandbox-feature","text":"To configure and url for the VehicleRentalServiceDirectory . // router-config.json { \"vehicleRentalServiceDirectory\" : { \"url\" : \"https://api.dev.entur.io/mobility/v1/bikes\" } }","title":"Vehicle Rental Service Directory configuration (sandbox feature)"},{"location":"RouterConfiguration/#configure-using-command-line-arguments","text":"Certain settings can be provided on the command line, when starting OpenTripPlanner. See the CommandLineParameters class for a full list of arguments .","title":"Configure using command-line arguments"},{"location":"RoutingModes/","text":"Routing modes TODO OTP2 - Where in the documentation does this belong? This is currently not part of the menu or - any linked to by any of the other documents. The routing request parameter mode determines which transport modalities should be considered when calculating the list of routes. Some modes (mostly bicycle and car) also have optional qualifiers RENT and PARK to specify if vehicles are to be parked at a station or rented. In theory this can also apply to other modes but makes sense only in select cases which are listed below. Whether a transport mode is available highly depends on the input feeds (GTFS, OSM, bike sharing feeds) and the graph building options supplied to OTP. The complete list of modes are: WALK : Walking some or all of the route. TRANSIT : General catch-all for all public transport modes. BICYCLE : Cycling for the entirety of the route or taking a bicycle onto the public transport and cycling from the arrival station to the destination. BICYCLE_RENT : Taking a rented, shared-mobility bike for part or the entirety of the route. Prerequisite: Vehicle positions need to be added to OTP from dynamic data feeds. For dynamic bike positions configure an input feed. See Configuring real-time updaters . BICYCLE_PARK : Leaving the bicycle at the departure station and walking from the arrival station to the destination. This mode needs to be combined with at least one transit mode (or TRANSIT ) otherwise it behaves like an ordinary bicycle journey. Prerequisite: Bicycle parking stations present in the OSM file and visible to OTP by enabling the property staticBikeParkAndRide during graph build. CAR : Driving your own car the entirety of the route. If this is combined with TRANSIT it will return routes with a Kiss & Ride component. This means that the car is not parked in a permanent parking area but rather the passenger is dropped off (for example, at an airport) and the driver continues driving the car away from the drop off location. CAR_PARK : Driving a car to the park-and-ride facilities near a station and taking public transport. This mode needs to be combined with at least one transit mode (or TRANSIT ) otherwise it behaves like an ordinary car journey. Prerequisite: Park-and-ride areas near the station need to be present in the OSM input file. The following modes are 1-to-1 mappings from the GTFS route_type : TRAM : Tram, streetcar, or light rail. Used for any light rail or street-level system within a metropolitan area. SUBWAY : Subway or metro. Used for any underground rail system within a metropolitan area. RAIL : Used for intercity or long-distance travel. BUS : Used for short- and long-distance bus routes. FERRY : Ferry. Used for short- and long-distance boat service. CABLE_CAR : Cable car. Used for street-level cable cars where the cable runs beneath the car. GONDOLA : Gondola or suspended cable car. Typically used for aerial cable cars where the car is suspended from the cable. FUNICULAR : Funicular. Used for any rail system that moves on steep inclines with a cable traction system. Lastly, this mode is part of the Extended GTFS route types : AIRPLANE : Taking an airplane. Note that there are conceptual overlaps between TRAM , SUBWAY and RAIL and some transport providers categorize their routes differently to others. In other words, what is considered a SUBWAY in one city might be of type RAIL in another. Study your input GTFS feed carefully to find out the appropriate mapping in your region.","title":"RoutingModes"},{"location":"RoutingModes/#routing-modes","text":"TODO OTP2 - Where in the documentation does this belong? This is currently not part of the menu or - any linked to by any of the other documents. The routing request parameter mode determines which transport modalities should be considered when calculating the list of routes. Some modes (mostly bicycle and car) also have optional qualifiers RENT and PARK to specify if vehicles are to be parked at a station or rented. In theory this can also apply to other modes but makes sense only in select cases which are listed below. Whether a transport mode is available highly depends on the input feeds (GTFS, OSM, bike sharing feeds) and the graph building options supplied to OTP. The complete list of modes are: WALK : Walking some or all of the route. TRANSIT : General catch-all for all public transport modes. BICYCLE : Cycling for the entirety of the route or taking a bicycle onto the public transport and cycling from the arrival station to the destination. BICYCLE_RENT : Taking a rented, shared-mobility bike for part or the entirety of the route. Prerequisite: Vehicle positions need to be added to OTP from dynamic data feeds. For dynamic bike positions configure an input feed. See Configuring real-time updaters . BICYCLE_PARK : Leaving the bicycle at the departure station and walking from the arrival station to the destination. This mode needs to be combined with at least one transit mode (or TRANSIT ) otherwise it behaves like an ordinary bicycle journey. Prerequisite: Bicycle parking stations present in the OSM file and visible to OTP by enabling the property staticBikeParkAndRide during graph build. CAR : Driving your own car the entirety of the route. If this is combined with TRANSIT it will return routes with a Kiss & Ride component. This means that the car is not parked in a permanent parking area but rather the passenger is dropped off (for example, at an airport) and the driver continues driving the car away from the drop off location. CAR_PARK : Driving a car to the park-and-ride facilities near a station and taking public transport. This mode needs to be combined with at least one transit mode (or TRANSIT ) otherwise it behaves like an ordinary car journey. Prerequisite: Park-and-ride areas near the station need to be present in the OSM input file. The following modes are 1-to-1 mappings from the GTFS route_type : TRAM : Tram, streetcar, or light rail. Used for any light rail or street-level system within a metropolitan area. SUBWAY : Subway or metro. Used for any underground rail system within a metropolitan area. RAIL : Used for intercity or long-distance travel. BUS : Used for short- and long-distance bus routes. FERRY : Ferry. Used for short- and long-distance boat service. CABLE_CAR : Cable car. Used for street-level cable cars where the cable runs beneath the car. GONDOLA : Gondola or suspended cable car. Typically used for aerial cable cars where the car is suspended from the cable. FUNICULAR : Funicular. Used for any rail system that moves on steep inclines with a cable traction system. Lastly, this mode is part of the Extended GTFS route types : AIRPLANE : Taking an airplane. Note that there are conceptual overlaps between TRAM , SUBWAY and RAIL and some transport providers categorize their routes differently to others. In other words, what is considered a SUBWAY in one city might be of type RAIL in another. Study your input GTFS feed carefully to find out the appropriate mapping in your region.","title":"Routing modes"},{"location":"SandboxExtension/","text":"OTP Sandbox Extensions The sandbox is a place to test and implement new \"experimental\" features. This should not be used for bug fixes and smaller changes. Consider forking if the feature is valuable to one deployment only. Available extensions Here is a list of features implemented as OTP Sandbox Extensions. The Sandbox extensions are provided \"as is\". Examples - Sandbox examples on how to implement extensions. Google Cloud Storage - Enable Google Cloud Storage as a OTP Data Source Actuator API - API used to check the health status of the OTP instance. Transfer analyser - Module used for analyzing the transfers between nearby stops generated by routing via OSM data. HSL Legacy GraphQL API - HSL's GraphQL API used by the Digitransit project. Transmodel API - Enturs GraphQL Transmodel API. SIRI updator - Update OTP with realtime information from a Transmodel SIRI data source. VehicleRentalServiceDirectory - GBFS service directory endpoint. Smoove Bike Rental Updator Support - Smoove Bike Rental Updator(HSL) Mapbox Vector Tiles API - Mapbox Vector Tiles API Flex Routing - Flexible transit routing for GTFS and Netex data sources Park and Ride API - Park and Ride API Data Overlay - StreetEdge grid data populating affecting the route planning Vehicle Parking - Vehicle Parking updaters Terminology Main/core -- All OTP code and additional files, NOT part of the sandbox. ( docs , src/main , src/test and so on) Extensions -- All features implemented in the OTP Sandbox, provided with no guarantees. ( src/ext , src/ext-test ) Sandbox Goals Reduce work for PR approval Allow experimental code to evolve (in a Sandbox) Encourage refactoring and creation of extension points in the main code. Increase visibility and cooperation of development of new features. Feature toggle Sandbox features should use the OTPFeature to enable the code. Sandbox features are by default off. To toggle features on/off se the configuration documentation . Contract Give your feature a name: <extension name> A new feature is isolated from the rest of the code by putting it in the directory src/ext . Java code should have package prefix org.opentripplanner.ext.<extension name> . Unit tests should be added in the test directory: src/ext-test To integrate the new feature into OTP you may have to create new extension points in the main/core code. Changes to the core OTP are subject to normal a review process. Create a readme file ( docs/sandbox/<Extension Name>.md package including: Extension Name Contact info Change log Documentation of the feature (optional) List your extension in the Available extensions section and in the mydocs config file . Use feature toggling to enable a feature at runtime. The feature must be disabled by default. A feature is toggled on using the config files. Only code modifying the main code( src/main , not src/ext ) is reviewed. The current coding standard apply to the extension code as well - but the code is not necessarily reviewed. There are no grantees - the authors of an extension can change its API any time they want. Anyone can request the feature to be merged into the main code. An approval from the PLC and a new review is then required. The reviewers may request any changes, including API changes. If an extension is taken into the core/main OTP code, any API included may change, no BACKWARD compatibility is guaranteed. I.e. the reviewers may require changes before it is merged. The feature submitters is responsible for maintaining and testing the extension code, but do not need to provide any guarantees or support. If the extension is merged into the main code the author will in fact need to provide support and maintenance. When someone at a later point in time want to change the main code the only thing they are responsible for - with regard to the extension code - is: that it compiles. that the unit tests run. If a test is not easy to fix, it can be tagged with @Ignore. If ignored it would be polite to notify the author. Changes to the main OTP API that cannot be toggled in must be clearly marked/tagged as part of an experimental feature and documented - This code is subject to review. If a feature is old and not maintained it can be removed 1 month after notifying the submitter (using contact info in README file). Introducing new dependencies needs approval. They are NOT approved if they are likely to be a maintenance challenge (many transitive dependencies or potential conflicts with other versions/libraries).","title":"About"},{"location":"SandboxExtension/#otp-sandbox-extensions","text":"The sandbox is a place to test and implement new \"experimental\" features. This should not be used for bug fixes and smaller changes. Consider forking if the feature is valuable to one deployment only.","title":"OTP Sandbox Extensions"},{"location":"SandboxExtension/#available-extensions","text":"Here is a list of features implemented as OTP Sandbox Extensions. The Sandbox extensions are provided \"as is\". Examples - Sandbox examples on how to implement extensions. Google Cloud Storage - Enable Google Cloud Storage as a OTP Data Source Actuator API - API used to check the health status of the OTP instance. Transfer analyser - Module used for analyzing the transfers between nearby stops generated by routing via OSM data. HSL Legacy GraphQL API - HSL's GraphQL API used by the Digitransit project. Transmodel API - Enturs GraphQL Transmodel API. SIRI updator - Update OTP with realtime information from a Transmodel SIRI data source. VehicleRentalServiceDirectory - GBFS service directory endpoint. Smoove Bike Rental Updator Support - Smoove Bike Rental Updator(HSL) Mapbox Vector Tiles API - Mapbox Vector Tiles API Flex Routing - Flexible transit routing for GTFS and Netex data sources Park and Ride API - Park and Ride API Data Overlay - StreetEdge grid data populating affecting the route planning Vehicle Parking - Vehicle Parking updaters","title":"Available extensions"},{"location":"SandboxExtension/#terminology","text":"Main/core -- All OTP code and additional files, NOT part of the sandbox. ( docs , src/main , src/test and so on) Extensions -- All features implemented in the OTP Sandbox, provided with no guarantees. ( src/ext , src/ext-test )","title":"Terminology"},{"location":"SandboxExtension/#sandbox-goals","text":"Reduce work for PR approval Allow experimental code to evolve (in a Sandbox) Encourage refactoring and creation of extension points in the main code. Increase visibility and cooperation of development of new features. Feature toggle Sandbox features should use the OTPFeature to enable the code. Sandbox features are by default off. To toggle features on/off se the configuration documentation .","title":"Sandbox Goals"},{"location":"SandboxExtension/#contract","text":"Give your feature a name: <extension name> A new feature is isolated from the rest of the code by putting it in the directory src/ext . Java code should have package prefix org.opentripplanner.ext.<extension name> . Unit tests should be added in the test directory: src/ext-test To integrate the new feature into OTP you may have to create new extension points in the main/core code. Changes to the core OTP are subject to normal a review process. Create a readme file ( docs/sandbox/<Extension Name>.md package including: Extension Name Contact info Change log Documentation of the feature (optional) List your extension in the Available extensions section and in the mydocs config file . Use feature toggling to enable a feature at runtime. The feature must be disabled by default. A feature is toggled on using the config files. Only code modifying the main code( src/main , not src/ext ) is reviewed. The current coding standard apply to the extension code as well - but the code is not necessarily reviewed. There are no grantees - the authors of an extension can change its API any time they want. Anyone can request the feature to be merged into the main code. An approval from the PLC and a new review is then required. The reviewers may request any changes, including API changes. If an extension is taken into the core/main OTP code, any API included may change, no BACKWARD compatibility is guaranteed. I.e. the reviewers may require changes before it is merged. The feature submitters is responsible for maintaining and testing the extension code, but do not need to provide any guarantees or support. If the extension is merged into the main code the author will in fact need to provide support and maintenance. When someone at a later point in time want to change the main code the only thing they are responsible for - with regard to the extension code - is: that it compiles. that the unit tests run. If a test is not easy to fix, it can be tagged with @Ignore. If ignored it would be polite to notify the author. Changes to the main OTP API that cannot be toggled in must be clearly marked/tagged as part of an experimental feature and documented - This code is subject to review. If a feature is old and not maintained it can be removed 1 month after notifying the submitter (using contact info in README file). Introducing new dependencies needs approval. They are NOT approved if they are likely to be a maintenance challenge (many transitive dependencies or potential conflicts with other versions/libraries).","title":"Contract"},{"location":"Security/","text":"Security OTP's built-in Grizzly web server is configured to accept HTTPS connections on port 8081 by default, but the HTTPS listener needs an encryption key to establish a connection. The key is placed in a \"keystore\", a format specific to Java server environments. Creating a keystore By default, OTP will look for the keystore at /var/otp/keystore . To generate a self-signed key for testing, use the command: keytool -genkey -keystore /var/otp/keystore -alias OTPServerKey The alias of the key is arbitrary, but it's best to supply one that indicates the purpose of the key to override the default. keytool will ask you a series of questions about you and your organization; again, any values will do when creating this self-signed test key. keytool will also ask you for a password to protect your keystore and key. This password will eventually be configurable, but for now it is hard-coded into the OTP server, so you must set the keystore and key passwords both to opentrip . Of course with a self-signed key, most clients will (rightfully) refuse to connect without special permission from the user. You'll need to add a security exception to most web browsers, or add the --insecure switch when using CURL. You could theoretically buy and install a \"real\" trusted SSL/TLS certificate it in the keystore using keytool -gencert , but since none of the functionality protected by this encryption is public-facing a self-signed key should be sufficient for most use cases. All connections to these API methods should be from trusted parties who can verify the validity of the key with you directly as needed. Testing Once you have created a key, start up the OTP server and test that HTTPS access and authentication are possible. You should also be able to fetch any OTP resources over HTTPS. For example, you could simply open https://localhost:8081/index.html in a browser, or open a raw TLS connection using openssl s_client -connect localhost:8081 , then issue the request GET index.html HTTP/1.1 . Other TODO explain CORS, explain adding TLS with reverse proxy e.g. nginx","title":"Security"},{"location":"Security/#security","text":"OTP's built-in Grizzly web server is configured to accept HTTPS connections on port 8081 by default, but the HTTPS listener needs an encryption key to establish a connection. The key is placed in a \"keystore\", a format specific to Java server environments.","title":"Security"},{"location":"Security/#creating-a-keystore","text":"By default, OTP will look for the keystore at /var/otp/keystore . To generate a self-signed key for testing, use the command: keytool -genkey -keystore /var/otp/keystore -alias OTPServerKey The alias of the key is arbitrary, but it's best to supply one that indicates the purpose of the key to override the default. keytool will ask you a series of questions about you and your organization; again, any values will do when creating this self-signed test key. keytool will also ask you for a password to protect your keystore and key. This password will eventually be configurable, but for now it is hard-coded into the OTP server, so you must set the keystore and key passwords both to opentrip . Of course with a self-signed key, most clients will (rightfully) refuse to connect without special permission from the user. You'll need to add a security exception to most web browsers, or add the --insecure switch when using CURL. You could theoretically buy and install a \"real\" trusted SSL/TLS certificate it in the keystore using keytool -gencert , but since none of the functionality protected by this encryption is public-facing a self-signed key should be sufficient for most use cases. All connections to these API methods should be from trusted parties who can verify the validity of the key with you directly as needed.","title":"Creating a keystore"},{"location":"Security/#testing","text":"Once you have created a key, start up the OTP server and test that HTTPS access and authentication are possible. You should also be able to fetch any OTP resources over HTTPS. For example, you could simply open https://localhost:8081/index.html in a browser, or open a raw TLS connection using openssl s_client -connect localhost:8081 , then issue the request GET index.html HTTP/1.1 .","title":"Testing"},{"location":"Security/#other","text":"TODO explain CORS, explain adding TLS with reverse proxy e.g. nginx","title":"Other"},{"location":"Troubleshooting-Routing/","text":"Troubleshooting Routing Graph Builder Data Import Issues When you build a graph, OTP may encounter clearly incorrect or ambiguous data, or may detect less severe, but potentially problematic situations in the input data. Such problems should result in a \"Data Import Issue\" being generated. These issues are logged the the DATA_IMPORT_ISSUES console logger, depending on your need you might turn this logger on/off. At the end of the graph build process, OTP prints a summary of all the issues, like the following: 11:35:57.515 INFO (Graph.java:970) Summary (number of each type of issues): 11:35:57.518 INFO (Graph.java:976) TurnRestrictionBad - 560 11:35:57.518 INFO (Graph.java:976) TurnRestrictionException - 15 11:35:57.518 INFO (Graph.java:976) StopLinkedTooFar - 22 11:35:57.518 INFO (Graph.java:976) HopSpeedSlow - 22 11:35:57.518 INFO (Graph.java:976) Graphwide - 1 11:35:57.518 INFO (Graph.java:976) GraphConnectivity - 407 11:35:57.519 INFO (Graph.java:976) ParkAndRideUnlinked - 1 11:35:57.519 INFO (Graph.java:976) StopNotLinkedForTransfers - 31 11:35:57.519 INFO (Graph.java:976) NoFutureDates - 1 The full set of issues can be written out to an HTML report for closer inspection. To enable the creation of these (potentially voluminous) HTML reports, add \"dataImportReport\" : true to your graph builder JSON configuration. If the graph is saved to a file, these issues are saved with it and can be examined later. Currently the only tool for doing this is the \"Graph Visualizer\", which is not particularly well maintained and is intended for use by software developers familiar with OTP who can patch up the code as needed. Debug layers OpenTripplanner has option to ease debugging problems with graph. Older option is graph visualizer. Which you can enable with --visualize parameter instead of --server when starting OTP. There you can see whole graph. You can click on edges and vertices and see the metadata. It is useful to see if street has expected options. And if connections are where they are expected. It can be hard to use on large graphs since, whole graph is displayed at once. And it can be hard to search for specific streets since only street graph is shown without the rest of information. Another option is to use debug layers, which shows extra layers on top of the normal debug UI map . If you want to see them you need to open the map layer selector on the top left hand side and choose the requested layer. Currently you can choose between: Wheelchair access (which colors street edges red if they don't allow wheelchair or green otherwise) Bicycle safety (colors street edges based on how good are for cycling [smaller is better]) Traversal permissions (colors street edges based on what types of transit modes are allowed to travel on them (Pedestrian, cycling, car are currently supported)) Traversal permissions layer also draws links from transit stops/vehicle rentals and P+R to graph. And also draws transit stops, vehicle rentals and P+R vertices with different color. No thru traffic - streets are colored if the edge has thru traffic restrictions (car and bicycle = red , car only = orange , bicycle only = blue , and no-restriction = light gray ) Interpretation Traversal permissions layer A sample traversal permissions layer looks like the following Yellow lines is the link between a stop and the street graph. Grey lines are streets one can travel with the mode walk, bike, or car Green lines are paths one can travel with the mode walk only Red lines are streets one can travel with the mode car only Grey dots vertices where edges are connected. If two edges are crossing w/o a vertice at the intersection point, users will not be able to go from one street to the other. But this can be valid in case of over/under pass for example. If it's an error, it's usually caused by improperly connected OSM data (a shared OSM node is required). OpenStreetMap Data Tags affecting permissions and bicycle safety OTP has a very flexible system for deciding when a street is to be allowed by pedestrians, bicycles or cars. To configure the which settings to use for your location, please use the osmWayPropertySet config attribute . In the following section we will discuss the default case, which will be used if the property is not set. Default settings Access tags (such as bicycle/foot = yes/no/designated) can be used to override default graph-building parameters. As a default, foot and bicycle traffic is ''not'' allowed on highway=trunk , highway=trunk_link , highway=motorway , highway=motorway_link , or highway=construction . Both are allowed on highway=pedestrian , highway=cycleway , and highway=footway . Finally, bicycles are not allowed on highway=footway when any of the following tags appear on a footway: footway=sidewalk , public_transport=platform , or railway=platform . Other access tags (such as access=no and access=private affect routing as well, and can be overridden similarly. While access=no prohibits all traffic, access=private disallows through traffic. Bicycle safety factor Bicycle routing is even more configurable than the other traverse modes: during graph build a so-called bicycle safety score is computed for each street. You can think of this score as a penalty for traversing this way so the lower the score the better. For example if a way is tagged with surface=sand it receives a safety score of 100 which means that it's 100 times worse to cycle on when compared to a way which has a safety score of 1. How this is calculated depends on two things the incline of the way (not read from OSM but from the separately configured elevation data ) its OSM tags At request time you can then use the triangleFactors to decide how important bicycle safety is compared to shorter distances and flatness. Each WayPropertySet contains rules for a given set of tag matchers that influence the bicycle safety score. For example, a rule looks like this: props . setProperties ( \"highway=track\" , StreetTraversalPermission . ALL , 1.3 , 1.3 ); This means that an OSM way with the tag highway=track is traversable by all modes (pedestrian, bicycle, car) and that its bicycle safety score when you traverse in order of the way is 1.3 and also 1.3 when going the other way (smaller means more cycle-friendly). If there is a more specific matcher like highway=track;bicycle=no and it matches a given OSM way, it is chosen instead and its settings applied. The score can be any positive number but the range (as of writing this) goes from 0.6 for bike lanes to 100 for ways that consist of sand. To figure out a good value for your set of tags you should read the bicycle safety report (see below) or the source code of your WayPropertySetSource to get a feeling for how much certain tags are penalised or rewarded. There are also so-called mixins. These are applied on top of the most specific matchers and a single OSM way can match many mixins. The mixins' safety values are multiplied with the value of the base (non-mixin) match. A mixin looks like this (note the true at the end): props . setProperties ( \"surface=mud\" , StreetTraversalPermission . ALL , 1.5 , 1.5 , true ); The Javadoc of OSMSpecifier.java contains the precise documentation about the syntax of the matchers. There are a lot of rules for which tags results in a specific safety score so it's not easy to get an overview. There is however an OTP feature to get an HTML viewer with a search feature that lets you browse through the rules. To enable it activate the Report API sandbox feature . To view the output of the bicycle safety calculation on a map, check the debug layers . Railway Platforms OTP users in Helsinki have documented their best practices for coding railway platforms in OpenStreetMap. These guidelines are available in the OSM Wiki. Debug logging OTP use logback and slj4j as a logging framework. Logging is configured in the logback.xml file inside the OTP jar file. See these frameworks for more documentation on log configuration. For developers, starting OTP using the InteractiveOtpMain is an easy way to configure debug logging. Some useful loggers - TRANSFERS_EXPORT Dump transfers to transfers-debug.csv file. - DATA_IMPORT_ISSUES Write issues to debug lag as well as to the issue report. - REQ_LOG Router request log. Enable with requestLogFile config parameter in build config. - org.opentripplanner.transit.raptor.RaptorService Debug Raptor request and response Transit search The Raptor implementation support instrumentation of ACCEPT, REJECT, and DROP events for stop-arrivals and trip boardings. Use the SpeedTest to pass in a set of stops and/or a specific path to debug. This is useful when debugging why you do (not) get a particular result. GTFS Transfers.txt and NeTEx Interchange import Transfers may have effects on the routing which may be difficult to predict. OTP can dump all imported transfers to file - transfers-debug.csv . This may help verify the result of the import or find special test cases. To turn on the export enable the slf4j logger: <logger name=\"TRANSFERS_EXPORT\" level=\"info\" /> Further information General information Bicycle routing Indoor mapping Elevators","title":"Troubleshooting"},{"location":"Troubleshooting-Routing/#troubleshooting-routing","text":"","title":"Troubleshooting Routing"},{"location":"Troubleshooting-Routing/#graph-builder-data-import-issues","text":"When you build a graph, OTP may encounter clearly incorrect or ambiguous data, or may detect less severe, but potentially problematic situations in the input data. Such problems should result in a \"Data Import Issue\" being generated. These issues are logged the the DATA_IMPORT_ISSUES console logger, depending on your need you might turn this logger on/off. At the end of the graph build process, OTP prints a summary of all the issues, like the following: 11:35:57.515 INFO (Graph.java:970) Summary (number of each type of issues): 11:35:57.518 INFO (Graph.java:976) TurnRestrictionBad - 560 11:35:57.518 INFO (Graph.java:976) TurnRestrictionException - 15 11:35:57.518 INFO (Graph.java:976) StopLinkedTooFar - 22 11:35:57.518 INFO (Graph.java:976) HopSpeedSlow - 22 11:35:57.518 INFO (Graph.java:976) Graphwide - 1 11:35:57.518 INFO (Graph.java:976) GraphConnectivity - 407 11:35:57.519 INFO (Graph.java:976) ParkAndRideUnlinked - 1 11:35:57.519 INFO (Graph.java:976) StopNotLinkedForTransfers - 31 11:35:57.519 INFO (Graph.java:976) NoFutureDates - 1 The full set of issues can be written out to an HTML report for closer inspection. To enable the creation of these (potentially voluminous) HTML reports, add \"dataImportReport\" : true to your graph builder JSON configuration. If the graph is saved to a file, these issues are saved with it and can be examined later. Currently the only tool for doing this is the \"Graph Visualizer\", which is not particularly well maintained and is intended for use by software developers familiar with OTP who can patch up the code as needed.","title":"Graph Builder Data Import Issues"},{"location":"Troubleshooting-Routing/#debug-layers","text":"OpenTripplanner has option to ease debugging problems with graph. Older option is graph visualizer. Which you can enable with --visualize parameter instead of --server when starting OTP. There you can see whole graph. You can click on edges and vertices and see the metadata. It is useful to see if street has expected options. And if connections are where they are expected. It can be hard to use on large graphs since, whole graph is displayed at once. And it can be hard to search for specific streets since only street graph is shown without the rest of information. Another option is to use debug layers, which shows extra layers on top of the normal debug UI map . If you want to see them you need to open the map layer selector on the top left hand side and choose the requested layer. Currently you can choose between: Wheelchair access (which colors street edges red if they don't allow wheelchair or green otherwise) Bicycle safety (colors street edges based on how good are for cycling [smaller is better]) Traversal permissions (colors street edges based on what types of transit modes are allowed to travel on them (Pedestrian, cycling, car are currently supported)) Traversal permissions layer also draws links from transit stops/vehicle rentals and P+R to graph. And also draws transit stops, vehicle rentals and P+R vertices with different color. No thru traffic - streets are colored if the edge has thru traffic restrictions (car and bicycle = red , car only = orange , bicycle only = blue , and no-restriction = light gray )","title":"Debug layers"},{"location":"Troubleshooting-Routing/#interpretation-traversal-permissions-layer","text":"A sample traversal permissions layer looks like the following Yellow lines is the link between a stop and the street graph. Grey lines are streets one can travel with the mode walk, bike, or car Green lines are paths one can travel with the mode walk only Red lines are streets one can travel with the mode car only Grey dots vertices where edges are connected. If two edges are crossing w/o a vertice at the intersection point, users will not be able to go from one street to the other. But this can be valid in case of over/under pass for example. If it's an error, it's usually caused by improperly connected OSM data (a shared OSM node is required).","title":"Interpretation Traversal permissions layer"},{"location":"Troubleshooting-Routing/#openstreetmap-data","text":"","title":"OpenStreetMap Data"},{"location":"Troubleshooting-Routing/#tags-affecting-permissions-and-bicycle-safety","text":"OTP has a very flexible system for deciding when a street is to be allowed by pedestrians, bicycles or cars. To configure the which settings to use for your location, please use the osmWayPropertySet config attribute . In the following section we will discuss the default case, which will be used if the property is not set.","title":"Tags affecting permissions and bicycle safety"},{"location":"Troubleshooting-Routing/#default-settings","text":"Access tags (such as bicycle/foot = yes/no/designated) can be used to override default graph-building parameters. As a default, foot and bicycle traffic is ''not'' allowed on highway=trunk , highway=trunk_link , highway=motorway , highway=motorway_link , or highway=construction . Both are allowed on highway=pedestrian , highway=cycleway , and highway=footway . Finally, bicycles are not allowed on highway=footway when any of the following tags appear on a footway: footway=sidewalk , public_transport=platform , or railway=platform . Other access tags (such as access=no and access=private affect routing as well, and can be overridden similarly. While access=no prohibits all traffic, access=private disallows through traffic.","title":"Default settings"},{"location":"Troubleshooting-Routing/#bicycle-safety-factor","text":"Bicycle routing is even more configurable than the other traverse modes: during graph build a so-called bicycle safety score is computed for each street. You can think of this score as a penalty for traversing this way so the lower the score the better. For example if a way is tagged with surface=sand it receives a safety score of 100 which means that it's 100 times worse to cycle on when compared to a way which has a safety score of 1. How this is calculated depends on two things the incline of the way (not read from OSM but from the separately configured elevation data ) its OSM tags At request time you can then use the triangleFactors to decide how important bicycle safety is compared to shorter distances and flatness. Each WayPropertySet contains rules for a given set of tag matchers that influence the bicycle safety score. For example, a rule looks like this: props . setProperties ( \"highway=track\" , StreetTraversalPermission . ALL , 1.3 , 1.3 ); This means that an OSM way with the tag highway=track is traversable by all modes (pedestrian, bicycle, car) and that its bicycle safety score when you traverse in order of the way is 1.3 and also 1.3 when going the other way (smaller means more cycle-friendly). If there is a more specific matcher like highway=track;bicycle=no and it matches a given OSM way, it is chosen instead and its settings applied. The score can be any positive number but the range (as of writing this) goes from 0.6 for bike lanes to 100 for ways that consist of sand. To figure out a good value for your set of tags you should read the bicycle safety report (see below) or the source code of your WayPropertySetSource to get a feeling for how much certain tags are penalised or rewarded. There are also so-called mixins. These are applied on top of the most specific matchers and a single OSM way can match many mixins. The mixins' safety values are multiplied with the value of the base (non-mixin) match. A mixin looks like this (note the true at the end): props . setProperties ( \"surface=mud\" , StreetTraversalPermission . ALL , 1.5 , 1.5 , true ); The Javadoc of OSMSpecifier.java contains the precise documentation about the syntax of the matchers. There are a lot of rules for which tags results in a specific safety score so it's not easy to get an overview. There is however an OTP feature to get an HTML viewer with a search feature that lets you browse through the rules. To enable it activate the Report API sandbox feature . To view the output of the bicycle safety calculation on a map, check the debug layers .","title":"Bicycle safety factor"},{"location":"Troubleshooting-Routing/#railway-platforms","text":"OTP users in Helsinki have documented their best practices for coding railway platforms in OpenStreetMap. These guidelines are available in the OSM Wiki.","title":"Railway Platforms"},{"location":"Troubleshooting-Routing/#debug-logging","text":"OTP use logback and slj4j as a logging framework. Logging is configured in the logback.xml file inside the OTP jar file. See these frameworks for more documentation on log configuration. For developers, starting OTP using the InteractiveOtpMain is an easy way to configure debug logging. Some useful loggers - TRANSFERS_EXPORT Dump transfers to transfers-debug.csv file. - DATA_IMPORT_ISSUES Write issues to debug lag as well as to the issue report. - REQ_LOG Router request log. Enable with requestLogFile config parameter in build config. - org.opentripplanner.transit.raptor.RaptorService Debug Raptor request and response","title":"Debug logging"},{"location":"Troubleshooting-Routing/#transit-search","text":"The Raptor implementation support instrumentation of ACCEPT, REJECT, and DROP events for stop-arrivals and trip boardings. Use the SpeedTest to pass in a set of stops and/or a specific path to debug. This is useful when debugging why you do (not) get a particular result.","title":"Transit search"},{"location":"Troubleshooting-Routing/#gtfs-transferstxt-and-netex-interchange-import","text":"Transfers may have effects on the routing which may be difficult to predict. OTP can dump all imported transfers to file - transfers-debug.csv . This may help verify the result of the import or find special test cases. To turn on the export enable the slf4j logger: <logger name=\"TRANSFERS_EXPORT\" level=\"info\" />","title":"GTFS Transfers.txt and NeTEx Interchange import"},{"location":"Troubleshooting-Routing/#further-information","text":"General information Bicycle routing Indoor mapping Elevators","title":"Further information"},{"location":"Version-Comparison/","text":"Comparing OTP2 and OTP1 Summary OpenTripPlanner has been under development since 2009, leading up to a 1.0 release in 2016. Research and development on higher performance routing has been ongoing since 2013-2014, and work on the second major release referred to as OTP2 officially began in 2018. As of Q3 2020, a release candidate of OTP2 is available and in limited production use. This page explains key differences between the two versions (referred to as OTP1 and OTP2) to help you decide which one to use. OTP1 has existed for over a decade and is in widespread use. It aims to do many things for many people: it provides passenger-facing itinerary services over APIs, but also serves as a network analysis toolkit for urban planning and research. Though OTP1 is widely used and gets the job done, its transit routing approach is obsolete. We have long recognized that more resource-efficient approaches were possible. Reasonable response times and scaling to larger data sets have been achieved through a series of complex incremental interventions that became difficult to maintain. OTP1 has also accumulated large amounts of experimental code and specialized tools, which can be useful in a research or consulting setting but complicate long-term maintenance. OTP2 is brand new and still in testing, though based on code and ideas in heavy use for over five years. It offers much better performance in larger transportation networks and geographic areas, and a wider variety of alternative itineraries. OTP2's public transit routing component has been completely rewritten, and is now distinct from bike, walk, and motor vehicle routing. Non-transit routing remains identical to OTP1, benefiting from years of adaptations to nuances of OpenStreetMap data and end-user walking and biking preferences. Unlike OTP1, OTP2 is completely focused on passenger-facing itinerary services. The innovations in OTP2 have already been applied to planning, research, and analysis work for several years through Conveyal's R5 project, which informed and inspired the OTP2 transit routing system. OTP2 will not supersede OTP1 immediately for all use cases. In some situations there are legitimate reasons to continue using OTP1, or even for new OpenTripPlanner users to adopt OTP1 instead of OTP2. As development work continues over 2021 and additional 2.x releases are made, we expect this gap to close and OTP2 (in combination with other projects) may eventually fully replace OTP1, but this process is expected to take a few years. OTP2 Use Cases The benefits of OTP2 will be most evident in large or dense networks spanning multiple cities: entire countries (Netherlands, Switzerland, Norway), US states, metropolitan regions and cross-border conurbations (e.g. NYC metro area). Although the scale of trip planners is sometimes limited by the geographic extent of administrative structures (national rail or bus operators or ticketing agencies), OTP2 should be capable of handling even larger networks, and we do for example regularly test on a unified Nordic trip planner in hopes that such systems will materialize over time as more territories adopt OTP. OTP2 development has been driven by adoption of open source routing software in Northern Europe. Importantly for deployments in Europe, OTP2 introduces support for EU-standard Netex and SIRI data sources in addition to GTFS. The Nordic profile of Netex understood by OTP2 uses the same schema as the EU profile, and generalization to the EU profile should be feasible once it is standardized. Choosing between OTP1 and OTP2 Much development effort has gone into OTP2, and most OTP development effort will continue to focus on OTP2 after its release. OTP2 is much more efficient than OTP1 for certain common use cases, providing faster responses for a larger number of simultaneous users over larger geographic areas and more complex transportation networks. However, this does not mean that all users of OpenTripPlanner should switch to OTP2, or that all new users will want to start with OTP2. As of fall 2020, OTP1 remains much more widely used than OTP2, and most importantly OTP2 has a smaller feature set than OTP1. That is to say, OTP2 can do less things than OTP1, but it does them much more efficiently and tries to cover the most common use cases for large-scale OTP deployments. When in doubt, new users are advised to try out OTP2 and switch to OTP1 if they need features that are not available in OTP2. If some feature you need is missing from OTP2, you can also create a new issue or comment on an existing one on GitHub, letting us know why it is important to you. New features can be added to the OTP2 if there is sufficient demand and development resources to maintain them. High-level feature comparison Feature OTP1 OTP2 OSM street data yes yes GTFS transit data yes yes Netex transit data no yes (Nordic profile) GTFS-Realtime yes (streaming, polling, incremental) yes (streaming, polling, incremental) SIRI Realtime no yes Elevation data TIFF and NED TIFF and NED One-to-many routing, isochrones and scripting yes no Java version 8+ 11+ Multiple regions per server yes no Hot reloading of graphs yes no Street (OSM) routing algorithm Generalized cost A* Generalized cost A* Transit routing algorithm Generalized cost A* Multi-criteria range-RAPTOR Search segmentation Single search through access, transit, egress Access/egress separate from transit search Goal direction Upper bound search backward from destination, over streets and transit, interleaved with forward search Upper bound search backward from destination on transit only, before forward search begins Alternative itineraries \"Trip banning\", N lowest generalized costs True Pareto-optimal results Departure/arrival time Single departure or arrival time only Every minute in a window up to several days long API Paging no yes Timetable View no yes Plugin Sandbox Extensions no yes ( See extensions ) Data storage local, S3 (elevation only) extensible with local, ZIP, and Google Cloud plugins, S3 available Transfer Priority yes yes REST API format XML, JSON JSON only Commentary on OTP1 features removed from OTP2 OTP2 brings significant improvements in speed and scalability, but does not retain all features of OTP1. We have chosen to prioritize long-term maintainability, so only those features that are \"owned\" by a team of professional developers will be carried over to OTP2. Features that have been removed to simplify the code base and improve maintainability may be removed permanently. Other missing features are still priorities for the organization leading OTP2 development (Entur) but have not yet been adapted to the new transit routing system, and will be added in upcoming releases. Some features have been removed to reflect separation of concerns: following principles of modular design they should be handled outside OTP, or are already covered by other projects where they are more actively developed. Analysis Many OpenTripPlanner contributors have been primarily interested in transportation and urban planning use cases. We consider these use cases quite important. This has been a major area of application for OpenTripPlanner and has helped popularize cumulative opportunities accessibility metrics. For example, the University of Minnesota Accessibility Observatory used OpenTripPlanner for Access Across America . Nonetheless, the analysis code in OTP1 is essentially an unmaintained and unsupported early prototype for later projects, specifically Conveyal's R5 (and the Conveyal Analysis system built upon it). OTP1 seems to have gained popularity for analysis uses due to the existence of documentation and an active user community, but has significant technical shortcomings. One of these is simply speed: OTP1 can be orders of magnitude slower (and more memory-intensive) than the approaches exemplified in R5. The other is the requirement to search at a single specific time. Travel times and especially wait times on scheduled transit vary greatly depending on when you depart. Accounting for variation over a time window requires repeated independent searches at each possible departure time, which is very inefficient. R5 is highly optimized to capture variations in travel time across time windows and account for uncertainty in waiting times on frequency-based routes. Due to its similarity to the R5 approach, OTP2's transit router would not have these same problems. Nonetheless, we have decided not to port the OTP1 analysis features over to OTP2 since it would broaden the focus away from passenger information and draw finite attention away from existing projects like R5 and Conveyal Analysis. Accordingly, we have made an effort to clean up and augment OTP1 analysis documentation for researchers who will continue to need it. It should remain possible for people to continue using OTP1 if they prefer. If you would instead like to apply the innovations present in OTP2, we recommend looking into R5 or Conveyal Analysis. Routers API and Hot Reloading Via it's Routers API, OTP1 allows loading data and serving APIs for multiple separate geographic areas. This is functionally equivalent to running more than one OTP server with separate data sets. This system also allows reloading transportation network data when it changes, or even pushing new data over a network connection. These were all adaptations to the very different IT environment that existed earlier in OTP history. These days, containerization and on-demand cloud servers have become ubiquitous, and most users solve these problems in totally different ways - by provisioning and starting up entirely new virtual servers, then switching a load balancer over to those new servers. Because the Routers API is complex and exposes potentially damaging functionality over the network, it has been removed from OTP2 to simplify the code base and make it easier to reason about security. Routing request parameters Less parameters are available on the OTP2 REST API than in OTP1. Often there is no practical loss of functionality, just a different way of expressing things due to the new routing algorithms. A summary of parameters that have been removed and their replacements can be found in the migration guide OTP2-MigrationGuide . OTP Trip planning and Transit index APIs OTP1 have two APIs for trip planning, the REST API and an obsolete GraphQL API(early version of the Digitransit GraphQL API). OTP2 still support the REST API and it is very similar in functionality compared with the OTP1 version. In the future we would like to create a new official OTP API using GraphQL replacing the REST API. We will probably support the REST API for a long time to allow everyone to migrate to the new GraphQL API. Today, OTP2 comes with two Sandbox extension APIs: HSL Legacy GraphQL API - HSL's GraphQL API used by the Digitransit project. Transmodel API - Entur\u00b4s Transmodel API The plan is to merge the two APIs above, clean it up and make it the new official API. The HSL API uses GTFS terminology, while the Entur API is Transmodel(NeTEx) based. Both APIs are similar in semantics/structure and provide the same functionality. The plan is to merge these to APIs into one new official OTP2 API. We will then deprecate the REST API, Transmodel API and the HSL API. The new API will be available in a GTFS and a Transmodel \"translated\" version. Additional characteristics added in OTP2 Sandbox Extensions OTP2's Sandbox system allows for plugins, proprietary extensions, and experimental feature development with less overhead. It forces OTP2 to become more extensible, while reducing process overhead when developing non-core features. Cloud support In OTP1 all data access (config, input data, and graph output) is by direct access to the local filesystem. The only exception is elevation data, which can be loaded from AWS S3 as well. In OTP2, all data access is through an abstraction layer. This can be configured to support individual local files, zip files, and Google Cloud Storage. The new data access treats directories and zip files as \u201cequal\u201d, and this functionality is used to read the contents of GTFS and NeTEx archives. Other data sources can be supported by writing plugins. Entur has written a plugin for AWS S3 which has not been merged. If requested they can provide this code for AWS S3. Library upgrades We have adapted OTP2 to run on Java 11+ and moved to newer versions of some dependencies such as GraphQL and One Bus Away. Bugfixes At least bug issues have been resolved in OTP2. Critical fixes have been backported to OTP1. See https://github.com/issues?q=is%3Aclosed+is%3Aissue+label%3AOTP2+label%3Abug Other features removed from OTP2 AlertPatch GTFS-RT Service Alerts will no longer affect routing (e.g. cancel trips). A GTFS-RT Trip Updates feed should be used for this purpose.","title":"Comparing OTP2 to OTP1"},{"location":"Version-Comparison/#comparing-otp2-and-otp1","text":"","title":"Comparing OTP2 and OTP1"},{"location":"Version-Comparison/#summary","text":"OpenTripPlanner has been under development since 2009, leading up to a 1.0 release in 2016. Research and development on higher performance routing has been ongoing since 2013-2014, and work on the second major release referred to as OTP2 officially began in 2018. As of Q3 2020, a release candidate of OTP2 is available and in limited production use. This page explains key differences between the two versions (referred to as OTP1 and OTP2) to help you decide which one to use. OTP1 has existed for over a decade and is in widespread use. It aims to do many things for many people: it provides passenger-facing itinerary services over APIs, but also serves as a network analysis toolkit for urban planning and research. Though OTP1 is widely used and gets the job done, its transit routing approach is obsolete. We have long recognized that more resource-efficient approaches were possible. Reasonable response times and scaling to larger data sets have been achieved through a series of complex incremental interventions that became difficult to maintain. OTP1 has also accumulated large amounts of experimental code and specialized tools, which can be useful in a research or consulting setting but complicate long-term maintenance. OTP2 is brand new and still in testing, though based on code and ideas in heavy use for over five years. It offers much better performance in larger transportation networks and geographic areas, and a wider variety of alternative itineraries. OTP2's public transit routing component has been completely rewritten, and is now distinct from bike, walk, and motor vehicle routing. Non-transit routing remains identical to OTP1, benefiting from years of adaptations to nuances of OpenStreetMap data and end-user walking and biking preferences. Unlike OTP1, OTP2 is completely focused on passenger-facing itinerary services. The innovations in OTP2 have already been applied to planning, research, and analysis work for several years through Conveyal's R5 project, which informed and inspired the OTP2 transit routing system. OTP2 will not supersede OTP1 immediately for all use cases. In some situations there are legitimate reasons to continue using OTP1, or even for new OpenTripPlanner users to adopt OTP1 instead of OTP2. As development work continues over 2021 and additional 2.x releases are made, we expect this gap to close and OTP2 (in combination with other projects) may eventually fully replace OTP1, but this process is expected to take a few years.","title":"Summary"},{"location":"Version-Comparison/#otp2-use-cases","text":"The benefits of OTP2 will be most evident in large or dense networks spanning multiple cities: entire countries (Netherlands, Switzerland, Norway), US states, metropolitan regions and cross-border conurbations (e.g. NYC metro area). Although the scale of trip planners is sometimes limited by the geographic extent of administrative structures (national rail or bus operators or ticketing agencies), OTP2 should be capable of handling even larger networks, and we do for example regularly test on a unified Nordic trip planner in hopes that such systems will materialize over time as more territories adopt OTP. OTP2 development has been driven by adoption of open source routing software in Northern Europe. Importantly for deployments in Europe, OTP2 introduces support for EU-standard Netex and SIRI data sources in addition to GTFS. The Nordic profile of Netex understood by OTP2 uses the same schema as the EU profile, and generalization to the EU profile should be feasible once it is standardized.","title":"OTP2 Use Cases"},{"location":"Version-Comparison/#choosing-between-otp1-and-otp2","text":"Much development effort has gone into OTP2, and most OTP development effort will continue to focus on OTP2 after its release. OTP2 is much more efficient than OTP1 for certain common use cases, providing faster responses for a larger number of simultaneous users over larger geographic areas and more complex transportation networks. However, this does not mean that all users of OpenTripPlanner should switch to OTP2, or that all new users will want to start with OTP2. As of fall 2020, OTP1 remains much more widely used than OTP2, and most importantly OTP2 has a smaller feature set than OTP1. That is to say, OTP2 can do less things than OTP1, but it does them much more efficiently and tries to cover the most common use cases for large-scale OTP deployments. When in doubt, new users are advised to try out OTP2 and switch to OTP1 if they need features that are not available in OTP2. If some feature you need is missing from OTP2, you can also create a new issue or comment on an existing one on GitHub, letting us know why it is important to you. New features can be added to the OTP2 if there is sufficient demand and development resources to maintain them.","title":"Choosing between OTP1 and OTP2"},{"location":"Version-Comparison/#high-level-feature-comparison","text":"Feature OTP1 OTP2 OSM street data yes yes GTFS transit data yes yes Netex transit data no yes (Nordic profile) GTFS-Realtime yes (streaming, polling, incremental) yes (streaming, polling, incremental) SIRI Realtime no yes Elevation data TIFF and NED TIFF and NED One-to-many routing, isochrones and scripting yes no Java version 8+ 11+ Multiple regions per server yes no Hot reloading of graphs yes no Street (OSM) routing algorithm Generalized cost A* Generalized cost A* Transit routing algorithm Generalized cost A* Multi-criteria range-RAPTOR Search segmentation Single search through access, transit, egress Access/egress separate from transit search Goal direction Upper bound search backward from destination, over streets and transit, interleaved with forward search Upper bound search backward from destination on transit only, before forward search begins Alternative itineraries \"Trip banning\", N lowest generalized costs True Pareto-optimal results Departure/arrival time Single departure or arrival time only Every minute in a window up to several days long API Paging no yes Timetable View no yes Plugin Sandbox Extensions no yes ( See extensions ) Data storage local, S3 (elevation only) extensible with local, ZIP, and Google Cloud plugins, S3 available Transfer Priority yes yes REST API format XML, JSON JSON only","title":"High-level feature comparison"},{"location":"Version-Comparison/#commentary-on-otp1-features-removed-from-otp2","text":"OTP2 brings significant improvements in speed and scalability, but does not retain all features of OTP1. We have chosen to prioritize long-term maintainability, so only those features that are \"owned\" by a team of professional developers will be carried over to OTP2. Features that have been removed to simplify the code base and improve maintainability may be removed permanently. Other missing features are still priorities for the organization leading OTP2 development (Entur) but have not yet been adapted to the new transit routing system, and will be added in upcoming releases. Some features have been removed to reflect separation of concerns: following principles of modular design they should be handled outside OTP, or are already covered by other projects where they are more actively developed.","title":"Commentary on OTP1 features removed from OTP2"},{"location":"Version-Comparison/#analysis","text":"Many OpenTripPlanner contributors have been primarily interested in transportation and urban planning use cases. We consider these use cases quite important. This has been a major area of application for OpenTripPlanner and has helped popularize cumulative opportunities accessibility metrics. For example, the University of Minnesota Accessibility Observatory used OpenTripPlanner for Access Across America . Nonetheless, the analysis code in OTP1 is essentially an unmaintained and unsupported early prototype for later projects, specifically Conveyal's R5 (and the Conveyal Analysis system built upon it). OTP1 seems to have gained popularity for analysis uses due to the existence of documentation and an active user community, but has significant technical shortcomings. One of these is simply speed: OTP1 can be orders of magnitude slower (and more memory-intensive) than the approaches exemplified in R5. The other is the requirement to search at a single specific time. Travel times and especially wait times on scheduled transit vary greatly depending on when you depart. Accounting for variation over a time window requires repeated independent searches at each possible departure time, which is very inefficient. R5 is highly optimized to capture variations in travel time across time windows and account for uncertainty in waiting times on frequency-based routes. Due to its similarity to the R5 approach, OTP2's transit router would not have these same problems. Nonetheless, we have decided not to port the OTP1 analysis features over to OTP2 since it would broaden the focus away from passenger information and draw finite attention away from existing projects like R5 and Conveyal Analysis. Accordingly, we have made an effort to clean up and augment OTP1 analysis documentation for researchers who will continue to need it. It should remain possible for people to continue using OTP1 if they prefer. If you would instead like to apply the innovations present in OTP2, we recommend looking into R5 or Conveyal Analysis.","title":"Analysis"},{"location":"Version-Comparison/#routers-api-and-hot-reloading","text":"Via it's Routers API, OTP1 allows loading data and serving APIs for multiple separate geographic areas. This is functionally equivalent to running more than one OTP server with separate data sets. This system also allows reloading transportation network data when it changes, or even pushing new data over a network connection. These were all adaptations to the very different IT environment that existed earlier in OTP history. These days, containerization and on-demand cloud servers have become ubiquitous, and most users solve these problems in totally different ways - by provisioning and starting up entirely new virtual servers, then switching a load balancer over to those new servers. Because the Routers API is complex and exposes potentially damaging functionality over the network, it has been removed from OTP2 to simplify the code base and make it easier to reason about security.","title":"Routers API and Hot Reloading"},{"location":"Version-Comparison/#routing-request-parameters","text":"Less parameters are available on the OTP2 REST API than in OTP1. Often there is no practical loss of functionality, just a different way of expressing things due to the new routing algorithms. A summary of parameters that have been removed and their replacements can be found in the migration guide OTP2-MigrationGuide .","title":"Routing request parameters"},{"location":"Version-Comparison/#otp-trip-planning-and-transit-index-apis","text":"OTP1 have two APIs for trip planning, the REST API and an obsolete GraphQL API(early version of the Digitransit GraphQL API). OTP2 still support the REST API and it is very similar in functionality compared with the OTP1 version. In the future we would like to create a new official OTP API using GraphQL replacing the REST API. We will probably support the REST API for a long time to allow everyone to migrate to the new GraphQL API. Today, OTP2 comes with two Sandbox extension APIs: HSL Legacy GraphQL API - HSL's GraphQL API used by the Digitransit project. Transmodel API - Entur\u00b4s Transmodel API The plan is to merge the two APIs above, clean it up and make it the new official API. The HSL API uses GTFS terminology, while the Entur API is Transmodel(NeTEx) based. Both APIs are similar in semantics/structure and provide the same functionality. The plan is to merge these to APIs into one new official OTP2 API. We will then deprecate the REST API, Transmodel API and the HSL API. The new API will be available in a GTFS and a Transmodel \"translated\" version.","title":"OTP Trip planning and Transit index APIs"},{"location":"Version-Comparison/#additional-characteristics-added-in-otp2","text":"Sandbox Extensions OTP2's Sandbox system allows for plugins, proprietary extensions, and experimental feature development with less overhead. It forces OTP2 to become more extensible, while reducing process overhead when developing non-core features. Cloud support In OTP1 all data access (config, input data, and graph output) is by direct access to the local filesystem. The only exception is elevation data, which can be loaded from AWS S3 as well. In OTP2, all data access is through an abstraction layer. This can be configured to support individual local files, zip files, and Google Cloud Storage. The new data access treats directories and zip files as \u201cequal\u201d, and this functionality is used to read the contents of GTFS and NeTEx archives. Other data sources can be supported by writing plugins. Entur has written a plugin for AWS S3 which has not been merged. If requested they can provide this code for AWS S3. Library upgrades We have adapted OTP2 to run on Java 11+ and moved to newer versions of some dependencies such as GraphQL and One Bus Away. Bugfixes At least bug issues have been resolved in OTP2. Critical fixes have been backported to OTP1. See https://github.com/issues?q=is%3Aclosed+is%3Aissue+label%3AOTP2+label%3Abug","title":"Additional characteristics added in OTP2"},{"location":"Version-Comparison/#other-features-removed-from-otp2","text":"AlertPatch GTFS-RT Service Alerts will no longer affect routing (e.g. cancel trips). A GTFS-RT Trip Updates feed should be used for this purpose.","title":"Other features removed from OTP2"},{"location":"Visual-Identity/","text":"OpenTripPlanner Visual Identity This is the OpenTripPlanner logo in scalable vector format, with knockout transparency: Here is a link to this SVG logo as a downloadable file . This is the raw SVG XML source code: <?xml version=\"1.0\" encoding=\"utf-8\"?> <!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"> <svg version=\"1.1\" id=\"Layer_1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" x=\"0px\" y=\"0px\" width=\"512px\" height=\"512px\" viewBox=\"0 0 125.333 125.334\" xml:space=\"preserve\"> <path fill=\"#2179BF\" d=\"M62.668,0C33.83,0,9.559,19.483,2.258,46l72.681-0.003c4.729-0.011,8.555-3.837,8.561-8.568 c-0.006-4.729-3.831-8.555-8.561-8.559c-4.731,0.004-8.557,3.83-8.564,8.559v4.592h-13.7v-4.592 c0-12.294,9.962-22.261,22.265-22.263c12.298,0.002,22.262,9.969,22.266,22.263c-0.003,12.3-9.968,22.264-22.266,22.271H0.074 C0.028,60.684,0,61.671,0,62.666c0,34.611,28.057,62.668,62.668,62.668c34.609,0,62.665-28.057,62.665-62.668 C125.333,28.057,97.277,0,62.668,0 M92.222,85.667v-3.473v-4.86l-47.058,0.003c-4.729,0.011-8.556,3.837-8.561,8.568 c0.005,4.728,3.831,8.555,8.561,8.559c4.731-0.004,8.558-3.831,8.565-8.559v-4.592h13.699v4.592 c0,12.294-9.961,22.261-22.265,22.263c-12.298-0.002-22.26-9.969-22.264-22.263c0.002-12.3,9.966-22.264,22.264-22.271h47.058V56.12 l21.712,14.775L92.222,85.667z\"/> </svg> This concept behind this logo design was \"infinite roads\". Besides the clear references to movement and wayfinding through a transportation network, it (somewhat subliminally) contains the letters O T and P. This design is more geometric and austere than our previous logo, which makes it readily recognizable in a crowd of small app icons, bookmarks, or favicons. It also channels the high modern logos and 1970s supergraphics that were the visual style of public transport for a generation. The color of the logo in the RGB colorspace is #2179BF . The name of the OpenTripPlanner project is written in CamelCase: capital letters at the beginning of each word, with no spaces between the words. For the logotype we do not strictly adhere to a standard typeface. The OTP website just uses the CSS declarations font: 30pt helvetica, sans-serif; font-weight: bold; . The OpenTripPlanner logo was created by Brooklyn-based cartographer and graphic designer Kate Chanba , who has also done extensive work on transit system maps.","title":"Visual Identity"},{"location":"Visual-Identity/#opentripplanner-visual-identity","text":"This is the OpenTripPlanner logo in scalable vector format, with knockout transparency: Here is a link to this SVG logo as a downloadable file . This is the raw SVG XML source code: <?xml version=\"1.0\" encoding=\"utf-8\"?> <!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"> <svg version=\"1.1\" id=\"Layer_1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" x=\"0px\" y=\"0px\" width=\"512px\" height=\"512px\" viewBox=\"0 0 125.333 125.334\" xml:space=\"preserve\"> <path fill=\"#2179BF\" d=\"M62.668,0C33.83,0,9.559,19.483,2.258,46l72.681-0.003c4.729-0.011,8.555-3.837,8.561-8.568 c-0.006-4.729-3.831-8.555-8.561-8.559c-4.731,0.004-8.557,3.83-8.564,8.559v4.592h-13.7v-4.592 c0-12.294,9.962-22.261,22.265-22.263c12.298,0.002,22.262,9.969,22.266,22.263c-0.003,12.3-9.968,22.264-22.266,22.271H0.074 C0.028,60.684,0,61.671,0,62.666c0,34.611,28.057,62.668,62.668,62.668c34.609,0,62.665-28.057,62.665-62.668 C125.333,28.057,97.277,0,62.668,0 M92.222,85.667v-3.473v-4.86l-47.058,0.003c-4.729,0.011-8.556,3.837-8.561,8.568 c0.005,4.728,3.831,8.555,8.561,8.559c4.731-0.004,8.558-3.831,8.565-8.559v-4.592h13.699v4.592 c0,12.294-9.961,22.261-22.265,22.263c-12.298-0.002-22.26-9.969-22.264-22.263c0.002-12.3,9.966-22.264,22.264-22.271h47.058V56.12 l21.712,14.775L92.222,85.667z\"/> </svg> This concept behind this logo design was \"infinite roads\". Besides the clear references to movement and wayfinding through a transportation network, it (somewhat subliminally) contains the letters O T and P. This design is more geometric and austere than our previous logo, which makes it readily recognizable in a crowd of small app icons, bookmarks, or favicons. It also channels the high modern logos and 1970s supergraphics that were the visual style of public transport for a generation. The color of the logo in the RGB colorspace is #2179BF . The name of the OpenTripPlanner project is written in CamelCase: capital letters at the beginning of each word, with no spaces between the words. For the logotype we do not strictly adhere to a standard typeface. The OTP website just uses the CSS declarations font: 30pt helvetica, sans-serif; font-weight: bold; . The OpenTripPlanner logo was created by Brooklyn-based cartographer and graphic designer Kate Chanba , who has also done extensive work on transit system maps.","title":"OpenTripPlanner Visual Identity"},{"location":"examples/Readme/","text":"Example configurations When setting up OTP it is often useful to have some examples to look at. If you have an example to share just add it here. Examples Name Organisation Description entur Entur, Norway Deployment Configuration with NeTEX input data Support The examples are provided \"as is\" - they may get outdated over time or miss information, and it is left to the provider, not the PLC, to include whatever the provider find useful. How to share an example Anyone who want can add their example here as long as it is OTP \"related\". Just create a normal pull-request to add it.","title":"Example configurations"},{"location":"examples/Readme/#example-configurations","text":"When setting up OTP it is often useful to have some examples to look at. If you have an example to share just add it here.","title":"Example configurations"},{"location":"examples/Readme/#examples","text":"Name Organisation Description entur Entur, Norway Deployment Configuration with NeTEX input data","title":"Examples"},{"location":"examples/Readme/#support","text":"The examples are provided \"as is\" - they may get outdated over time or miss information, and it is left to the provider, not the PLC, to include whatever the provider find useful.","title":"Support"},{"location":"examples/Readme/#how-to-share-an-example","text":"Anyone who want can add their example here as long as it is OTP \"related\". Just create a normal pull-request to add it.","title":"How to share an example"},{"location":"examples/entur/Readme/","text":"Entur Deployment Configuration This is a snapshot of Enturs deployment configuration. At Entur we run OTP in the cloud, so some of the provided config will not work outside Enturs cluster, but it is provided \"as is\" for others to replicate if they want. Config files See the config files provided. The updaters section of the router-config.json is provided, but is not working. Remove it if you want to run OTP. It is provided for others as an example on how to configure the SIRI updaters. The same goes for the storage section in the build-config.json , remove it run OTP locally. The <host> , <OperatorNameSpace> and <bucket> are placeholders you need to change. Data input files At Entur we run OTP with the latest NeTEx data we have. You may download it from here: https://developer.entur.org/stops-and-timetable-data We use the Entire Norway file. In the past the file did not contain the stops, so they needed to be downloaded separably (Entire Norway (Current stops) - Latest valid version of all country stops) and inserted into the Netex-file. Unpack the stops zipfile, rename the stops file to _stops.xml . Unpack the netex file and move the _stops.xml into the netex directory. Copy the netex directory and config files into the same directory and start OTP with it as the base directory. We also build with elevation data, which is not available on the internet without transformation. Send us a request, and we will find a way to share it. We download the OSM data file norway-latest.osm.pbf every night and build a street-graph with OSM and elevation data. We also use some custom OSM files for areas outside Norway, but they in most cases insignificant. If requested, we can provide them.","title":"Entur Deployment Configuration"},{"location":"examples/entur/Readme/#entur-deployment-configuration","text":"This is a snapshot of Enturs deployment configuration. At Entur we run OTP in the cloud, so some of the provided config will not work outside Enturs cluster, but it is provided \"as is\" for others to replicate if they want.","title":"Entur Deployment Configuration"},{"location":"examples/entur/Readme/#config-files","text":"See the config files provided. The updaters section of the router-config.json is provided, but is not working. Remove it if you want to run OTP. It is provided for others as an example on how to configure the SIRI updaters. The same goes for the storage section in the build-config.json , remove it run OTP locally. The <host> , <OperatorNameSpace> and <bucket> are placeholders you need to change.","title":"Config files"},{"location":"examples/entur/Readme/#data-input-files","text":"At Entur we run OTP with the latest NeTEx data we have. You may download it from here: https://developer.entur.org/stops-and-timetable-data We use the Entire Norway file. In the past the file did not contain the stops, so they needed to be downloaded separably (Entire Norway (Current stops) - Latest valid version of all country stops) and inserted into the Netex-file. Unpack the stops zipfile, rename the stops file to _stops.xml . Unpack the netex file and move the _stops.xml into the netex directory. Copy the netex directory and config files into the same directory and start OTP with it as the base directory. We also build with elevation data, which is not available on the internet without transformation. Send us a request, and we will find a way to share it. We download the OSM data file norway-latest.osm.pbf every night and build a street-graph with OSM and elevation data. We also use some custom OSM files for areas outside Norway, but they in most cases insignificant. If requested, we can provide them.","title":"Data input files"},{"location":"sandbox/ActuatorAPI/","text":"Actuator API Contact Info Entur, Norway Changelog Initial implementation of readiness endpoint (November 2019) Prometheus metrics added using Micrometer (October 2021) GraphQL metrics added to prometheus export (November 2021) Documentation This provides endpoints for checking the health status of the OTP instance. It can be useful when running OTP in a container. The API will be at the endpoint http://localhost:8080/otp/actuators and follows the Spring Boot actuator API standard. Endpoints /health The health endpoints returns an 200 OK status code once the graph is loaded and all updaters are ready. Otherwise, a 404 NOT FOUND is returned. /prometheus Prometheus metrics are returned using Micrometer. The default JVM and jersey metrics are enabled. Also, GraphQL timing metrics are exported under graphql.timer.query and graphql.timer.resolver , if the GraphQL endpoints are enabled. Configuration To enable this you need to add the feature ActuatorAPI .","title":"Actuator API"},{"location":"sandbox/ActuatorAPI/#actuator-api","text":"","title":"Actuator API"},{"location":"sandbox/ActuatorAPI/#contact-info","text":"Entur, Norway","title":"Contact Info"},{"location":"sandbox/ActuatorAPI/#changelog","text":"Initial implementation of readiness endpoint (November 2019) Prometheus metrics added using Micrometer (October 2021) GraphQL metrics added to prometheus export (November 2021)","title":"Changelog"},{"location":"sandbox/ActuatorAPI/#documentation","text":"This provides endpoints for checking the health status of the OTP instance. It can be useful when running OTP in a container. The API will be at the endpoint http://localhost:8080/otp/actuators and follows the Spring Boot actuator API standard.","title":"Documentation"},{"location":"sandbox/ActuatorAPI/#endpoints","text":"","title":"Endpoints"},{"location":"sandbox/ActuatorAPI/#health","text":"The health endpoints returns an 200 OK status code once the graph is loaded and all updaters are ready. Otherwise, a 404 NOT FOUND is returned.","title":"/health"},{"location":"sandbox/ActuatorAPI/#prometheus","text":"Prometheus metrics are returned using Micrometer. The default JVM and jersey metrics are enabled. Also, GraphQL timing metrics are exported under graphql.timer.query and graphql.timer.resolver , if the GraphQL endpoints are enabled.","title":"/prometheus"},{"location":"sandbox/ActuatorAPI/#configuration","text":"To enable this you need to add the feature ActuatorAPI .","title":"Configuration"},{"location":"sandbox/DataOverlay/","text":"Data Overlay Use grid data in NetCDF format to populate the graph. Also provides custom route endpoint parameters for the data \"penalty\" and \"threshold\". This allows route planning to be based on the custom data calculated penalties. Data examples: air quality, environmental, and other data types that are tied to certain geographical locations. Contact Info Developed and maintained by Metatavu OY , Finland. Developers: Katja Danilova - katja.danilova@metatavu.fi\\ Simeon Platonov - simeon.platonov@metatavu.fi\\ Daniil Smirnov - daniil.smirnov@metatavu.fi In case of any questions please contact any of the people above by emails. We would like to continue developing and improving this feature and would love to hear any ideas from the community. Company email: info@metatavu.fi Changelog Initial version (December 2021) Documentation We have been working with OTP since version 1 mainly for producing the Air Quality affected routing for the city of Helsinki, Finland. That project required us to modify the original OTP quite a lot so we didn't propose our efforts for the community. With the OTP2 release we decided to create a dedicated layer on top of OTP2 which not only leaves the initial structure of the OpenTripPlanner intact, but also brings some additional features for those, who actually need them. This layer's main feature is populating the graph with a grid data (i.e air quality, temperature, humidity, pressure, wind speed and direction, and e.t.c). For this to work two files are required: the actual data file (i.e in NetCDF format) and a .json settings file which describes the contents of the data file. Please refer to the diagram for more information. It is a sandbox feature. Please see the configuration part for setup instructions and examples. Configuration Enable the feature by including it to the otp-config.json : // otp-config.json { \"otpFeatures\" : { \"DataOverlay\" : true } } Plugin configuration should explain the NetCDF data file and request parameters that use the data file. * fileName points to the data file * latitudeVariable , longitudeVariable and timeVariable should be equal to the corresponding variable names of the data file * timeFormat options: MS_EPOCH, SECONDS, HOURS * indexVariables contain a list of variables of data file that will affect the routing. * name can have any value and exists to act as a reference for requestPatameters (see below) * displayName is a variable name in human-readable form that should make it more understandable * variable is the actual name of the variable from data file * requestParameters contains the list of REST request parameters that affects the cost calculation. * name should be chosen from the list of enums: org.opentripplanner.ext.dataoverlay.api.ParameterName * variable should correspond to the name of one of the entries from indexVariables list and explain which data field this parameter corresponds to * formula should use the keywords VALUE and THRESHOLD and describe the way the penalty is calculated. Note: if the result of the formula is negative it is ignored. Example of build-config.json that includes the dataOverlay plugin configuration: // build-config.json { \"dataOverlay\" : { \"fileName\" : \"graphs/data-file.nc4\" , \"latitudeVariable\" : \"lat\" , \"longitudeVariable\" : \"lon\" , \"timeVariable\" : \"time\" , \"timeFormat\" : \"HOURS\" , \"indexVariables\" : [ { \"name\" : \"harmfulMicroparticlesPM2_5\" , \"displayName\" : \"Harmful micro particles pm 2.5\" , \"variable\" : \"cnc_PM2_5\" }, { \"name\" : \"harmfulMicroparticlesPM10\" , \"displayName\" : \"Harmful micro particles pm 10\" , \"variable\" : \"cnc_PM10\" } ], \"requestParameters\" : [ { \"name\" : \"PARTICULATE_MATTER_2_5\" , \"variable\" : \"harmfulMicroparticlesPM2_5\" , \"formula\" : \"(VALUE + 1 - THRESHOLD) * PENALTY\" }, { \"name\" : \"PARTICULATE_MATTER_10\" , \"variable\" : \"harmfulMicroparticlesPM10\" , \"formula\" : \"(VALUE + 1 - THRESHOLD) * PENALTY\" } ] } } Default values for Data overlay plugin can also be included in router-config instead of being sent with each request. If any Data overlay parameters are passed in user query, all the default values from router-config are ignored. // router-config.json { \"routingDefaults\" : { \"dataOverlay\" : { \"particulate_matter_10_threshold\" : 100 , \"particulate_matter_10_penalty\" : 19 } } }","title":"Data Overlay"},{"location":"sandbox/DataOverlay/#data-overlay","text":"Use grid data in NetCDF format to populate the graph. Also provides custom route endpoint parameters for the data \"penalty\" and \"threshold\". This allows route planning to be based on the custom data calculated penalties. Data examples: air quality, environmental, and other data types that are tied to certain geographical locations.","title":"Data Overlay"},{"location":"sandbox/DataOverlay/#contact-info","text":"Developed and maintained by Metatavu OY , Finland. Developers: Katja Danilova - katja.danilova@metatavu.fi\\ Simeon Platonov - simeon.platonov@metatavu.fi\\ Daniil Smirnov - daniil.smirnov@metatavu.fi In case of any questions please contact any of the people above by emails. We would like to continue developing and improving this feature and would love to hear any ideas from the community. Company email: info@metatavu.fi","title":"Contact Info"},{"location":"sandbox/DataOverlay/#changelog","text":"Initial version (December 2021)","title":"Changelog"},{"location":"sandbox/DataOverlay/#documentation","text":"We have been working with OTP since version 1 mainly for producing the Air Quality affected routing for the city of Helsinki, Finland. That project required us to modify the original OTP quite a lot so we didn't propose our efforts for the community. With the OTP2 release we decided to create a dedicated layer on top of OTP2 which not only leaves the initial structure of the OpenTripPlanner intact, but also brings some additional features for those, who actually need them. This layer's main feature is populating the graph with a grid data (i.e air quality, temperature, humidity, pressure, wind speed and direction, and e.t.c). For this to work two files are required: the actual data file (i.e in NetCDF format) and a .json settings file which describes the contents of the data file. Please refer to the diagram for more information. It is a sandbox feature. Please see the configuration part for setup instructions and examples.","title":"Documentation"},{"location":"sandbox/DataOverlay/#configuration","text":"Enable the feature by including it to the otp-config.json : // otp-config.json { \"otpFeatures\" : { \"DataOverlay\" : true } } Plugin configuration should explain the NetCDF data file and request parameters that use the data file. * fileName points to the data file * latitudeVariable , longitudeVariable and timeVariable should be equal to the corresponding variable names of the data file * timeFormat options: MS_EPOCH, SECONDS, HOURS * indexVariables contain a list of variables of data file that will affect the routing. * name can have any value and exists to act as a reference for requestPatameters (see below) * displayName is a variable name in human-readable form that should make it more understandable * variable is the actual name of the variable from data file * requestParameters contains the list of REST request parameters that affects the cost calculation. * name should be chosen from the list of enums: org.opentripplanner.ext.dataoverlay.api.ParameterName * variable should correspond to the name of one of the entries from indexVariables list and explain which data field this parameter corresponds to * formula should use the keywords VALUE and THRESHOLD and describe the way the penalty is calculated. Note: if the result of the formula is negative it is ignored. Example of build-config.json that includes the dataOverlay plugin configuration: // build-config.json { \"dataOverlay\" : { \"fileName\" : \"graphs/data-file.nc4\" , \"latitudeVariable\" : \"lat\" , \"longitudeVariable\" : \"lon\" , \"timeVariable\" : \"time\" , \"timeFormat\" : \"HOURS\" , \"indexVariables\" : [ { \"name\" : \"harmfulMicroparticlesPM2_5\" , \"displayName\" : \"Harmful micro particles pm 2.5\" , \"variable\" : \"cnc_PM2_5\" }, { \"name\" : \"harmfulMicroparticlesPM10\" , \"displayName\" : \"Harmful micro particles pm 10\" , \"variable\" : \"cnc_PM10\" } ], \"requestParameters\" : [ { \"name\" : \"PARTICULATE_MATTER_2_5\" , \"variable\" : \"harmfulMicroparticlesPM2_5\" , \"formula\" : \"(VALUE + 1 - THRESHOLD) * PENALTY\" }, { \"name\" : \"PARTICULATE_MATTER_10\" , \"variable\" : \"harmfulMicroparticlesPM10\" , \"formula\" : \"(VALUE + 1 - THRESHOLD) * PENALTY\" } ] } } Default values for Data overlay plugin can also be included in router-config instead of being sent with each request. If any Data overlay parameters are passed in user query, all the default values from router-config are ignored. // router-config.json { \"routingDefaults\" : { \"dataOverlay\" : { \"particulate_matter_10_threshold\" : 100 , \"particulate_matter_10_penalty\" : 19 } } }","title":"Configuration"},{"location":"sandbox/Examples/","text":"Statistics API - OTP Sandbox Extension Example Contact Info Thomas Gran, Entur, Norway Changelog April 2019 (in progress) Initial setup of the first new OTP Sandbox Extension. (April 2019) Added a simple GraphQL API for retrieving Graph statistics. (May 2019) Moved Graph Example Updaters from main code to sandbox examples. (May 2019) Delete the Example Updaters, there are real-life examples in the Sandbox now. (Sep 2020) Documentation Graph Statistics Resource This extension show how to create a web endpoint to get some simple statistics: - Number of stops in the graph","title":"Sandbox Extension Example"},{"location":"sandbox/Examples/#statistics-api-otp-sandbox-extension-example","text":"","title":"Statistics API - OTP Sandbox Extension Example"},{"location":"sandbox/Examples/#contact-info","text":"Thomas Gran, Entur, Norway","title":"Contact Info"},{"location":"sandbox/Examples/#changelog","text":"","title":"Changelog"},{"location":"sandbox/Examples/#april-2019-in-progress","text":"Initial setup of the first new OTP Sandbox Extension. (April 2019) Added a simple GraphQL API for retrieving Graph statistics. (May 2019) Moved Graph Example Updaters from main code to sandbox examples. (May 2019) Delete the Example Updaters, there are real-life examples in the Sandbox now. (Sep 2020)","title":"April 2019 (in progress)"},{"location":"sandbox/Examples/#documentation","text":"","title":"Documentation"},{"location":"sandbox/Examples/#graph-statistics-resource","text":"This extension show how to create a web endpoint to get some simple statistics: - Number of stops in the graph","title":"Graph Statistics Resource"},{"location":"sandbox/Flex/","text":"Flexible transit routing Contact Info Kyyti Group Oy, Finland Entur, Norway Hannes Junnila Changelog OTP 2.1 Initial implementation of Flexible transit routing Use one-to-many search in order to make the performance of the StreetFlexPathCalculator acceptable. (April 2021) Also link transit stops used by flex trips to the closest car traversable edge. This allows flex street routing all the way to the stop. (April 2021) Fix performance issues with the StreetFlexPathCalculator #3460 Improve performance of flex access/egress routing #3661 Allow getting on and off at the same flex stop time #3720 Calculate fare for flex routes #3743 Documentation To enable this turn on FlexRouting as a feature in otp-config.json . The GTFS feeds should conform to the GTFS-Flex v2.1 draft Configuration This features allows a limited number of config options (currently just one). To change the configuration, add the following to router-config.json . { \"flex\": { \"maxTransferDurationSeconds\": 300 } } Config parameters maxTransferDurationSeconds Default: 300 How long should a passenger be allowed to walk after getting out of a flex vehicle and transferring to a flex or transit one. This was mainly introduced to improve performance which is also the reason for not using the existing value with the same name: fixed schedule transfers are computed during the graph build but flex ones are calculated at request time and are more sensitive to slowdown. A lower value means that the routing is faster.","title":"Flex Routing"},{"location":"sandbox/Flex/#flexible-transit-routing","text":"","title":"Flexible transit routing"},{"location":"sandbox/Flex/#contact-info","text":"Kyyti Group Oy, Finland Entur, Norway Hannes Junnila","title":"Contact Info"},{"location":"sandbox/Flex/#changelog","text":"","title":"Changelog"},{"location":"sandbox/Flex/#otp-21","text":"Initial implementation of Flexible transit routing Use one-to-many search in order to make the performance of the StreetFlexPathCalculator acceptable. (April 2021) Also link transit stops used by flex trips to the closest car traversable edge. This allows flex street routing all the way to the stop. (April 2021) Fix performance issues with the StreetFlexPathCalculator #3460 Improve performance of flex access/egress routing #3661 Allow getting on and off at the same flex stop time #3720 Calculate fare for flex routes #3743","title":"OTP 2.1"},{"location":"sandbox/Flex/#documentation","text":"To enable this turn on FlexRouting as a feature in otp-config.json . The GTFS feeds should conform to the GTFS-Flex v2.1 draft","title":"Documentation"},{"location":"sandbox/Flex/#configuration","text":"This features allows a limited number of config options (currently just one). To change the configuration, add the following to router-config.json . { \"flex\": { \"maxTransferDurationSeconds\": 300 } } Config parameters","title":"Configuration"},{"location":"sandbox/Flex/#maxtransferdurationseconds","text":"Default: 300 How long should a passenger be allowed to walk after getting out of a flex vehicle and transferring to a flex or transit one. This was mainly introduced to improve performance which is also the reason for not using the existing value with the same name: fixed schedule transfers are computed during the graph build but flex ones are calculated at request time and are more sensitive to slowdown. A lower value means that the routing is faster.","title":"maxTransferDurationSeconds"},{"location":"sandbox/GoogleCloudStorage/","text":"Google Cloud Storage - Using GCS Bucket as a OTP Data Source Contact Info Thomas Gran, Entur, Norway Changelog OTP 2.0 Initial implementation to access Google Cloud Storage (read and write). (December 2019) Documentation To enable this turn on the feature GoogleCloudStorage . OTP can load or store artifacts from one or more Google Cloud Storge locations. Each artifact must be configured in the build-config.json : See StorageConfig on how to configure artifacts. Example (build-config.json): { : s t orage : { gcsCrede nt ials : \"/Users/alf/secret/otp-test-1234567890.json\" , osm : [ \"gs://otp-test-bucket/a/b/northpole.pbf\" ], dem : [ \"gs://otp-test-bucket/a/b/northpole.dem.tif\" ], g tfs : [ \"gs://otp-test-bucket/a/b/gtfs.zip\" ], graph : \"gs://otp-test-bucket/a/b/graph.obj\" buildRepor t Dir : \"gs://otp-test-bucket/a/b/np-report\" } }","title":"Google Cloud Storage"},{"location":"sandbox/GoogleCloudStorage/#google-cloud-storage-using-gcs-bucket-as-a-otp-data-source","text":"","title":"Google Cloud Storage - Using GCS Bucket as a OTP Data Source"},{"location":"sandbox/GoogleCloudStorage/#contact-info","text":"Thomas Gran, Entur, Norway","title":"Contact Info"},{"location":"sandbox/GoogleCloudStorage/#changelog","text":"","title":"Changelog"},{"location":"sandbox/GoogleCloudStorage/#otp-20","text":"Initial implementation to access Google Cloud Storage (read and write). (December 2019)","title":"OTP 2.0"},{"location":"sandbox/GoogleCloudStorage/#documentation","text":"To enable this turn on the feature GoogleCloudStorage . OTP can load or store artifacts from one or more Google Cloud Storge locations. Each artifact must be configured in the build-config.json : See StorageConfig on how to configure artifacts. Example (build-config.json): { : s t orage : { gcsCrede nt ials : \"/Users/alf/secret/otp-test-1234567890.json\" , osm : [ \"gs://otp-test-bucket/a/b/northpole.pbf\" ], dem : [ \"gs://otp-test-bucket/a/b/northpole.dem.tif\" ], g tfs : [ \"gs://otp-test-bucket/a/b/gtfs.zip\" ], graph : \"gs://otp-test-bucket/a/b/graph.obj\" buildRepor t Dir : \"gs://otp-test-bucket/a/b/np-report\" } }","title":"Documentation"},{"location":"sandbox/InteractiveOtpMain/","text":"Interactive OTP Launcher A GUI popup window to which help you to start OTP Main interactively. Contact Info Thomas Gran, Norway Changelog Initial version (October 2020) Documentation This is a simple GUI to help launch OTP Main. It is useful if you frequently launch OTP with data set and/or configuration. The InteractiveOtpMain search for all OTP data configurations directories available and help the user configure and start OTP.","title":"Interactive OTP Launcher"},{"location":"sandbox/InteractiveOtpMain/#interactive-otp-launcher","text":"A GUI popup window to which help you to start OTP Main interactively.","title":"Interactive OTP Launcher"},{"location":"sandbox/InteractiveOtpMain/#contact-info","text":"Thomas Gran, Norway","title":"Contact Info"},{"location":"sandbox/InteractiveOtpMain/#changelog","text":"Initial version (October 2020)","title":"Changelog"},{"location":"sandbox/InteractiveOtpMain/#documentation","text":"This is a simple GUI to help launch OTP Main. It is useful if you frequently launch OTP with data set and/or configuration. The InteractiveOtpMain search for all OTP data configurations directories available and help the user configure and start OTP.","title":"Documentation"},{"location":"sandbox/LegacyGraphQLApi/","text":"HSL Legacy GraphQL API - OTP Sandbox Extension Contact Info Digitransit team, HSL, Helsinki, Finland Kyyti, Helsinki, Finland Changelog Initial version of Legacy Graph QL API (September 2020) Added ids parameter to bikeRentalStations query (May 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3450) Added capacity and allowOverloading fields to bike rental stations (not yet properly implemented) (May 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3450) Updated documentation and process for generating Java code from GraphQL schema definition (May 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3450) Implemented modeWeight and added debugItineraryFilter to plan query. Added systemNotices to itineraries (May 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3503) Updated to ignore modes which are not valid in OTP2 (June 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3464) Add Leg#walkingBike (June 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3550) Add GBFS bike rental URIs to bike rental stations (June 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3543) Properly implement all bike rental station fields and add allowPickup, allowPickupNow, allowDropoffNow and operative fields (October 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3632) Create RentalVehicle, VehicleRentalStation and VehicleRentalUris types. Deprecate BikeRentalStation and BikeRentalStationUris types (October 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3632) Create VehicleParking type. Deprecate BikePark and CarPark types (November 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3480) Update and implement Alert type and alerts query. Add ACCESSIBILITY_ISSUE to AlertEffectType enum (November 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3747) Add geometries for stops (December 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3757) Add RouteType and Unknown entities and implement alerts fields (add add alerts field to Feed) (December 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3780) Take free-floating vehicles into account when computing state (February 2022, https://github.com/opentripplanner/OpenTripPlanner/pull/3857) Fix issue with GraphQL code generator (February 2022, https://github.com/opentripplanner/OpenTripPlanner/pull/3881) Documentation This is a copy of HSL's GraphQL API used by the Digitransit project. The API is used to run OTP2 together with the digitransit-ui . The GraphQL endpoints are available at: single query: http://localhost:8080/otp/routers/default/index/graphql batch query: http://localhost:8080/otp/routers/default/index/graphql/batch A complete example that fetches the list of all stops from OTP is: curl --request POST \\ --url http://localhost:8080/otp/routers/default/index/graphql \\ --header 'Content-Type: application/json' \\ --header 'OTPTimeout: 180000' \\ --data '{\"query\":\"query stops {\\n stops {\\n gtfsId\\n name\\n }\\n}\\n\",\"operationName\":\"stops\"}' OTP2 Official GraphQL API (Not available) We plan to make a new offical OTP2 API, replacing the REST API. The plan is to base the new API on this API and the Legacy GraphQL Api . The new API will most likely have 2 \"translations\": A GTFS version and a Transmodel version, we will try to keep the semantics the same. Configuration To enable this you need to add the feature SandboxAPILegacyGraphQLApi . // otp-config.json { \"otpFeatures\" : { \"SandboxAPILegacyGraphQLApi\": true } }","title":"HSL Legacy GraphQL API"},{"location":"sandbox/LegacyGraphQLApi/#hsl-legacy-graphql-api-otp-sandbox-extension","text":"","title":"HSL Legacy GraphQL API - OTP Sandbox Extension"},{"location":"sandbox/LegacyGraphQLApi/#contact-info","text":"Digitransit team, HSL, Helsinki, Finland Kyyti, Helsinki, Finland","title":"Contact Info"},{"location":"sandbox/LegacyGraphQLApi/#changelog","text":"Initial version of Legacy Graph QL API (September 2020) Added ids parameter to bikeRentalStations query (May 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3450) Added capacity and allowOverloading fields to bike rental stations (not yet properly implemented) (May 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3450) Updated documentation and process for generating Java code from GraphQL schema definition (May 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3450) Implemented modeWeight and added debugItineraryFilter to plan query. Added systemNotices to itineraries (May 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3503) Updated to ignore modes which are not valid in OTP2 (June 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3464) Add Leg#walkingBike (June 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3550) Add GBFS bike rental URIs to bike rental stations (June 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3543) Properly implement all bike rental station fields and add allowPickup, allowPickupNow, allowDropoffNow and operative fields (October 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3632) Create RentalVehicle, VehicleRentalStation and VehicleRentalUris types. Deprecate BikeRentalStation and BikeRentalStationUris types (October 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3632) Create VehicleParking type. Deprecate BikePark and CarPark types (November 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3480) Update and implement Alert type and alerts query. Add ACCESSIBILITY_ISSUE to AlertEffectType enum (November 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3747) Add geometries for stops (December 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3757) Add RouteType and Unknown entities and implement alerts fields (add add alerts field to Feed) (December 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3780) Take free-floating vehicles into account when computing state (February 2022, https://github.com/opentripplanner/OpenTripPlanner/pull/3857) Fix issue with GraphQL code generator (February 2022, https://github.com/opentripplanner/OpenTripPlanner/pull/3881)","title":"Changelog"},{"location":"sandbox/LegacyGraphQLApi/#documentation","text":"This is a copy of HSL's GraphQL API used by the Digitransit project. The API is used to run OTP2 together with the digitransit-ui . The GraphQL endpoints are available at: single query: http://localhost:8080/otp/routers/default/index/graphql batch query: http://localhost:8080/otp/routers/default/index/graphql/batch A complete example that fetches the list of all stops from OTP is: curl --request POST \\ --url http://localhost:8080/otp/routers/default/index/graphql \\ --header 'Content-Type: application/json' \\ --header 'OTPTimeout: 180000' \\ --data '{\"query\":\"query stops {\\n stops {\\n gtfsId\\n name\\n }\\n}\\n\",\"operationName\":\"stops\"}'","title":"Documentation"},{"location":"sandbox/LegacyGraphQLApi/#otp2-official-graphql-api-not-available","text":"We plan to make a new offical OTP2 API, replacing the REST API. The plan is to base the new API on this API and the Legacy GraphQL Api . The new API will most likely have 2 \"translations\": A GTFS version and a Transmodel version, we will try to keep the semantics the same.","title":"OTP2 Official GraphQL API (Not available)"},{"location":"sandbox/LegacyGraphQLApi/#configuration","text":"To enable this you need to add the feature SandboxAPILegacyGraphQLApi . // otp-config.json { \"otpFeatures\" : { \"SandboxAPILegacyGraphQLApi\": true } }","title":"Configuration"},{"location":"sandbox/MapboxVectorTilesApi/","text":"Mapbox Vector Tiles API Contact Info HSL, Finland Kyyti Group Oy, Finland Hannes Junnila Changelog 2020-07-09: Initial version of Mapbox vector tiles API 2021-05-12: Make expansion factor configurable 2021-09-07: Rename BikeRental to VehicleRental 2021-10-13: Correctly serialize the vehicle rental name #3648 2022-01-03: Add support for VehicleParking entities Documentation This API produces Mapbox vector tiles , which are used by eg. Digitransit-ui to show information about public transit entities on the map. The tiles can be fetched from /otp/routers/{routerId}/vectorTiles/{layers}/{z}/{x}/{y}.pbf , where layers is a comma separated list of layer names from the configuration. Configuration To enable this you need to add the feature SandboxAPIMapboxVectorTilesApi in otp-config.json . The feature must be configured in router-config.json as follows { \"vectorTileLayers\": [ { \"name\": \"stops\", \"type\": \"Stop\", \"mapper\": \"Digitransit\", \"maxZoom\": 20, \"minZoom\": 14, \"cacheMaxSeconds\": 600 }, { \"name\": \"stations\", \"type\": \"Station\", \"mapper\": \"Digitransit\", \"maxZoom\": 20, \"minZoom\": 12, \"cacheMaxSeconds\": 600 }, { \"name\": \"citybikes\", \"type\": \"VehicleRental\", \"mapper\": \"Digitransit\", \"maxZoom\": 20, \"minZoom\": 14, \"cacheMaxSeconds\": 60, \"expansionFactor\": 0.25 }, { \"name\": \"vehicleParking\", \"type\": \"VehicleParking\", \"mapper\": \"Digitransit\", \"maxZoom\": 20, \"minZoom\": 14, \"cacheMaxSeconds\": 60, \"expansionFactor\": 0.25 } ] } For each layer, the configuration includes: name which is used in the url to fetch tiles, and as the layer name in the vector tiles. type which tells the type of the layer. Currently Stop , Station , VehicleRental and VehicleParking are supported. mapper which describes the mapper converting the properties from the OTP model entities to the vector tile properties. Currently Digitransit is supported for all layer types. minZoom and maxZoom which describe the zoom levels the layer is active for. cacheMaxSeconds which sets the cache header in the response. The lowest value of the layers included is selected. expansionFactor How far outside its boundaries should the tile contain information. The value is a fraction of the tile size. If you are having problem with icons and shapes being clipped at tile edges, then increase this number. Extending If more generic layers are created for this API, it should be moved out from the sandbox, into the core code, with potentially leaving specific property mappers in place. Creating a new layer In order to create a new type of layer, you need to create a new class extending LayerBuilder<T> . You need to implement two methods, List<Geometry> getGeometries(Envelope query) , which returns a list of geometries, with an object of type T as their userData in the geometry, and double getExpansionFactor() , which describes how much information outside the tile bounds should be included. This layer then needs to be added into VectorTilesResource.layers , with a new LayerType enum as the key, and the class constructor as the value. A new mapper needs to be added every time a new layer is added. See below for information. Creating a new mapper The mapping contains information of what data to include in the vector tiles. The mappers are defined per layer. In order to create a new mapper for a layer, you need to create a new class extending PropertyMapper<T> . In that class, you need to implement the method Collection<T2<String, Object>> map(T input) . The type T is dependent on the layer for which you implement the mapper for. It needs to return a list of attributes, as key-value pairs which will be written into the vector tile. The mapper needs to be added to the mappers map in the layer, with a new MapperType enum as the key, and a function to create the mapper, with a Graph object as a parameter, as the value.","title":"Mapbox Vector Tiles API"},{"location":"sandbox/MapboxVectorTilesApi/#mapbox-vector-tiles-api","text":"","title":"Mapbox Vector Tiles API"},{"location":"sandbox/MapboxVectorTilesApi/#contact-info","text":"HSL, Finland Kyyti Group Oy, Finland Hannes Junnila","title":"Contact Info"},{"location":"sandbox/MapboxVectorTilesApi/#changelog","text":"2020-07-09: Initial version of Mapbox vector tiles API 2021-05-12: Make expansion factor configurable 2021-09-07: Rename BikeRental to VehicleRental 2021-10-13: Correctly serialize the vehicle rental name #3648 2022-01-03: Add support for VehicleParking entities","title":"Changelog"},{"location":"sandbox/MapboxVectorTilesApi/#documentation","text":"This API produces Mapbox vector tiles , which are used by eg. Digitransit-ui to show information about public transit entities on the map. The tiles can be fetched from /otp/routers/{routerId}/vectorTiles/{layers}/{z}/{x}/{y}.pbf , where layers is a comma separated list of layer names from the configuration.","title":"Documentation"},{"location":"sandbox/MapboxVectorTilesApi/#configuration","text":"To enable this you need to add the feature SandboxAPIMapboxVectorTilesApi in otp-config.json . The feature must be configured in router-config.json as follows { \"vectorTileLayers\": [ { \"name\": \"stops\", \"type\": \"Stop\", \"mapper\": \"Digitransit\", \"maxZoom\": 20, \"minZoom\": 14, \"cacheMaxSeconds\": 600 }, { \"name\": \"stations\", \"type\": \"Station\", \"mapper\": \"Digitransit\", \"maxZoom\": 20, \"minZoom\": 12, \"cacheMaxSeconds\": 600 }, { \"name\": \"citybikes\", \"type\": \"VehicleRental\", \"mapper\": \"Digitransit\", \"maxZoom\": 20, \"minZoom\": 14, \"cacheMaxSeconds\": 60, \"expansionFactor\": 0.25 }, { \"name\": \"vehicleParking\", \"type\": \"VehicleParking\", \"mapper\": \"Digitransit\", \"maxZoom\": 20, \"minZoom\": 14, \"cacheMaxSeconds\": 60, \"expansionFactor\": 0.25 } ] } For each layer, the configuration includes: name which is used in the url to fetch tiles, and as the layer name in the vector tiles. type which tells the type of the layer. Currently Stop , Station , VehicleRental and VehicleParking are supported. mapper which describes the mapper converting the properties from the OTP model entities to the vector tile properties. Currently Digitransit is supported for all layer types. minZoom and maxZoom which describe the zoom levels the layer is active for. cacheMaxSeconds which sets the cache header in the response. The lowest value of the layers included is selected. expansionFactor How far outside its boundaries should the tile contain information. The value is a fraction of the tile size. If you are having problem with icons and shapes being clipped at tile edges, then increase this number.","title":"Configuration"},{"location":"sandbox/MapboxVectorTilesApi/#extending","text":"If more generic layers are created for this API, it should be moved out from the sandbox, into the core code, with potentially leaving specific property mappers in place.","title":"Extending"},{"location":"sandbox/MapboxVectorTilesApi/#creating-a-new-layer","text":"In order to create a new type of layer, you need to create a new class extending LayerBuilder<T> . You need to implement two methods, List<Geometry> getGeometries(Envelope query) , which returns a list of geometries, with an object of type T as their userData in the geometry, and double getExpansionFactor() , which describes how much information outside the tile bounds should be included. This layer then needs to be added into VectorTilesResource.layers , with a new LayerType enum as the key, and the class constructor as the value. A new mapper needs to be added every time a new layer is added. See below for information.","title":"Creating a new layer"},{"location":"sandbox/MapboxVectorTilesApi/#creating-a-new-mapper","text":"The mapping contains information of what data to include in the vector tiles. The mappers are defined per layer. In order to create a new mapper for a layer, you need to create a new class extending PropertyMapper<T> . In that class, you need to implement the method Collection<T2<String, Object>> map(T input) . The type T is dependent on the layer for which you implement the mapper for. It needs to return a list of attributes, as key-value pairs which will be written into the vector tile. The mapper needs to be added to the mappers map in the layer, with a new MapperType enum as the key, and a function to create the mapper, with a Graph object as a parameter, as the value.","title":"Creating a new mapper"},{"location":"sandbox/ParkAndRideApi/","text":"Park and Ride API Contact Info Evan Siroky, IBI Group, USA Changelog Initial version of the Park and Ride API. (February 2021) Documentation This adds a new API endpoint for fetching Park and Rides included in the current graph. It is possible to search using a bounding box and/or proximity of Park and Rides to nearby transit stops.","title":"Park and Ride API"},{"location":"sandbox/ParkAndRideApi/#park-and-ride-api","text":"","title":"Park and Ride API"},{"location":"sandbox/ParkAndRideApi/#contact-info","text":"Evan Siroky, IBI Group, USA","title":"Contact Info"},{"location":"sandbox/ParkAndRideApi/#changelog","text":"Initial version of the Park and Ride API. (February 2021)","title":"Changelog"},{"location":"sandbox/ParkAndRideApi/#documentation","text":"This adds a new API endpoint for fetching Park and Rides included in the current graph. It is possible to search using a bounding box and/or proximity of Park and Rides to nearby transit stops.","title":"Documentation"},{"location":"sandbox/ReportApi/","text":"Report API The report API is a collection of reports generated as CSV files. The main use-case is to download data for manual analyzes and verification. The CSV files should not be used as a service by another programs, the report can be changed at any time - without any notice. Feel free to add more reports and to add your organization to the contact info list. Contact Info Entur, Norway Leonard Ehrenfried , Germany, mail@leonard.io Changelog 2021-05-19: Initial version of the report API. Support listing all transfers as a CSV text file. 2021-07-19: Add report that exports the bicycle safety factors as CSV and an interactive HTML table view. Documentation This module mounts an endpoint for generating reports under otp/report . Available reports: /otp/report/transfers.csv /otp/report/bicycle-safety.html : Interactive viewer of the rules that determine how bicycle safety factors are calculated. /otp/report/bicycle-safety.csv : Raw CSV data for the bicycle safety report. Norwegian version German version UK version Finnish version Configuration The report API is turned off by default. To turn it on enable the ReportApi feature. // otp-config.json { \"otpFeatures\" : { \"ReportApi\" : true } }","title":"Report API"},{"location":"sandbox/ReportApi/#report-api","text":"The report API is a collection of reports generated as CSV files. The main use-case is to download data for manual analyzes and verification. The CSV files should not be used as a service by another programs, the report can be changed at any time - without any notice. Feel free to add more reports and to add your organization to the contact info list.","title":"Report API"},{"location":"sandbox/ReportApi/#contact-info","text":"Entur, Norway Leonard Ehrenfried , Germany, mail@leonard.io","title":"Contact Info"},{"location":"sandbox/ReportApi/#changelog","text":"2021-05-19: Initial version of the report API. Support listing all transfers as a CSV text file. 2021-07-19: Add report that exports the bicycle safety factors as CSV and an interactive HTML table view.","title":"Changelog"},{"location":"sandbox/ReportApi/#documentation","text":"This module mounts an endpoint for generating reports under otp/report . Available reports: /otp/report/transfers.csv /otp/report/bicycle-safety.html : Interactive viewer of the rules that determine how bicycle safety factors are calculated. /otp/report/bicycle-safety.csv : Raw CSV data for the bicycle safety report. Norwegian version German version UK version Finnish version","title":"Documentation"},{"location":"sandbox/ReportApi/#configuration","text":"The report API is turned off by default. To turn it on enable the ReportApi feature. // otp-config.json { \"otpFeatures\" : { \"ReportApi\" : true } }","title":"Configuration"},{"location":"sandbox/SiriUpdator/","text":"Siri Updator Support for consuming SIRI ET, SX and ET messages. The updator is developed to support the Norwegian SIRI profile which is a subset of the SIRI specification. Contact Info Lasse Tyrihjell, Entur, Norway Changelog Initial version of SIRI updator (October 2019) Include situations with no or no handled entity selectors with Unknown EntitySelector (December 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3780) Documentation This updator consumes SIRI Real Time Information. It is developed by entur and support the Nordic Profile for SIRI. It should be possible to develop it further to support a broader set of the SIRI specification. For more documentation goto the Entur Real-Time Data documentation and the Norwegian SIRI profile . Configuration To enable the SIRI updator you need to add it to the updators section of the router-config.json . { \"type\": \"siri-updater\", \"frequencySec\": 60, \"url\": \"https://api.updater.com/example-updater\" }","title":"SIRI Updater"},{"location":"sandbox/SiriUpdator/#siri-updator","text":"Support for consuming SIRI ET, SX and ET messages. The updator is developed to support the Norwegian SIRI profile which is a subset of the SIRI specification.","title":"Siri Updator"},{"location":"sandbox/SiriUpdator/#contact-info","text":"Lasse Tyrihjell, Entur, Norway","title":"Contact Info"},{"location":"sandbox/SiriUpdator/#changelog","text":"Initial version of SIRI updator (October 2019) Include situations with no or no handled entity selectors with Unknown EntitySelector (December 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3780)","title":"Changelog"},{"location":"sandbox/SiriUpdator/#documentation","text":"This updator consumes SIRI Real Time Information. It is developed by entur and support the Nordic Profile for SIRI. It should be possible to develop it further to support a broader set of the SIRI specification. For more documentation goto the Entur Real-Time Data documentation and the Norwegian SIRI profile .","title":"Documentation"},{"location":"sandbox/SiriUpdator/#configuration","text":"To enable the SIRI updator you need to add it to the updators section of the router-config.json . { \"type\": \"siri-updater\", \"frequencySec\": 60, \"url\": \"https://api.updater.com/example-updater\" }","title":"Configuration"},{"location":"sandbox/SmooveBikeRental/","text":"HSL Smoove Bike Rental Updater Support - OTP Sandbox Extension Contact Info Digitransit team, HSL, Helsinki, Finland Changelog Move this functonality into a sandbox Add allowOverloading through updater config to the stations and isRenting, isReturning and capacity from the data to stations (October 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3632) Documentation TODO Configuration An example updater configuration: { \"type\": \"bike-rental\", \"sourceType\": \"smoove\", \"network\": \"smoove-network-1\", \"url\": \"https://helsinki-fi.smoove.pro/api-public/stations\", \"frequencySec\": 10, \"allowOverloading\": true } network (optional) allows defining custom network id allowOverloading (optional) defines if the stations in the network allow overloading (ignoring available spaces)","title":"Smoove Bike Rental Updator Support"},{"location":"sandbox/SmooveBikeRental/#hsl-smoove-bike-rental-updater-support-otp-sandbox-extension","text":"","title":"HSL Smoove Bike Rental Updater Support - OTP Sandbox Extension"},{"location":"sandbox/SmooveBikeRental/#contact-info","text":"Digitransit team, HSL, Helsinki, Finland","title":"Contact Info"},{"location":"sandbox/SmooveBikeRental/#changelog","text":"Move this functonality into a sandbox Add allowOverloading through updater config to the stations and isRenting, isReturning and capacity from the data to stations (October 2021, https://github.com/opentripplanner/OpenTripPlanner/pull/3632)","title":"Changelog"},{"location":"sandbox/SmooveBikeRental/#documentation","text":"TODO","title":"Documentation"},{"location":"sandbox/SmooveBikeRental/#configuration","text":"An example updater configuration: { \"type\": \"bike-rental\", \"sourceType\": \"smoove\", \"network\": \"smoove-network-1\", \"url\": \"https://helsinki-fi.smoove.pro/api-public/stations\", \"frequencySec\": 10, \"allowOverloading\": true } network (optional) allows defining custom network id allowOverloading (optional) defines if the stations in the network allow overloading (ignoring available spaces)","title":"Configuration"},{"location":"sandbox/TransmodelApi/","text":"Transmodel GraphQL API Contact Info Entur, Norway Changelog Initial version of Transmodel Graph QL API (September 2019) Added support for multimodal StopPlaces (November 2019) Fix bug querying stopPlaces #3591 Fix the field bikesAllowed #3586 Add triangle factors for bicycle routing #3585 Fix correct type for BookingArrangementType#latestBookingDay Fix NPE in BookingArrangementType data fetchers #3649 Add BookingInfo to TimetabledPassingTime and EstimatedCall #3666 Use correct capitalization for GraphQL fields #3707 Allow filtering by a list of ids #3738 Don't filter out stops who don't have multimodal parents in the nearest query #3752 Restore ability to filter by private code #3764 Narrow down non-null types type #3803 Fix issue with fetching parent StopPlaces in nearest query in Transmodel API #3807 Fix invalid cast in situations resolver for line type #3810 Deduce enum for bookWhen in Transmodel API #3854 Fix coercion of default parameter for maximumDistance in nearest #3846 Expose stopPositionInPattern on EstimatedCall #3846 Allow selecting first or last quays in a ServiceJourney #3846 Documentation This is the official Entur OTP2 API. The terminology is based on the Transmodel(NeTEx) with some limitations/simplification. It provides both a routing API (trip query) and index API for transit data. Entur provide a GraphQL explorer where you may browse the GraphQL schema and try your own queries. After enabling this feature (see below), the endpoint is available at: http://localhost:8080/otp/routers/default/transmodel/index/graphql OTP2 Official GraphQL API (Not available) We plan to make a new offical OTP2 API, replacing the REST API. The plan is to base the new API on this API and the Legacy GraphQL Api . The new API will most likely have 2 \"translations\": A GTFS version and a Transmodel version, we will try to keep the semantics the same. Configuration To enable this you need to add the feature SandboxAPITransmodelApi .","title":"Transmodel(NeTEx) GraphQL API"},{"location":"sandbox/TransmodelApi/#transmodel-graphql-api","text":"","title":"Transmodel GraphQL API"},{"location":"sandbox/TransmodelApi/#contact-info","text":"Entur, Norway","title":"Contact Info"},{"location":"sandbox/TransmodelApi/#changelog","text":"Initial version of Transmodel Graph QL API (September 2019) Added support for multimodal StopPlaces (November 2019) Fix bug querying stopPlaces #3591 Fix the field bikesAllowed #3586 Add triangle factors for bicycle routing #3585 Fix correct type for BookingArrangementType#latestBookingDay Fix NPE in BookingArrangementType data fetchers #3649 Add BookingInfo to TimetabledPassingTime and EstimatedCall #3666 Use correct capitalization for GraphQL fields #3707 Allow filtering by a list of ids #3738 Don't filter out stops who don't have multimodal parents in the nearest query #3752 Restore ability to filter by private code #3764 Narrow down non-null types type #3803 Fix issue with fetching parent StopPlaces in nearest query in Transmodel API #3807 Fix invalid cast in situations resolver for line type #3810 Deduce enum for bookWhen in Transmodel API #3854 Fix coercion of default parameter for maximumDistance in nearest #3846 Expose stopPositionInPattern on EstimatedCall #3846 Allow selecting first or last quays in a ServiceJourney #3846","title":"Changelog"},{"location":"sandbox/TransmodelApi/#documentation","text":"This is the official Entur OTP2 API. The terminology is based on the Transmodel(NeTEx) with some limitations/simplification. It provides both a routing API (trip query) and index API for transit data. Entur provide a GraphQL explorer where you may browse the GraphQL schema and try your own queries. After enabling this feature (see below), the endpoint is available at: http://localhost:8080/otp/routers/default/transmodel/index/graphql","title":"Documentation"},{"location":"sandbox/TransmodelApi/#otp2-official-graphql-api-not-available","text":"We plan to make a new offical OTP2 API, replacing the REST API. The plan is to base the new API on this API and the Legacy GraphQL Api . The new API will most likely have 2 \"translations\": A GTFS version and a Transmodel version, we will try to keep the semantics the same.","title":"OTP2 Official GraphQL API (Not available)"},{"location":"sandbox/TransmodelApi/#configuration","text":"To enable this you need to add the feature SandboxAPITransmodelApi .","title":"Configuration"},{"location":"sandbox/VehicleParking/","text":"Vehicle Parking Updaters - OTP Sandbox Extension Contact Info For HSL Park and Ride updater: Digitransit team, HSL, Helsinki, Finland Changelog Create initial sandbox implementation (January 2022, https://github.com/opentripplanner/OpenTripPlanner/pull/3796) Documentation This sandbox contains vehicle parking updaters. Unlike for some other sandbox features, this is not enabled/disabled through otp-config.json but from router-config.json updaters. Currently contains the following updaters: - HSL Park and Ride (https://p.hsl.fi/docs/index.html) - ParkAPI (https://github.com/offenesdresden/ParkAPI) - KML (Keyhole Markup language) placemark parks. Use name as bike park name and point coordinates. Configuration These sandboxed vehicle parking updaters can be enabled by editing the updaters section in the router-config.json according to the following examples. All updaters have the following parameters in common: - type : this needs to be \"vehicle-parking\" - feedId : this is used as a \"prefix\" for park ids, entrance ids and sometimes also for tags. To use HSL park updater: { \"type\": \"vehicle-parking\", \"sourceType\": \"hsl-park\", \"feedId\": \"hslpark\", \"facilitiesFrequencySec\": 3600, \"facilitiesUrl\": \"https://p.hsl.fi/api/v1/facilities.json?limit=-1\", \"utilizationsFrequencySec\": 600, \"utilizationsUrl\": \"https://p.hsl.fi/api/v1/utilizations.json?limit=-1\" } - sourceType : needs to be \"hsl-park\" - facilitiesUrl : URL that contains the basic information for the parks - facilitiesFrequencySec : how often should the basic information for parks be refetched. Should be more than utilizationsFrequencySec and if it's <= 0, parks are only fetched once. Default 600 . - utilizationsUrl : URL that contains realtime updates to parks - utilizationsFrequencySec : how often should the basic information for parks be refetched. Should be less than facilitiesFrequencySec and if it's < 0, realtime information is never refetched. Default 3600 . To use KML park updater: { \"type\": \"vehicle-parking\", \"sourceType\": \"kml\", \"feedId\": \"kml\", \"frequencySec\": 600, \"url\": \"https://foo.bar\", \"namePrefix\": \"foo\", \"zip\": true } - sourceType : needs to be \"kml\" - url : URL that contains the park data in KML format - frequencySec : how often park data is refetched. Default 60 . - namePrefix : Adds this prefix to park names - zip : Tells if the data is zipped or not. To use ParkAPI updater: { \"type\": \"vehicle-parking\", \"sourceType\": \"park-api\", \"feedId\": \"parkapi\", \"frequencySec\": 600, \"url\": \"https://foo.bar\", \"headers\": {\"Cache-Control\": \"max-age=604800\"}, \"tags\": [\"source:parkapi\"] } - sourceType : needs to be \"park-api\" if car parks are fetched, \"bicycle-park-api\" if bicycle parks. - url : URL that contains the park data in KML format - frequencySec : how often park data is refetched. Default 60 . - headers : Use these headers for requests - tags : Add these tags to all parks.","title":"Vehicle Parking Updaters"},{"location":"sandbox/VehicleParking/#vehicle-parking-updaters-otp-sandbox-extension","text":"","title":"Vehicle Parking Updaters - OTP Sandbox Extension"},{"location":"sandbox/VehicleParking/#contact-info","text":"For HSL Park and Ride updater: Digitransit team, HSL, Helsinki, Finland","title":"Contact Info"},{"location":"sandbox/VehicleParking/#changelog","text":"Create initial sandbox implementation (January 2022, https://github.com/opentripplanner/OpenTripPlanner/pull/3796)","title":"Changelog"},{"location":"sandbox/VehicleParking/#documentation","text":"This sandbox contains vehicle parking updaters. Unlike for some other sandbox features, this is not enabled/disabled through otp-config.json but from router-config.json updaters. Currently contains the following updaters: - HSL Park and Ride (https://p.hsl.fi/docs/index.html) - ParkAPI (https://github.com/offenesdresden/ParkAPI) - KML (Keyhole Markup language) placemark parks. Use name as bike park name and point coordinates.","title":"Documentation"},{"location":"sandbox/VehicleParking/#configuration","text":"These sandboxed vehicle parking updaters can be enabled by editing the updaters section in the router-config.json according to the following examples. All updaters have the following parameters in common: - type : this needs to be \"vehicle-parking\" - feedId : this is used as a \"prefix\" for park ids, entrance ids and sometimes also for tags. To use HSL park updater: { \"type\": \"vehicle-parking\", \"sourceType\": \"hsl-park\", \"feedId\": \"hslpark\", \"facilitiesFrequencySec\": 3600, \"facilitiesUrl\": \"https://p.hsl.fi/api/v1/facilities.json?limit=-1\", \"utilizationsFrequencySec\": 600, \"utilizationsUrl\": \"https://p.hsl.fi/api/v1/utilizations.json?limit=-1\" } - sourceType : needs to be \"hsl-park\" - facilitiesUrl : URL that contains the basic information for the parks - facilitiesFrequencySec : how often should the basic information for parks be refetched. Should be more than utilizationsFrequencySec and if it's <= 0, parks are only fetched once. Default 600 . - utilizationsUrl : URL that contains realtime updates to parks - utilizationsFrequencySec : how often should the basic information for parks be refetched. Should be less than facilitiesFrequencySec and if it's < 0, realtime information is never refetched. Default 3600 . To use KML park updater: { \"type\": \"vehicle-parking\", \"sourceType\": \"kml\", \"feedId\": \"kml\", \"frequencySec\": 600, \"url\": \"https://foo.bar\", \"namePrefix\": \"foo\", \"zip\": true } - sourceType : needs to be \"kml\" - url : URL that contains the park data in KML format - frequencySec : how often park data is refetched. Default 60 . - namePrefix : Adds this prefix to park names - zip : Tells if the data is zipped or not. To use ParkAPI updater: { \"type\": \"vehicle-parking\", \"sourceType\": \"park-api\", \"feedId\": \"parkapi\", \"frequencySec\": 600, \"url\": \"https://foo.bar\", \"headers\": {\"Cache-Control\": \"max-age=604800\"}, \"tags\": [\"source:parkapi\"] } - sourceType : needs to be \"park-api\" if car parks are fetched, \"bicycle-park-api\" if bicycle parks. - url : URL that contains the park data in KML format - frequencySec : how often park data is refetched. Default 60 . - headers : Use these headers for requests - tags : Add these tags to all parks.","title":"Configuration"},{"location":"sandbox/VehicleRentalServiceDirectory/","text":"Vehicle Rental Service Directory API support. Contact Info Gard Mellemstrand, Entur, Norway Changelog Initial implementation of bike share updater API support Make json tag names configurable #3447 Documentation This adds support for the GBFS service directory endpoint component located at https://github.com/entur/lahmu. OTP use the service directory to lookup and connect to all GBFS endpoints registered in the directory. This simplify the management of the GBFS enpoints, since multiple services/components like OTP can connect to the directory and get the necessary configuration from it. Configuration To enable this you need to specify a url for the vehicleRentalServiceDirectory in the router-config.json","title":"Vehicle Rental Service Directory API support"},{"location":"sandbox/VehicleRentalServiceDirectory/#vehicle-rental-service-directory-api-support","text":"","title":"Vehicle Rental Service Directory API support."},{"location":"sandbox/VehicleRentalServiceDirectory/#contact-info","text":"Gard Mellemstrand, Entur, Norway","title":"Contact Info"},{"location":"sandbox/VehicleRentalServiceDirectory/#changelog","text":"Initial implementation of bike share updater API support Make json tag names configurable #3447","title":"Changelog"},{"location":"sandbox/VehicleRentalServiceDirectory/#documentation","text":"This adds support for the GBFS service directory endpoint component located at https://github.com/entur/lahmu. OTP use the service directory to lookup and connect to all GBFS endpoints registered in the directory. This simplify the management of the GBFS enpoints, since multiple services/components like OTP can connect to the directory and get the necessary configuration from it.","title":"Documentation"},{"location":"sandbox/VehicleRentalServiceDirectory/#configuration","text":"To enable this you need to specify a url for the vehicleRentalServiceDirectory in the router-config.json","title":"Configuration"},{"location":"sandbox/transferanalyzer/","text":"Direct transfer analyzer module Contact Info Gard Mellemstrand, Entur, Norway Changelog May 20th 2019 Added the direct transfer analyzer module (May 2019) Documentation Module used for analyzing the transfers between nearby stops generated by routing via OSM data. It generates lists of both unusually long and unroutable transfers. These lists can typically be used to improve the quality of OSM data for transfer purposes. See javadoc in DirectTransferAnalyzer class","title":"Direct transfer analyzer"},{"location":"sandbox/transferanalyzer/#direct-transfer-analyzer-module","text":"","title":"Direct transfer analyzer module"},{"location":"sandbox/transferanalyzer/#contact-info","text":"Gard Mellemstrand, Entur, Norway","title":"Contact Info"},{"location":"sandbox/transferanalyzer/#changelog","text":"","title":"Changelog"},{"location":"sandbox/transferanalyzer/#may-20th-2019","text":"Added the direct transfer analyzer module (May 2019)","title":"May 20th 2019"},{"location":"sandbox/transferanalyzer/#documentation","text":"Module used for analyzing the transfers between nearby stops generated by routing via OSM data. It generates lists of both unusually long and unroutable transfers. These lists can typically be used to improve the quality of OSM data for transfer purposes. See javadoc in DirectTransferAnalyzer class","title":"Documentation"}]}